{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAl2v1saXgt9"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/mnt',force_remount=True)\n",
    "nb_path = '/content/notebooks'\n",
    "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
    "sys.path.insert(0, nb_path)  # or append(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1HfIw8BXrL4"
   },
   "outputs": [],
   "source": [
    "!pip install --target=$nb_path git+https://github.com/arviz-devs/arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOrWAnlmXrC0"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --target=$nb_path pymc3>=3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTeDYhbtXq-3"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pymc3 as pm # for uncertainty quantification and model calibration\n",
    "from scipy.integrate import solve_ivp # to solve ODE system\n",
    "from scipy import optimize # to solve minimization problem from least-squares fitting\n",
    "from numba import jit # to accelerate ODE system RHS evaluations\n",
    "import theano # to control better pymc3 backend and write a wrapper\n",
    "import theano.tensor as t # for the wrapper to a custom model to pymc3\n",
    "import arviz as az\n",
    "# Plotting libs\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "import corner\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from pymc3.distributions.dist_math import normal_lcdf\n",
    "\n",
    "seed = 12345 # for the sake of reproducibility :)\n",
    "np.random.seed(seed)\n",
    "\n",
    "plt.style.use('seaborn-talk') # beautify the plots!\n",
    "\n",
    "THEANO_FLAGS='optimizer=fast_compile' # A theano trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0v25TDmXq7k"
   },
   "outputs": [],
   "source": [
    "TotalNumIter = 4000\n",
    "NumProc      = 2\n",
    "NumEqs       = 7\n",
    "NumParams    = 10\n",
    "\n",
    "# pesos para la cuadratura trapezoidal\n",
    "weigths = np.ones(11)\n",
    "weigths[0] = 0.5\n",
    "weigths[-1] = 0.5\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"/content/mnt/My Drive/Colab Notebooks/covidMexico.csv\")\n",
    "yobs=data[[\"Suspects\",\"New cases (HUC)\",\"Deaths (HUC)\"]]\n",
    "y_obs_temp=yobs.to_numpy()\n",
    "\n",
    "y_obs=y_obs_temp.astype(float)\n",
    "   \n",
    "muM    = 0.0171361/365\n",
    "nu    = 0.0058/365\n",
    "#   tau_A = 1/14 # period of being active: 14 days\n",
    "k_conts     = 500/365 # number of contacts per year\n",
    "tau_Q =1/14  #(1/tau_Q := period of quarantined) \n",
    "rho  =1/15    \n",
    "N     = 128932753\n",
    "\n",
    "# Initial conditions\n",
    "\n",
    "R0 = 0\n",
    "P0 = 0\n",
    "\n",
    "\n",
    "#save_results_to = 'MODEL_PRED/'\n",
    "  \n",
    "# # HUC\n",
    "Suspect = data[\"Suspects\"]\n",
    "Sick = data[\"New cases (HUC)\"]\n",
    "Deaths  = data[\"Deaths (HUC)\"] \n",
    "\n",
    "# datahub\n",
    "# Sick = data[\"New cases (datahub)\"]\n",
    "# Deaths  = data[\"Deaths (datahub)\"] \n",
    "\n",
    "## OWD\n",
    "#Sick = data[\"New cases (OWD)\"]\n",
    "#Deaths  = data[\"Deaths (OWD)\"] + data[\"Recovered (noData)\"]\n",
    "\n",
    "# # DGE\n",
    "# Sick = data[\"New cases (DGE)\"]\n",
    "# Deaths  = data[\"Deaths (DGE)\"] \n",
    "\n",
    "#ttime = np.linspace(0.0,float(len(Sick)),len(Sick))\n",
    "#ttime = list(float(i) for i in range(len(Sick)))\n",
    "ttime = np.array([float(i)  for i in range( len(Sick) )])\n",
    "t_pred = np.array([float(i) for i in range( 120 )])\n",
    "\n",
    "fig0= plt.figure()\n",
    "plt.plot(ttime, Suspect,'m.', ttime, Sick,'r.',ttime, Deaths,'g.')\n",
    "#plt.show()\n",
    "plt.savefig( 'Suspects_NewCases_Deaths.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3u6bryA7Xq5E"
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def modelo(t,y,p):\n",
    "    \n",
    "  \"\"\"\n",
    "  model:SsEIQRP\n",
    "  \n",
    "  Parameters:\n",
    "  p[0]: beta factor b\n",
    "  p[1]: qu contact tracing rate\n",
    "  p[2]: delta Detection and isolation rate\n",
    "  p[3]: alpha transmision rate from E to I\n",
    "  p[4]: gamma recovery rate\n",
    "  p[5]: sigma death rate by disease \n",
    "  \n",
    "  State variables: SsEIQRP\n",
    "  \n",
    "  x[0]: Susceptibles\n",
    "  x[1]: suspects\n",
    "  x[2]: Exposeds\n",
    "  x[3]: Infecteds\n",
    "  x[4]: Quarainteds\n",
    "  x[5]: Recovereds\n",
    "  x[6]: Deaths\n",
    "  \"\"\"\n",
    "  \n",
    "  dS = muM*N -(k_conts*p[0]*y[3] + p[1]*k_conts*(1- p[0])*y[3]   )*y[0]/N \\\n",
    "         + tau_Q*y[1] - nu*y[0]\n",
    "  ds =  p[1]*k_conts*(1- p[0])*y[3] *y[0]/N - (tau_Q + nu)*y[1]\n",
    "  dE =  k_conts*p[0]*(1- p[1])*y[3] *y[0]/N - (p[3] + nu)*y[2] \n",
    "  dI =  p[3]*y[2] - ( p[5] + p[2] + nu  )* y[3]\n",
    "  dQ =  p[1]* k_conts* p[0]*y[3] *y[0]/N + p[2]*y[3] - (tau_Q + p[5]  )*y[4]\n",
    "  dR = p[4]*y[3] + tau_Q*y[4]\n",
    "  dP = p[5]*y[4]\n",
    "  \n",
    "\n",
    "  return dS,ds,dE,dI,dQ,dR,dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qusS9MF1Xs_j"
   },
   "outputs": [],
   "source": [
    "def seir_ode_solver(y0, t_span, t_eval, p):\n",
    "\n",
    "    solution_ODE = solve_ivp(\n",
    "        fun=lambda t, y: modelo(t, y, p), \n",
    "        t_span=t_span, \n",
    "        y0=y0,\n",
    "        t_eval=t_eval,\n",
    "        method='LSODA'\n",
    "    )\n",
    "    \n",
    "    return solution_ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iScw7LDDXs63"
   },
   "outputs": [],
   "source": [
    "@theano.compile.ops.as_op(itypes=[t.dvector, t.dmatrix,t.dvector], otypes=[t.dmatrix])\n",
    "def seir_ode_solver_wrapper(time_exp, Obs_s,p):\n",
    "\n",
    "    time_span = (time_exp.min(), time_exp.max())\n",
    "    initial_conditions=x0 = np.array([N-(p[6] + p[7] + p[8] + p[9] + R0 + P0),p[6],p[7]\n",
    "                   ,p[8],p[9],R0,P0]) # SsEIQRP                             \n",
    "                             \n",
    "    y_model = seir_ode_solver(initial_conditions, time_span, time_exp, p)\n",
    "    simulated_time = y_model.t\n",
    "    simulated_ode_solution = y_model.y\n",
    "    _, x_s, _, _, x_Q, _, x_P = simulated_ode_solution\n",
    "\n",
    "    return np.array([x_s,x_Q,x_P]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2S77TUqXs4C"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_CT:\n",
    "\n",
    "#    Prior distributions for the model's parameters\n",
    "    # Beta  =pm.Bound(pm.Gamma, lower=0., upper=6.)('Beta', alpha=2.5, beta=1.0)\n",
    "    # qu    =pm.Bound(pm.Gamma, lower=0., upper=4.)('qu',   alpha=2.5, beta=1.0)\n",
    "    # delta =pm.Bound(pm.Gamma, lower=0., upper=5.)('delta', alpha=2.5, beta=1.0)\n",
    "    # alfa  =pm.Bound(pm.Gamma, lower=0., upper=5.)('alfa', alpha=3.0, beta=1.0)\n",
    "    # gama  =pm.Bound(pm.Gamma, lower=0., upper=5.)('gama', alpha=2.5, beta=1.0)\n",
    "    # sigm = pm.Bound(pm.Gamma, lower=0., upper=3.)('sigm', alpha=2.5, beta=1.0)\n",
    "    # s0    =pm.Bound(pm.Gamma, lower=0., upper=1e3)('s0', alpha=10, beta=1.0)\n",
    "    # E0    =pm.Bound(pm.Gamma, lower=0., upper=1e4)('E0', alpha=10, beta=1.0)\n",
    "    # I0    =pm.Bound(pm.Gamma, lower=0., upper=1e4)('I0', alpha=10, beta=1.0)\n",
    "    # Q0    =pm.Bound(pm.Gamma, lower=0., upper=1e3)('Q0', alpha=10, beta=1.0)\n",
    "\n",
    "    Beta   = pm.Lognormal('Beta', mu=0, sigma=1.5)\n",
    "#    Beta   = pm.Uniform('Beta', lower=0, upper=2.0)\n",
    "    qu     = pm.Uniform('qu'  , lower=0, upper=2.0)\n",
    "    delta  = pm.Uniform('delta'  , lower=0, upper=2.0)\n",
    "    alfa   = pm.Uniform('alfa'  , lower=0, upper=2.0)\n",
    "    gama   = pm.Uniform('gama'  , lower=0, upper=2.0)\n",
    "    sigm   = pm.Uniform('sigm'  , lower=0, upper=2.0)\n",
    "    s0     = pm.Uniform('s0'  , lower=0, upper=1e3)\n",
    "    E0     = pm.Uniform('E0'  , lower=0, upper=1e4)\n",
    "    I0     = pm.Uniform('I0'  , lower=0, upper=1e4)\n",
    "    Q0     = pm.Uniform('Q0'  , lower=0, upper=1e3)\n",
    "\n",
    "    sigmaH = pm.HalfCauchy('sigmaH',1)\n",
    "#    print(type(Beta))\n",
    "\n",
    "#    p=np.array([Beta,qu,delta,alfa,gama,sigm,s0,E0,I0,Q0]).T\n",
    "#    p=[Beta,qu,delta,alfa,gama,sigm,s0,E0,I0,Q0]\n",
    "#    p =t.stack([Beta,qu,delta,alfa,gama,sigm,s0,E0,I0,Q0])\n",
    "#    p = pm.math.stack(([[Beta],[qu],[delta],[alfa],[gama],[sigm],[s0],[E0],[I0],[Q0]]))\n",
    "    p = t.transpose(pm.math.stack((Beta,qu,delta,alfa,gama,sigm,s0,E0,I0,Q0)))\n",
    "\n",
    "    # Defining the deterministic formulation of the problem\n",
    "    fitting_model = pm.Deterministic('modelo', seir_ode_solver_wrapper(\n",
    "        theano.shared(ttime),\n",
    "        theano.shared(y_obs), \n",
    "        p\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    Y = pm.Normal('Y' , mu=fitting_model, sigma=sigmaH, observed=y_obs)\n",
    "#    Y = pm.Poisson('Y', mu=fitting_model,  observed=y_obs)\n",
    "#    Y = pm.NegativeBinomial('Y',mu=fitting_model, alpha=sigmaH,observed=yobs)\n",
    "\n",
    "    # The Monte Carlo procedure driver\n",
    "    step = pm.step_methods.Metropolis()\n",
    "#    seir_trace = pm.sample(2000, chains=4, cores=2, step=step)\n",
    "\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    trace = pm.sample(TotalNumIter,tune=1000,init='adapt_diag', cores=NumProc,step=step)\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "    data = az.from_pymc3(trace=trace, prior = prior, posterior_predictive = posterior_predictive)\n",
    "varnames = [\"Beta\", \"qu\",\"delta\",\"alfa\",\"gama\",\"sigm\",\"s0\",\"E0\",\"I0\",\"Q0\",\"sigmaH\"]\n",
    "pm.summary(trace, var_names=varnames,hdi_prob=0.95)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPgShrJ/AVdjadbsabtUiNp",
   "collapsed_sections": [],
   "name": "CT_Model.ipynb",
   "provenance": [
    {
     "file_id": "1DLyEPUlLwx4q3BNtQ0peFGnxbpG4qEqw",
     "timestamp": 1595351837901
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
