{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DDX6Yq1KkbCT",
    "outputId": "38bc8d59-0fbb-4763-9213-d1201a053a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHqFePPnjiO5"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bbc59c89810f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mheaviside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Generate random name in order to avoid conflicts with inbuilt names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrnd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HeavisideGrad-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%0x'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrandbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Alireza Yazdani\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "def heaviside(x: tf.Tensor, g: tf.Graph = tf.get_default_graph()):\n",
    "    # Generate random name in order to avoid conflicts with inbuilt names\n",
    "    rnd_name = 'HeavisideGrad-' + '%0x' % random.getrandbits(30 * 4)\n",
    "    \n",
    "    @tf.RegisterGradient(rnd_name)\n",
    "    def _heaviside_grad(unused_op: tf.Operation, grad: tf.Tensor):\n",
    "        return tf.maximum(0.0, 1.0 - tf.abs(unused_op.inputs[0])) * grad\n",
    "    \n",
    "    custom_grads = {\n",
    "        'Identity': rnd_name\n",
    "    }\n",
    "    \n",
    "    with g.gradient_override_map(custom_grads):\n",
    "        i = tf.identity(x, name='identity_' + str(uuid.uuid1()))\n",
    "        ge = tf.greater_equal(x, 0, name='ge_' + str(uuid.uuid1()))\n",
    "        # tf.stop_gradient is needed to exclude tf.to_float from derivative\n",
    "        step_func = i + tf.stop_gradient(tf.to_float(ge) - i)\n",
    "        return step_func\n",
    "\n",
    "def tf_session():\n",
    "    # tf session\n",
    "    config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                            log_device_placement=True)\n",
    "    config.gpu_options.force_gpu_compatible = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    # init\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    return sess\n",
    "\n",
    "def relative_error(exact, pred):\n",
    "    if type(pred) is np.ndarray:\n",
    "        return np.sqrt(np.mean(np.square(pred - exact))/np.mean(np.square(exact - np.mean(exact))))\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(pred - exact))/tf.reduce_mean(tf.square(exact - tf.reduce_mean(exact))))\n",
    "\n",
    "def mean_squared_error(exact, pred):\n",
    "    if type(pred) is np.ndarray:\n",
    "        return np.mean(np.square(pred - exact))\n",
    "    return tf.reduce_mean(tf.square(pred - exact))\n",
    "\n",
    "def fwd_gradients(Y, x):\n",
    "    dummy = tf.ones_like(Y)\n",
    "    G = tf.gradients(Y, x, grad_ys=dummy, colocate_gradients_with_ops=True)[0]\n",
    "    Y_x = tf.gradients(G, dummy, colocate_gradients_with_ops=True)[0]\n",
    "    return Y_x\n",
    "\n",
    "class neural_net(object):\n",
    "    def __init__(self, layers):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.num_layers = len(self.layers)\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.gammas = []\n",
    "        \n",
    "        for l in range(0, self.num_layers-1):\n",
    "            in_dim = self.layers[l]\n",
    "            out_dim = self.layers[l+1]\n",
    "            W = self.xavier_init(size=[in_dim, out_dim])\n",
    "            b = np.zeros([1, out_dim])\n",
    "            g = np.ones([1, out_dim])\n",
    "            # tensorflow variables\n",
    "            self.weights.append(tf.Variable(W, dtype=tf.float32, trainable=True))\n",
    "            self.biases.append(tf.Variable(b, dtype=tf.float32, trainable=True))\n",
    "            self.gammas.append(tf.Variable(g, dtype=tf.float32, trainable=True))\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.random.truncated_normal([in_dim, out_dim], stddev=xavier_stddev)\n",
    "            \n",
    "    def __call__(self, *inputs):\n",
    "                \n",
    "        H = tf.concat(inputs, 1)\n",
    "    \n",
    "        for l in range(0, self.num_layers-1):\n",
    "            W = self.weights[l]\n",
    "            b = self.biases[l]\n",
    "            g = self.gammas[l]\n",
    "            # weight normalization\n",
    "            V = W / tf.norm(W, axis = 0, keepdims=True)\n",
    "            # matrix multiplication\n",
    "            H = tf.matmul(H, V)\n",
    "            # add bias\n",
    "            H = g*H + b\n",
    "            # activation\n",
    "            if l < self.num_layers-2:\n",
    "                H = H*tf.sigmoid(H)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqTCDe1Zj18w"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct  9 20:11:57 2017\n",
    "\n",
    "@author: mraissi\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "#mpl.use('pgf')\n",
    "\n",
    "def figsize(scale, nplots = 1):\n",
    "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
    "    fig_size = [fig_width,fig_height]\n",
    "    return fig_size\n",
    "\n",
    "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": False,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 10,\n",
    "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    }\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I make my own newfig and savefig functions\n",
    "def newfig(width, nplots = 1):\n",
    "    fig = plt.figure(figsize=figsize(width, nplots))\n",
    "    ax = fig.add_subplot(111)\n",
    "    return fig, ax\n",
    "\n",
    "def savefig(filename, crop = True):\n",
    "    if crop == True:\n",
    "#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "    else:\n",
    "#        plt.savefig('{}.pgf'.format(filename))\n",
    "        plt.savefig('{}.pdf'.format(filename))\n",
    "        plt.savefig('{}.eps'.format(filename))\n",
    "\n",
    "## Simple plot\n",
    "#fig, ax  = newfig(1.0)\n",
    "#\n",
    "#def ema(y, a):\n",
    "#    s = []\n",
    "#    s.append(y[0])\n",
    "#    for t in range(1, len(y)):\n",
    "#        s.append(a * y[t] + (1-a) * s[t-1])\n",
    "#    return np.array(s)\n",
    "#    \n",
    "#y = [0]*200\n",
    "#y.extend([20]*(1000-len(y)))\n",
    "#s = ema(y, 0.01)\n",
    "#\n",
    "#ax.plot(s)\n",
    "#ax.set_xlabel('X Label')\n",
    "#ax.set_ylabel('EMA')\n",
    "#\n",
    "#savefig('ema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L3VJEtIWkGRV",
    "outputId": "8504aab1-befb-4db5-8e9e-216ae4058e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "Epoch: 0, It: 0, Loss Data: 4.112e+00, Loss Eqns: 2.864e+02, Loss Aux: 4.259e+00, Time: 4.938, Learning Rate: 1.0e-03\n",
      "Epoch: 1, It: 0, Loss Data: 4.002e+00, Loss Eqns: 2.598e+02, Loss Aux: 3.948e+00, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2, It: 0, Loss Data: 3.798e+00, Loss Eqns: 2.263e+02, Loss Aux: 4.016e+00, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3, It: 0, Loss Data: 3.610e+00, Loss Eqns: 2.350e+02, Loss Aux: 7.218e+00, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4, It: 0, Loss Data: 3.368e+00, Loss Eqns: 2.104e+02, Loss Aux: 5.068e+00, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5, It: 0, Loss Data: 3.244e+00, Loss Eqns: 2.010e+02, Loss Aux: 3.373e+00, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6, It: 0, Loss Data: 3.028e+00, Loss Eqns: 2.004e+02, Loss Aux: 2.605e+00, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7, It: 0, Loss Data: 3.065e+00, Loss Eqns: 1.967e+02, Loss Aux: 2.252e+00, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8, It: 0, Loss Data: 2.679e+00, Loss Eqns: 1.876e+02, Loss Aux: 2.119e+00, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 9, It: 0, Loss Data: 2.765e+00, Loss Eqns: 1.733e+02, Loss Aux: 2.314e+00, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10, It: 0, Loss Data: 2.549e+00, Loss Eqns: 1.664e+02, Loss Aux: 2.718e+00, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11, It: 0, Loss Data: 2.610e+00, Loss Eqns: 1.482e+02, Loss Aux: 2.766e+00, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12, It: 0, Loss Data: 2.393e+00, Loss Eqns: 1.282e+02, Loss Aux: 2.477e+00, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13, It: 0, Loss Data: 2.276e+00, Loss Eqns: 1.170e+02, Loss Aux: 2.236e+00, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14, It: 0, Loss Data: 2.188e+00, Loss Eqns: 1.023e+02, Loss Aux: 2.170e+00, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15, It: 0, Loss Data: 2.025e+00, Loss Eqns: 8.638e+01, Loss Aux: 2.221e+00, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16, It: 0, Loss Data: 2.037e+00, Loss Eqns: 6.754e+01, Loss Aux: 2.279e+00, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17, It: 0, Loss Data: 1.677e+00, Loss Eqns: 4.726e+01, Loss Aux: 2.146e+00, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18, It: 0, Loss Data: 1.637e+00, Loss Eqns: 3.269e+01, Loss Aux: 1.882e+00, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19, It: 0, Loss Data: 1.581e+00, Loss Eqns: 4.272e+01, Loss Aux: 2.312e+00, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 20, It: 0, Loss Data: 1.437e+00, Loss Eqns: 3.611e+01, Loss Aux: 1.710e+00, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 21, It: 0, Loss Data: 1.328e+00, Loss Eqns: 3.210e+01, Loss Aux: 1.448e+00, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 22, It: 0, Loss Data: 1.325e+00, Loss Eqns: 2.618e+01, Loss Aux: 1.335e+00, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 23, It: 0, Loss Data: 1.317e+00, Loss Eqns: 2.999e+01, Loss Aux: 1.359e+00, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 24, It: 0, Loss Data: 1.355e+00, Loss Eqns: 3.068e+01, Loss Aux: 1.162e+00, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 25, It: 0, Loss Data: 1.358e+00, Loss Eqns: 2.597e+01, Loss Aux: 1.038e+00, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 26, It: 0, Loss Data: 1.260e+00, Loss Eqns: 2.061e+01, Loss Aux: 1.129e+00, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 27, It: 0, Loss Data: 1.130e+00, Loss Eqns: 1.724e+01, Loss Aux: 1.201e+00, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 28, It: 0, Loss Data: 1.133e+00, Loss Eqns: 1.721e+01, Loss Aux: 1.145e+00, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 29, It: 0, Loss Data: 1.182e+00, Loss Eqns: 1.965e+01, Loss Aux: 1.084e+00, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 30, It: 0, Loss Data: 1.128e+00, Loss Eqns: 1.861e+01, Loss Aux: 1.075e+00, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 31, It: 0, Loss Data: 1.204e+00, Loss Eqns: 1.518e+01, Loss Aux: 1.104e+00, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 32, It: 0, Loss Data: 1.173e+00, Loss Eqns: 1.583e+01, Loss Aux: 1.161e+00, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 33, It: 0, Loss Data: 1.176e+00, Loss Eqns: 1.535e+01, Loss Aux: 1.230e+00, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 34, It: 0, Loss Data: 1.175e+00, Loss Eqns: 1.482e+01, Loss Aux: 1.286e+00, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 35, It: 0, Loss Data: 1.185e+00, Loss Eqns: 1.460e+01, Loss Aux: 1.280e+00, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 36, It: 0, Loss Data: 1.064e+00, Loss Eqns: 1.501e+01, Loss Aux: 1.198e+00, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 37, It: 0, Loss Data: 1.122e+00, Loss Eqns: 1.523e+01, Loss Aux: 1.056e+00, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 38, It: 0, Loss Data: 1.119e+00, Loss Eqns: 1.488e+01, Loss Aux: 9.078e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 39, It: 0, Loss Data: 1.042e+00, Loss Eqns: 1.430e+01, Loss Aux: 7.988e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 40, It: 0, Loss Data: 1.170e+00, Loss Eqns: 1.494e+01, Loss Aux: 7.429e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 41, It: 0, Loss Data: 1.059e+00, Loss Eqns: 1.469e+01, Loss Aux: 7.443e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 42, It: 0, Loss Data: 1.099e+00, Loss Eqns: 1.269e+01, Loss Aux: 7.911e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 43, It: 0, Loss Data: 1.045e+00, Loss Eqns: 1.331e+01, Loss Aux: 8.508e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 44, It: 0, Loss Data: 9.771e-01, Loss Eqns: 1.262e+01, Loss Aux: 9.037e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 45, It: 0, Loss Data: 1.061e+00, Loss Eqns: 1.187e+01, Loss Aux: 8.898e-01, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 46, It: 0, Loss Data: 1.051e+00, Loss Eqns: 1.298e+01, Loss Aux: 8.511e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 47, It: 0, Loss Data: 1.023e+00, Loss Eqns: 1.122e+01, Loss Aux: 8.290e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 48, It: 0, Loss Data: 1.096e+00, Loss Eqns: 1.074e+01, Loss Aux: 8.263e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 49, It: 0, Loss Data: 1.050e+00, Loss Eqns: 1.132e+01, Loss Aux: 8.378e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 50, It: 0, Loss Data: 1.047e+00, Loss Eqns: 1.126e+01, Loss Aux: 8.643e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 51, It: 0, Loss Data: 1.150e+00, Loss Eqns: 1.106e+01, Loss Aux: 8.942e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 52, It: 0, Loss Data: 1.073e+00, Loss Eqns: 1.009e+01, Loss Aux: 9.005e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 53, It: 0, Loss Data: 1.176e+00, Loss Eqns: 1.085e+01, Loss Aux: 8.600e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 54, It: 0, Loss Data: 1.026e+00, Loss Eqns: 9.934e+00, Loss Aux: 8.047e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 55, It: 0, Loss Data: 1.053e+00, Loss Eqns: 9.416e+00, Loss Aux: 7.752e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 56, It: 0, Loss Data: 1.024e+00, Loss Eqns: 1.064e+01, Loss Aux: 7.877e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 57, It: 0, Loss Data: 1.142e+00, Loss Eqns: 9.053e+00, Loss Aux: 8.350e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 58, It: 0, Loss Data: 1.093e+00, Loss Eqns: 8.790e+00, Loss Aux: 8.875e-01, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 59, It: 0, Loss Data: 1.001e+00, Loss Eqns: 9.668e+00, Loss Aux: 9.173e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 60, It: 0, Loss Data: 9.803e-01, Loss Eqns: 9.696e+00, Loss Aux: 9.049e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 61, It: 0, Loss Data: 1.120e+00, Loss Eqns: 1.069e+01, Loss Aux: 8.620e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 62, It: 0, Loss Data: 1.055e+00, Loss Eqns: 9.471e+00, Loss Aux: 8.044e-01, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 63, It: 0, Loss Data: 1.056e+00, Loss Eqns: 9.056e+00, Loss Aux: 7.567e-01, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 64, It: 0, Loss Data: 1.094e+00, Loss Eqns: 1.041e+01, Loss Aux: 7.296e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 65, It: 0, Loss Data: 1.100e+00, Loss Eqns: 9.310e+00, Loss Aux: 7.297e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 66, It: 0, Loss Data: 1.032e+00, Loss Eqns: 9.118e+00, Loss Aux: 7.444e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 67, It: 0, Loss Data: 1.036e+00, Loss Eqns: 9.474e+00, Loss Aux: 7.528e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 68, It: 0, Loss Data: 1.057e+00, Loss Eqns: 9.917e+00, Loss Aux: 7.484e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 69, It: 0, Loss Data: 1.029e+00, Loss Eqns: 8.379e+00, Loss Aux: 7.272e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 70, It: 0, Loss Data: 1.030e+00, Loss Eqns: 8.451e+00, Loss Aux: 6.958e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 71, It: 0, Loss Data: 1.110e+00, Loss Eqns: 7.868e+00, Loss Aux: 6.614e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 72, It: 0, Loss Data: 1.045e+00, Loss Eqns: 9.481e+00, Loss Aux: 6.454e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 73, It: 0, Loss Data: 9.541e-01, Loss Eqns: 8.563e+00, Loss Aux: 6.586e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 74, It: 0, Loss Data: 1.006e+00, Loss Eqns: 8.161e+00, Loss Aux: 6.885e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 75, It: 0, Loss Data: 1.033e+00, Loss Eqns: 7.553e+00, Loss Aux: 7.099e-01, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 76, It: 0, Loss Data: 9.408e-01, Loss Eqns: 7.519e+00, Loss Aux: 7.090e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 77, It: 0, Loss Data: 1.022e+00, Loss Eqns: 8.245e+00, Loss Aux: 6.788e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 78, It: 0, Loss Data: 1.123e+00, Loss Eqns: 7.832e+00, Loss Aux: 6.337e-01, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 79, It: 0, Loss Data: 1.048e+00, Loss Eqns: 8.490e+00, Loss Aux: 6.121e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 80, It: 0, Loss Data: 1.067e+00, Loss Eqns: 7.881e+00, Loss Aux: 6.285e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 81, It: 0, Loss Data: 8.832e-01, Loss Eqns: 8.544e+00, Loss Aux: 6.839e-01, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 82, It: 0, Loss Data: 1.007e+00, Loss Eqns: 7.475e+00, Loss Aux: 6.972e-01, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 83, It: 0, Loss Data: 1.033e+00, Loss Eqns: 8.013e+00, Loss Aux: 6.477e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 84, It: 0, Loss Data: 1.063e+00, Loss Eqns: 8.000e+00, Loss Aux: 5.977e-01, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 85, It: 0, Loss Data: 1.011e+00, Loss Eqns: 7.392e+00, Loss Aux: 5.135e-01, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 86, It: 0, Loss Data: 1.062e+00, Loss Eqns: 7.732e+00, Loss Aux: 4.896e-01, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 87, It: 0, Loss Data: 1.055e+00, Loss Eqns: 6.457e+00, Loss Aux: 5.143e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 88, It: 0, Loss Data: 1.041e+00, Loss Eqns: 7.320e+00, Loss Aux: 5.620e-01, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 89, It: 0, Loss Data: 1.013e+00, Loss Eqns: 7.786e+00, Loss Aux: 5.456e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 90, It: 0, Loss Data: 1.022e+00, Loss Eqns: 6.750e+00, Loss Aux: 4.874e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 91, It: 0, Loss Data: 1.082e+00, Loss Eqns: 7.442e+00, Loss Aux: 4.595e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 92, It: 0, Loss Data: 9.887e-01, Loss Eqns: 6.608e+00, Loss Aux: 4.353e-01, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 93, It: 0, Loss Data: 1.082e+00, Loss Eqns: 6.584e+00, Loss Aux: 4.851e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 94, It: 0, Loss Data: 1.032e+00, Loss Eqns: 7.139e+00, Loss Aux: 5.324e-01, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 95, It: 0, Loss Data: 9.596e-01, Loss Eqns: 7.499e+00, Loss Aux: 5.167e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 96, It: 0, Loss Data: 9.269e-01, Loss Eqns: 7.481e+00, Loss Aux: 4.910e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 97, It: 0, Loss Data: 1.035e+00, Loss Eqns: 7.367e+00, Loss Aux: 4.884e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 98, It: 0, Loss Data: 9.910e-01, Loss Eqns: 6.268e+00, Loss Aux: 4.980e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 99, It: 0, Loss Data: 1.092e+00, Loss Eqns: 6.868e+00, Loss Aux: 4.851e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 100, It: 0, Loss Data: 1.022e+00, Loss Eqns: 7.454e+00, Loss Aux: 4.617e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 101, It: 0, Loss Data: 1.005e+00, Loss Eqns: 7.639e+00, Loss Aux: 4.434e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 102, It: 0, Loss Data: 1.068e+00, Loss Eqns: 6.302e+00, Loss Aux: 4.309e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 103, It: 0, Loss Data: 1.139e+00, Loss Eqns: 7.124e+00, Loss Aux: 3.858e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 104, It: 0, Loss Data: 1.049e+00, Loss Eqns: 6.580e+00, Loss Aux: 3.783e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 105, It: 0, Loss Data: 9.865e-01, Loss Eqns: 5.798e+00, Loss Aux: 4.335e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 106, It: 0, Loss Data: 1.037e+00, Loss Eqns: 6.634e+00, Loss Aux: 4.949e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 107, It: 0, Loss Data: 1.042e+00, Loss Eqns: 5.871e+00, Loss Aux: 4.758e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 108, It: 0, Loss Data: 9.954e-01, Loss Eqns: 6.962e+00, Loss Aux: 3.976e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 109, It: 0, Loss Data: 1.071e+00, Loss Eqns: 6.087e+00, Loss Aux: 3.134e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 110, It: 0, Loss Data: 1.090e+00, Loss Eqns: 5.930e+00, Loss Aux: 2.853e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 111, It: 0, Loss Data: 1.028e+00, Loss Eqns: 6.070e+00, Loss Aux: 3.393e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 112, It: 0, Loss Data: 9.884e-01, Loss Eqns: 6.675e+00, Loss Aux: 3.831e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 113, It: 0, Loss Data: 1.027e+00, Loss Eqns: 5.408e+00, Loss Aux: 3.768e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 114, It: 0, Loss Data: 1.144e+00, Loss Eqns: 6.374e+00, Loss Aux: 3.752e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 115, It: 0, Loss Data: 1.052e+00, Loss Eqns: 6.134e+00, Loss Aux: 4.076e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 116, It: 0, Loss Data: 9.886e-01, Loss Eqns: 5.778e+00, Loss Aux: 4.419e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 117, It: 0, Loss Data: 1.055e+00, Loss Eqns: 5.305e+00, Loss Aux: 3.977e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 118, It: 0, Loss Data: 1.077e+00, Loss Eqns: 6.316e+00, Loss Aux: 3.590e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 119, It: 0, Loss Data: 9.795e-01, Loss Eqns: 5.992e+00, Loss Aux: 3.556e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 120, It: 0, Loss Data: 9.592e-01, Loss Eqns: 5.494e+00, Loss Aux: 3.744e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 121, It: 0, Loss Data: 1.067e+00, Loss Eqns: 6.154e+00, Loss Aux: 3.162e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 122, It: 0, Loss Data: 1.008e+00, Loss Eqns: 5.473e+00, Loss Aux: 2.988e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 123, It: 0, Loss Data: 1.000e+00, Loss Eqns: 5.402e+00, Loss Aux: 3.128e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 124, It: 0, Loss Data: 9.293e-01, Loss Eqns: 5.322e+00, Loss Aux: 3.091e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 125, It: 0, Loss Data: 1.054e+00, Loss Eqns: 5.977e+00, Loss Aux: 3.172e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 126, It: 0, Loss Data: 9.273e-01, Loss Eqns: 5.337e+00, Loss Aux: 3.356e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 127, It: 0, Loss Data: 9.621e-01, Loss Eqns: 5.599e+00, Loss Aux: 3.054e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 128, It: 0, Loss Data: 1.067e+00, Loss Eqns: 5.497e+00, Loss Aux: 2.331e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 129, It: 0, Loss Data: 9.847e-01, Loss Eqns: 6.436e+00, Loss Aux: 2.322e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 130, It: 0, Loss Data: 9.996e-01, Loss Eqns: 5.005e+00, Loss Aux: 3.204e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 131, It: 0, Loss Data: 1.073e+00, Loss Eqns: 6.121e+00, Loss Aux: 4.251e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 132, It: 0, Loss Data: 9.754e-01, Loss Eqns: 5.716e+00, Loss Aux: 4.467e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 133, It: 0, Loss Data: 9.525e-01, Loss Eqns: 5.375e+00, Loss Aux: 3.997e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 134, It: 0, Loss Data: 9.126e-01, Loss Eqns: 5.102e+00, Loss Aux: 2.975e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 135, It: 0, Loss Data: 9.406e-01, Loss Eqns: 5.660e+00, Loss Aux: 2.189e-01, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 136, It: 0, Loss Data: 9.431e-01, Loss Eqns: 6.160e+00, Loss Aux: 2.228e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 137, It: 0, Loss Data: 1.025e+00, Loss Eqns: 4.926e+00, Loss Aux: 2.559e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 138, It: 0, Loss Data: 1.022e+00, Loss Eqns: 5.511e+00, Loss Aux: 3.048e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 139, It: 0, Loss Data: 9.901e-01, Loss Eqns: 4.631e+00, Loss Aux: 4.902e-01, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 140, It: 0, Loss Data: 1.023e+00, Loss Eqns: 5.275e+00, Loss Aux: 4.189e-01, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 141, It: 0, Loss Data: 1.020e+00, Loss Eqns: 5.613e+00, Loss Aux: 3.026e-01, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 142, It: 0, Loss Data: 1.011e+00, Loss Eqns: 5.638e+00, Loss Aux: 3.209e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 143, It: 0, Loss Data: 1.042e+00, Loss Eqns: 5.192e+00, Loss Aux: 2.369e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 144, It: 0, Loss Data: 9.989e-01, Loss Eqns: 6.422e+00, Loss Aux: 2.298e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 145, It: 0, Loss Data: 1.080e+00, Loss Eqns: 7.035e+00, Loss Aux: 4.057e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 146, It: 0, Loss Data: 1.004e+00, Loss Eqns: 4.793e+00, Loss Aux: 3.470e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 147, It: 0, Loss Data: 1.059e+00, Loss Eqns: 9.529e+00, Loss Aux: 3.167e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 148, It: 0, Loss Data: 1.023e+00, Loss Eqns: 7.522e+00, Loss Aux: 6.440e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 149, It: 0, Loss Data: 1.084e+00, Loss Eqns: 6.996e+00, Loss Aux: 3.483e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 150, It: 0, Loss Data: 1.038e+00, Loss Eqns: 7.195e+00, Loss Aux: 2.290e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 151, It: 0, Loss Data: 9.563e-01, Loss Eqns: 5.631e+00, Loss Aux: 3.361e-01, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 152, It: 0, Loss Data: 9.782e-01, Loss Eqns: 7.193e+00, Loss Aux: 5.143e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 153, It: 0, Loss Data: 9.605e-01, Loss Eqns: 5.407e+00, Loss Aux: 1.976e-01, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 154, It: 0, Loss Data: 9.086e-01, Loss Eqns: 6.712e+00, Loss Aux: 1.997e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 155, It: 0, Loss Data: 1.043e+00, Loss Eqns: 5.278e+00, Loss Aux: 4.196e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 156, It: 0, Loss Data: 9.373e-01, Loss Eqns: 5.530e+00, Loss Aux: 7.421e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 157, It: 0, Loss Data: 9.983e-01, Loss Eqns: 4.370e+00, Loss Aux: 2.967e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 158, It: 0, Loss Data: 1.013e+00, Loss Eqns: 6.373e+00, Loss Aux: 1.613e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 159, It: 0, Loss Data: 9.840e-01, Loss Eqns: 7.149e+00, Loss Aux: 2.026e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 160, It: 0, Loss Data: 1.077e+00, Loss Eqns: 6.126e+00, Loss Aux: 5.592e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 161, It: 0, Loss Data: 9.695e-01, Loss Eqns: 5.383e+00, Loss Aux: 5.877e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 162, It: 0, Loss Data: 9.310e-01, Loss Eqns: 5.531e+00, Loss Aux: 2.281e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 163, It: 0, Loss Data: 1.066e+00, Loss Eqns: 5.978e+00, Loss Aux: 2.466e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 164, It: 0, Loss Data: 1.001e+00, Loss Eqns: 4.681e+00, Loss Aux: 2.749e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 165, It: 0, Loss Data: 1.044e+00, Loss Eqns: 4.809e+00, Loss Aux: 4.944e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 166, It: 0, Loss Data: 1.038e+00, Loss Eqns: 5.470e+00, Loss Aux: 4.808e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 167, It: 0, Loss Data: 1.069e+00, Loss Eqns: 5.696e+00, Loss Aux: 2.996e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 168, It: 0, Loss Data: 8.599e-01, Loss Eqns: 5.307e+00, Loss Aux: 2.100e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 169, It: 0, Loss Data: 9.707e-01, Loss Eqns: 5.979e+00, Loss Aux: 2.021e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 170, It: 0, Loss Data: 9.914e-01, Loss Eqns: 4.662e+00, Loss Aux: 2.441e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 171, It: 0, Loss Data: 9.780e-01, Loss Eqns: 6.076e+00, Loss Aux: 2.767e-01, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 172, It: 0, Loss Data: 9.564e-01, Loss Eqns: 4.991e+00, Loss Aux: 2.733e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 173, It: 0, Loss Data: 9.536e-01, Loss Eqns: 4.458e+00, Loss Aux: 2.522e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 174, It: 0, Loss Data: 1.070e+00, Loss Eqns: 4.906e+00, Loss Aux: 2.040e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 175, It: 0, Loss Data: 1.005e+00, Loss Eqns: 4.929e+00, Loss Aux: 2.383e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 176, It: 0, Loss Data: 9.910e-01, Loss Eqns: 4.382e+00, Loss Aux: 3.369e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 177, It: 0, Loss Data: 1.092e+00, Loss Eqns: 4.562e+00, Loss Aux: 3.727e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 178, It: 0, Loss Data: 1.020e+00, Loss Eqns: 4.605e+00, Loss Aux: 2.728e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 179, It: 0, Loss Data: 9.706e-01, Loss Eqns: 5.156e+00, Loss Aux: 1.919e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 180, It: 0, Loss Data: 1.040e+00, Loss Eqns: 5.364e+00, Loss Aux: 1.902e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 181, It: 0, Loss Data: 9.507e-01, Loss Eqns: 4.449e+00, Loss Aux: 2.401e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 182, It: 0, Loss Data: 1.070e+00, Loss Eqns: 4.475e+00, Loss Aux: 2.480e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 183, It: 0, Loss Data: 9.167e-01, Loss Eqns: 4.619e+00, Loss Aux: 1.966e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 184, It: 0, Loss Data: 9.041e-01, Loss Eqns: 5.561e+00, Loss Aux: 1.743e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 185, It: 0, Loss Data: 9.843e-01, Loss Eqns: 4.719e+00, Loss Aux: 2.031e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 186, It: 0, Loss Data: 1.012e+00, Loss Eqns: 4.683e+00, Loss Aux: 2.849e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 187, It: 0, Loss Data: 9.518e-01, Loss Eqns: 4.027e+00, Loss Aux: 3.370e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 188, It: 0, Loss Data: 9.788e-01, Loss Eqns: 4.892e+00, Loss Aux: 2.840e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 189, It: 0, Loss Data: 1.029e+00, Loss Eqns: 4.381e+00, Loss Aux: 2.002e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 190, It: 0, Loss Data: 1.052e+00, Loss Eqns: 5.295e+00, Loss Aux: 1.747e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 191, It: 0, Loss Data: 9.660e-01, Loss Eqns: 5.514e+00, Loss Aux: 1.419e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 192, It: 0, Loss Data: 8.947e-01, Loss Eqns: 5.103e+00, Loss Aux: 1.769e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 193, It: 0, Loss Data: 9.539e-01, Loss Eqns: 4.551e+00, Loss Aux: 2.411e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 194, It: 0, Loss Data: 9.889e-01, Loss Eqns: 5.090e+00, Loss Aux: 2.625e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 195, It: 0, Loss Data: 9.033e-01, Loss Eqns: 4.612e+00, Loss Aux: 1.892e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 196, It: 0, Loss Data: 9.765e-01, Loss Eqns: 5.022e+00, Loss Aux: 1.818e-01, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 197, It: 0, Loss Data: 9.923e-01, Loss Eqns: 5.263e+00, Loss Aux: 3.220e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 198, It: 0, Loss Data: 1.042e+00, Loss Eqns: 4.515e+00, Loss Aux: 4.172e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 199, It: 0, Loss Data: 1.001e+00, Loss Eqns: 4.420e+00, Loss Aux: 2.895e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 200, It: 0, Loss Data: 9.634e-01, Loss Eqns: 5.285e+00, Loss Aux: 1.392e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 201, It: 0, Loss Data: 9.754e-01, Loss Eqns: 3.961e+00, Loss Aux: 1.394e-01, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 202, It: 0, Loss Data: 1.007e+00, Loss Eqns: 4.292e+00, Loss Aux: 1.917e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 203, It: 0, Loss Data: 1.005e+00, Loss Eqns: 5.090e+00, Loss Aux: 3.765e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 204, It: 0, Loss Data: 8.687e-01, Loss Eqns: 4.811e+00, Loss Aux: 4.890e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 205, It: 0, Loss Data: 9.317e-01, Loss Eqns: 4.035e+00, Loss Aux: 3.587e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 206, It: 0, Loss Data: 9.131e-01, Loss Eqns: 4.920e+00, Loss Aux: 1.459e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 207, It: 0, Loss Data: 1.024e+00, Loss Eqns: 4.890e+00, Loss Aux: 1.009e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 208, It: 0, Loss Data: 9.850e-01, Loss Eqns: 4.807e+00, Loss Aux: 1.590e-01, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 209, It: 0, Loss Data: 9.780e-01, Loss Eqns: 4.887e+00, Loss Aux: 3.025e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 210, It: 0, Loss Data: 9.152e-01, Loss Eqns: 4.528e+00, Loss Aux: 2.785e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 211, It: 0, Loss Data: 9.681e-01, Loss Eqns: 5.212e+00, Loss Aux: 1.237e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 212, It: 0, Loss Data: 9.831e-01, Loss Eqns: 4.596e+00, Loss Aux: 1.042e-01, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 213, It: 0, Loss Data: 9.012e-01, Loss Eqns: 4.502e+00, Loss Aux: 1.649e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 214, It: 0, Loss Data: 9.027e-01, Loss Eqns: 4.184e+00, Loss Aux: 3.704e-01, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 215, It: 0, Loss Data: 9.749e-01, Loss Eqns: 4.078e+00, Loss Aux: 3.899e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 216, It: 0, Loss Data: 1.051e+00, Loss Eqns: 4.502e+00, Loss Aux: 2.177e-01, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 217, It: 0, Loss Data: 9.846e-01, Loss Eqns: 4.462e+00, Loss Aux: 1.596e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 218, It: 0, Loss Data: 1.043e+00, Loss Eqns: 4.313e+00, Loss Aux: 1.961e-01, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 219, It: 0, Loss Data: 9.985e-01, Loss Eqns: 4.378e+00, Loss Aux: 2.613e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 220, It: 0, Loss Data: 9.234e-01, Loss Eqns: 4.390e+00, Loss Aux: 1.850e-01, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 221, It: 0, Loss Data: 9.746e-01, Loss Eqns: 3.687e+00, Loss Aux: 1.434e-01, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 222, It: 0, Loss Data: 9.606e-01, Loss Eqns: 4.237e+00, Loss Aux: 1.374e-01, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 223, It: 0, Loss Data: 9.380e-01, Loss Eqns: 4.919e+00, Loss Aux: 2.241e-01, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 224, It: 0, Loss Data: 9.654e-01, Loss Eqns: 4.382e+00, Loss Aux: 3.312e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 225, It: 0, Loss Data: 9.478e-01, Loss Eqns: 4.728e+00, Loss Aux: 2.569e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 226, It: 0, Loss Data: 8.573e-01, Loss Eqns: 5.017e+00, Loss Aux: 1.450e-01, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 227, It: 0, Loss Data: 9.536e-01, Loss Eqns: 4.582e+00, Loss Aux: 1.064e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 228, It: 0, Loss Data: 1.082e+00, Loss Eqns: 4.565e+00, Loss Aux: 1.243e-01, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 229, It: 0, Loss Data: 9.287e-01, Loss Eqns: 5.599e+00, Loss Aux: 1.541e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 230, It: 0, Loss Data: 8.967e-01, Loss Eqns: 4.423e+00, Loss Aux: 1.771e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 231, It: 0, Loss Data: 9.293e-01, Loss Eqns: 4.155e+00, Loss Aux: 1.501e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 232, It: 0, Loss Data: 8.803e-01, Loss Eqns: 4.583e+00, Loss Aux: 9.604e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 233, It: 0, Loss Data: 9.137e-01, Loss Eqns: 4.395e+00, Loss Aux: 1.679e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 234, It: 0, Loss Data: 8.735e-01, Loss Eqns: 3.829e+00, Loss Aux: 2.359e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 235, It: 0, Loss Data: 9.080e-01, Loss Eqns: 4.491e+00, Loss Aux: 1.786e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 236, It: 0, Loss Data: 9.691e-01, Loss Eqns: 4.427e+00, Loss Aux: 1.592e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 237, It: 0, Loss Data: 8.660e-01, Loss Eqns: 4.221e+00, Loss Aux: 1.115e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 238, It: 0, Loss Data: 8.921e-01, Loss Eqns: 4.373e+00, Loss Aux: 1.180e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 239, It: 0, Loss Data: 9.568e-01, Loss Eqns: 4.305e+00, Loss Aux: 1.841e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 240, It: 0, Loss Data: 9.368e-01, Loss Eqns: 4.705e+00, Loss Aux: 2.367e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 241, It: 0, Loss Data: 9.601e-01, Loss Eqns: 4.094e+00, Loss Aux: 1.492e-01, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 242, It: 0, Loss Data: 9.377e-01, Loss Eqns: 3.755e+00, Loss Aux: 1.199e-01, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 243, It: 0, Loss Data: 9.193e-01, Loss Eqns: 5.502e+00, Loss Aux: 1.180e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 244, It: 0, Loss Data: 9.239e-01, Loss Eqns: 4.429e+00, Loss Aux: 1.486e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 245, It: 0, Loss Data: 9.454e-01, Loss Eqns: 4.684e+00, Loss Aux: 1.487e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 246, It: 0, Loss Data: 9.502e-01, Loss Eqns: 3.461e+00, Loss Aux: 1.689e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 247, It: 0, Loss Data: 1.007e+00, Loss Eqns: 5.111e+00, Loss Aux: 1.878e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 248, It: 0, Loss Data: 9.541e-01, Loss Eqns: 4.590e+00, Loss Aux: 1.940e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 249, It: 0, Loss Data: 9.206e-01, Loss Eqns: 2.998e+00, Loss Aux: 1.198e-01, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 250, It: 0, Loss Data: 9.754e-01, Loss Eqns: 4.229e+00, Loss Aux: 7.497e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 251, It: 0, Loss Data: 8.647e-01, Loss Eqns: 4.031e+00, Loss Aux: 1.025e-01, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 252, It: 0, Loss Data: 1.010e+00, Loss Eqns: 4.079e+00, Loss Aux: 1.172e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 253, It: 0, Loss Data: 9.359e-01, Loss Eqns: 4.292e+00, Loss Aux: 2.502e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 254, It: 0, Loss Data: 8.918e-01, Loss Eqns: 4.831e+00, Loss Aux: 2.700e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 255, It: 0, Loss Data: 1.026e+00, Loss Eqns: 5.197e+00, Loss Aux: 6.060e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 256, It: 0, Loss Data: 9.662e-01, Loss Eqns: 4.479e+00, Loss Aux: 7.918e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 257, It: 0, Loss Data: 8.925e-01, Loss Eqns: 7.040e+00, Loss Aux: 2.754e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 258, It: 0, Loss Data: 9.694e-01, Loss Eqns: 4.525e+00, Loss Aux: 2.862e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 259, It: 0, Loss Data: 1.040e+00, Loss Eqns: 5.367e+00, Loss Aux: 1.097e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 260, It: 0, Loss Data: 9.353e-01, Loss Eqns: 5.501e+00, Loss Aux: 9.534e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 261, It: 0, Loss Data: 9.436e-01, Loss Eqns: 4.967e+00, Loss Aux: 2.499e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 262, It: 0, Loss Data: 9.606e-01, Loss Eqns: 4.891e+00, Loss Aux: 2.022e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 263, It: 0, Loss Data: 9.880e-01, Loss Eqns: 4.561e+00, Loss Aux: 1.101e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 264, It: 0, Loss Data: 9.293e-01, Loss Eqns: 5.008e+00, Loss Aux: 1.094e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 265, It: 0, Loss Data: 9.303e-01, Loss Eqns: 4.338e+00, Loss Aux: 9.264e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 266, It: 0, Loss Data: 9.626e-01, Loss Eqns: 4.549e+00, Loss Aux: 1.481e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 267, It: 0, Loss Data: 8.714e-01, Loss Eqns: 3.579e+00, Loss Aux: 1.577e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 268, It: 0, Loss Data: 8.735e-01, Loss Eqns: 5.443e+00, Loss Aux: 1.244e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 269, It: 0, Loss Data: 9.823e-01, Loss Eqns: 3.720e+00, Loss Aux: 1.395e-01, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 270, It: 0, Loss Data: 9.899e-01, Loss Eqns: 4.487e+00, Loss Aux: 1.986e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 271, It: 0, Loss Data: 8.993e-01, Loss Eqns: 4.508e+00, Loss Aux: 1.102e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 272, It: 0, Loss Data: 8.206e-01, Loss Eqns: 4.482e+00, Loss Aux: 8.591e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 273, It: 0, Loss Data: 9.474e-01, Loss Eqns: 3.668e+00, Loss Aux: 1.463e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 274, It: 0, Loss Data: 9.988e-01, Loss Eqns: 3.860e+00, Loss Aux: 3.518e-01, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 275, It: 0, Loss Data: 1.017e+00, Loss Eqns: 4.619e+00, Loss Aux: 3.065e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 276, It: 0, Loss Data: 9.521e-01, Loss Eqns: 4.179e+00, Loss Aux: 8.365e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 277, It: 0, Loss Data: 9.931e-01, Loss Eqns: 4.691e+00, Loss Aux: 7.670e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 278, It: 0, Loss Data: 9.352e-01, Loss Eqns: 4.219e+00, Loss Aux: 1.394e-01, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 279, It: 0, Loss Data: 8.840e-01, Loss Eqns: 4.160e+00, Loss Aux: 1.639e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 280, It: 0, Loss Data: 9.596e-01, Loss Eqns: 3.596e+00, Loss Aux: 9.428e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 281, It: 0, Loss Data: 9.096e-01, Loss Eqns: 4.304e+00, Loss Aux: 1.038e-01, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 282, It: 0, Loss Data: 8.964e-01, Loss Eqns: 3.961e+00, Loss Aux: 2.006e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 283, It: 0, Loss Data: 9.140e-01, Loss Eqns: 3.648e+00, Loss Aux: 1.296e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 284, It: 0, Loss Data: 9.551e-01, Loss Eqns: 3.826e+00, Loss Aux: 8.569e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 285, It: 0, Loss Data: 8.825e-01, Loss Eqns: 4.291e+00, Loss Aux: 2.257e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 286, It: 0, Loss Data: 1.033e+00, Loss Eqns: 5.365e+00, Loss Aux: 7.786e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 287, It: 0, Loss Data: 9.529e-01, Loss Eqns: 4.298e+00, Loss Aux: 1.644e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 288, It: 0, Loss Data: 9.494e-01, Loss Eqns: 5.162e+00, Loss Aux: 2.114e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 289, It: 0, Loss Data: 9.464e-01, Loss Eqns: 4.199e+00, Loss Aux: 7.052e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 290, It: 0, Loss Data: 8.923e-01, Loss Eqns: 4.543e+00, Loss Aux: 8.038e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 291, It: 0, Loss Data: 9.628e-01, Loss Eqns: 4.043e+00, Loss Aux: 2.531e-01, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 292, It: 0, Loss Data: 8.777e-01, Loss Eqns: 5.853e+00, Loss Aux: 2.822e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 293, It: 0, Loss Data: 9.557e-01, Loss Eqns: 4.211e+00, Loss Aux: 8.411e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 294, It: 0, Loss Data: 8.710e-01, Loss Eqns: 4.526e+00, Loss Aux: 9.894e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 295, It: 0, Loss Data: 9.633e-01, Loss Eqns: 4.868e+00, Loss Aux: 2.147e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 296, It: 0, Loss Data: 8.540e-01, Loss Eqns: 4.574e+00, Loss Aux: 3.483e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 297, It: 0, Loss Data: 8.578e-01, Loss Eqns: 4.451e+00, Loss Aux: 1.656e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 298, It: 0, Loss Data: 9.000e-01, Loss Eqns: 4.485e+00, Loss Aux: 8.269e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 299, It: 0, Loss Data: 9.153e-01, Loss Eqns: 3.669e+00, Loss Aux: 1.262e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 300, It: 0, Loss Data: 9.254e-01, Loss Eqns: 4.641e+00, Loss Aux: 2.579e-01, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 301, It: 0, Loss Data: 9.298e-01, Loss Eqns: 3.448e+00, Loss Aux: 6.304e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 302, It: 0, Loss Data: 9.531e-01, Loss Eqns: 3.790e+00, Loss Aux: 5.925e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 303, It: 0, Loss Data: 8.661e-01, Loss Eqns: 4.015e+00, Loss Aux: 1.730e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 304, It: 0, Loss Data: 9.486e-01, Loss Eqns: 3.595e+00, Loss Aux: 2.646e-01, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 305, It: 0, Loss Data: 8.514e-01, Loss Eqns: 4.176e+00, Loss Aux: 1.004e-01, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 306, It: 0, Loss Data: 8.979e-01, Loss Eqns: 4.063e+00, Loss Aux: 7.500e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 307, It: 0, Loss Data: 8.933e-01, Loss Eqns: 4.043e+00, Loss Aux: 2.158e-01, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 308, It: 0, Loss Data: 9.063e-01, Loss Eqns: 3.617e+00, Loss Aux: 2.881e-01, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 309, It: 0, Loss Data: 9.219e-01, Loss Eqns: 4.357e+00, Loss Aux: 8.874e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 310, It: 0, Loss Data: 8.982e-01, Loss Eqns: 4.062e+00, Loss Aux: 7.719e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 311, It: 0, Loss Data: 9.330e-01, Loss Eqns: 4.068e+00, Loss Aux: 1.064e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 312, It: 0, Loss Data: 9.597e-01, Loss Eqns: 3.999e+00, Loss Aux: 1.152e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 313, It: 0, Loss Data: 9.677e-01, Loss Eqns: 3.303e+00, Loss Aux: 1.932e-01, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 314, It: 0, Loss Data: 9.357e-01, Loss Eqns: 3.450e+00, Loss Aux: 7.372e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 315, It: 0, Loss Data: 9.352e-01, Loss Eqns: 4.197e+00, Loss Aux: 8.605e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 316, It: 0, Loss Data: 1.027e+00, Loss Eqns: 3.738e+00, Loss Aux: 2.049e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 317, It: 0, Loss Data: 9.492e-01, Loss Eqns: 3.991e+00, Loss Aux: 2.457e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 318, It: 0, Loss Data: 8.674e-01, Loss Eqns: 4.476e+00, Loss Aux: 8.460e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 319, It: 0, Loss Data: 8.894e-01, Loss Eqns: 3.510e+00, Loss Aux: 1.066e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 320, It: 0, Loss Data: 9.303e-01, Loss Eqns: 4.359e+00, Loss Aux: 2.343e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 321, It: 0, Loss Data: 9.314e-01, Loss Eqns: 3.487e+00, Loss Aux: 1.742e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 322, It: 0, Loss Data: 9.903e-01, Loss Eqns: 3.914e+00, Loss Aux: 6.168e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 323, It: 0, Loss Data: 8.823e-01, Loss Eqns: 3.367e+00, Loss Aux: 1.110e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 324, It: 0, Loss Data: 9.275e-01, Loss Eqns: 3.857e+00, Loss Aux: 2.355e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 325, It: 0, Loss Data: 8.540e-01, Loss Eqns: 3.583e+00, Loss Aux: 1.688e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 326, It: 0, Loss Data: 8.979e-01, Loss Eqns: 4.131e+00, Loss Aux: 7.246e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 327, It: 0, Loss Data: 8.440e-01, Loss Eqns: 3.994e+00, Loss Aux: 8.512e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 328, It: 0, Loss Data: 9.179e-01, Loss Eqns: 3.748e+00, Loss Aux: 1.458e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 329, It: 0, Loss Data: 9.655e-01, Loss Eqns: 3.622e+00, Loss Aux: 1.506e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 330, It: 0, Loss Data: 9.095e-01, Loss Eqns: 4.367e+00, Loss Aux: 8.663e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 331, It: 0, Loss Data: 9.684e-01, Loss Eqns: 3.778e+00, Loss Aux: 8.010e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 332, It: 0, Loss Data: 9.330e-01, Loss Eqns: 4.058e+00, Loss Aux: 8.206e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 333, It: 0, Loss Data: 9.584e-01, Loss Eqns: 3.337e+00, Loss Aux: 1.533e-01, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 334, It: 0, Loss Data: 9.398e-01, Loss Eqns: 3.501e+00, Loss Aux: 2.215e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 335, It: 0, Loss Data: 9.445e-01, Loss Eqns: 4.458e+00, Loss Aux: 1.017e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 336, It: 0, Loss Data: 9.130e-01, Loss Eqns: 3.824e+00, Loss Aux: 9.039e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 337, It: 0, Loss Data: 9.132e-01, Loss Eqns: 4.027e+00, Loss Aux: 2.060e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 338, It: 0, Loss Data: 9.117e-01, Loss Eqns: 3.637e+00, Loss Aux: 2.491e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 339, It: 0, Loss Data: 8.641e-01, Loss Eqns: 4.030e+00, Loss Aux: 1.098e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 340, It: 0, Loss Data: 1.002e+00, Loss Eqns: 3.973e+00, Loss Aux: 1.027e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 341, It: 0, Loss Data: 9.624e-01, Loss Eqns: 3.974e+00, Loss Aux: 2.345e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 342, It: 0, Loss Data: 9.344e-01, Loss Eqns: 4.102e+00, Loss Aux: 2.303e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 343, It: 0, Loss Data: 9.796e-01, Loss Eqns: 4.272e+00, Loss Aux: 8.754e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 344, It: 0, Loss Data: 9.245e-01, Loss Eqns: 4.711e+00, Loss Aux: 8.196e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 345, It: 0, Loss Data: 8.727e-01, Loss Eqns: 3.599e+00, Loss Aux: 1.824e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 346, It: 0, Loss Data: 9.378e-01, Loss Eqns: 4.016e+00, Loss Aux: 2.036e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 347, It: 0, Loss Data: 8.574e-01, Loss Eqns: 3.443e+00, Loss Aux: 1.016e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 348, It: 0, Loss Data: 8.875e-01, Loss Eqns: 3.830e+00, Loss Aux: 1.236e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 349, It: 0, Loss Data: 8.975e-01, Loss Eqns: 3.229e+00, Loss Aux: 1.533e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 350, It: 0, Loss Data: 9.165e-01, Loss Eqns: 2.931e+00, Loss Aux: 2.646e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 351, It: 0, Loss Data: 8.871e-01, Loss Eqns: 4.225e+00, Loss Aux: 1.529e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 352, It: 0, Loss Data: 9.233e-01, Loss Eqns: 4.175e+00, Loss Aux: 1.033e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 353, It: 0, Loss Data: 8.626e-01, Loss Eqns: 3.632e+00, Loss Aux: 1.581e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 354, It: 0, Loss Data: 9.002e-01, Loss Eqns: 3.509e+00, Loss Aux: 2.287e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 355, It: 0, Loss Data: 8.951e-01, Loss Eqns: 3.682e+00, Loss Aux: 1.786e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 356, It: 0, Loss Data: 8.942e-01, Loss Eqns: 3.755e+00, Loss Aux: 7.553e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 357, It: 0, Loss Data: 8.553e-01, Loss Eqns: 3.692e+00, Loss Aux: 8.916e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 358, It: 0, Loss Data: 8.252e-01, Loss Eqns: 3.950e+00, Loss Aux: 1.463e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 359, It: 0, Loss Data: 9.424e-01, Loss Eqns: 3.432e+00, Loss Aux: 2.533e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 360, It: 0, Loss Data: 8.594e-01, Loss Eqns: 3.887e+00, Loss Aux: 1.568e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 361, It: 0, Loss Data: 8.986e-01, Loss Eqns: 4.241e+00, Loss Aux: 1.229e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 362, It: 0, Loss Data: 9.368e-01, Loss Eqns: 3.345e+00, Loss Aux: 1.854e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 363, It: 0, Loss Data: 9.492e-01, Loss Eqns: 3.615e+00, Loss Aux: 2.454e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 364, It: 0, Loss Data: 9.478e-01, Loss Eqns: 3.577e+00, Loss Aux: 1.478e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 365, It: 0, Loss Data: 8.546e-01, Loss Eqns: 3.773e+00, Loss Aux: 9.079e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 366, It: 0, Loss Data: 9.020e-01, Loss Eqns: 3.650e+00, Loss Aux: 1.072e-01, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 367, It: 0, Loss Data: 8.329e-01, Loss Eqns: 4.985e+00, Loss Aux: 3.042e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 368, It: 0, Loss Data: 8.895e-01, Loss Eqns: 3.905e+00, Loss Aux: 1.311e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 369, It: 0, Loss Data: 9.023e-01, Loss Eqns: 4.804e+00, Loss Aux: 7.404e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 370, It: 0, Loss Data: 8.870e-01, Loss Eqns: 6.189e+00, Loss Aux: 9.789e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 371, It: 0, Loss Data: 9.350e-01, Loss Eqns: 4.050e+00, Loss Aux: 3.016e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 372, It: 0, Loss Data: 9.890e-01, Loss Eqns: 4.469e+00, Loss Aux: 2.348e-01, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 373, It: 0, Loss Data: 8.107e-01, Loss Eqns: 5.079e+00, Loss Aux: 9.277e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 374, It: 0, Loss Data: 8.694e-01, Loss Eqns: 3.653e+00, Loss Aux: 2.165e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 375, It: 0, Loss Data: 9.644e-01, Loss Eqns: 4.036e+00, Loss Aux: 8.356e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 376, It: 0, Loss Data: 8.714e-01, Loss Eqns: 4.109e+00, Loss Aux: 3.849e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 377, It: 0, Loss Data: 9.598e-01, Loss Eqns: 3.670e+00, Loss Aux: 3.308e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 378, It: 0, Loss Data: 9.447e-01, Loss Eqns: 3.499e+00, Loss Aux: 9.233e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 379, It: 0, Loss Data: 8.437e-01, Loss Eqns: 4.354e+00, Loss Aux: 1.404e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 380, It: 0, Loss Data: 8.217e-01, Loss Eqns: 4.600e+00, Loss Aux: 1.273e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 381, It: 0, Loss Data: 8.828e-01, Loss Eqns: 3.442e+00, Loss Aux: 2.503e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 382, It: 0, Loss Data: 8.813e-01, Loss Eqns: 3.589e+00, Loss Aux: 1.987e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 383, It: 0, Loss Data: 8.554e-01, Loss Eqns: 5.453e+00, Loss Aux: 2.177e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 384, It: 0, Loss Data: 1.021e+00, Loss Eqns: 5.379e+00, Loss Aux: 1.283e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 385, It: 0, Loss Data: 9.325e-01, Loss Eqns: 5.260e+00, Loss Aux: 1.990e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 386, It: 0, Loss Data: 9.419e-01, Loss Eqns: 5.395e+00, Loss Aux: 2.325e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 387, It: 0, Loss Data: 7.898e-01, Loss Eqns: 5.957e+00, Loss Aux: 1.820e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 388, It: 0, Loss Data: 9.336e-01, Loss Eqns: 4.696e+00, Loss Aux: 1.163e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 389, It: 0, Loss Data: 8.949e-01, Loss Eqns: 5.620e+00, Loss Aux: 1.561e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 390, It: 0, Loss Data: 9.772e-01, Loss Eqns: 3.923e+00, Loss Aux: 2.191e-01, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 391, It: 0, Loss Data: 9.207e-01, Loss Eqns: 4.635e+00, Loss Aux: 1.553e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 392, It: 0, Loss Data: 9.479e-01, Loss Eqns: 4.162e+00, Loss Aux: 8.246e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 393, It: 0, Loss Data: 8.975e-01, Loss Eqns: 4.531e+00, Loss Aux: 5.573e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 394, It: 0, Loss Data: 9.309e-01, Loss Eqns: 3.463e+00, Loss Aux: 3.972e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 395, It: 0, Loss Data: 9.177e-01, Loss Eqns: 4.023e+00, Loss Aux: 6.693e-01, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 396, It: 0, Loss Data: 8.675e-01, Loss Eqns: 3.786e+00, Loss Aux: 3.934e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 397, It: 0, Loss Data: 8.641e-01, Loss Eqns: 3.937e+00, Loss Aux: 1.790e-01, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 398, It: 0, Loss Data: 9.003e-01, Loss Eqns: 3.942e+00, Loss Aux: 2.729e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 399, It: 0, Loss Data: 8.979e-01, Loss Eqns: 4.408e+00, Loss Aux: 1.236e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 400, It: 0, Loss Data: 9.348e-01, Loss Eqns: 2.982e+00, Loss Aux: 2.742e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 401, It: 0, Loss Data: 7.990e-01, Loss Eqns: 3.738e+00, Loss Aux: 3.865e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 402, It: 0, Loss Data: 8.379e-01, Loss Eqns: 3.440e+00, Loss Aux: 2.614e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 403, It: 0, Loss Data: 8.778e-01, Loss Eqns: 3.721e+00, Loss Aux: 8.360e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 404, It: 0, Loss Data: 8.541e-01, Loss Eqns: 3.902e+00, Loss Aux: 8.994e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 405, It: 0, Loss Data: 8.568e-01, Loss Eqns: 3.502e+00, Loss Aux: 1.100e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 406, It: 0, Loss Data: 9.088e-01, Loss Eqns: 3.804e+00, Loss Aux: 1.156e-01, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 407, It: 0, Loss Data: 9.083e-01, Loss Eqns: 3.854e+00, Loss Aux: 1.563e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 408, It: 0, Loss Data: 1.007e+00, Loss Eqns: 3.674e+00, Loss Aux: 1.667e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 409, It: 0, Loss Data: 8.748e-01, Loss Eqns: 3.297e+00, Loss Aux: 1.613e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 410, It: 0, Loss Data: 8.913e-01, Loss Eqns: 3.806e+00, Loss Aux: 1.807e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 411, It: 0, Loss Data: 8.399e-01, Loss Eqns: 3.612e+00, Loss Aux: 1.495e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 412, It: 0, Loss Data: 8.796e-01, Loss Eqns: 3.706e+00, Loss Aux: 1.042e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 413, It: 0, Loss Data: 8.948e-01, Loss Eqns: 3.697e+00, Loss Aux: 1.027e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 414, It: 0, Loss Data: 7.832e-01, Loss Eqns: 4.018e+00, Loss Aux: 1.607e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 415, It: 0, Loss Data: 9.649e-01, Loss Eqns: 3.275e+00, Loss Aux: 2.622e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 416, It: 0, Loss Data: 8.680e-01, Loss Eqns: 3.997e+00, Loss Aux: 1.757e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 417, It: 0, Loss Data: 9.201e-01, Loss Eqns: 4.208e+00, Loss Aux: 1.087e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 418, It: 0, Loss Data: 8.167e-01, Loss Eqns: 4.205e+00, Loss Aux: 1.234e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 419, It: 0, Loss Data: 8.175e-01, Loss Eqns: 3.340e+00, Loss Aux: 1.625e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 420, It: 0, Loss Data: 9.134e-01, Loss Eqns: 3.231e+00, Loss Aux: 1.793e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 421, It: 0, Loss Data: 9.114e-01, Loss Eqns: 3.670e+00, Loss Aux: 1.537e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 422, It: 0, Loss Data: 8.552e-01, Loss Eqns: 3.179e+00, Loss Aux: 1.392e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 423, It: 0, Loss Data: 8.775e-01, Loss Eqns: 3.968e+00, Loss Aux: 1.619e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 424, It: 0, Loss Data: 8.618e-01, Loss Eqns: 3.374e+00, Loss Aux: 1.255e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 425, It: 0, Loss Data: 8.714e-01, Loss Eqns: 3.588e+00, Loss Aux: 1.236e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 426, It: 0, Loss Data: 9.097e-01, Loss Eqns: 3.614e+00, Loss Aux: 1.177e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 427, It: 0, Loss Data: 7.968e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.653e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 428, It: 0, Loss Data: 8.358e-01, Loss Eqns: 3.338e+00, Loss Aux: 1.455e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 429, It: 0, Loss Data: 8.964e-01, Loss Eqns: 3.404e+00, Loss Aux: 9.839e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 430, It: 0, Loss Data: 8.642e-01, Loss Eqns: 3.625e+00, Loss Aux: 9.834e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 431, It: 0, Loss Data: 8.662e-01, Loss Eqns: 3.975e+00, Loss Aux: 1.175e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 432, It: 0, Loss Data: 8.865e-01, Loss Eqns: 3.013e+00, Loss Aux: 1.609e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 433, It: 0, Loss Data: 8.561e-01, Loss Eqns: 3.377e+00, Loss Aux: 1.614e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 434, It: 0, Loss Data: 8.782e-01, Loss Eqns: 3.822e+00, Loss Aux: 9.025e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 435, It: 0, Loss Data: 8.800e-01, Loss Eqns: 3.636e+00, Loss Aux: 7.657e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 436, It: 0, Loss Data: 8.671e-01, Loss Eqns: 3.664e+00, Loss Aux: 1.151e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 437, It: 0, Loss Data: 8.904e-01, Loss Eqns: 3.431e+00, Loss Aux: 1.436e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 438, It: 0, Loss Data: 8.627e-01, Loss Eqns: 3.435e+00, Loss Aux: 9.053e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 439, It: 0, Loss Data: 8.328e-01, Loss Eqns: 3.567e+00, Loss Aux: 9.138e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 440, It: 0, Loss Data: 8.326e-01, Loss Eqns: 3.503e+00, Loss Aux: 1.351e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 441, It: 0, Loss Data: 9.056e-01, Loss Eqns: 3.297e+00, Loss Aux: 1.687e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 442, It: 0, Loss Data: 8.813e-01, Loss Eqns: 3.471e+00, Loss Aux: 1.573e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 443, It: 0, Loss Data: 8.362e-01, Loss Eqns: 3.433e+00, Loss Aux: 1.375e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 444, It: 0, Loss Data: 9.315e-01, Loss Eqns: 3.201e+00, Loss Aux: 1.394e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 445, It: 0, Loss Data: 9.125e-01, Loss Eqns: 3.245e+00, Loss Aux: 1.952e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 446, It: 0, Loss Data: 9.390e-01, Loss Eqns: 3.314e+00, Loss Aux: 1.216e-01, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 447, It: 0, Loss Data: 8.362e-01, Loss Eqns: 3.879e+00, Loss Aux: 6.197e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 448, It: 0, Loss Data: 8.092e-01, Loss Eqns: 3.831e+00, Loss Aux: 7.380e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 449, It: 0, Loss Data: 8.973e-01, Loss Eqns: 3.032e+00, Loss Aux: 1.146e-01, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 450, It: 0, Loss Data: 8.957e-01, Loss Eqns: 4.099e+00, Loss Aux: 1.579e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 451, It: 0, Loss Data: 8.183e-01, Loss Eqns: 3.407e+00, Loss Aux: 1.435e-01, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 452, It: 0, Loss Data: 8.046e-01, Loss Eqns: 3.610e+00, Loss Aux: 1.046e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 453, It: 0, Loss Data: 8.768e-01, Loss Eqns: 4.017e+00, Loss Aux: 9.842e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 454, It: 0, Loss Data: 8.853e-01, Loss Eqns: 3.520e+00, Loss Aux: 1.132e-01, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 455, It: 0, Loss Data: 8.873e-01, Loss Eqns: 4.199e+00, Loss Aux: 1.331e-01, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 456, It: 0, Loss Data: 8.051e-01, Loss Eqns: 3.537e+00, Loss Aux: 1.149e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 457, It: 0, Loss Data: 8.359e-01, Loss Eqns: 3.314e+00, Loss Aux: 9.618e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 458, It: 0, Loss Data: 8.645e-01, Loss Eqns: 4.125e+00, Loss Aux: 1.227e-01, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 459, It: 0, Loss Data: 9.189e-01, Loss Eqns: 3.123e+00, Loss Aux: 1.886e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 460, It: 0, Loss Data: 7.976e-01, Loss Eqns: 3.656e+00, Loss Aux: 1.119e-01, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 461, It: 0, Loss Data: 8.304e-01, Loss Eqns: 3.826e+00, Loss Aux: 1.142e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 462, It: 0, Loss Data: 9.156e-01, Loss Eqns: 3.019e+00, Loss Aux: 1.536e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 463, It: 0, Loss Data: 8.945e-01, Loss Eqns: 2.965e+00, Loss Aux: 1.771e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 464, It: 0, Loss Data: 8.541e-01, Loss Eqns: 3.732e+00, Loss Aux: 1.318e-01, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 465, It: 0, Loss Data: 9.032e-01, Loss Eqns: 3.306e+00, Loss Aux: 7.838e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 466, It: 0, Loss Data: 8.184e-01, Loss Eqns: 2.979e+00, Loss Aux: 7.455e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 467, It: 0, Loss Data: 8.283e-01, Loss Eqns: 3.210e+00, Loss Aux: 1.362e-01, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 468, It: 0, Loss Data: 8.542e-01, Loss Eqns: 3.533e+00, Loss Aux: 1.436e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 469, It: 0, Loss Data: 8.769e-01, Loss Eqns: 3.307e+00, Loss Aux: 8.636e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 470, It: 0, Loss Data: 8.246e-01, Loss Eqns: 3.491e+00, Loss Aux: 9.411e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 471, It: 0, Loss Data: 8.812e-01, Loss Eqns: 3.219e+00, Loss Aux: 1.172e-01, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 472, It: 0, Loss Data: 8.477e-01, Loss Eqns: 3.871e+00, Loss Aux: 1.776e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 473, It: 0, Loss Data: 8.294e-01, Loss Eqns: 3.101e+00, Loss Aux: 1.399e-01, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 474, It: 0, Loss Data: 8.566e-01, Loss Eqns: 5.179e+00, Loss Aux: 7.694e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 475, It: 0, Loss Data: 8.975e-01, Loss Eqns: 3.936e+00, Loss Aux: 1.024e-01, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 476, It: 0, Loss Data: 8.413e-01, Loss Eqns: 6.739e+00, Loss Aux: 1.273e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 477, It: 0, Loss Data: 9.239e-01, Loss Eqns: 5.985e+00, Loss Aux: 1.260e-01, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 478, It: 0, Loss Data: 9.768e-01, Loss Eqns: 4.816e+00, Loss Aux: 1.023e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 479, It: 0, Loss Data: 8.001e-01, Loss Eqns: 4.235e+00, Loss Aux: 2.316e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 480, It: 0, Loss Data: 9.056e-01, Loss Eqns: 3.318e+00, Loss Aux: 1.604e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 481, It: 0, Loss Data: 8.978e-01, Loss Eqns: 3.433e+00, Loss Aux: 7.672e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 482, It: 0, Loss Data: 8.908e-01, Loss Eqns: 3.261e+00, Loss Aux: 1.299e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 483, It: 0, Loss Data: 9.966e-01, Loss Eqns: 3.940e+00, Loss Aux: 1.861e-01, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 484, It: 0, Loss Data: 1.004e+00, Loss Eqns: 3.965e+00, Loss Aux: 4.436e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 485, It: 0, Loss Data: 8.494e-01, Loss Eqns: 4.279e+00, Loss Aux: 4.313e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 486, It: 0, Loss Data: 8.294e-01, Loss Eqns: 3.367e+00, Loss Aux: 2.428e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 487, It: 0, Loss Data: 7.960e-01, Loss Eqns: 3.684e+00, Loss Aux: 3.143e-01, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 488, It: 0, Loss Data: 8.438e-01, Loss Eqns: 4.475e+00, Loss Aux: 1.406e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 489, It: 0, Loss Data: 8.657e-01, Loss Eqns: 4.294e+00, Loss Aux: 6.681e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 490, It: 0, Loss Data: 8.535e-01, Loss Eqns: 4.278e+00, Loss Aux: 7.715e-02, Time: 0.268, Learning Rate: 1.0e-03\n",
      "Epoch: 491, It: 0, Loss Data: 8.874e-01, Loss Eqns: 3.322e+00, Loss Aux: 1.324e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 492, It: 0, Loss Data: 7.968e-01, Loss Eqns: 3.731e+00, Loss Aux: 1.158e-01, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 493, It: 0, Loss Data: 7.342e-01, Loss Eqns: 3.873e+00, Loss Aux: 1.063e-01, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 494, It: 0, Loss Data: 8.195e-01, Loss Eqns: 3.136e+00, Loss Aux: 1.043e-01, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 495, It: 0, Loss Data: 8.140e-01, Loss Eqns: 3.669e+00, Loss Aux: 7.562e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 496, It: 0, Loss Data: 8.062e-01, Loss Eqns: 3.548e+00, Loss Aux: 9.307e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 497, It: 0, Loss Data: 8.249e-01, Loss Eqns: 3.615e+00, Loss Aux: 1.421e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 498, It: 0, Loss Data: 8.415e-01, Loss Eqns: 3.158e+00, Loss Aux: 9.443e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 499, It: 0, Loss Data: 7.984e-01, Loss Eqns: 3.584e+00, Loss Aux: 6.704e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 500, It: 0, Loss Data: 8.701e-01, Loss Eqns: 3.288e+00, Loss Aux: 1.091e-01, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 501, It: 0, Loss Data: 8.213e-01, Loss Eqns: 3.699e+00, Loss Aux: 1.052e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 502, It: 0, Loss Data: 8.085e-01, Loss Eqns: 3.423e+00, Loss Aux: 3.487e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 503, It: 0, Loss Data: 7.753e-01, Loss Eqns: 2.997e+00, Loss Aux: 8.936e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 504, It: 0, Loss Data: 8.210e-01, Loss Eqns: 3.805e+00, Loss Aux: 1.571e-01, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 505, It: 0, Loss Data: 7.723e-01, Loss Eqns: 3.502e+00, Loss Aux: 7.688e-02, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 506, It: 0, Loss Data: 8.335e-01, Loss Eqns: 3.320e+00, Loss Aux: 1.608e-01, Time: 0.251, Learning Rate: 1.0e-03\n",
      "Epoch: 507, It: 0, Loss Data: 7.934e-01, Loss Eqns: 3.104e+00, Loss Aux: 1.740e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 508, It: 0, Loss Data: 7.738e-01, Loss Eqns: 3.234e+00, Loss Aux: 8.725e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 509, It: 0, Loss Data: 8.217e-01, Loss Eqns: 4.033e+00, Loss Aux: 1.424e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 510, It: 0, Loss Data: 7.582e-01, Loss Eqns: 2.939e+00, Loss Aux: 1.652e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 511, It: 0, Loss Data: 8.306e-01, Loss Eqns: 3.607e+00, Loss Aux: 3.348e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 512, It: 0, Loss Data: 8.260e-01, Loss Eqns: 3.285e+00, Loss Aux: 1.104e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 513, It: 0, Loss Data: 7.601e-01, Loss Eqns: 3.308e+00, Loss Aux: 1.686e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 514, It: 0, Loss Data: 8.151e-01, Loss Eqns: 4.266e+00, Loss Aux: 2.732e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 515, It: 0, Loss Data: 9.086e-01, Loss Eqns: 3.809e+00, Loss Aux: 4.870e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 516, It: 0, Loss Data: 8.587e-01, Loss Eqns: 3.957e+00, Loss Aux: 4.889e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 517, It: 0, Loss Data: 8.190e-01, Loss Eqns: 4.140e+00, Loss Aux: 2.813e-01, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 518, It: 0, Loss Data: 1.013e+00, Loss Eqns: 1.109e+01, Loss Aux: 1.066e+00, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 519, It: 0, Loss Data: 1.128e+00, Loss Eqns: 1.141e+01, Loss Aux: 1.101e+00, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 520, It: 0, Loss Data: 1.073e+00, Loss Eqns: 1.162e+01, Loss Aux: 1.775e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 521, It: 0, Loss Data: 1.042e+00, Loss Eqns: 1.224e+01, Loss Aux: 2.223e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 522, It: 0, Loss Data: 1.007e+00, Loss Eqns: 1.084e+01, Loss Aux: 1.826e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 523, It: 0, Loss Data: 1.093e+00, Loss Eqns: 1.049e+01, Loss Aux: 2.299e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 524, It: 0, Loss Data: 9.231e-01, Loss Eqns: 9.082e+00, Loss Aux: 4.558e-01, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 525, It: 0, Loss Data: 9.704e-01, Loss Eqns: 7.841e+00, Loss Aux: 6.374e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 526, It: 0, Loss Data: 9.244e-01, Loss Eqns: 8.062e+00, Loss Aux: 4.656e-01, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 527, It: 0, Loss Data: 1.049e+00, Loss Eqns: 6.388e+00, Loss Aux: 3.120e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 528, It: 0, Loss Data: 9.299e-01, Loss Eqns: 6.324e+00, Loss Aux: 2.094e-01, Time: 0.271, Learning Rate: 1.0e-03\n",
      "Epoch: 529, It: 0, Loss Data: 9.882e-01, Loss Eqns: 6.565e+00, Loss Aux: 1.679e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 530, It: 0, Loss Data: 1.077e+00, Loss Eqns: 5.981e+00, Loss Aux: 3.320e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 531, It: 0, Loss Data: 9.459e-01, Loss Eqns: 6.047e+00, Loss Aux: 2.503e-01, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 532, It: 0, Loss Data: 9.586e-01, Loss Eqns: 5.149e+00, Loss Aux: 1.132e-01, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 533, It: 0, Loss Data: 9.625e-01, Loss Eqns: 5.845e+00, Loss Aux: 2.562e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 534, It: 0, Loss Data: 9.144e-01, Loss Eqns: 5.758e+00, Loss Aux: 3.336e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 535, It: 0, Loss Data: 1.015e+00, Loss Eqns: 6.202e+00, Loss Aux: 2.561e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 536, It: 0, Loss Data: 8.742e-01, Loss Eqns: 5.544e+00, Loss Aux: 2.442e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 537, It: 0, Loss Data: 1.002e+00, Loss Eqns: 5.460e+00, Loss Aux: 2.299e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 538, It: 0, Loss Data: 9.890e-01, Loss Eqns: 5.398e+00, Loss Aux: 2.123e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 539, It: 0, Loss Data: 9.565e-01, Loss Eqns: 5.982e+00, Loss Aux: 2.200e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 540, It: 0, Loss Data: 9.873e-01, Loss Eqns: 4.115e+00, Loss Aux: 2.313e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 541, It: 0, Loss Data: 1.015e+00, Loss Eqns: 5.176e+00, Loss Aux: 2.555e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 542, It: 0, Loss Data: 9.497e-01, Loss Eqns: 5.371e+00, Loss Aux: 2.425e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 543, It: 0, Loss Data: 9.386e-01, Loss Eqns: 4.603e+00, Loss Aux: 1.770e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 544, It: 0, Loss Data: 9.608e-01, Loss Eqns: 4.302e+00, Loss Aux: 1.273e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 545, It: 0, Loss Data: 9.341e-01, Loss Eqns: 4.412e+00, Loss Aux: 1.200e-01, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 546, It: 0, Loss Data: 9.894e-01, Loss Eqns: 4.428e+00, Loss Aux: 1.635e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 547, It: 0, Loss Data: 9.269e-01, Loss Eqns: 4.202e+00, Loss Aux: 2.214e-01, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 548, It: 0, Loss Data: 9.848e-01, Loss Eqns: 3.573e+00, Loss Aux: 1.584e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 549, It: 0, Loss Data: 1.006e+00, Loss Eqns: 4.513e+00, Loss Aux: 8.678e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 550, It: 0, Loss Data: 9.449e-01, Loss Eqns: 4.055e+00, Loss Aux: 6.435e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 551, It: 0, Loss Data: 9.429e-01, Loss Eqns: 4.494e+00, Loss Aux: 6.627e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 552, It: 0, Loss Data: 9.595e-01, Loss Eqns: 4.411e+00, Loss Aux: 1.316e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 553, It: 0, Loss Data: 9.563e-01, Loss Eqns: 3.070e+00, Loss Aux: 1.901e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 554, It: 0, Loss Data: 8.868e-01, Loss Eqns: 4.138e+00, Loss Aux: 1.777e-01, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 555, It: 0, Loss Data: 9.868e-01, Loss Eqns: 4.410e+00, Loss Aux: 1.411e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 556, It: 0, Loss Data: 9.057e-01, Loss Eqns: 3.705e+00, Loss Aux: 1.418e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 557, It: 0, Loss Data: 1.044e+00, Loss Eqns: 4.120e+00, Loss Aux: 1.709e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 558, It: 0, Loss Data: 8.885e-01, Loss Eqns: 4.112e+00, Loss Aux: 1.478e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 559, It: 0, Loss Data: 8.624e-01, Loss Eqns: 3.976e+00, Loss Aux: 1.091e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 560, It: 0, Loss Data: 9.058e-01, Loss Eqns: 4.251e+00, Loss Aux: 1.006e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 561, It: 0, Loss Data: 8.947e-01, Loss Eqns: 4.218e+00, Loss Aux: 1.021e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 562, It: 0, Loss Data: 9.144e-01, Loss Eqns: 3.157e+00, Loss Aux: 1.439e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 563, It: 0, Loss Data: 8.884e-01, Loss Eqns: 4.070e+00, Loss Aux: 1.216e-01, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 564, It: 0, Loss Data: 9.533e-01, Loss Eqns: 4.147e+00, Loss Aux: 9.199e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 565, It: 0, Loss Data: 8.463e-01, Loss Eqns: 4.330e+00, Loss Aux: 9.938e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 566, It: 0, Loss Data: 8.925e-01, Loss Eqns: 3.204e+00, Loss Aux: 1.153e-01, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 567, It: 0, Loss Data: 9.437e-01, Loss Eqns: 4.291e+00, Loss Aux: 1.292e-01, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 568, It: 0, Loss Data: 8.641e-01, Loss Eqns: 3.931e+00, Loss Aux: 1.232e-01, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 569, It: 0, Loss Data: 8.342e-01, Loss Eqns: 3.564e+00, Loss Aux: 1.030e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 570, It: 0, Loss Data: 8.301e-01, Loss Eqns: 3.484e+00, Loss Aux: 7.000e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 571, It: 0, Loss Data: 8.552e-01, Loss Eqns: 3.862e+00, Loss Aux: 5.422e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 572, It: 0, Loss Data: 8.415e-01, Loss Eqns: 4.085e+00, Loss Aux: 7.011e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 573, It: 0, Loss Data: 8.661e-01, Loss Eqns: 4.170e+00, Loss Aux: 1.121e-01, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 574, It: 0, Loss Data: 8.130e-01, Loss Eqns: 3.913e+00, Loss Aux: 8.614e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 575, It: 0, Loss Data: 7.941e-01, Loss Eqns: 3.280e+00, Loss Aux: 6.397e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 576, It: 0, Loss Data: 8.735e-01, Loss Eqns: 2.995e+00, Loss Aux: 5.576e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 577, It: 0, Loss Data: 8.397e-01, Loss Eqns: 4.337e+00, Loss Aux: 4.345e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 578, It: 0, Loss Data: 7.595e-01, Loss Eqns: 3.532e+00, Loss Aux: 7.411e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 579, It: 0, Loss Data: 7.625e-01, Loss Eqns: 3.466e+00, Loss Aux: 1.568e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 580, It: 0, Loss Data: 8.618e-01, Loss Eqns: 3.532e+00, Loss Aux: 1.899e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 581, It: 0, Loss Data: 8.736e-01, Loss Eqns: 4.578e+00, Loss Aux: 8.703e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 582, It: 0, Loss Data: 8.194e-01, Loss Eqns: 4.039e+00, Loss Aux: 1.133e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 583, It: 0, Loss Data: 8.879e-01, Loss Eqns: 3.493e+00, Loss Aux: 1.119e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 584, It: 0, Loss Data: 8.306e-01, Loss Eqns: 3.794e+00, Loss Aux: 7.969e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 585, It: 0, Loss Data: 8.272e-01, Loss Eqns: 4.036e+00, Loss Aux: 8.176e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 586, It: 0, Loss Data: 8.078e-01, Loss Eqns: 3.622e+00, Loss Aux: 1.259e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 587, It: 0, Loss Data: 8.425e-01, Loss Eqns: 4.099e+00, Loss Aux: 6.041e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 588, It: 0, Loss Data: 8.773e-01, Loss Eqns: 4.067e+00, Loss Aux: 1.479e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 589, It: 0, Loss Data: 7.787e-01, Loss Eqns: 3.481e+00, Loss Aux: 1.410e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 590, It: 0, Loss Data: 8.018e-01, Loss Eqns: 3.808e+00, Loss Aux: 4.626e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 591, It: 0, Loss Data: 8.590e-01, Loss Eqns: 3.972e+00, Loss Aux: 4.751e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 592, It: 0, Loss Data: 8.411e-01, Loss Eqns: 3.799e+00, Loss Aux: 2.008e-01, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 593, It: 0, Loss Data: 7.892e-01, Loss Eqns: 4.087e+00, Loss Aux: 6.357e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 594, It: 0, Loss Data: 7.255e-01, Loss Eqns: 3.406e+00, Loss Aux: 5.959e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 595, It: 0, Loss Data: 7.906e-01, Loss Eqns: 3.695e+00, Loss Aux: 1.363e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 596, It: 0, Loss Data: 7.494e-01, Loss Eqns: 4.818e+00, Loss Aux: 1.138e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 597, It: 0, Loss Data: 8.355e-01, Loss Eqns: 4.037e+00, Loss Aux: 1.310e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 598, It: 0, Loss Data: 8.614e-01, Loss Eqns: 4.541e+00, Loss Aux: 1.719e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 599, It: 0, Loss Data: 8.555e-01, Loss Eqns: 4.248e+00, Loss Aux: 9.116e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 600, It: 0, Loss Data: 7.858e-01, Loss Eqns: 3.494e+00, Loss Aux: 9.323e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 601, It: 0, Loss Data: 7.900e-01, Loss Eqns: 4.174e+00, Loss Aux: 1.066e-01, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 602, It: 0, Loss Data: 7.569e-01, Loss Eqns: 5.072e+00, Loss Aux: 4.062e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 603, It: 0, Loss Data: 8.045e-01, Loss Eqns: 4.017e+00, Loss Aux: 1.773e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 604, It: 0, Loss Data: 8.319e-01, Loss Eqns: 3.523e+00, Loss Aux: 4.998e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 605, It: 0, Loss Data: 8.932e-01, Loss Eqns: 4.219e+00, Loss Aux: 6.341e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 606, It: 0, Loss Data: 7.527e-01, Loss Eqns: 4.888e+00, Loss Aux: 2.248e-01, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 607, It: 0, Loss Data: 7.715e-01, Loss Eqns: 3.586e+00, Loss Aux: 1.221e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 608, It: 0, Loss Data: 8.248e-01, Loss Eqns: 3.842e+00, Loss Aux: 1.498e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 609, It: 0, Loss Data: 8.497e-01, Loss Eqns: 4.206e+00, Loss Aux: 9.590e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 610, It: 0, Loss Data: 7.967e-01, Loss Eqns: 3.833e+00, Loss Aux: 1.846e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 611, It: 0, Loss Data: 8.121e-01, Loss Eqns: 3.965e+00, Loss Aux: 9.608e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 612, It: 0, Loss Data: 7.629e-01, Loss Eqns: 4.032e+00, Loss Aux: 4.440e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 613, It: 0, Loss Data: 7.970e-01, Loss Eqns: 4.056e+00, Loss Aux: 6.937e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 614, It: 0, Loss Data: 7.510e-01, Loss Eqns: 4.050e+00, Loss Aux: 1.014e-01, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 615, It: 0, Loss Data: 8.185e-01, Loss Eqns: 3.761e+00, Loss Aux: 8.359e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 616, It: 0, Loss Data: 8.142e-01, Loss Eqns: 3.972e+00, Loss Aux: 1.027e-01, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 617, It: 0, Loss Data: 8.291e-01, Loss Eqns: 3.540e+00, Loss Aux: 7.219e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 618, It: 0, Loss Data: 7.867e-01, Loss Eqns: 3.953e+00, Loss Aux: 3.081e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 619, It: 0, Loss Data: 7.497e-01, Loss Eqns: 3.641e+00, Loss Aux: 6.306e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 620, It: 0, Loss Data: 8.540e-01, Loss Eqns: 3.497e+00, Loss Aux: 5.841e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 621, It: 0, Loss Data: 8.096e-01, Loss Eqns: 3.595e+00, Loss Aux: 7.462e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 622, It: 0, Loss Data: 7.898e-01, Loss Eqns: 3.169e+00, Loss Aux: 1.141e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 623, It: 0, Loss Data: 8.004e-01, Loss Eqns: 3.699e+00, Loss Aux: 7.523e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 624, It: 0, Loss Data: 8.428e-01, Loss Eqns: 3.232e+00, Loss Aux: 3.982e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 625, It: 0, Loss Data: 7.777e-01, Loss Eqns: 3.761e+00, Loss Aux: 5.235e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 626, It: 0, Loss Data: 7.667e-01, Loss Eqns: 3.258e+00, Loss Aux: 1.551e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 627, It: 0, Loss Data: 8.592e-01, Loss Eqns: 3.519e+00, Loss Aux: 7.873e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 628, It: 0, Loss Data: 8.036e-01, Loss Eqns: 3.728e+00, Loss Aux: 8.197e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 629, It: 0, Loss Data: 7.361e-01, Loss Eqns: 3.571e+00, Loss Aux: 7.620e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 630, It: 0, Loss Data: 8.134e-01, Loss Eqns: 3.625e+00, Loss Aux: 3.163e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 631, It: 0, Loss Data: 8.528e-01, Loss Eqns: 4.994e+00, Loss Aux: 2.980e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 632, It: 0, Loss Data: 8.176e-01, Loss Eqns: 5.624e+00, Loss Aux: 2.986e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 633, It: 0, Loss Data: 7.582e-01, Loss Eqns: 4.282e+00, Loss Aux: 1.846e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 634, It: 0, Loss Data: 8.555e-01, Loss Eqns: 5.332e+00, Loss Aux: 6.928e-01, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 635, It: 0, Loss Data: 8.273e-01, Loss Eqns: 3.933e+00, Loss Aux: 3.755e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 636, It: 0, Loss Data: 7.470e-01, Loss Eqns: 3.948e+00, Loss Aux: 1.429e-01, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 637, It: 0, Loss Data: 8.097e-01, Loss Eqns: 4.051e+00, Loss Aux: 7.693e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 638, It: 0, Loss Data: 8.498e-01, Loss Eqns: 3.562e+00, Loss Aux: 2.304e-01, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 639, It: 0, Loss Data: 7.993e-01, Loss Eqns: 4.233e+00, Loss Aux: 1.712e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 640, It: 0, Loss Data: 8.029e-01, Loss Eqns: 3.932e+00, Loss Aux: 8.679e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 641, It: 0, Loss Data: 7.932e-01, Loss Eqns: 5.083e+00, Loss Aux: 6.687e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 642, It: 0, Loss Data: 8.340e-01, Loss Eqns: 3.598e+00, Loss Aux: 1.846e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 643, It: 0, Loss Data: 8.411e-01, Loss Eqns: 4.194e+00, Loss Aux: 2.412e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 644, It: 0, Loss Data: 7.643e-01, Loss Eqns: 2.931e+00, Loss Aux: 1.854e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 645, It: 0, Loss Data: 8.079e-01, Loss Eqns: 4.288e+00, Loss Aux: 1.299e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 646, It: 0, Loss Data: 8.118e-01, Loss Eqns: 3.452e+00, Loss Aux: 9.469e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 647, It: 0, Loss Data: 8.110e-01, Loss Eqns: 3.856e+00, Loss Aux: 2.191e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 648, It: 0, Loss Data: 8.307e-01, Loss Eqns: 3.986e+00, Loss Aux: 1.861e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 649, It: 0, Loss Data: 7.565e-01, Loss Eqns: 4.139e+00, Loss Aux: 8.437e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 650, It: 0, Loss Data: 8.430e-01, Loss Eqns: 3.928e+00, Loss Aux: 4.218e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 651, It: 0, Loss Data: 8.639e-01, Loss Eqns: 3.205e+00, Loss Aux: 1.669e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 652, It: 0, Loss Data: 8.246e-01, Loss Eqns: 3.295e+00, Loss Aux: 3.049e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 653, It: 0, Loss Data: 7.652e-01, Loss Eqns: 3.829e+00, Loss Aux: 1.895e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 654, It: 0, Loss Data: 8.435e-01, Loss Eqns: 3.234e+00, Loss Aux: 7.069e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 655, It: 0, Loss Data: 8.433e-01, Loss Eqns: 3.621e+00, Loss Aux: 7.807e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 656, It: 0, Loss Data: 8.047e-01, Loss Eqns: 3.385e+00, Loss Aux: 2.297e-01, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 657, It: 0, Loss Data: 7.535e-01, Loss Eqns: 3.469e+00, Loss Aux: 2.002e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 658, It: 0, Loss Data: 8.939e-01, Loss Eqns: 3.495e+00, Loss Aux: 5.881e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 659, It: 0, Loss Data: 8.097e-01, Loss Eqns: 3.813e+00, Loss Aux: 8.149e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 660, It: 0, Loss Data: 7.422e-01, Loss Eqns: 3.643e+00, Loss Aux: 1.074e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 661, It: 0, Loss Data: 7.843e-01, Loss Eqns: 3.950e+00, Loss Aux: 8.204e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 662, It: 0, Loss Data: 7.951e-01, Loss Eqns: 4.180e+00, Loss Aux: 7.144e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 663, It: 0, Loss Data: 7.182e-01, Loss Eqns: 4.125e+00, Loss Aux: 7.698e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 664, It: 0, Loss Data: 8.210e-01, Loss Eqns: 3.468e+00, Loss Aux: 6.586e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 665, It: 0, Loss Data: 7.774e-01, Loss Eqns: 3.074e+00, Loss Aux: 8.757e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 666, It: 0, Loss Data: 7.855e-01, Loss Eqns: 3.521e+00, Loss Aux: 1.020e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 667, It: 0, Loss Data: 7.508e-01, Loss Eqns: 3.713e+00, Loss Aux: 7.645e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 668, It: 0, Loss Data: 7.933e-01, Loss Eqns: 3.497e+00, Loss Aux: 7.883e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 669, It: 0, Loss Data: 8.007e-01, Loss Eqns: 4.115e+00, Loss Aux: 6.362e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 670, It: 0, Loss Data: 7.587e-01, Loss Eqns: 4.037e+00, Loss Aux: 1.002e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 671, It: 0, Loss Data: 7.054e-01, Loss Eqns: 3.390e+00, Loss Aux: 9.796e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 672, It: 0, Loss Data: 7.587e-01, Loss Eqns: 3.468e+00, Loss Aux: 9.014e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 673, It: 0, Loss Data: 7.814e-01, Loss Eqns: 3.330e+00, Loss Aux: 1.087e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 674, It: 0, Loss Data: 6.622e-01, Loss Eqns: 3.566e+00, Loss Aux: 7.799e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 675, It: 0, Loss Data: 7.824e-01, Loss Eqns: 3.187e+00, Loss Aux: 7.491e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 676, It: 0, Loss Data: 6.764e-01, Loss Eqns: 3.805e+00, Loss Aux: 8.085e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 677, It: 0, Loss Data: 8.288e-01, Loss Eqns: 3.502e+00, Loss Aux: 6.014e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 678, It: 0, Loss Data: 7.363e-01, Loss Eqns: 3.544e+00, Loss Aux: 4.985e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 679, It: 0, Loss Data: 6.676e-01, Loss Eqns: 3.410e+00, Loss Aux: 7.537e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 680, It: 0, Loss Data: 7.293e-01, Loss Eqns: 3.752e+00, Loss Aux: 7.666e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 681, It: 0, Loss Data: 7.037e-01, Loss Eqns: 3.865e+00, Loss Aux: 6.651e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 682, It: 0, Loss Data: 8.101e-01, Loss Eqns: 3.725e+00, Loss Aux: 8.847e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 683, It: 0, Loss Data: 7.247e-01, Loss Eqns: 3.095e+00, Loss Aux: 9.710e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 684, It: 0, Loss Data: 7.677e-01, Loss Eqns: 4.019e+00, Loss Aux: 8.041e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 685, It: 0, Loss Data: 6.995e-01, Loss Eqns: 3.397e+00, Loss Aux: 8.025e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 686, It: 0, Loss Data: 7.133e-01, Loss Eqns: 3.816e+00, Loss Aux: 7.464e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 687, It: 0, Loss Data: 7.760e-01, Loss Eqns: 3.730e+00, Loss Aux: 3.447e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 688, It: 0, Loss Data: 7.649e-01, Loss Eqns: 4.158e+00, Loss Aux: 7.920e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 689, It: 0, Loss Data: 7.595e-01, Loss Eqns: 3.384e+00, Loss Aux: 5.944e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 690, It: 0, Loss Data: 7.369e-01, Loss Eqns: 3.636e+00, Loss Aux: 1.049e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 691, It: 0, Loss Data: 7.594e-01, Loss Eqns: 3.452e+00, Loss Aux: 7.913e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 692, It: 0, Loss Data: 6.919e-01, Loss Eqns: 3.523e+00, Loss Aux: 1.031e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 693, It: 0, Loss Data: 6.986e-01, Loss Eqns: 3.743e+00, Loss Aux: 4.940e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 694, It: 0, Loss Data: 7.071e-01, Loss Eqns: 3.279e+00, Loss Aux: 5.915e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 695, It: 0, Loss Data: 7.798e-01, Loss Eqns: 3.384e+00, Loss Aux: 8.620e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 696, It: 0, Loss Data: 6.688e-01, Loss Eqns: 3.311e+00, Loss Aux: 4.465e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 697, It: 0, Loss Data: 7.795e-01, Loss Eqns: 3.290e+00, Loss Aux: 5.503e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 698, It: 0, Loss Data: 6.997e-01, Loss Eqns: 3.583e+00, Loss Aux: 5.936e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 699, It: 0, Loss Data: 8.358e-01, Loss Eqns: 3.107e+00, Loss Aux: 5.604e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 700, It: 0, Loss Data: 7.438e-01, Loss Eqns: 3.347e+00, Loss Aux: 4.435e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 701, It: 0, Loss Data: 6.382e-01, Loss Eqns: 3.378e+00, Loss Aux: 4.455e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 702, It: 0, Loss Data: 7.762e-01, Loss Eqns: 3.443e+00, Loss Aux: 4.905e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 703, It: 0, Loss Data: 7.506e-01, Loss Eqns: 3.722e+00, Loss Aux: 5.720e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 704, It: 0, Loss Data: 7.273e-01, Loss Eqns: 3.421e+00, Loss Aux: 5.679e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 705, It: 0, Loss Data: 8.124e-01, Loss Eqns: 3.715e+00, Loss Aux: 6.336e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 706, It: 0, Loss Data: 7.292e-01, Loss Eqns: 3.914e+00, Loss Aux: 9.559e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 707, It: 0, Loss Data: 7.592e-01, Loss Eqns: 2.995e+00, Loss Aux: 5.836e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 708, It: 0, Loss Data: 7.327e-01, Loss Eqns: 3.424e+00, Loss Aux: 5.455e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 709, It: 0, Loss Data: 7.136e-01, Loss Eqns: 3.752e+00, Loss Aux: 1.841e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 710, It: 0, Loss Data: 8.858e-01, Loss Eqns: 5.398e+00, Loss Aux: 1.123e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 711, It: 0, Loss Data: 7.375e-01, Loss Eqns: 3.745e+00, Loss Aux: 1.608e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 712, It: 0, Loss Data: 7.590e-01, Loss Eqns: 4.182e+00, Loss Aux: 2.031e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 713, It: 0, Loss Data: 7.593e-01, Loss Eqns: 4.157e+00, Loss Aux: 3.565e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 714, It: 0, Loss Data: 6.746e-01, Loss Eqns: 3.884e+00, Loss Aux: 3.568e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 715, It: 0, Loss Data: 8.543e-01, Loss Eqns: 3.603e+00, Loss Aux: 1.944e-01, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 716, It: 0, Loss Data: 6.601e-01, Loss Eqns: 3.457e+00, Loss Aux: 6.887e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 717, It: 0, Loss Data: 7.822e-01, Loss Eqns: 4.596e+00, Loss Aux: 1.892e-01, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 718, It: 0, Loss Data: 7.586e-01, Loss Eqns: 3.447e+00, Loss Aux: 1.383e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 719, It: 0, Loss Data: 8.067e-01, Loss Eqns: 4.481e+00, Loss Aux: 3.206e-01, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 720, It: 0, Loss Data: 7.670e-01, Loss Eqns: 3.551e+00, Loss Aux: 5.450e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 721, It: 0, Loss Data: 7.398e-01, Loss Eqns: 3.745e+00, Loss Aux: 5.545e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 722, It: 0, Loss Data: 8.021e-01, Loss Eqns: 2.821e+00, Loss Aux: 8.960e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 723, It: 0, Loss Data: 8.653e-01, Loss Eqns: 3.318e+00, Loss Aux: 1.501e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 724, It: 0, Loss Data: 7.505e-01, Loss Eqns: 3.229e+00, Loss Aux: 5.911e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 725, It: 0, Loss Data: 7.600e-01, Loss Eqns: 3.028e+00, Loss Aux: 4.655e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 726, It: 0, Loss Data: 7.253e-01, Loss Eqns: 3.384e+00, Loss Aux: 1.166e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 727, It: 0, Loss Data: 6.755e-01, Loss Eqns: 3.409e+00, Loss Aux: 8.742e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 728, It: 0, Loss Data: 7.188e-01, Loss Eqns: 3.628e+00, Loss Aux: 6.233e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 729, It: 0, Loss Data: 6.889e-01, Loss Eqns: 3.639e+00, Loss Aux: 9.022e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 730, It: 0, Loss Data: 7.382e-01, Loss Eqns: 3.125e+00, Loss Aux: 1.237e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 731, It: 0, Loss Data: 7.398e-01, Loss Eqns: 3.380e+00, Loss Aux: 6.524e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 732, It: 0, Loss Data: 8.158e-01, Loss Eqns: 3.235e+00, Loss Aux: 3.945e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 733, It: 0, Loss Data: 6.911e-01, Loss Eqns: 3.425e+00, Loss Aux: 6.375e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 734, It: 0, Loss Data: 7.570e-01, Loss Eqns: 3.382e+00, Loss Aux: 8.528e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 735, It: 0, Loss Data: 6.783e-01, Loss Eqns: 3.435e+00, Loss Aux: 4.526e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 736, It: 0, Loss Data: 6.763e-01, Loss Eqns: 3.298e+00, Loss Aux: 9.181e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 737, It: 0, Loss Data: 6.684e-01, Loss Eqns: 3.083e+00, Loss Aux: 1.215e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 738, It: 0, Loss Data: 7.627e-01, Loss Eqns: 3.692e+00, Loss Aux: 9.114e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 739, It: 0, Loss Data: 6.922e-01, Loss Eqns: 3.616e+00, Loss Aux: 5.128e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 740, It: 0, Loss Data: 6.890e-01, Loss Eqns: 3.742e+00, Loss Aux: 1.001e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 741, It: 0, Loss Data: 7.197e-01, Loss Eqns: 4.011e+00, Loss Aux: 9.131e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 742, It: 0, Loss Data: 6.510e-01, Loss Eqns: 3.792e+00, Loss Aux: 9.218e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 743, It: 0, Loss Data: 7.382e-01, Loss Eqns: 3.687e+00, Loss Aux: 1.085e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 744, It: 0, Loss Data: 6.586e-01, Loss Eqns: 3.288e+00, Loss Aux: 1.104e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 745, It: 0, Loss Data: 6.913e-01, Loss Eqns: 3.805e+00, Loss Aux: 1.211e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 746, It: 0, Loss Data: 7.151e-01, Loss Eqns: 4.199e+00, Loss Aux: 8.017e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 747, It: 0, Loss Data: 6.167e-01, Loss Eqns: 3.535e+00, Loss Aux: 1.065e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 748, It: 0, Loss Data: 7.282e-01, Loss Eqns: 4.219e+00, Loss Aux: 8.315e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 749, It: 0, Loss Data: 7.458e-01, Loss Eqns: 3.382e+00, Loss Aux: 9.186e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 750, It: 0, Loss Data: 6.575e-01, Loss Eqns: 3.579e+00, Loss Aux: 1.040e-01, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 751, It: 0, Loss Data: 6.727e-01, Loss Eqns: 3.683e+00, Loss Aux: 7.576e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 752, It: 0, Loss Data: 6.883e-01, Loss Eqns: 3.396e+00, Loss Aux: 7.858e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 753, It: 0, Loss Data: 7.137e-01, Loss Eqns: 4.268e+00, Loss Aux: 4.611e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 754, It: 0, Loss Data: 6.838e-01, Loss Eqns: 3.625e+00, Loss Aux: 3.626e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 755, It: 0, Loss Data: 6.023e-01, Loss Eqns: 3.007e+00, Loss Aux: 4.911e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 756, It: 0, Loss Data: 6.639e-01, Loss Eqns: 3.131e+00, Loss Aux: 1.118e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 757, It: 0, Loss Data: 6.154e-01, Loss Eqns: 3.520e+00, Loss Aux: 7.239e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 758, It: 0, Loss Data: 5.943e-01, Loss Eqns: 3.407e+00, Loss Aux: 6.634e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 759, It: 0, Loss Data: 6.613e-01, Loss Eqns: 3.415e+00, Loss Aux: 1.070e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 760, It: 0, Loss Data: 6.706e-01, Loss Eqns: 3.303e+00, Loss Aux: 5.061e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 761, It: 0, Loss Data: 6.789e-01, Loss Eqns: 3.378e+00, Loss Aux: 3.758e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 762, It: 0, Loss Data: 5.854e-01, Loss Eqns: 3.832e+00, Loss Aux: 8.175e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 763, It: 0, Loss Data: 5.914e-01, Loss Eqns: 3.692e+00, Loss Aux: 1.135e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 764, It: 0, Loss Data: 6.663e-01, Loss Eqns: 3.504e+00, Loss Aux: 6.969e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 765, It: 0, Loss Data: 5.645e-01, Loss Eqns: 3.548e+00, Loss Aux: 8.948e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 766, It: 0, Loss Data: 6.279e-01, Loss Eqns: 3.550e+00, Loss Aux: 8.708e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 767, It: 0, Loss Data: 6.952e-01, Loss Eqns: 3.838e+00, Loss Aux: 4.177e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 768, It: 0, Loss Data: 6.806e-01, Loss Eqns: 3.798e+00, Loss Aux: 6.309e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 769, It: 0, Loss Data: 6.243e-01, Loss Eqns: 3.501e+00, Loss Aux: 4.375e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 770, It: 0, Loss Data: 5.927e-01, Loss Eqns: 3.378e+00, Loss Aux: 7.175e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 771, It: 0, Loss Data: 6.585e-01, Loss Eqns: 3.103e+00, Loss Aux: 9.401e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 772, It: 0, Loss Data: 6.561e-01, Loss Eqns: 3.358e+00, Loss Aux: 9.618e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 773, It: 0, Loss Data: 6.063e-01, Loss Eqns: 3.298e+00, Loss Aux: 8.753e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 774, It: 0, Loss Data: 6.046e-01, Loss Eqns: 3.711e+00, Loss Aux: 1.016e-01, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 775, It: 0, Loss Data: 6.404e-01, Loss Eqns: 3.713e+00, Loss Aux: 8.573e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 776, It: 0, Loss Data: 6.597e-01, Loss Eqns: 3.575e+00, Loss Aux: 2.869e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 777, It: 0, Loss Data: 6.044e-01, Loss Eqns: 3.223e+00, Loss Aux: 6.174e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 778, It: 0, Loss Data: 6.122e-01, Loss Eqns: 3.152e+00, Loss Aux: 5.006e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 779, It: 0, Loss Data: 5.331e-01, Loss Eqns: 3.533e+00, Loss Aux: 4.688e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 780, It: 0, Loss Data: 5.962e-01, Loss Eqns: 3.621e+00, Loss Aux: 1.038e-01, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 781, It: 0, Loss Data: 6.059e-01, Loss Eqns: 3.414e+00, Loss Aux: 1.172e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 782, It: 0, Loss Data: 5.323e-01, Loss Eqns: 3.875e+00, Loss Aux: 4.782e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 783, It: 0, Loss Data: 6.006e-01, Loss Eqns: 3.816e+00, Loss Aux: 1.140e-01, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 784, It: 0, Loss Data: 5.597e-01, Loss Eqns: 3.547e+00, Loss Aux: 1.300e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 785, It: 0, Loss Data: 5.819e-01, Loss Eqns: 3.621e+00, Loss Aux: 6.285e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 786, It: 0, Loss Data: 5.993e-01, Loss Eqns: 3.513e+00, Loss Aux: 2.097e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 787, It: 0, Loss Data: 6.149e-01, Loss Eqns: 3.293e+00, Loss Aux: 8.296e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 788, It: 0, Loss Data: 6.206e-01, Loss Eqns: 3.424e+00, Loss Aux: 1.001e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 789, It: 0, Loss Data: 5.544e-01, Loss Eqns: 3.133e+00, Loss Aux: 8.054e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 790, It: 0, Loss Data: 5.519e-01, Loss Eqns: 4.038e+00, Loss Aux: 4.622e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 791, It: 0, Loss Data: 6.172e-01, Loss Eqns: 3.355e+00, Loss Aux: 7.988e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 792, It: 0, Loss Data: 5.807e-01, Loss Eqns: 4.132e+00, Loss Aux: 1.088e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 793, It: 0, Loss Data: 5.617e-01, Loss Eqns: 3.592e+00, Loss Aux: 1.232e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 794, It: 0, Loss Data: 5.897e-01, Loss Eqns: 3.705e+00, Loss Aux: 1.356e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 795, It: 0, Loss Data: 5.806e-01, Loss Eqns: 3.540e+00, Loss Aux: 1.142e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 796, It: 0, Loss Data: 5.294e-01, Loss Eqns: 3.591e+00, Loss Aux: 4.109e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 797, It: 0, Loss Data: 5.431e-01, Loss Eqns: 3.393e+00, Loss Aux: 2.037e-01, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 798, It: 0, Loss Data: 4.900e-01, Loss Eqns: 3.459e+00, Loss Aux: 1.083e-01, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 799, It: 0, Loss Data: 5.407e-01, Loss Eqns: 3.795e+00, Loss Aux: 6.940e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 800, It: 0, Loss Data: 5.478e-01, Loss Eqns: 3.794e+00, Loss Aux: 4.727e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 801, It: 0, Loss Data: 5.304e-01, Loss Eqns: 3.744e+00, Loss Aux: 1.045e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 802, It: 0, Loss Data: 5.277e-01, Loss Eqns: 3.996e+00, Loss Aux: 9.483e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 803, It: 0, Loss Data: 6.318e-01, Loss Eqns: 3.662e+00, Loss Aux: 1.202e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 804, It: 0, Loss Data: 4.783e-01, Loss Eqns: 3.831e+00, Loss Aux: 1.865e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 805, It: 0, Loss Data: 4.528e-01, Loss Eqns: 4.266e+00, Loss Aux: 7.991e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 806, It: 0, Loss Data: 5.574e-01, Loss Eqns: 3.474e+00, Loss Aux: 1.200e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 807, It: 0, Loss Data: 7.709e-01, Loss Eqns: 7.021e+00, Loss Aux: 4.797e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 808, It: 0, Loss Data: 5.355e-01, Loss Eqns: 3.590e+00, Loss Aux: 1.315e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 809, It: 0, Loss Data: 7.249e-01, Loss Eqns: 4.808e+00, Loss Aux: 1.403e-01, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 810, It: 0, Loss Data: 6.746e-01, Loss Eqns: 4.814e+00, Loss Aux: 5.787e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 811, It: 0, Loss Data: 7.020e-01, Loss Eqns: 6.827e+00, Loss Aux: 6.618e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 812, It: 0, Loss Data: 5.270e-01, Loss Eqns: 3.704e+00, Loss Aux: 1.929e-01, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 813, It: 0, Loss Data: 7.039e-01, Loss Eqns: 4.437e+00, Loss Aux: 5.830e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 814, It: 0, Loss Data: 6.474e-01, Loss Eqns: 6.012e+00, Loss Aux: 1.663e-01, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 815, It: 0, Loss Data: 5.651e-01, Loss Eqns: 4.001e+00, Loss Aux: 2.132e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 816, It: 0, Loss Data: 5.455e-01, Loss Eqns: 3.900e+00, Loss Aux: 1.517e-01, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 817, It: 0, Loss Data: 5.690e-01, Loss Eqns: 4.249e+00, Loss Aux: 7.365e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 818, It: 0, Loss Data: 5.889e-01, Loss Eqns: 3.430e+00, Loss Aux: 1.507e-01, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 819, It: 0, Loss Data: 6.782e-01, Loss Eqns: 3.443e+00, Loss Aux: 1.671e-01, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 820, It: 0, Loss Data: 5.631e-01, Loss Eqns: 3.299e+00, Loss Aux: 6.957e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 821, It: 0, Loss Data: 5.410e-01, Loss Eqns: 4.005e+00, Loss Aux: 4.908e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 822, It: 0, Loss Data: 6.232e-01, Loss Eqns: 4.658e+00, Loss Aux: 2.691e-01, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 823, It: 0, Loss Data: 5.529e-01, Loss Eqns: 4.502e+00, Loss Aux: 1.048e-01, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 824, It: 0, Loss Data: 6.301e-01, Loss Eqns: 5.922e+00, Loss Aux: 5.457e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 825, It: 0, Loss Data: 5.834e-01, Loss Eqns: 4.009e+00, Loss Aux: 1.795e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 826, It: 0, Loss Data: 5.914e-01, Loss Eqns: 4.939e+00, Loss Aux: 1.110e-01, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 827, It: 0, Loss Data: 7.089e-01, Loss Eqns: 5.121e+00, Loss Aux: 2.935e-01, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 828, It: 0, Loss Data: 6.715e-01, Loss Eqns: 5.880e+00, Loss Aux: 6.521e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 829, It: 0, Loss Data: 6.116e-01, Loss Eqns: 3.608e+00, Loss Aux: 4.205e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 830, It: 0, Loss Data: 7.935e-01, Loss Eqns: 5.183e+00, Loss Aux: 4.518e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 831, It: 0, Loss Data: 6.770e-01, Loss Eqns: 5.052e+00, Loss Aux: 1.978e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 832, It: 0, Loss Data: 6.097e-01, Loss Eqns: 4.406e+00, Loss Aux: 6.287e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 833, It: 0, Loss Data: 7.824e-01, Loss Eqns: 5.657e+00, Loss Aux: 7.932e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 834, It: 0, Loss Data: 5.354e-01, Loss Eqns: 3.434e+00, Loss Aux: 2.428e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 835, It: 0, Loss Data: 5.980e-01, Loss Eqns: 5.315e+00, Loss Aux: 2.295e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 836, It: 0, Loss Data: 5.442e-01, Loss Eqns: 5.665e+00, Loss Aux: 1.398e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 837, It: 0, Loss Data: 5.362e-01, Loss Eqns: 4.737e+00, Loss Aux: 1.073e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 838, It: 0, Loss Data: 5.894e-01, Loss Eqns: 4.109e+00, Loss Aux: 8.182e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 839, It: 0, Loss Data: 5.046e-01, Loss Eqns: 4.848e+00, Loss Aux: 7.952e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 840, It: 0, Loss Data: 5.370e-01, Loss Eqns: 5.037e+00, Loss Aux: 1.104e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 841, It: 0, Loss Data: 5.538e-01, Loss Eqns: 4.364e+00, Loss Aux: 1.332e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 842, It: 0, Loss Data: 5.032e-01, Loss Eqns: 4.219e+00, Loss Aux: 1.400e-01, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 843, It: 0, Loss Data: 5.996e-01, Loss Eqns: 5.253e+00, Loss Aux: 7.007e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 844, It: 0, Loss Data: 5.918e-01, Loss Eqns: 5.602e+00, Loss Aux: 3.946e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 845, It: 0, Loss Data: 6.816e-01, Loss Eqns: 4.248e+00, Loss Aux: 1.312e-01, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 846, It: 0, Loss Data: 7.091e-01, Loss Eqns: 4.915e+00, Loss Aux: 8.320e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 847, It: 0, Loss Data: 6.933e-01, Loss Eqns: 4.278e+00, Loss Aux: 8.286e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 848, It: 0, Loss Data: 6.499e-01, Loss Eqns: 6.222e+00, Loss Aux: 9.212e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 849, It: 0, Loss Data: 6.170e-01, Loss Eqns: 4.575e+00, Loss Aux: 2.044e-01, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 850, It: 0, Loss Data: 5.474e-01, Loss Eqns: 3.846e+00, Loss Aux: 1.749e-01, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 851, It: 0, Loss Data: 6.251e-01, Loss Eqns: 4.284e+00, Loss Aux: 5.959e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 852, It: 0, Loss Data: 5.967e-01, Loss Eqns: 4.034e+00, Loss Aux: 4.981e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 853, It: 0, Loss Data: 6.189e-01, Loss Eqns: 3.585e+00, Loss Aux: 9.084e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 854, It: 0, Loss Data: 6.730e-01, Loss Eqns: 3.235e+00, Loss Aux: 1.334e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 855, It: 0, Loss Data: 5.827e-01, Loss Eqns: 3.125e+00, Loss Aux: 8.041e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 856, It: 0, Loss Data: 6.863e-01, Loss Eqns: 3.292e+00, Loss Aux: 8.168e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 857, It: 0, Loss Data: 5.676e-01, Loss Eqns: 3.538e+00, Loss Aux: 3.170e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 858, It: 0, Loss Data: 5.647e-01, Loss Eqns: 3.148e+00, Loss Aux: 1.710e-01, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 859, It: 0, Loss Data: 5.464e-01, Loss Eqns: 3.557e+00, Loss Aux: 2.116e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 860, It: 0, Loss Data: 4.590e-01, Loss Eqns: 3.977e+00, Loss Aux: 8.282e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 861, It: 0, Loss Data: 4.843e-01, Loss Eqns: 4.127e+00, Loss Aux: 1.952e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 862, It: 0, Loss Data: 5.022e-01, Loss Eqns: 3.731e+00, Loss Aux: 4.221e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 863, It: 0, Loss Data: 4.764e-01, Loss Eqns: 3.646e+00, Loss Aux: 1.254e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 864, It: 0, Loss Data: 5.075e-01, Loss Eqns: 4.247e+00, Loss Aux: 1.098e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 865, It: 0, Loss Data: 5.198e-01, Loss Eqns: 3.752e+00, Loss Aux: 8.455e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 866, It: 0, Loss Data: 5.107e-01, Loss Eqns: 4.195e+00, Loss Aux: 5.516e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 867, It: 0, Loss Data: 5.124e-01, Loss Eqns: 3.879e+00, Loss Aux: 4.784e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 868, It: 0, Loss Data: 4.359e-01, Loss Eqns: 4.073e+00, Loss Aux: 6.265e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 869, It: 0, Loss Data: 4.730e-01, Loss Eqns: 4.014e+00, Loss Aux: 1.097e-01, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 870, It: 0, Loss Data: 4.731e-01, Loss Eqns: 3.989e+00, Loss Aux: 6.017e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 871, It: 0, Loss Data: 3.685e-01, Loss Eqns: 4.048e+00, Loss Aux: 6.543e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 872, It: 0, Loss Data: 4.425e-01, Loss Eqns: 4.186e+00, Loss Aux: 5.796e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 873, It: 0, Loss Data: 3.602e-01, Loss Eqns: 4.565e+00, Loss Aux: 4.647e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 874, It: 0, Loss Data: 3.591e-01, Loss Eqns: 4.361e+00, Loss Aux: 7.045e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 875, It: 0, Loss Data: 3.673e-01, Loss Eqns: 4.215e+00, Loss Aux: 5.813e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 876, It: 0, Loss Data: 3.893e-01, Loss Eqns: 4.353e+00, Loss Aux: 4.803e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 877, It: 0, Loss Data: 4.490e-01, Loss Eqns: 5.118e+00, Loss Aux: 6.812e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 878, It: 0, Loss Data: 8.560e-01, Loss Eqns: 6.262e+00, Loss Aux: 8.375e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 879, It: 0, Loss Data: 5.635e-01, Loss Eqns: 4.065e+00, Loss Aux: 1.817e-01, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 880, It: 0, Loss Data: 7.356e-01, Loss Eqns: 5.809e+00, Loss Aux: 3.927e-01, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 881, It: 0, Loss Data: 4.395e-01, Loss Eqns: 4.296e+00, Loss Aux: 1.861e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 882, It: 0, Loss Data: 6.641e-01, Loss Eqns: 4.644e+00, Loss Aux: 3.307e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 883, It: 0, Loss Data: 6.041e-01, Loss Eqns: 6.051e+00, Loss Aux: 4.436e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 884, It: 0, Loss Data: 5.268e-01, Loss Eqns: 3.845e+00, Loss Aux: 2.545e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 885, It: 0, Loss Data: 6.190e-01, Loss Eqns: 4.415e+00, Loss Aux: 4.169e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 886, It: 0, Loss Data: 5.224e-01, Loss Eqns: 4.473e+00, Loss Aux: 5.188e-01, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 887, It: 0, Loss Data: 5.322e-01, Loss Eqns: 4.828e+00, Loss Aux: 3.974e-01, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 888, It: 0, Loss Data: 5.279e-01, Loss Eqns: 4.492e+00, Loss Aux: 1.710e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 889, It: 0, Loss Data: 5.400e-01, Loss Eqns: 4.723e+00, Loss Aux: 7.838e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 890, It: 0, Loss Data: 5.718e-01, Loss Eqns: 4.212e+00, Loss Aux: 6.026e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 891, It: 0, Loss Data: 4.213e-01, Loss Eqns: 4.009e+00, Loss Aux: 9.051e-02, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 892, It: 0, Loss Data: 5.712e-01, Loss Eqns: 3.690e+00, Loss Aux: 1.839e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 893, It: 0, Loss Data: 4.160e-01, Loss Eqns: 4.104e+00, Loss Aux: 1.145e-01, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 894, It: 0, Loss Data: 4.377e-01, Loss Eqns: 3.936e+00, Loss Aux: 9.411e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 895, It: 0, Loss Data: 4.332e-01, Loss Eqns: 4.368e+00, Loss Aux: 7.075e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 896, It: 0, Loss Data: 4.042e-01, Loss Eqns: 4.157e+00, Loss Aux: 7.623e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 897, It: 0, Loss Data: 4.302e-01, Loss Eqns: 4.226e+00, Loss Aux: 1.086e-01, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 898, It: 0, Loss Data: 4.202e-01, Loss Eqns: 4.605e+00, Loss Aux: 1.013e-01, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 899, It: 0, Loss Data: 4.258e-01, Loss Eqns: 4.559e+00, Loss Aux: 9.534e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 900, It: 0, Loss Data: 3.539e-01, Loss Eqns: 4.331e+00, Loss Aux: 1.009e-01, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 901, It: 0, Loss Data: 3.971e-01, Loss Eqns: 4.487e+00, Loss Aux: 1.346e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 902, It: 0, Loss Data: 3.910e-01, Loss Eqns: 3.902e+00, Loss Aux: 1.290e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 903, It: 0, Loss Data: 3.238e-01, Loss Eqns: 4.051e+00, Loss Aux: 9.064e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 904, It: 0, Loss Data: 4.172e-01, Loss Eqns: 4.097e+00, Loss Aux: 6.763e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 905, It: 0, Loss Data: 3.546e-01, Loss Eqns: 4.157e+00, Loss Aux: 7.225e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 906, It: 0, Loss Data: 4.316e-01, Loss Eqns: 4.554e+00, Loss Aux: 9.334e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 907, It: 0, Loss Data: 3.204e-01, Loss Eqns: 4.158e+00, Loss Aux: 4.641e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 908, It: 0, Loss Data: 3.975e-01, Loss Eqns: 4.465e+00, Loss Aux: 4.283e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 909, It: 0, Loss Data: 3.421e-01, Loss Eqns: 4.316e+00, Loss Aux: 1.182e-01, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 910, It: 0, Loss Data: 3.650e-01, Loss Eqns: 4.548e+00, Loss Aux: 1.985e-01, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 911, It: 0, Loss Data: 2.843e-01, Loss Eqns: 4.480e+00, Loss Aux: 1.173e-01, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 912, It: 0, Loss Data: 3.263e-01, Loss Eqns: 4.172e+00, Loss Aux: 4.473e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 913, It: 0, Loss Data: 3.083e-01, Loss Eqns: 4.494e+00, Loss Aux: 3.818e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 914, It: 0, Loss Data: 2.762e-01, Loss Eqns: 4.439e+00, Loss Aux: 6.742e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 915, It: 0, Loss Data: 3.205e-01, Loss Eqns: 4.639e+00, Loss Aux: 1.022e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 916, It: 0, Loss Data: 3.064e-01, Loss Eqns: 4.530e+00, Loss Aux: 6.784e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 917, It: 0, Loss Data: 3.217e-01, Loss Eqns: 4.710e+00, Loss Aux: 6.773e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 918, It: 0, Loss Data: 2.992e-01, Loss Eqns: 4.288e+00, Loss Aux: 6.692e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 919, It: 0, Loss Data: 2.809e-01, Loss Eqns: 4.757e+00, Loss Aux: 8.952e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 920, It: 0, Loss Data: 2.971e-01, Loss Eqns: 4.982e+00, Loss Aux: 8.317e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 921, It: 0, Loss Data: 2.799e-01, Loss Eqns: 5.006e+00, Loss Aux: 7.020e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 922, It: 0, Loss Data: 3.010e-01, Loss Eqns: 5.114e+00, Loss Aux: 5.559e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 923, It: 0, Loss Data: 2.941e-01, Loss Eqns: 4.538e+00, Loss Aux: 1.068e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 924, It: 0, Loss Data: 2.951e-01, Loss Eqns: 4.707e+00, Loss Aux: 7.684e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 925, It: 0, Loss Data: 2.836e-01, Loss Eqns: 4.079e+00, Loss Aux: 5.962e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 926, It: 0, Loss Data: 2.899e-01, Loss Eqns: 4.556e+00, Loss Aux: 5.768e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 927, It: 0, Loss Data: 2.457e-01, Loss Eqns: 4.590e+00, Loss Aux: 4.499e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 928, It: 0, Loss Data: 2.938e-01, Loss Eqns: 4.781e+00, Loss Aux: 4.783e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 929, It: 0, Loss Data: 2.620e-01, Loss Eqns: 4.370e+00, Loss Aux: 4.145e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 930, It: 0, Loss Data: 3.032e-01, Loss Eqns: 4.261e+00, Loss Aux: 3.690e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 931, It: 0, Loss Data: 2.598e-01, Loss Eqns: 4.540e+00, Loss Aux: 6.150e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 932, It: 0, Loss Data: 2.430e-01, Loss Eqns: 4.345e+00, Loss Aux: 9.945e-02, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 933, It: 0, Loss Data: 2.480e-01, Loss Eqns: 4.757e+00, Loss Aux: 5.974e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 934, It: 0, Loss Data: 3.193e-01, Loss Eqns: 4.572e+00, Loss Aux: 5.616e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 935, It: 0, Loss Data: 4.433e-01, Loss Eqns: 6.440e+00, Loss Aux: 6.486e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 936, It: 0, Loss Data: 8.897e-01, Loss Eqns: 6.944e+00, Loss Aux: 1.382e-01, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 937, It: 0, Loss Data: 6.007e-01, Loss Eqns: 4.655e+00, Loss Aux: 7.215e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 938, It: 0, Loss Data: 7.941e-01, Loss Eqns: 5.863e+00, Loss Aux: 3.902e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 939, It: 0, Loss Data: 7.007e-01, Loss Eqns: 5.485e+00, Loss Aux: 6.450e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 940, It: 0, Loss Data: 5.374e-01, Loss Eqns: 5.514e+00, Loss Aux: 1.359e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 941, It: 0, Loss Data: 7.608e-01, Loss Eqns: 5.056e+00, Loss Aux: 7.965e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 942, It: 0, Loss Data: 5.998e-01, Loss Eqns: 4.142e+00, Loss Aux: 1.266e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 943, It: 0, Loss Data: 6.680e-01, Loss Eqns: 4.322e+00, Loss Aux: 9.816e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 944, It: 0, Loss Data: 5.736e-01, Loss Eqns: 3.492e+00, Loss Aux: 9.234e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 945, It: 0, Loss Data: 7.157e-01, Loss Eqns: 4.305e+00, Loss Aux: 3.871e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 946, It: 0, Loss Data: 6.234e-01, Loss Eqns: 4.803e+00, Loss Aux: 3.926e-01, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 947, It: 0, Loss Data: 6.315e-01, Loss Eqns: 4.046e+00, Loss Aux: 6.110e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 948, It: 0, Loss Data: 7.265e-01, Loss Eqns: 5.403e+00, Loss Aux: 3.219e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 949, It: 0, Loss Data: 5.485e-01, Loss Eqns: 3.594e+00, Loss Aux: 1.301e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 950, It: 0, Loss Data: 6.187e-01, Loss Eqns: 4.074e+00, Loss Aux: 2.108e-01, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 951, It: 0, Loss Data: 6.391e-01, Loss Eqns: 3.759e+00, Loss Aux: 9.413e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 952, It: 0, Loss Data: 5.822e-01, Loss Eqns: 3.422e+00, Loss Aux: 9.064e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 953, It: 0, Loss Data: 5.105e-01, Loss Eqns: 3.263e+00, Loss Aux: 4.091e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 954, It: 0, Loss Data: 5.298e-01, Loss Eqns: 3.310e+00, Loss Aux: 8.669e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 955, It: 0, Loss Data: 6.119e-01, Loss Eqns: 3.522e+00, Loss Aux: 1.777e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 956, It: 0, Loss Data: 5.177e-01, Loss Eqns: 3.376e+00, Loss Aux: 1.558e-01, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 957, It: 0, Loss Data: 5.968e-01, Loss Eqns: 3.924e+00, Loss Aux: 1.144e-01, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 958, It: 0, Loss Data: 5.361e-01, Loss Eqns: 3.598e+00, Loss Aux: 1.099e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 959, It: 0, Loss Data: 5.807e-01, Loss Eqns: 3.296e+00, Loss Aux: 1.151e-01, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 960, It: 0, Loss Data: 4.839e-01, Loss Eqns: 3.979e+00, Loss Aux: 7.776e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 961, It: 0, Loss Data: 4.264e-01, Loss Eqns: 3.678e+00, Loss Aux: 5.546e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 962, It: 0, Loss Data: 4.424e-01, Loss Eqns: 3.948e+00, Loss Aux: 4.960e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 963, It: 0, Loss Data: 4.373e-01, Loss Eqns: 4.024e+00, Loss Aux: 3.761e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 964, It: 0, Loss Data: 4.272e-01, Loss Eqns: 3.572e+00, Loss Aux: 8.930e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 965, It: 0, Loss Data: 4.680e-01, Loss Eqns: 3.858e+00, Loss Aux: 1.189e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 966, It: 0, Loss Data: 4.369e-01, Loss Eqns: 4.082e+00, Loss Aux: 9.793e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 967, It: 0, Loss Data: 4.079e-01, Loss Eqns: 3.734e+00, Loss Aux: 8.225e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 968, It: 0, Loss Data: 4.002e-01, Loss Eqns: 4.546e+00, Loss Aux: 7.080e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 969, It: 0, Loss Data: 4.616e-01, Loss Eqns: 4.005e+00, Loss Aux: 5.332e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 970, It: 0, Loss Data: 4.376e-01, Loss Eqns: 3.721e+00, Loss Aux: 4.989e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 971, It: 0, Loss Data: 4.088e-01, Loss Eqns: 3.742e+00, Loss Aux: 6.108e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 972, It: 0, Loss Data: 4.619e-01, Loss Eqns: 4.138e+00, Loss Aux: 6.789e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 973, It: 0, Loss Data: 4.055e-01, Loss Eqns: 4.189e+00, Loss Aux: 4.888e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 974, It: 0, Loss Data: 4.244e-01, Loss Eqns: 3.921e+00, Loss Aux: 4.291e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 975, It: 0, Loss Data: 3.880e-01, Loss Eqns: 4.181e+00, Loss Aux: 3.981e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 976, It: 0, Loss Data: 3.479e-01, Loss Eqns: 4.281e+00, Loss Aux: 4.666e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 977, It: 0, Loss Data: 4.250e-01, Loss Eqns: 4.220e+00, Loss Aux: 5.626e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 978, It: 0, Loss Data: 3.749e-01, Loss Eqns: 3.763e+00, Loss Aux: 7.060e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 979, It: 0, Loss Data: 3.766e-01, Loss Eqns: 4.190e+00, Loss Aux: 7.424e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 980, It: 0, Loss Data: 4.486e-01, Loss Eqns: 4.392e+00, Loss Aux: 4.853e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 981, It: 0, Loss Data: 4.323e-01, Loss Eqns: 3.670e+00, Loss Aux: 4.108e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 982, It: 0, Loss Data: 4.122e-01, Loss Eqns: 4.111e+00, Loss Aux: 4.532e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 983, It: 0, Loss Data: 3.715e-01, Loss Eqns: 4.010e+00, Loss Aux: 5.812e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 984, It: 0, Loss Data: 3.682e-01, Loss Eqns: 4.117e+00, Loss Aux: 4.897e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 985, It: 0, Loss Data: 4.078e-01, Loss Eqns: 3.943e+00, Loss Aux: 4.291e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 986, It: 0, Loss Data: 3.913e-01, Loss Eqns: 4.188e+00, Loss Aux: 4.547e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 987, It: 0, Loss Data: 3.969e-01, Loss Eqns: 4.217e+00, Loss Aux: 4.432e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 988, It: 0, Loss Data: 3.791e-01, Loss Eqns: 3.942e+00, Loss Aux: 3.955e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 989, It: 0, Loss Data: 3.395e-01, Loss Eqns: 4.099e+00, Loss Aux: 4.338e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 990, It: 0, Loss Data: 3.835e-01, Loss Eqns: 3.986e+00, Loss Aux: 3.670e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 991, It: 0, Loss Data: 3.688e-01, Loss Eqns: 3.644e+00, Loss Aux: 3.842e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 992, It: 0, Loss Data: 3.646e-01, Loss Eqns: 4.079e+00, Loss Aux: 4.463e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 993, It: 0, Loss Data: 3.794e-01, Loss Eqns: 3.961e+00, Loss Aux: 4.559e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 994, It: 0, Loss Data: 3.120e-01, Loss Eqns: 3.993e+00, Loss Aux: 4.683e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 995, It: 0, Loss Data: 3.345e-01, Loss Eqns: 3.921e+00, Loss Aux: 4.765e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 996, It: 0, Loss Data: 3.367e-01, Loss Eqns: 4.167e+00, Loss Aux: 3.546e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 997, It: 0, Loss Data: 3.749e-01, Loss Eqns: 4.233e+00, Loss Aux: 2.788e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 998, It: 0, Loss Data: 3.283e-01, Loss Eqns: 4.071e+00, Loss Aux: 3.014e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 999, It: 0, Loss Data: 3.016e-01, Loss Eqns: 4.311e+00, Loss Aux: 5.407e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1000, It: 0, Loss Data: 3.664e-01, Loss Eqns: 3.922e+00, Loss Aux: 5.306e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1001, It: 0, Loss Data: 4.121e-01, Loss Eqns: 4.006e+00, Loss Aux: 5.104e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1002, It: 0, Loss Data: 4.108e-01, Loss Eqns: 3.935e+00, Loss Aux: 3.760e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1003, It: 0, Loss Data: 3.749e-01, Loss Eqns: 3.606e+00, Loss Aux: 4.340e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1004, It: 0, Loss Data: 3.826e-01, Loss Eqns: 3.957e+00, Loss Aux: 4.777e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 1005, It: 0, Loss Data: 3.316e-01, Loss Eqns: 3.993e+00, Loss Aux: 4.311e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1006, It: 0, Loss Data: 3.521e-01, Loss Eqns: 4.383e+00, Loss Aux: 4.208e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1007, It: 0, Loss Data: 4.144e-01, Loss Eqns: 4.113e+00, Loss Aux: 4.680e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1008, It: 0, Loss Data: 3.724e-01, Loss Eqns: 4.010e+00, Loss Aux: 3.812e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1009, It: 0, Loss Data: 3.395e-01, Loss Eqns: 3.875e+00, Loss Aux: 4.098e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1010, It: 0, Loss Data: 3.434e-01, Loss Eqns: 3.604e+00, Loss Aux: 5.828e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1011, It: 0, Loss Data: 3.477e-01, Loss Eqns: 4.169e+00, Loss Aux: 6.676e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1012, It: 0, Loss Data: 3.844e-01, Loss Eqns: 3.794e+00, Loss Aux: 4.411e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1013, It: 0, Loss Data: 3.306e-01, Loss Eqns: 3.942e+00, Loss Aux: 3.008e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1014, It: 0, Loss Data: 3.075e-01, Loss Eqns: 3.945e+00, Loss Aux: 2.733e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1015, It: 0, Loss Data: 3.774e-01, Loss Eqns: 3.990e+00, Loss Aux: 3.051e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1016, It: 0, Loss Data: 3.833e-01, Loss Eqns: 3.657e+00, Loss Aux: 4.117e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1017, It: 0, Loss Data: 3.561e-01, Loss Eqns: 3.632e+00, Loss Aux: 4.505e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1018, It: 0, Loss Data: 3.436e-01, Loss Eqns: 4.252e+00, Loss Aux: 4.317e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1019, It: 0, Loss Data: 3.959e-01, Loss Eqns: 3.942e+00, Loss Aux: 3.829e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1020, It: 0, Loss Data: 3.654e-01, Loss Eqns: 3.949e+00, Loss Aux: 3.431e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1021, It: 0, Loss Data: 3.735e-01, Loss Eqns: 3.884e+00, Loss Aux: 3.772e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1022, It: 0, Loss Data: 3.349e-01, Loss Eqns: 4.063e+00, Loss Aux: 5.384e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1023, It: 0, Loss Data: 3.557e-01, Loss Eqns: 4.116e+00, Loss Aux: 4.979e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1024, It: 0, Loss Data: 3.311e-01, Loss Eqns: 4.139e+00, Loss Aux: 3.427e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1025, It: 0, Loss Data: 3.151e-01, Loss Eqns: 4.200e+00, Loss Aux: 2.922e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1026, It: 0, Loss Data: 3.529e-01, Loss Eqns: 4.422e+00, Loss Aux: 3.528e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1027, It: 0, Loss Data: 3.179e-01, Loss Eqns: 4.481e+00, Loss Aux: 5.084e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1028, It: 0, Loss Data: 3.340e-01, Loss Eqns: 4.093e+00, Loss Aux: 4.451e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1029, It: 0, Loss Data: 3.559e-01, Loss Eqns: 3.891e+00, Loss Aux: 3.496e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1030, It: 0, Loss Data: 3.396e-01, Loss Eqns: 3.573e+00, Loss Aux: 2.782e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 1031, It: 0, Loss Data: 3.104e-01, Loss Eqns: 4.387e+00, Loss Aux: 2.834e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1032, It: 0, Loss Data: 3.403e-01, Loss Eqns: 4.142e+00, Loss Aux: 3.833e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1033, It: 0, Loss Data: 3.431e-01, Loss Eqns: 4.029e+00, Loss Aux: 5.338e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1034, It: 0, Loss Data: 3.479e-01, Loss Eqns: 3.974e+00, Loss Aux: 3.819e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1035, It: 0, Loss Data: 3.451e-01, Loss Eqns: 4.115e+00, Loss Aux: 4.241e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1036, It: 0, Loss Data: 3.492e-01, Loss Eqns: 4.108e+00, Loss Aux: 3.962e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1037, It: 0, Loss Data: 3.132e-01, Loss Eqns: 3.898e+00, Loss Aux: 4.112e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 1038, It: 0, Loss Data: 2.991e-01, Loss Eqns: 3.999e+00, Loss Aux: 5.995e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1039, It: 0, Loss Data: 2.668e-01, Loss Eqns: 4.257e+00, Loss Aux: 5.284e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1040, It: 0, Loss Data: 3.053e-01, Loss Eqns: 3.951e+00, Loss Aux: 2.630e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1041, It: 0, Loss Data: 3.307e-01, Loss Eqns: 4.087e+00, Loss Aux: 3.679e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1042, It: 0, Loss Data: 3.483e-01, Loss Eqns: 3.912e+00, Loss Aux: 4.121e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1043, It: 0, Loss Data: 3.663e-01, Loss Eqns: 4.244e+00, Loss Aux: 4.502e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1044, It: 0, Loss Data: 3.229e-01, Loss Eqns: 4.127e+00, Loss Aux: 5.910e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1045, It: 0, Loss Data: 3.071e-01, Loss Eqns: 3.790e+00, Loss Aux: 3.920e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1046, It: 0, Loss Data: 3.756e-01, Loss Eqns: 3.928e+00, Loss Aux: 3.037e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1047, It: 0, Loss Data: 2.863e-01, Loss Eqns: 4.067e+00, Loss Aux: 3.805e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1048, It: 0, Loss Data: 2.515e-01, Loss Eqns: 4.152e+00, Loss Aux: 4.087e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1049, It: 0, Loss Data: 3.231e-01, Loss Eqns: 4.221e+00, Loss Aux: 4.697e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1050, It: 0, Loss Data: 2.414e-01, Loss Eqns: 4.387e+00, Loss Aux: 3.506e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1051, It: 0, Loss Data: 3.137e-01, Loss Eqns: 4.241e+00, Loss Aux: 3.405e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1052, It: 0, Loss Data: 3.252e-01, Loss Eqns: 4.044e+00, Loss Aux: 3.468e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1053, It: 0, Loss Data: 2.950e-01, Loss Eqns: 3.717e+00, Loss Aux: 5.783e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1054, It: 0, Loss Data: 3.203e-01, Loss Eqns: 4.031e+00, Loss Aux: 5.915e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1055, It: 0, Loss Data: 3.217e-01, Loss Eqns: 4.164e+00, Loss Aux: 4.831e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1056, It: 0, Loss Data: 3.497e-01, Loss Eqns: 4.054e+00, Loss Aux: 3.822e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1057, It: 0, Loss Data: 3.689e-01, Loss Eqns: 4.054e+00, Loss Aux: 5.606e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1058, It: 0, Loss Data: 3.433e-01, Loss Eqns: 4.158e+00, Loss Aux: 3.719e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1059, It: 0, Loss Data: 2.949e-01, Loss Eqns: 4.164e+00, Loss Aux: 3.232e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1060, It: 0, Loss Data: 3.003e-01, Loss Eqns: 4.360e+00, Loss Aux: 3.447e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1061, It: 0, Loss Data: 3.335e-01, Loss Eqns: 3.987e+00, Loss Aux: 3.797e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1062, It: 0, Loss Data: 2.776e-01, Loss Eqns: 3.811e+00, Loss Aux: 4.126e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1063, It: 0, Loss Data: 2.774e-01, Loss Eqns: 4.426e+00, Loss Aux: 3.405e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1064, It: 0, Loss Data: 2.744e-01, Loss Eqns: 3.716e+00, Loss Aux: 2.317e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1065, It: 0, Loss Data: 2.610e-01, Loss Eqns: 4.337e+00, Loss Aux: 2.322e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1066, It: 0, Loss Data: 3.471e-01, Loss Eqns: 3.782e+00, Loss Aux: 2.607e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1067, It: 0, Loss Data: 3.052e-01, Loss Eqns: 4.202e+00, Loss Aux: 3.968e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1068, It: 0, Loss Data: 2.836e-01, Loss Eqns: 4.066e+00, Loss Aux: 4.515e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 1069, It: 0, Loss Data: 3.198e-01, Loss Eqns: 4.065e+00, Loss Aux: 4.156e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1070, It: 0, Loss Data: 3.069e-01, Loss Eqns: 4.160e+00, Loss Aux: 3.919e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1071, It: 0, Loss Data: 2.747e-01, Loss Eqns: 4.155e+00, Loss Aux: 4.027e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1072, It: 0, Loss Data: 2.921e-01, Loss Eqns: 3.880e+00, Loss Aux: 2.748e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1073, It: 0, Loss Data: 2.591e-01, Loss Eqns: 4.019e+00, Loss Aux: 3.107e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1074, It: 0, Loss Data: 2.539e-01, Loss Eqns: 4.096e+00, Loss Aux: 3.887e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 1075, It: 0, Loss Data: 3.348e-01, Loss Eqns: 3.903e+00, Loss Aux: 3.636e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 1076, It: 0, Loss Data: 2.704e-01, Loss Eqns: 3.921e+00, Loss Aux: 4.230e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1077, It: 0, Loss Data: 2.828e-01, Loss Eqns: 4.443e+00, Loss Aux: 3.691e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1078, It: 0, Loss Data: 3.044e-01, Loss Eqns: 4.052e+00, Loss Aux: 2.837e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1079, It: 0, Loss Data: 2.515e-01, Loss Eqns: 3.888e+00, Loss Aux: 2.533e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1080, It: 0, Loss Data: 2.741e-01, Loss Eqns: 4.071e+00, Loss Aux: 3.280e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1081, It: 0, Loss Data: 2.519e-01, Loss Eqns: 3.943e+00, Loss Aux: 3.700e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 1082, It: 0, Loss Data: 2.441e-01, Loss Eqns: 4.255e+00, Loss Aux: 3.642e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1083, It: 0, Loss Data: 2.719e-01, Loss Eqns: 4.770e+00, Loss Aux: 3.751e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 1084, It: 0, Loss Data: 2.698e-01, Loss Eqns: 4.061e+00, Loss Aux: 3.233e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1085, It: 0, Loss Data: 2.886e-01, Loss Eqns: 4.058e+00, Loss Aux: 3.396e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1086, It: 0, Loss Data: 2.835e-01, Loss Eqns: 4.019e+00, Loss Aux: 4.139e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 1087, It: 0, Loss Data: 2.469e-01, Loss Eqns: 4.072e+00, Loss Aux: 2.970e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1088, It: 0, Loss Data: 2.305e-01, Loss Eqns: 4.112e+00, Loss Aux: 2.771e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1089, It: 0, Loss Data: 2.808e-01, Loss Eqns: 4.182e+00, Loss Aux: 3.393e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1090, It: 0, Loss Data: 2.497e-01, Loss Eqns: 3.926e+00, Loss Aux: 3.630e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 1091, It: 0, Loss Data: 2.878e-01, Loss Eqns: 4.714e+00, Loss Aux: 6.017e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1092, It: 0, Loss Data: 3.078e-01, Loss Eqns: 4.150e+00, Loss Aux: 3.485e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1093, It: 0, Loss Data: 3.056e-01, Loss Eqns: 4.259e+00, Loss Aux: 3.905e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1094, It: 0, Loss Data: 2.668e-01, Loss Eqns: 4.329e+00, Loss Aux: 3.934e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1095, It: 0, Loss Data: 3.479e-01, Loss Eqns: 4.214e+00, Loss Aux: 5.581e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1096, It: 0, Loss Data: 3.718e-01, Loss Eqns: 3.918e+00, Loss Aux: 2.457e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1097, It: 0, Loss Data: 5.659e-01, Loss Eqns: 6.908e+00, Loss Aux: 2.141e-01, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 1098, It: 0, Loss Data: 4.493e-01, Loss Eqns: 6.081e+00, Loss Aux: 2.074e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1099, It: 0, Loss Data: 5.318e-01, Loss Eqns: 6.441e+00, Loss Aux: 2.766e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1100, It: 0, Loss Data: 4.046e-01, Loss Eqns: 4.698e+00, Loss Aux: 9.782e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1101, It: 0, Loss Data: 5.221e-01, Loss Eqns: 5.918e+00, Loss Aux: 2.141e-01, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1102, It: 0, Loss Data: 3.965e-01, Loss Eqns: 5.407e+00, Loss Aux: 2.897e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1103, It: 0, Loss Data: 4.651e-01, Loss Eqns: 5.374e+00, Loss Aux: 2.013e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1104, It: 0, Loss Data: 3.383e-01, Loss Eqns: 4.163e+00, Loss Aux: 2.456e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1105, It: 0, Loss Data: 4.691e-01, Loss Eqns: 5.986e+00, Loss Aux: 2.077e-01, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1106, It: 0, Loss Data: 3.476e-01, Loss Eqns: 3.809e+00, Loss Aux: 1.941e-01, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 1107, It: 0, Loss Data: 4.375e-01, Loss Eqns: 4.367e+00, Loss Aux: 5.038e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1108, It: 0, Loss Data: 3.951e-01, Loss Eqns: 3.682e+00, Loss Aux: 3.473e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 1109, It: 0, Loss Data: 3.655e-01, Loss Eqns: 4.204e+00, Loss Aux: 3.545e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1110, It: 0, Loss Data: 3.010e-01, Loss Eqns: 4.169e+00, Loss Aux: 4.826e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 1111, It: 0, Loss Data: 3.361e-01, Loss Eqns: 4.133e+00, Loss Aux: 3.716e-02, Time: 0.346, Learning Rate: 1.0e-03\n",
      "Epoch: 1112, It: 0, Loss Data: 2.668e-01, Loss Eqns: 4.382e+00, Loss Aux: 3.252e-02, Time: 0.373, Learning Rate: 1.0e-03\n",
      "Epoch: 1113, It: 0, Loss Data: 2.917e-01, Loss Eqns: 4.337e+00, Loss Aux: 4.794e-02, Time: 0.363, Learning Rate: 1.0e-03\n",
      "Epoch: 1114, It: 0, Loss Data: 3.496e-01, Loss Eqns: 4.178e+00, Loss Aux: 5.794e-02, Time: 0.335, Learning Rate: 1.0e-03\n",
      "Epoch: 1115, It: 0, Loss Data: 2.962e-01, Loss Eqns: 5.173e+00, Loss Aux: 4.048e-02, Time: 0.333, Learning Rate: 1.0e-03\n",
      "Epoch: 1116, It: 0, Loss Data: 3.063e-01, Loss Eqns: 4.643e+00, Loss Aux: 4.489e-02, Time: 0.330, Learning Rate: 1.0e-03\n",
      "Epoch: 1117, It: 0, Loss Data: 3.062e-01, Loss Eqns: 3.918e+00, Loss Aux: 5.242e-02, Time: 0.356, Learning Rate: 1.0e-03\n",
      "Epoch: 1118, It: 0, Loss Data: 2.682e-01, Loss Eqns: 4.524e+00, Loss Aux: 5.996e-02, Time: 0.433, Learning Rate: 1.0e-03\n",
      "Epoch: 1119, It: 0, Loss Data: 3.127e-01, Loss Eqns: 4.175e+00, Loss Aux: 6.187e-02, Time: 0.319, Learning Rate: 1.0e-03\n",
      "Epoch: 1120, It: 0, Loss Data: 2.782e-01, Loss Eqns: 3.845e+00, Loss Aux: 5.159e-02, Time: 0.347, Learning Rate: 1.0e-03\n",
      "Epoch: 1121, It: 0, Loss Data: 2.799e-01, Loss Eqns: 4.203e+00, Loss Aux: 3.233e-02, Time: 0.321, Learning Rate: 1.0e-03\n",
      "Epoch: 1122, It: 0, Loss Data: 2.924e-01, Loss Eqns: 4.687e+00, Loss Aux: 1.739e-02, Time: 0.324, Learning Rate: 1.0e-03\n",
      "Epoch: 1123, It: 0, Loss Data: 2.839e-01, Loss Eqns: 3.899e+00, Loss Aux: 3.146e-02, Time: 0.361, Learning Rate: 1.0e-03\n",
      "Epoch: 1124, It: 0, Loss Data: 2.853e-01, Loss Eqns: 3.926e+00, Loss Aux: 3.794e-02, Time: 0.354, Learning Rate: 1.0e-03\n",
      "Epoch: 1125, It: 0, Loss Data: 2.867e-01, Loss Eqns: 4.459e+00, Loss Aux: 8.179e-02, Time: 0.343, Learning Rate: 1.0e-03\n",
      "Epoch: 1126, It: 0, Loss Data: 2.572e-01, Loss Eqns: 4.046e+00, Loss Aux: 6.831e-02, Time: 0.318, Learning Rate: 1.0e-03\n",
      "Epoch: 1127, It: 0, Loss Data: 2.761e-01, Loss Eqns: 4.201e+00, Loss Aux: 3.350e-02, Time: 0.303, Learning Rate: 1.0e-03\n",
      "Epoch: 1128, It: 0, Loss Data: 3.054e-01, Loss Eqns: 4.529e+00, Loss Aux: 3.395e-02, Time: 0.351, Learning Rate: 1.0e-03\n",
      "Epoch: 1129, It: 0, Loss Data: 2.956e-01, Loss Eqns: 3.948e+00, Loss Aux: 5.102e-02, Time: 0.378, Learning Rate: 1.0e-03\n",
      "Epoch: 1130, It: 0, Loss Data: 2.251e-01, Loss Eqns: 3.827e+00, Loss Aux: 5.106e-02, Time: 0.329, Learning Rate: 1.0e-03\n",
      "Epoch: 1131, It: 0, Loss Data: 2.530e-01, Loss Eqns: 4.005e+00, Loss Aux: 3.833e-02, Time: 0.313, Learning Rate: 1.0e-03\n",
      "Epoch: 1132, It: 0, Loss Data: 2.341e-01, Loss Eqns: 3.811e+00, Loss Aux: 2.915e-02, Time: 0.356, Learning Rate: 1.0e-03\n",
      "Epoch: 1133, It: 0, Loss Data: 2.477e-01, Loss Eqns: 4.049e+00, Loss Aux: 4.663e-02, Time: 0.363, Learning Rate: 1.0e-03\n",
      "Epoch: 1134, It: 0, Loss Data: 2.277e-01, Loss Eqns: 4.332e+00, Loss Aux: 3.250e-02, Time: 0.341, Learning Rate: 1.0e-03\n",
      "Epoch: 1135, It: 0, Loss Data: 2.720e-01, Loss Eqns: 4.712e+00, Loss Aux: 2.852e-02, Time: 0.321, Learning Rate: 1.0e-03\n",
      "Epoch: 1136, It: 0, Loss Data: 2.211e-01, Loss Eqns: 4.136e+00, Loss Aux: 4.251e-02, Time: 0.352, Learning Rate: 1.0e-03\n",
      "Epoch: 1137, It: 0, Loss Data: 2.325e-01, Loss Eqns: 4.525e+00, Loss Aux: 5.936e-02, Time: 0.359, Learning Rate: 1.0e-03\n",
      "Epoch: 1138, It: 0, Loss Data: 2.224e-01, Loss Eqns: 4.029e+00, Loss Aux: 3.812e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1139, It: 0, Loss Data: 2.354e-01, Loss Eqns: 4.234e+00, Loss Aux: 2.714e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1140, It: 0, Loss Data: 2.345e-01, Loss Eqns: 4.244e+00, Loss Aux: 2.945e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1141, It: 0, Loss Data: 2.800e-01, Loss Eqns: 4.987e+00, Loss Aux: 3.808e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1142, It: 0, Loss Data: 2.605e-01, Loss Eqns: 4.367e+00, Loss Aux: 4.972e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1143, It: 0, Loss Data: 3.725e-01, Loss Eqns: 5.417e+00, Loss Aux: 4.946e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1144, It: 0, Loss Data: 4.108e-01, Loss Eqns: 6.813e+00, Loss Aux: 3.862e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1145, It: 0, Loss Data: 4.096e-01, Loss Eqns: 5.042e+00, Loss Aux: 1.456e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1146, It: 0, Loss Data: 5.361e-01, Loss Eqns: 6.045e+00, Loss Aux: 4.399e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1147, It: 0, Loss Data: 4.986e-01, Loss Eqns: 4.349e+00, Loss Aux: 3.350e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1148, It: 0, Loss Data: 4.003e-01, Loss Eqns: 5.536e+00, Loss Aux: 2.535e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1149, It: 0, Loss Data: 3.086e-01, Loss Eqns: 4.171e+00, Loss Aux: 1.082e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1150, It: 0, Loss Data: 4.655e-01, Loss Eqns: 5.424e+00, Loss Aux: 8.511e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1151, It: 0, Loss Data: 2.789e-01, Loss Eqns: 4.225e+00, Loss Aux: 8.639e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1152, It: 0, Loss Data: 4.445e-01, Loss Eqns: 4.167e+00, Loss Aux: 1.152e-01, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1153, It: 0, Loss Data: 2.943e-01, Loss Eqns: 3.891e+00, Loss Aux: 8.565e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1154, It: 0, Loss Data: 3.849e-01, Loss Eqns: 4.465e+00, Loss Aux: 3.427e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1155, It: 0, Loss Data: 3.589e-01, Loss Eqns: 3.513e+00, Loss Aux: 2.986e-01, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1156, It: 0, Loss Data: 2.989e-01, Loss Eqns: 4.595e+00, Loss Aux: 7.870e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1157, It: 0, Loss Data: 3.355e-01, Loss Eqns: 4.034e+00, Loss Aux: 2.541e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1158, It: 0, Loss Data: 2.971e-01, Loss Eqns: 3.995e+00, Loss Aux: 4.125e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1159, It: 0, Loss Data: 3.249e-01, Loss Eqns: 4.630e+00, Loss Aux: 8.884e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1160, It: 0, Loss Data: 2.647e-01, Loss Eqns: 4.373e+00, Loss Aux: 7.878e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1161, It: 0, Loss Data: 2.637e-01, Loss Eqns: 5.059e+00, Loss Aux: 4.091e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1162, It: 0, Loss Data: 2.544e-01, Loss Eqns: 4.399e+00, Loss Aux: 3.432e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1163, It: 0, Loss Data: 3.002e-01, Loss Eqns: 4.413e+00, Loss Aux: 4.041e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1164, It: 0, Loss Data: 2.345e-01, Loss Eqns: 4.116e+00, Loss Aux: 7.660e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1165, It: 0, Loss Data: 2.380e-01, Loss Eqns: 4.969e+00, Loss Aux: 8.081e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1166, It: 0, Loss Data: 2.022e-01, Loss Eqns: 3.969e+00, Loss Aux: 6.234e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1167, It: 0, Loss Data: 2.573e-01, Loss Eqns: 5.090e+00, Loss Aux: 4.742e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1168, It: 0, Loss Data: 2.394e-01, Loss Eqns: 4.273e+00, Loss Aux: 4.334e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1169, It: 0, Loss Data: 3.163e-01, Loss Eqns: 4.457e+00, Loss Aux: 3.764e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1170, It: 0, Loss Data: 2.583e-01, Loss Eqns: 4.204e+00, Loss Aux: 8.315e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1171, It: 0, Loss Data: 3.216e-01, Loss Eqns: 4.578e+00, Loss Aux: 9.638e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1172, It: 0, Loss Data: 2.205e-01, Loss Eqns: 4.139e+00, Loss Aux: 2.891e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1173, It: 0, Loss Data: 2.666e-01, Loss Eqns: 4.540e+00, Loss Aux: 2.448e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1174, It: 0, Loss Data: 1.954e-01, Loss Eqns: 4.469e+00, Loss Aux: 3.779e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1175, It: 0, Loss Data: 2.514e-01, Loss Eqns: 4.232e+00, Loss Aux: 9.279e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1176, It: 0, Loss Data: 2.089e-01, Loss Eqns: 4.267e+00, Loss Aux: 7.678e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1177, It: 0, Loss Data: 2.292e-01, Loss Eqns: 4.153e+00, Loss Aux: 4.594e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1178, It: 0, Loss Data: 2.284e-01, Loss Eqns: 4.140e+00, Loss Aux: 3.852e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1179, It: 0, Loss Data: 2.107e-01, Loss Eqns: 4.312e+00, Loss Aux: 5.498e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1180, It: 0, Loss Data: 2.040e-01, Loss Eqns: 4.106e+00, Loss Aux: 5.582e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1181, It: 0, Loss Data: 1.881e-01, Loss Eqns: 3.960e+00, Loss Aux: 2.278e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 1182, It: 0, Loss Data: 1.945e-01, Loss Eqns: 4.347e+00, Loss Aux: 3.010e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1183, It: 0, Loss Data: 1.998e-01, Loss Eqns: 4.284e+00, Loss Aux: 3.103e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1184, It: 0, Loss Data: 1.932e-01, Loss Eqns: 4.231e+00, Loss Aux: 3.981e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1185, It: 0, Loss Data: 1.971e-01, Loss Eqns: 4.253e+00, Loss Aux: 7.169e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1186, It: 0, Loss Data: 1.663e-01, Loss Eqns: 4.801e+00, Loss Aux: 5.244e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1187, It: 0, Loss Data: 1.981e-01, Loss Eqns: 4.386e+00, Loss Aux: 3.136e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1188, It: 0, Loss Data: 1.905e-01, Loss Eqns: 4.832e+00, Loss Aux: 2.893e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1189, It: 0, Loss Data: 2.119e-01, Loss Eqns: 4.447e+00, Loss Aux: 3.962e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1190, It: 0, Loss Data: 1.879e-01, Loss Eqns: 4.272e+00, Loss Aux: 6.689e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1191, It: 0, Loss Data: 1.749e-01, Loss Eqns: 4.286e+00, Loss Aux: 4.858e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1192, It: 0, Loss Data: 2.029e-01, Loss Eqns: 4.190e+00, Loss Aux: 1.999e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1193, It: 0, Loss Data: 2.003e-01, Loss Eqns: 4.121e+00, Loss Aux: 2.436e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1194, It: 0, Loss Data: 1.853e-01, Loss Eqns: 4.458e+00, Loss Aux: 3.960e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1195, It: 0, Loss Data: 2.229e-01, Loss Eqns: 4.358e+00, Loss Aux: 8.455e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1196, It: 0, Loss Data: 1.879e-01, Loss Eqns: 4.118e+00, Loss Aux: 5.122e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1197, It: 0, Loss Data: 1.812e-01, Loss Eqns: 4.377e+00, Loss Aux: 3.810e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1198, It: 0, Loss Data: 1.937e-01, Loss Eqns: 4.371e+00, Loss Aux: 2.999e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1199, It: 0, Loss Data: 1.957e-01, Loss Eqns: 4.238e+00, Loss Aux: 3.293e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1200, It: 0, Loss Data: 1.607e-01, Loss Eqns: 4.164e+00, Loss Aux: 4.797e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1201, It: 0, Loss Data: 1.837e-01, Loss Eqns: 4.278e+00, Loss Aux: 4.313e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1202, It: 0, Loss Data: 1.679e-01, Loss Eqns: 4.240e+00, Loss Aux: 3.772e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1203, It: 0, Loss Data: 1.750e-01, Loss Eqns: 4.211e+00, Loss Aux: 3.744e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1204, It: 0, Loss Data: 1.771e-01, Loss Eqns: 4.622e+00, Loss Aux: 3.200e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1205, It: 0, Loss Data: 1.639e-01, Loss Eqns: 4.161e+00, Loss Aux: 2.627e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 1206, It: 0, Loss Data: 1.650e-01, Loss Eqns: 4.434e+00, Loss Aux: 2.466e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1207, It: 0, Loss Data: 1.738e-01, Loss Eqns: 4.492e+00, Loss Aux: 1.919e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1208, It: 0, Loss Data: 1.529e-01, Loss Eqns: 4.187e+00, Loss Aux: 2.089e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1209, It: 0, Loss Data: 1.372e-01, Loss Eqns: 4.606e+00, Loss Aux: 2.850e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1210, It: 0, Loss Data: 1.775e-01, Loss Eqns: 4.477e+00, Loss Aux: 4.135e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1211, It: 0, Loss Data: 1.696e-01, Loss Eqns: 4.235e+00, Loss Aux: 3.588e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1212, It: 0, Loss Data: 1.934e-01, Loss Eqns: 4.541e+00, Loss Aux: 3.740e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1213, It: 0, Loss Data: 1.682e-01, Loss Eqns: 4.197e+00, Loss Aux: 2.404e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1214, It: 0, Loss Data: 1.552e-01, Loss Eqns: 4.340e+00, Loss Aux: 4.557e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1215, It: 0, Loss Data: 1.556e-01, Loss Eqns: 4.601e+00, Loss Aux: 6.557e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1216, It: 0, Loss Data: 1.401e-01, Loss Eqns: 4.128e+00, Loss Aux: 3.229e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1217, It: 0, Loss Data: 1.441e-01, Loss Eqns: 4.461e+00, Loss Aux: 2.524e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1218, It: 0, Loss Data: 1.713e-01, Loss Eqns: 4.496e+00, Loss Aux: 3.894e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1219, It: 0, Loss Data: 1.567e-01, Loss Eqns: 4.429e+00, Loss Aux: 4.327e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1220, It: 0, Loss Data: 1.416e-01, Loss Eqns: 4.266e+00, Loss Aux: 3.512e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1221, It: 0, Loss Data: 1.511e-01, Loss Eqns: 4.484e+00, Loss Aux: 2.467e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1222, It: 0, Loss Data: 1.668e-01, Loss Eqns: 4.307e+00, Loss Aux: 2.632e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1223, It: 0, Loss Data: 1.495e-01, Loss Eqns: 4.442e+00, Loss Aux: 2.908e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1224, It: 0, Loss Data: 1.334e-01, Loss Eqns: 4.073e+00, Loss Aux: 3.652e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1225, It: 0, Loss Data: 1.272e-01, Loss Eqns: 4.307e+00, Loss Aux: 3.758e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1226, It: 0, Loss Data: 1.608e-01, Loss Eqns: 4.404e+00, Loss Aux: 3.765e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1227, It: 0, Loss Data: 1.436e-01, Loss Eqns: 4.114e+00, Loss Aux: 3.198e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1228, It: 0, Loss Data: 1.530e-01, Loss Eqns: 4.456e+00, Loss Aux: 2.463e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1229, It: 0, Loss Data: 1.550e-01, Loss Eqns: 4.250e+00, Loss Aux: 2.097e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1230, It: 0, Loss Data: 1.546e-01, Loss Eqns: 4.203e+00, Loss Aux: 2.373e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1231, It: 0, Loss Data: 1.535e-01, Loss Eqns: 4.278e+00, Loss Aux: 2.370e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1232, It: 0, Loss Data: 1.398e-01, Loss Eqns: 4.370e+00, Loss Aux: 3.004e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1233, It: 0, Loss Data: 1.473e-01, Loss Eqns: 4.330e+00, Loss Aux: 3.843e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1234, It: 0, Loss Data: 1.692e-01, Loss Eqns: 4.036e+00, Loss Aux: 3.611e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1235, It: 0, Loss Data: 1.468e-01, Loss Eqns: 4.458e+00, Loss Aux: 2.814e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1236, It: 0, Loss Data: 1.722e-01, Loss Eqns: 4.523e+00, Loss Aux: 2.674e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1237, It: 0, Loss Data: 1.449e-01, Loss Eqns: 4.614e+00, Loss Aux: 2.841e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1238, It: 0, Loss Data: 1.397e-01, Loss Eqns: 4.645e+00, Loss Aux: 3.036e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1239, It: 0, Loss Data: 1.305e-01, Loss Eqns: 4.532e+00, Loss Aux: 3.190e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1240, It: 0, Loss Data: 1.311e-01, Loss Eqns: 4.107e+00, Loss Aux: 2.403e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1241, It: 0, Loss Data: 1.282e-01, Loss Eqns: 4.252e+00, Loss Aux: 2.373e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1242, It: 0, Loss Data: 1.358e-01, Loss Eqns: 4.354e+00, Loss Aux: 2.666e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1243, It: 0, Loss Data: 1.234e-01, Loss Eqns: 4.504e+00, Loss Aux: 2.576e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1244, It: 0, Loss Data: 1.287e-01, Loss Eqns: 4.385e+00, Loss Aux: 2.238e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1245, It: 0, Loss Data: 1.350e-01, Loss Eqns: 4.277e+00, Loss Aux: 2.047e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1246, It: 0, Loss Data: 1.354e-01, Loss Eqns: 4.644e+00, Loss Aux: 3.125e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1247, It: 0, Loss Data: 1.274e-01, Loss Eqns: 4.081e+00, Loss Aux: 3.800e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1248, It: 0, Loss Data: 1.466e-01, Loss Eqns: 4.479e+00, Loss Aux: 2.472e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1249, It: 0, Loss Data: 1.584e-01, Loss Eqns: 4.364e+00, Loss Aux: 2.552e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1250, It: 0, Loss Data: 1.437e-01, Loss Eqns: 4.138e+00, Loss Aux: 2.871e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1251, It: 0, Loss Data: 1.406e-01, Loss Eqns: 4.304e+00, Loss Aux: 3.459e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1252, It: 0, Loss Data: 1.743e-01, Loss Eqns: 4.881e+00, Loss Aux: 2.708e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1253, It: 0, Loss Data: 1.647e-01, Loss Eqns: 4.938e+00, Loss Aux: 3.055e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1254, It: 0, Loss Data: 1.408e-01, Loss Eqns: 4.724e+00, Loss Aux: 2.365e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1255, It: 0, Loss Data: 1.614e-01, Loss Eqns: 4.751e+00, Loss Aux: 2.657e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1256, It: 0, Loss Data: 1.346e-01, Loss Eqns: 4.151e+00, Loss Aux: 3.082e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1257, It: 0, Loss Data: 1.962e-01, Loss Eqns: 4.190e+00, Loss Aux: 6.500e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1258, It: 0, Loss Data: 1.606e-01, Loss Eqns: 4.216e+00, Loss Aux: 2.037e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1259, It: 0, Loss Data: 1.642e-01, Loss Eqns: 4.452e+00, Loss Aux: 2.728e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1260, It: 0, Loss Data: 1.672e-01, Loss Eqns: 4.545e+00, Loss Aux: 2.466e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1261, It: 0, Loss Data: 1.694e-01, Loss Eqns: 4.192e+00, Loss Aux: 3.792e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1262, It: 0, Loss Data: 1.574e-01, Loss Eqns: 4.761e+00, Loss Aux: 2.511e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1263, It: 0, Loss Data: 1.550e-01, Loss Eqns: 4.338e+00, Loss Aux: 2.407e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1264, It: 0, Loss Data: 1.456e-01, Loss Eqns: 4.654e+00, Loss Aux: 4.021e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1265, It: 0, Loss Data: 1.427e-01, Loss Eqns: 4.455e+00, Loss Aux: 3.129e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1266, It: 0, Loss Data: 1.466e-01, Loss Eqns: 4.646e+00, Loss Aux: 2.484e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1267, It: 0, Loss Data: 1.482e-01, Loss Eqns: 4.580e+00, Loss Aux: 2.962e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1268, It: 0, Loss Data: 1.352e-01, Loss Eqns: 4.026e+00, Loss Aux: 3.053e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1269, It: 0, Loss Data: 1.458e-01, Loss Eqns: 4.265e+00, Loss Aux: 2.708e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 1270, It: 0, Loss Data: 1.202e-01, Loss Eqns: 4.291e+00, Loss Aux: 2.199e-02, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 1271, It: 0, Loss Data: 1.649e-01, Loss Eqns: 4.269e+00, Loss Aux: 3.533e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1272, It: 0, Loss Data: 1.534e-01, Loss Eqns: 4.033e+00, Loss Aux: 2.817e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1273, It: 0, Loss Data: 1.540e-01, Loss Eqns: 4.700e+00, Loss Aux: 2.377e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1274, It: 0, Loss Data: 1.477e-01, Loss Eqns: 4.258e+00, Loss Aux: 2.984e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1275, It: 0, Loss Data: 1.481e-01, Loss Eqns: 4.185e+00, Loss Aux: 3.909e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1276, It: 0, Loss Data: 1.529e-01, Loss Eqns: 4.178e+00, Loss Aux: 3.721e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1277, It: 0, Loss Data: 1.468e-01, Loss Eqns: 4.390e+00, Loss Aux: 3.407e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1278, It: 0, Loss Data: 1.351e-01, Loss Eqns: 4.444e+00, Loss Aux: 2.518e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1279, It: 0, Loss Data: 1.277e-01, Loss Eqns: 4.361e+00, Loss Aux: 1.716e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1280, It: 0, Loss Data: 1.450e-01, Loss Eqns: 4.092e+00, Loss Aux: 1.777e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1281, It: 0, Loss Data: 1.384e-01, Loss Eqns: 4.283e+00, Loss Aux: 2.741e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1282, It: 0, Loss Data: 1.190e-01, Loss Eqns: 4.064e+00, Loss Aux: 2.496e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1283, It: 0, Loss Data: 1.444e-01, Loss Eqns: 4.435e+00, Loss Aux: 2.749e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1284, It: 0, Loss Data: 1.485e-01, Loss Eqns: 4.068e+00, Loss Aux: 2.510e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1285, It: 0, Loss Data: 1.387e-01, Loss Eqns: 4.177e+00, Loss Aux: 4.248e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1286, It: 0, Loss Data: 1.312e-01, Loss Eqns: 4.227e+00, Loss Aux: 3.425e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1287, It: 0, Loss Data: 1.676e-01, Loss Eqns: 4.007e+00, Loss Aux: 2.595e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 1288, It: 0, Loss Data: 1.478e-01, Loss Eqns: 4.295e+00, Loss Aux: 2.598e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1289, It: 0, Loss Data: 1.406e-01, Loss Eqns: 4.365e+00, Loss Aux: 3.599e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1290, It: 0, Loss Data: 1.407e-01, Loss Eqns: 4.113e+00, Loss Aux: 2.708e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1291, It: 0, Loss Data: 1.336e-01, Loss Eqns: 3.928e+00, Loss Aux: 2.046e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1292, It: 0, Loss Data: 1.449e-01, Loss Eqns: 4.748e+00, Loss Aux: 1.760e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1293, It: 0, Loss Data: 1.539e-01, Loss Eqns: 4.455e+00, Loss Aux: 1.798e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1294, It: 0, Loss Data: 1.327e-01, Loss Eqns: 4.518e+00, Loss Aux: 1.808e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1295, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.939e+00, Loss Aux: 2.812e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1296, It: 0, Loss Data: 1.287e-01, Loss Eqns: 4.894e+00, Loss Aux: 2.346e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1297, It: 0, Loss Data: 1.338e-01, Loss Eqns: 4.244e+00, Loss Aux: 2.387e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1298, It: 0, Loss Data: 1.547e-01, Loss Eqns: 4.296e+00, Loss Aux: 2.571e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1299, It: 0, Loss Data: 1.825e-01, Loss Eqns: 5.357e+00, Loss Aux: 3.560e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1300, It: 0, Loss Data: 1.402e-01, Loss Eqns: 4.548e+00, Loss Aux: 2.729e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1301, It: 0, Loss Data: 1.487e-01, Loss Eqns: 4.342e+00, Loss Aux: 2.400e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1302, It: 0, Loss Data: 1.371e-01, Loss Eqns: 4.112e+00, Loss Aux: 2.492e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1303, It: 0, Loss Data: 1.474e-01, Loss Eqns: 4.342e+00, Loss Aux: 3.554e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1304, It: 0, Loss Data: 1.435e-01, Loss Eqns: 4.550e+00, Loss Aux: 2.596e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1305, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.808e+00, Loss Aux: 2.179e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1306, It: 0, Loss Data: 1.461e-01, Loss Eqns: 4.407e+00, Loss Aux: 2.449e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1307, It: 0, Loss Data: 1.156e-01, Loss Eqns: 4.759e+00, Loss Aux: 1.865e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1308, It: 0, Loss Data: 1.383e-01, Loss Eqns: 4.257e+00, Loss Aux: 2.903e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1309, It: 0, Loss Data: 1.405e-01, Loss Eqns: 4.396e+00, Loss Aux: 2.590e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1310, It: 0, Loss Data: 1.362e-01, Loss Eqns: 4.212e+00, Loss Aux: 2.789e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1311, It: 0, Loss Data: 1.377e-01, Loss Eqns: 4.551e+00, Loss Aux: 2.939e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1312, It: 0, Loss Data: 1.488e-01, Loss Eqns: 4.667e+00, Loss Aux: 2.470e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1313, It: 0, Loss Data: 1.318e-01, Loss Eqns: 4.221e+00, Loss Aux: 2.643e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1314, It: 0, Loss Data: 1.644e-01, Loss Eqns: 4.419e+00, Loss Aux: 3.951e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1315, It: 0, Loss Data: 1.316e-01, Loss Eqns: 4.117e+00, Loss Aux: 3.254e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1316, It: 0, Loss Data: 1.484e-01, Loss Eqns: 4.495e+00, Loss Aux: 2.657e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1317, It: 0, Loss Data: 1.532e-01, Loss Eqns: 4.676e+00, Loss Aux: 2.441e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1318, It: 0, Loss Data: 1.442e-01, Loss Eqns: 4.616e+00, Loss Aux: 1.876e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1319, It: 0, Loss Data: 1.289e-01, Loss Eqns: 4.575e+00, Loss Aux: 1.755e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1320, It: 0, Loss Data: 1.313e-01, Loss Eqns: 4.657e+00, Loss Aux: 1.540e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1321, It: 0, Loss Data: 1.295e-01, Loss Eqns: 4.410e+00, Loss Aux: 1.593e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1322, It: 0, Loss Data: 1.520e-01, Loss Eqns: 3.860e+00, Loss Aux: 2.874e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1323, It: 0, Loss Data: 1.387e-01, Loss Eqns: 4.781e+00, Loss Aux: 3.410e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1324, It: 0, Loss Data: 1.421e-01, Loss Eqns: 4.619e+00, Loss Aux: 3.812e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1325, It: 0, Loss Data: 1.424e-01, Loss Eqns: 4.658e+00, Loss Aux: 2.462e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1326, It: 0, Loss Data: 1.361e-01, Loss Eqns: 4.550e+00, Loss Aux: 2.036e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1327, It: 0, Loss Data: 1.496e-01, Loss Eqns: 4.596e+00, Loss Aux: 2.358e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1328, It: 0, Loss Data: 1.448e-01, Loss Eqns: 3.856e+00, Loss Aux: 3.086e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1329, It: 0, Loss Data: 1.651e-01, Loss Eqns: 4.599e+00, Loss Aux: 2.711e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1330, It: 0, Loss Data: 1.422e-01, Loss Eqns: 4.071e+00, Loss Aux: 2.462e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1331, It: 0, Loss Data: 1.478e-01, Loss Eqns: 4.751e+00, Loss Aux: 2.179e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1332, It: 0, Loss Data: 1.235e-01, Loss Eqns: 4.368e+00, Loss Aux: 1.893e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1333, It: 0, Loss Data: 1.352e-01, Loss Eqns: 4.530e+00, Loss Aux: 2.023e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1334, It: 0, Loss Data: 1.386e-01, Loss Eqns: 4.417e+00, Loss Aux: 2.686e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1335, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.648e+00, Loss Aux: 4.234e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1336, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.228e+00, Loss Aux: 3.203e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1337, It: 0, Loss Data: 1.405e-01, Loss Eqns: 3.976e+00, Loss Aux: 4.484e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1338, It: 0, Loss Data: 1.500e-01, Loss Eqns: 4.552e+00, Loss Aux: 2.589e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1339, It: 0, Loss Data: 1.451e-01, Loss Eqns: 4.163e+00, Loss Aux: 2.666e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1340, It: 0, Loss Data: 1.312e-01, Loss Eqns: 4.579e+00, Loss Aux: 5.295e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1341, It: 0, Loss Data: 1.354e-01, Loss Eqns: 4.089e+00, Loss Aux: 4.578e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 1342, It: 0, Loss Data: 1.432e-01, Loss Eqns: 4.512e+00, Loss Aux: 1.992e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1343, It: 0, Loss Data: 1.336e-01, Loss Eqns: 4.453e+00, Loss Aux: 3.084e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1344, It: 0, Loss Data: 1.301e-01, Loss Eqns: 4.544e+00, Loss Aux: 2.932e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1345, It: 0, Loss Data: 1.448e-01, Loss Eqns: 4.215e+00, Loss Aux: 2.419e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 1346, It: 0, Loss Data: 1.536e-01, Loss Eqns: 4.385e+00, Loss Aux: 2.213e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1347, It: 0, Loss Data: 1.428e-01, Loss Eqns: 4.365e+00, Loss Aux: 2.096e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1348, It: 0, Loss Data: 1.277e-01, Loss Eqns: 4.429e+00, Loss Aux: 2.308e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1349, It: 0, Loss Data: 1.337e-01, Loss Eqns: 4.508e+00, Loss Aux: 2.249e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1350, It: 0, Loss Data: 1.432e-01, Loss Eqns: 4.315e+00, Loss Aux: 1.957e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1351, It: 0, Loss Data: 1.387e-01, Loss Eqns: 4.436e+00, Loss Aux: 2.808e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1352, It: 0, Loss Data: 1.413e-01, Loss Eqns: 4.350e+00, Loss Aux: 3.590e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1353, It: 0, Loss Data: 1.376e-01, Loss Eqns: 4.321e+00, Loss Aux: 2.510e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 1354, It: 0, Loss Data: 1.257e-01, Loss Eqns: 4.702e+00, Loss Aux: 1.350e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1355, It: 0, Loss Data: 1.278e-01, Loss Eqns: 4.249e+00, Loss Aux: 1.369e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1356, It: 0, Loss Data: 1.489e-01, Loss Eqns: 4.596e+00, Loss Aux: 2.069e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1357, It: 0, Loss Data: 1.326e-01, Loss Eqns: 3.992e+00, Loss Aux: 2.988e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1358, It: 0, Loss Data: 1.338e-01, Loss Eqns: 4.463e+00, Loss Aux: 3.064e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1359, It: 0, Loss Data: 1.326e-01, Loss Eqns: 3.978e+00, Loss Aux: 2.277e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 1360, It: 0, Loss Data: 1.296e-01, Loss Eqns: 4.293e+00, Loss Aux: 2.440e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1361, It: 0, Loss Data: 1.406e-01, Loss Eqns: 4.332e+00, Loss Aux: 3.040e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1362, It: 0, Loss Data: 1.428e-01, Loss Eqns: 4.511e+00, Loss Aux: 1.919e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1363, It: 0, Loss Data: 1.340e-01, Loss Eqns: 4.518e+00, Loss Aux: 2.232e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1364, It: 0, Loss Data: 1.226e-01, Loss Eqns: 4.280e+00, Loss Aux: 2.333e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1365, It: 0, Loss Data: 1.338e-01, Loss Eqns: 4.483e+00, Loss Aux: 3.457e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1366, It: 0, Loss Data: 1.424e-01, Loss Eqns: 4.084e+00, Loss Aux: 1.874e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1367, It: 0, Loss Data: 1.136e-01, Loss Eqns: 4.184e+00, Loss Aux: 2.245e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1368, It: 0, Loss Data: 1.365e-01, Loss Eqns: 4.235e+00, Loss Aux: 4.522e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1369, It: 0, Loss Data: 1.445e-01, Loss Eqns: 4.579e+00, Loss Aux: 2.899e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1370, It: 0, Loss Data: 1.381e-01, Loss Eqns: 4.489e+00, Loss Aux: 2.904e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 1371, It: 0, Loss Data: 1.344e-01, Loss Eqns: 4.101e+00, Loss Aux: 2.496e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1372, It: 0, Loss Data: 1.460e-01, Loss Eqns: 4.371e+00, Loss Aux: 3.016e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1373, It: 0, Loss Data: 1.445e-01, Loss Eqns: 4.181e+00, Loss Aux: 3.008e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1374, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.437e+00, Loss Aux: 1.733e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1375, It: 0, Loss Data: 1.496e-01, Loss Eqns: 4.317e+00, Loss Aux: 2.305e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1376, It: 0, Loss Data: 1.286e-01, Loss Eqns: 4.536e+00, Loss Aux: 2.515e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1377, It: 0, Loss Data: 1.389e-01, Loss Eqns: 4.474e+00, Loss Aux: 4.317e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1378, It: 0, Loss Data: 1.418e-01, Loss Eqns: 4.471e+00, Loss Aux: 1.903e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 1379, It: 0, Loss Data: 1.296e-01, Loss Eqns: 4.357e+00, Loss Aux: 2.147e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1380, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.374e+00, Loss Aux: 3.215e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1381, It: 0, Loss Data: 1.355e-01, Loss Eqns: 4.784e+00, Loss Aux: 4.527e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1382, It: 0, Loss Data: 1.441e-01, Loss Eqns: 4.742e+00, Loss Aux: 1.825e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1383, It: 0, Loss Data: 1.531e-01, Loss Eqns: 4.684e+00, Loss Aux: 2.353e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1384, It: 0, Loss Data: 1.293e-01, Loss Eqns: 4.435e+00, Loss Aux: 2.208e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1385, It: 0, Loss Data: 1.368e-01, Loss Eqns: 4.331e+00, Loss Aux: 5.158e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1386, It: 0, Loss Data: 1.163e-01, Loss Eqns: 4.435e+00, Loss Aux: 2.466e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1387, It: 0, Loss Data: 1.300e-01, Loss Eqns: 4.116e+00, Loss Aux: 1.781e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1388, It: 0, Loss Data: 1.401e-01, Loss Eqns: 4.244e+00, Loss Aux: 1.747e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 1389, It: 0, Loss Data: 1.415e-01, Loss Eqns: 4.416e+00, Loss Aux: 2.133e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1390, It: 0, Loss Data: 1.455e-01, Loss Eqns: 4.417e+00, Loss Aux: 2.253e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1391, It: 0, Loss Data: 1.399e-01, Loss Eqns: 4.100e+00, Loss Aux: 2.099e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1392, It: 0, Loss Data: 1.339e-01, Loss Eqns: 4.201e+00, Loss Aux: 2.082e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1393, It: 0, Loss Data: 1.237e-01, Loss Eqns: 4.147e+00, Loss Aux: 4.303e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1394, It: 0, Loss Data: 1.055e-01, Loss Eqns: 4.422e+00, Loss Aux: 3.741e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1395, It: 0, Loss Data: 1.457e-01, Loss Eqns: 4.151e+00, Loss Aux: 1.592e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1396, It: 0, Loss Data: 1.349e-01, Loss Eqns: 4.398e+00, Loss Aux: 2.051e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1397, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.514e+00, Loss Aux: 4.297e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1398, It: 0, Loss Data: 1.559e-01, Loss Eqns: 4.486e+00, Loss Aux: 2.210e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 1399, It: 0, Loss Data: 1.438e-01, Loss Eqns: 4.376e+00, Loss Aux: 2.956e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1400, It: 0, Loss Data: 1.454e-01, Loss Eqns: 4.365e+00, Loss Aux: 1.272e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 1401, It: 0, Loss Data: 1.332e-01, Loss Eqns: 4.469e+00, Loss Aux: 2.353e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 1402, It: 0, Loss Data: 1.317e-01, Loss Eqns: 4.193e+00, Loss Aux: 3.202e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 1403, It: 0, Loss Data: 1.269e-01, Loss Eqns: 4.207e+00, Loss Aux: 2.451e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1404, It: 0, Loss Data: 1.242e-01, Loss Eqns: 4.373e+00, Loss Aux: 2.246e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 1405, It: 0, Loss Data: 1.409e-01, Loss Eqns: 4.460e+00, Loss Aux: 2.658e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1406, It: 0, Loss Data: 1.338e-01, Loss Eqns: 4.121e+00, Loss Aux: 2.658e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1407, It: 0, Loss Data: 1.378e-01, Loss Eqns: 4.486e+00, Loss Aux: 1.902e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1408, It: 0, Loss Data: 1.219e-01, Loss Eqns: 4.044e+00, Loss Aux: 1.508e-02, Time: 0.272, Learning Rate: 1.0e-03\n",
      "Epoch: 1409, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.320e+00, Loss Aux: 1.618e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 1410, It: 0, Loss Data: 1.230e-01, Loss Eqns: 4.505e+00, Loss Aux: 1.950e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 1411, It: 0, Loss Data: 1.209e-01, Loss Eqns: 4.427e+00, Loss Aux: 2.442e-02, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 1412, It: 0, Loss Data: 1.057e-01, Loss Eqns: 4.463e+00, Loss Aux: 2.621e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 1413, It: 0, Loss Data: 1.375e-01, Loss Eqns: 3.993e+00, Loss Aux: 2.243e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 1414, It: 0, Loss Data: 1.374e-01, Loss Eqns: 4.009e+00, Loss Aux: 3.502e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1415, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.856e+00, Loss Aux: 1.815e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1416, It: 0, Loss Data: 1.383e-01, Loss Eqns: 4.079e+00, Loss Aux: 2.121e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1417, It: 0, Loss Data: 1.317e-01, Loss Eqns: 4.226e+00, Loss Aux: 2.794e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1418, It: 0, Loss Data: 1.344e-01, Loss Eqns: 4.438e+00, Loss Aux: 3.892e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1419, It: 0, Loss Data: 1.280e-01, Loss Eqns: 4.268e+00, Loss Aux: 1.743e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1420, It: 0, Loss Data: 1.488e-01, Loss Eqns: 4.479e+00, Loss Aux: 1.822e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1421, It: 0, Loss Data: 1.294e-01, Loss Eqns: 4.527e+00, Loss Aux: 3.840e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1422, It: 0, Loss Data: 1.377e-01, Loss Eqns: 4.694e+00, Loss Aux: 4.049e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 1423, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.587e+00, Loss Aux: 3.179e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1424, It: 0, Loss Data: 1.280e-01, Loss Eqns: 4.068e+00, Loss Aux: 2.650e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1425, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.519e+00, Loss Aux: 3.731e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1426, It: 0, Loss Data: 1.178e-01, Loss Eqns: 4.416e+00, Loss Aux: 1.134e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1427, It: 0, Loss Data: 1.408e-01, Loss Eqns: 4.556e+00, Loss Aux: 4.415e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 1428, It: 0, Loss Data: 1.379e-01, Loss Eqns: 4.322e+00, Loss Aux: 3.152e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1429, It: 0, Loss Data: 1.427e-01, Loss Eqns: 4.161e+00, Loss Aux: 2.590e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1430, It: 0, Loss Data: 1.499e-01, Loss Eqns: 4.738e+00, Loss Aux: 3.646e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1431, It: 0, Loss Data: 1.333e-01, Loss Eqns: 4.190e+00, Loss Aux: 3.171e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1432, It: 0, Loss Data: 1.426e-01, Loss Eqns: 4.515e+00, Loss Aux: 1.972e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1433, It: 0, Loss Data: 1.319e-01, Loss Eqns: 4.662e+00, Loss Aux: 1.492e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1434, It: 0, Loss Data: 1.237e-01, Loss Eqns: 4.171e+00, Loss Aux: 1.384e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1435, It: 0, Loss Data: 1.383e-01, Loss Eqns: 4.607e+00, Loss Aux: 2.440e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1436, It: 0, Loss Data: 1.652e-01, Loss Eqns: 4.648e+00, Loss Aux: 2.049e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1437, It: 0, Loss Data: 2.100e-01, Loss Eqns: 5.075e+00, Loss Aux: 4.493e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1438, It: 0, Loss Data: 1.465e-01, Loss Eqns: 4.066e+00, Loss Aux: 1.800e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1439, It: 0, Loss Data: 1.974e-01, Loss Eqns: 4.562e+00, Loss Aux: 1.855e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1440, It: 0, Loss Data: 1.368e-01, Loss Eqns: 4.713e+00, Loss Aux: 4.060e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1441, It: 0, Loss Data: 2.188e-01, Loss Eqns: 5.175e+00, Loss Aux: 3.627e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 1442, It: 0, Loss Data: 1.660e-01, Loss Eqns: 4.082e+00, Loss Aux: 3.419e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 1443, It: 0, Loss Data: 2.239e-01, Loss Eqns: 4.736e+00, Loss Aux: 1.653e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 1444, It: 0, Loss Data: 2.649e-01, Loss Eqns: 4.760e+00, Loss Aux: 1.166e-01, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 1445, It: 0, Loss Data: 1.653e-01, Loss Eqns: 4.332e+00, Loss Aux: 6.974e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 1446, It: 0, Loss Data: 2.163e-01, Loss Eqns: 5.335e+00, Loss Aux: 4.956e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1447, It: 0, Loss Data: 1.533e-01, Loss Eqns: 4.556e+00, Loss Aux: 1.533e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 1448, It: 0, Loss Data: 2.381e-01, Loss Eqns: 4.437e+00, Loss Aux: 7.498e-02, Time: 0.255, Learning Rate: 1.0e-03\n",
      "Epoch: 1449, It: 0, Loss Data: 1.326e-01, Loss Eqns: 4.063e+00, Loss Aux: 3.577e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1450, It: 0, Loss Data: 1.636e-01, Loss Eqns: 5.054e+00, Loss Aux: 2.098e-02, Time: 0.251, Learning Rate: 1.0e-03\n",
      "Epoch: 1451, It: 0, Loss Data: 1.299e-01, Loss Eqns: 4.430e+00, Loss Aux: 1.907e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1452, It: 0, Loss Data: 1.874e-01, Loss Eqns: 4.398e+00, Loss Aux: 3.838e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1453, It: 0, Loss Data: 1.529e-01, Loss Eqns: 4.102e+00, Loss Aux: 2.760e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1454, It: 0, Loss Data: 1.749e-01, Loss Eqns: 4.166e+00, Loss Aux: 1.672e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1455, It: 0, Loss Data: 1.437e-01, Loss Eqns: 4.594e+00, Loss Aux: 1.552e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1456, It: 0, Loss Data: 1.576e-01, Loss Eqns: 4.311e+00, Loss Aux: 1.951e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1457, It: 0, Loss Data: 1.361e-01, Loss Eqns: 4.351e+00, Loss Aux: 1.935e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1458, It: 0, Loss Data: 1.588e-01, Loss Eqns: 4.481e+00, Loss Aux: 2.695e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1459, It: 0, Loss Data: 1.373e-01, Loss Eqns: 4.086e+00, Loss Aux: 3.877e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1460, It: 0, Loss Data: 1.530e-01, Loss Eqns: 4.589e+00, Loss Aux: 2.495e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1461, It: 0, Loss Data: 1.409e-01, Loss Eqns: 4.373e+00, Loss Aux: 3.622e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1462, It: 0, Loss Data: 1.647e-01, Loss Eqns: 4.438e+00, Loss Aux: 1.979e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1463, It: 0, Loss Data: 1.538e-01, Loss Eqns: 4.426e+00, Loss Aux: 4.581e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1464, It: 0, Loss Data: 1.372e-01, Loss Eqns: 4.202e+00, Loss Aux: 7.099e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1465, It: 0, Loss Data: 1.466e-01, Loss Eqns: 4.368e+00, Loss Aux: 1.942e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1466, It: 0, Loss Data: 1.319e-01, Loss Eqns: 4.230e+00, Loss Aux: 2.214e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1467, It: 0, Loss Data: 1.300e-01, Loss Eqns: 4.461e+00, Loss Aux: 2.861e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 1468, It: 0, Loss Data: 1.402e-01, Loss Eqns: 4.108e+00, Loss Aux: 1.991e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 1469, It: 0, Loss Data: 1.342e-01, Loss Eqns: 4.385e+00, Loss Aux: 1.451e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 1470, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.081e+00, Loss Aux: 2.658e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1471, It: 0, Loss Data: 1.424e-01, Loss Eqns: 4.609e+00, Loss Aux: 2.639e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 1472, It: 0, Loss Data: 1.305e-01, Loss Eqns: 4.410e+00, Loss Aux: 1.706e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 1473, It: 0, Loss Data: 1.258e-01, Loss Eqns: 4.261e+00, Loss Aux: 2.091e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 1474, It: 0, Loss Data: 1.434e-01, Loss Eqns: 4.359e+00, Loss Aux: 2.030e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 1475, It: 0, Loss Data: 1.228e-01, Loss Eqns: 4.315e+00, Loss Aux: 3.064e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1476, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.925e+00, Loss Aux: 2.673e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1477, It: 0, Loss Data: 1.358e-01, Loss Eqns: 4.010e+00, Loss Aux: 2.239e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1478, It: 0, Loss Data: 1.311e-01, Loss Eqns: 4.329e+00, Loss Aux: 1.865e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 1479, It: 0, Loss Data: 1.326e-01, Loss Eqns: 4.217e+00, Loss Aux: 1.618e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 1480, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.951e+00, Loss Aux: 1.568e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 1481, It: 0, Loss Data: 1.066e-01, Loss Eqns: 4.123e+00, Loss Aux: 1.921e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1482, It: 0, Loss Data: 1.162e-01, Loss Eqns: 4.373e+00, Loss Aux: 2.336e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1483, It: 0, Loss Data: 1.198e-01, Loss Eqns: 4.301e+00, Loss Aux: 2.385e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1484, It: 0, Loss Data: 1.390e-01, Loss Eqns: 4.429e+00, Loss Aux: 2.297e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1485, It: 0, Loss Data: 1.284e-01, Loss Eqns: 4.612e+00, Loss Aux: 2.528e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1486, It: 0, Loss Data: 1.170e-01, Loss Eqns: 4.092e+00, Loss Aux: 1.482e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1487, It: 0, Loss Data: 1.293e-01, Loss Eqns: 4.166e+00, Loss Aux: 1.259e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1488, It: 0, Loss Data: 1.332e-01, Loss Eqns: 4.405e+00, Loss Aux: 1.824e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1489, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.168e+00, Loss Aux: 2.079e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1490, It: 0, Loss Data: 1.360e-01, Loss Eqns: 4.199e+00, Loss Aux: 2.419e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1491, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.225e+00, Loss Aux: 3.516e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1492, It: 0, Loss Data: 1.266e-01, Loss Eqns: 4.477e+00, Loss Aux: 1.982e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 1493, It: 0, Loss Data: 1.210e-01, Loss Eqns: 4.435e+00, Loss Aux: 2.025e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 1494, It: 0, Loss Data: 1.269e-01, Loss Eqns: 4.407e+00, Loss Aux: 1.603e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1495, It: 0, Loss Data: 1.407e-01, Loss Eqns: 4.188e+00, Loss Aux: 3.382e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 1496, It: 0, Loss Data: 1.126e-01, Loss Eqns: 4.383e+00, Loss Aux: 5.008e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 1497, It: 0, Loss Data: 1.208e-01, Loss Eqns: 4.130e+00, Loss Aux: 2.411e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1498, It: 0, Loss Data: 1.358e-01, Loss Eqns: 3.958e+00, Loss Aux: 3.732e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1499, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.964e+00, Loss Aux: 1.927e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1500, It: 0, Loss Data: 1.407e-01, Loss Eqns: 3.876e+00, Loss Aux: 3.080e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1501, It: 0, Loss Data: 1.527e-01, Loss Eqns: 4.506e+00, Loss Aux: 2.713e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1502, It: 0, Loss Data: 1.504e-01, Loss Eqns: 4.601e+00, Loss Aux: 1.756e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1503, It: 0, Loss Data: 1.323e-01, Loss Eqns: 4.049e+00, Loss Aux: 2.124e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1504, It: 0, Loss Data: 1.145e-01, Loss Eqns: 4.547e+00, Loss Aux: 2.085e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 1505, It: 0, Loss Data: 1.344e-01, Loss Eqns: 4.097e+00, Loss Aux: 4.091e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1506, It: 0, Loss Data: 1.247e-01, Loss Eqns: 4.113e+00, Loss Aux: 5.021e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1507, It: 0, Loss Data: 1.288e-01, Loss Eqns: 4.161e+00, Loss Aux: 2.373e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1508, It: 0, Loss Data: 1.383e-01, Loss Eqns: 4.278e+00, Loss Aux: 2.110e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1509, It: 0, Loss Data: 1.192e-01, Loss Eqns: 4.450e+00, Loss Aux: 2.206e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1510, It: 0, Loss Data: 1.314e-01, Loss Eqns: 4.487e+00, Loss Aux: 1.764e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1511, It: 0, Loss Data: 1.298e-01, Loss Eqns: 4.283e+00, Loss Aux: 1.989e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1512, It: 0, Loss Data: 1.034e-01, Loss Eqns: 4.181e+00, Loss Aux: 3.195e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1513, It: 0, Loss Data: 1.182e-01, Loss Eqns: 4.285e+00, Loss Aux: 3.758e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1514, It: 0, Loss Data: 1.393e-01, Loss Eqns: 4.268e+00, Loss Aux: 3.229e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1515, It: 0, Loss Data: 1.232e-01, Loss Eqns: 4.512e+00, Loss Aux: 2.204e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1516, It: 0, Loss Data: 1.235e-01, Loss Eqns: 4.209e+00, Loss Aux: 1.890e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1517, It: 0, Loss Data: 1.291e-01, Loss Eqns: 4.241e+00, Loss Aux: 1.486e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1518, It: 0, Loss Data: 1.170e-01, Loss Eqns: 4.266e+00, Loss Aux: 1.329e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1519, It: 0, Loss Data: 1.308e-01, Loss Eqns: 4.240e+00, Loss Aux: 1.420e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1520, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.079e+00, Loss Aux: 1.483e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1521, It: 0, Loss Data: 1.240e-01, Loss Eqns: 4.186e+00, Loss Aux: 1.970e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1522, It: 0, Loss Data: 1.124e-01, Loss Eqns: 4.314e+00, Loss Aux: 2.514e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1523, It: 0, Loss Data: 1.409e-01, Loss Eqns: 4.454e+00, Loss Aux: 2.157e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1524, It: 0, Loss Data: 1.337e-01, Loss Eqns: 4.330e+00, Loss Aux: 2.168e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1525, It: 0, Loss Data: 1.263e-01, Loss Eqns: 4.270e+00, Loss Aux: 2.329e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1526, It: 0, Loss Data: 1.269e-01, Loss Eqns: 4.454e+00, Loss Aux: 2.155e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1527, It: 0, Loss Data: 1.235e-01, Loss Eqns: 4.431e+00, Loss Aux: 1.684e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1528, It: 0, Loss Data: 1.142e-01, Loss Eqns: 4.596e+00, Loss Aux: 1.831e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 1529, It: 0, Loss Data: 1.182e-01, Loss Eqns: 4.847e+00, Loss Aux: 2.230e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1530, It: 0, Loss Data: 1.400e-01, Loss Eqns: 4.544e+00, Loss Aux: 1.993e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1531, It: 0, Loss Data: 1.468e-01, Loss Eqns: 4.361e+00, Loss Aux: 2.092e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1532, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.426e+00, Loss Aux: 1.947e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1533, It: 0, Loss Data: 1.052e-01, Loss Eqns: 4.709e+00, Loss Aux: 1.914e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1534, It: 0, Loss Data: 1.258e-01, Loss Eqns: 4.458e+00, Loss Aux: 1.756e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1535, It: 0, Loss Data: 1.371e-01, Loss Eqns: 4.260e+00, Loss Aux: 2.564e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1536, It: 0, Loss Data: 1.398e-01, Loss Eqns: 4.320e+00, Loss Aux: 1.728e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1537, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.583e+00, Loss Aux: 1.436e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1538, It: 0, Loss Data: 1.373e-01, Loss Eqns: 4.167e+00, Loss Aux: 1.394e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1539, It: 0, Loss Data: 1.265e-01, Loss Eqns: 4.419e+00, Loss Aux: 1.606e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1540, It: 0, Loss Data: 1.417e-01, Loss Eqns: 4.098e+00, Loss Aux: 2.027e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1541, It: 0, Loss Data: 1.241e-01, Loss Eqns: 4.220e+00, Loss Aux: 2.053e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1542, It: 0, Loss Data: 1.570e-01, Loss Eqns: 4.291e+00, Loss Aux: 7.236e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1543, It: 0, Loss Data: 1.982e-01, Loss Eqns: 4.779e+00, Loss Aux: 5.149e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 1544, It: 0, Loss Data: 1.255e-01, Loss Eqns: 4.927e+00, Loss Aux: 6.815e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1545, It: 0, Loss Data: 1.632e-01, Loss Eqns: 4.890e+00, Loss Aux: 1.666e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1546, It: 0, Loss Data: 1.720e-01, Loss Eqns: 4.222e+00, Loss Aux: 2.830e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1547, It: 0, Loss Data: 1.692e-01, Loss Eqns: 4.545e+00, Loss Aux: 3.472e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1548, It: 0, Loss Data: 1.537e-01, Loss Eqns: 5.002e+00, Loss Aux: 2.667e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1549, It: 0, Loss Data: 1.750e-01, Loss Eqns: 4.953e+00, Loss Aux: 2.343e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1550, It: 0, Loss Data: 1.529e-01, Loss Eqns: 4.202e+00, Loss Aux: 4.729e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1551, It: 0, Loss Data: 1.538e-01, Loss Eqns: 4.689e+00, Loss Aux: 3.263e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1552, It: 0, Loss Data: 1.822e-01, Loss Eqns: 4.253e+00, Loss Aux: 1.454e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1553, It: 0, Loss Data: 1.467e-01, Loss Eqns: 4.735e+00, Loss Aux: 1.725e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1554, It: 0, Loss Data: 1.595e-01, Loss Eqns: 4.362e+00, Loss Aux: 2.147e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1555, It: 0, Loss Data: 1.382e-01, Loss Eqns: 4.219e+00, Loss Aux: 2.568e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 1556, It: 0, Loss Data: 1.422e-01, Loss Eqns: 4.287e+00, Loss Aux: 2.939e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1557, It: 0, Loss Data: 1.431e-01, Loss Eqns: 4.074e+00, Loss Aux: 2.602e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1558, It: 0, Loss Data: 1.555e-01, Loss Eqns: 4.468e+00, Loss Aux: 6.446e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1559, It: 0, Loss Data: 1.474e-01, Loss Eqns: 4.232e+00, Loss Aux: 1.914e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1560, It: 0, Loss Data: 1.619e-01, Loss Eqns: 4.223e+00, Loss Aux: 1.804e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1561, It: 0, Loss Data: 1.185e-01, Loss Eqns: 4.315e+00, Loss Aux: 2.953e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1562, It: 0, Loss Data: 1.504e-01, Loss Eqns: 4.191e+00, Loss Aux: 5.553e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1563, It: 0, Loss Data: 1.230e-01, Loss Eqns: 4.077e+00, Loss Aux: 2.014e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1564, It: 0, Loss Data: 1.448e-01, Loss Eqns: 4.239e+00, Loss Aux: 1.604e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1565, It: 0, Loss Data: 1.362e-01, Loss Eqns: 4.410e+00, Loss Aux: 1.917e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 1566, It: 0, Loss Data: 1.417e-01, Loss Eqns: 4.150e+00, Loss Aux: 3.018e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1567, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.326e+00, Loss Aux: 1.745e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1568, It: 0, Loss Data: 1.589e-01, Loss Eqns: 4.235e+00, Loss Aux: 1.512e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 1569, It: 0, Loss Data: 1.468e-01, Loss Eqns: 4.116e+00, Loss Aux: 2.952e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1570, It: 0, Loss Data: 1.251e-01, Loss Eqns: 4.322e+00, Loss Aux: 3.250e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1571, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.411e+00, Loss Aux: 1.619e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1572, It: 0, Loss Data: 1.364e-01, Loss Eqns: 4.617e+00, Loss Aux: 1.740e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1573, It: 0, Loss Data: 1.354e-01, Loss Eqns: 3.998e+00, Loss Aux: 2.445e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1574, It: 0, Loss Data: 1.212e-01, Loss Eqns: 4.040e+00, Loss Aux: 2.636e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1575, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.461e+00, Loss Aux: 1.561e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1576, It: 0, Loss Data: 1.181e-01, Loss Eqns: 4.182e+00, Loss Aux: 1.111e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1577, It: 0, Loss Data: 1.259e-01, Loss Eqns: 4.306e+00, Loss Aux: 1.161e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1578, It: 0, Loss Data: 1.317e-01, Loss Eqns: 4.317e+00, Loss Aux: 2.847e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1579, It: 0, Loss Data: 1.261e-01, Loss Eqns: 4.118e+00, Loss Aux: 4.589e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1580, It: 0, Loss Data: 1.287e-01, Loss Eqns: 4.473e+00, Loss Aux: 2.285e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1581, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.986e+00, Loss Aux: 1.928e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1582, It: 0, Loss Data: 1.036e-01, Loss Eqns: 4.123e+00, Loss Aux: 1.555e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1583, It: 0, Loss Data: 1.263e-01, Loss Eqns: 4.286e+00, Loss Aux: 2.677e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 1584, It: 0, Loss Data: 1.288e-01, Loss Eqns: 4.306e+00, Loss Aux: 1.646e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1585, It: 0, Loss Data: 1.162e-01, Loss Eqns: 4.504e+00, Loss Aux: 1.181e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1586, It: 0, Loss Data: 1.244e-01, Loss Eqns: 4.136e+00, Loss Aux: 1.525e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 1587, It: 0, Loss Data: 1.158e-01, Loss Eqns: 4.215e+00, Loss Aux: 1.988e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1588, It: 0, Loss Data: 1.254e-01, Loss Eqns: 4.659e+00, Loss Aux: 2.013e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 1589, It: 0, Loss Data: 1.316e-01, Loss Eqns: 4.125e+00, Loss Aux: 1.509e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1590, It: 0, Loss Data: 1.354e-01, Loss Eqns: 4.102e+00, Loss Aux: 2.097e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 1591, It: 0, Loss Data: 1.124e-01, Loss Eqns: 4.223e+00, Loss Aux: 2.645e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1592, It: 0, Loss Data: 1.233e-01, Loss Eqns: 4.368e+00, Loss Aux: 2.269e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1593, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.348e+00, Loss Aux: 1.472e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 1594, It: 0, Loss Data: 1.347e-01, Loss Eqns: 4.130e+00, Loss Aux: 1.360e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1595, It: 0, Loss Data: 1.328e-01, Loss Eqns: 4.388e+00, Loss Aux: 1.388e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1596, It: 0, Loss Data: 1.160e-01, Loss Eqns: 4.227e+00, Loss Aux: 1.703e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 1597, It: 0, Loss Data: 1.296e-01, Loss Eqns: 4.367e+00, Loss Aux: 1.070e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1598, It: 0, Loss Data: 1.316e-01, Loss Eqns: 4.143e+00, Loss Aux: 1.246e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1599, It: 0, Loss Data: 1.204e-01, Loss Eqns: 4.330e+00, Loss Aux: 1.758e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1600, It: 0, Loss Data: 1.214e-01, Loss Eqns: 4.385e+00, Loss Aux: 2.542e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 1601, It: 0, Loss Data: 1.124e-01, Loss Eqns: 4.528e+00, Loss Aux: 2.151e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1602, It: 0, Loss Data: 1.228e-01, Loss Eqns: 4.320e+00, Loss Aux: 1.627e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1603, It: 0, Loss Data: 1.251e-01, Loss Eqns: 4.311e+00, Loss Aux: 1.311e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 1604, It: 0, Loss Data: 1.175e-01, Loss Eqns: 4.533e+00, Loss Aux: 1.352e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1605, It: 0, Loss Data: 1.062e-01, Loss Eqns: 4.686e+00, Loss Aux: 1.380e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 1606, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.032e+00, Loss Aux: 1.339e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1607, It: 0, Loss Data: 1.149e-01, Loss Eqns: 4.391e+00, Loss Aux: 1.910e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1608, It: 0, Loss Data: 1.189e-01, Loss Eqns: 4.496e+00, Loss Aux: 2.780e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1609, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.955e+00, Loss Aux: 2.089e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1610, It: 0, Loss Data: 1.427e-01, Loss Eqns: 4.322e+00, Loss Aux: 1.267e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1611, It: 0, Loss Data: 1.030e-01, Loss Eqns: 4.067e+00, Loss Aux: 1.211e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1612, It: 0, Loss Data: 1.310e-01, Loss Eqns: 4.321e+00, Loss Aux: 1.332e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1613, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.320e+00, Loss Aux: 1.608e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1614, It: 0, Loss Data: 1.164e-01, Loss Eqns: 4.282e+00, Loss Aux: 1.827e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1615, It: 0, Loss Data: 1.345e-01, Loss Eqns: 4.576e+00, Loss Aux: 1.660e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1616, It: 0, Loss Data: 1.307e-01, Loss Eqns: 4.089e+00, Loss Aux: 1.520e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1617, It: 0, Loss Data: 1.139e-01, Loss Eqns: 4.335e+00, Loss Aux: 2.298e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1618, It: 0, Loss Data: 1.177e-01, Loss Eqns: 4.179e+00, Loss Aux: 2.636e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 1619, It: 0, Loss Data: 1.355e-01, Loss Eqns: 4.020e+00, Loss Aux: 1.402e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 1620, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.312e+00, Loss Aux: 1.606e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1621, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.483e+00, Loss Aux: 1.545e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1622, It: 0, Loss Data: 1.200e-01, Loss Eqns: 4.376e+00, Loss Aux: 2.719e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1623, It: 0, Loss Data: 1.109e-01, Loss Eqns: 4.310e+00, Loss Aux: 1.610e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1624, It: 0, Loss Data: 1.160e-01, Loss Eqns: 4.251e+00, Loss Aux: 1.132e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1625, It: 0, Loss Data: 1.216e-01, Loss Eqns: 4.380e+00, Loss Aux: 1.308e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 1626, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.948e+00, Loss Aux: 3.135e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1627, It: 0, Loss Data: 1.276e-01, Loss Eqns: 4.277e+00, Loss Aux: 3.271e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1628, It: 0, Loss Data: 1.363e-01, Loss Eqns: 4.622e+00, Loss Aux: 1.645e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1629, It: 0, Loss Data: 1.271e-01, Loss Eqns: 4.269e+00, Loss Aux: 1.578e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1630, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.425e+00, Loss Aux: 1.211e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1631, It: 0, Loss Data: 1.341e-01, Loss Eqns: 4.545e+00, Loss Aux: 1.169e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1632, It: 0, Loss Data: 1.217e-01, Loss Eqns: 4.323e+00, Loss Aux: 1.155e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1633, It: 0, Loss Data: 1.237e-01, Loss Eqns: 4.191e+00, Loss Aux: 3.497e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1634, It: 0, Loss Data: 1.299e-01, Loss Eqns: 4.388e+00, Loss Aux: 2.615e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1635, It: 0, Loss Data: 1.260e-01, Loss Eqns: 4.053e+00, Loss Aux: 1.546e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1636, It: 0, Loss Data: 1.244e-01, Loss Eqns: 4.449e+00, Loss Aux: 1.500e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1637, It: 0, Loss Data: 1.211e-01, Loss Eqns: 4.081e+00, Loss Aux: 1.351e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1638, It: 0, Loss Data: 1.307e-01, Loss Eqns: 4.173e+00, Loss Aux: 1.302e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 1639, It: 0, Loss Data: 1.274e-01, Loss Eqns: 4.524e+00, Loss Aux: 1.997e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1640, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.415e+00, Loss Aux: 1.009e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1641, It: 0, Loss Data: 1.236e-01, Loss Eqns: 4.587e+00, Loss Aux: 1.129e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1642, It: 0, Loss Data: 1.188e-01, Loss Eqns: 4.359e+00, Loss Aux: 1.747e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1643, It: 0, Loss Data: 1.119e-01, Loss Eqns: 4.409e+00, Loss Aux: 1.910e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1644, It: 0, Loss Data: 1.299e-01, Loss Eqns: 4.338e+00, Loss Aux: 1.260e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1645, It: 0, Loss Data: 1.278e-01, Loss Eqns: 4.012e+00, Loss Aux: 1.247e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1646, It: 0, Loss Data: 1.407e-01, Loss Eqns: 4.284e+00, Loss Aux: 1.706e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1647, It: 0, Loss Data: 1.199e-01, Loss Eqns: 4.265e+00, Loss Aux: 1.528e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1648, It: 0, Loss Data: 1.231e-01, Loss Eqns: 4.391e+00, Loss Aux: 1.220e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 1649, It: 0, Loss Data: 1.140e-01, Loss Eqns: 4.171e+00, Loss Aux: 1.396e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1650, It: 0, Loss Data: 1.172e-01, Loss Eqns: 4.180e+00, Loss Aux: 2.443e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1651, It: 0, Loss Data: 1.229e-01, Loss Eqns: 4.371e+00, Loss Aux: 1.994e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1652, It: 0, Loss Data: 1.176e-01, Loss Eqns: 4.140e+00, Loss Aux: 1.420e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1653, It: 0, Loss Data: 1.220e-01, Loss Eqns: 4.399e+00, Loss Aux: 1.972e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1654, It: 0, Loss Data: 1.303e-01, Loss Eqns: 4.048e+00, Loss Aux: 1.801e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1655, It: 0, Loss Data: 1.328e-01, Loss Eqns: 4.203e+00, Loss Aux: 9.784e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1656, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.924e+00, Loss Aux: 9.157e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1657, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.200e+00, Loss Aux: 9.776e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1658, It: 0, Loss Data: 1.261e-01, Loss Eqns: 4.241e+00, Loss Aux: 1.391e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1659, It: 0, Loss Data: 1.109e-01, Loss Eqns: 4.271e+00, Loss Aux: 2.650e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1660, It: 0, Loss Data: 1.260e-01, Loss Eqns: 4.516e+00, Loss Aux: 1.436e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1661, It: 0, Loss Data: 1.272e-01, Loss Eqns: 4.169e+00, Loss Aux: 1.604e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1662, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.954e+00, Loss Aux: 1.463e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1663, It: 0, Loss Data: 1.295e-01, Loss Eqns: 4.541e+00, Loss Aux: 2.345e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1664, It: 0, Loss Data: 1.106e-01, Loss Eqns: 4.217e+00, Loss Aux: 1.293e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1665, It: 0, Loss Data: 1.238e-01, Loss Eqns: 4.372e+00, Loss Aux: 1.200e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1666, It: 0, Loss Data: 1.322e-01, Loss Eqns: 4.208e+00, Loss Aux: 1.316e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1667, It: 0, Loss Data: 1.194e-01, Loss Eqns: 4.230e+00, Loss Aux: 1.971e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 1668, It: 0, Loss Data: 1.346e-01, Loss Eqns: 4.062e+00, Loss Aux: 1.542e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1669, It: 0, Loss Data: 1.231e-01, Loss Eqns: 4.215e+00, Loss Aux: 1.398e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1670, It: 0, Loss Data: 1.148e-01, Loss Eqns: 4.783e+00, Loss Aux: 1.139e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1671, It: 0, Loss Data: 1.151e-01, Loss Eqns: 4.386e+00, Loss Aux: 1.762e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 1672, It: 0, Loss Data: 1.272e-01, Loss Eqns: 4.255e+00, Loss Aux: 1.715e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1673, It: 0, Loss Data: 1.050e-01, Loss Eqns: 4.196e+00, Loss Aux: 1.267e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1674, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.995e+00, Loss Aux: 1.357e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1675, It: 0, Loss Data: 1.259e-01, Loss Eqns: 4.191e+00, Loss Aux: 1.238e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 1676, It: 0, Loss Data: 9.205e-02, Loss Eqns: 4.463e+00, Loss Aux: 1.192e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1677, It: 0, Loss Data: 1.421e-01, Loss Eqns: 4.377e+00, Loss Aux: 1.042e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1678, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.320e+00, Loss Aux: 1.192e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1679, It: 0, Loss Data: 1.258e-01, Loss Eqns: 4.226e+00, Loss Aux: 1.402e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1680, It: 0, Loss Data: 1.090e-01, Loss Eqns: 4.408e+00, Loss Aux: 1.323e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 1681, It: 0, Loss Data: 1.178e-01, Loss Eqns: 4.574e+00, Loss Aux: 9.919e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1682, It: 0, Loss Data: 1.340e-01, Loss Eqns: 4.118e+00, Loss Aux: 2.005e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1683, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.446e+00, Loss Aux: 2.189e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1684, It: 0, Loss Data: 1.113e-01, Loss Eqns: 4.000e+00, Loss Aux: 2.415e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1685, It: 0, Loss Data: 1.297e-01, Loss Eqns: 4.376e+00, Loss Aux: 1.640e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1686, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.309e+00, Loss Aux: 1.758e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1687, It: 0, Loss Data: 1.238e-01, Loss Eqns: 4.322e+00, Loss Aux: 1.234e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1688, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.260e+00, Loss Aux: 1.799e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1689, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.974e+00, Loss Aux: 1.765e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1690, It: 0, Loss Data: 1.341e-01, Loss Eqns: 4.258e+00, Loss Aux: 1.806e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1691, It: 0, Loss Data: 1.194e-01, Loss Eqns: 4.045e+00, Loss Aux: 1.445e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1692, It: 0, Loss Data: 1.467e-01, Loss Eqns: 4.297e+00, Loss Aux: 1.517e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1693, It: 0, Loss Data: 1.265e-01, Loss Eqns: 4.431e+00, Loss Aux: 1.640e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1694, It: 0, Loss Data: 1.035e-01, Loss Eqns: 4.461e+00, Loss Aux: 1.230e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1695, It: 0, Loss Data: 1.121e-01, Loss Eqns: 4.585e+00, Loss Aux: 8.202e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 1696, It: 0, Loss Data: 1.847e-01, Loss Eqns: 5.356e+00, Loss Aux: 2.175e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1697, It: 0, Loss Data: 4.610e-01, Loss Eqns: 7.463e+00, Loss Aux: 3.191e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1698, It: 0, Loss Data: 2.313e-01, Loss Eqns: 6.015e+00, Loss Aux: 5.855e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1699, It: 0, Loss Data: 3.021e-01, Loss Eqns: 4.802e+00, Loss Aux: 1.806e-01, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1700, It: 0, Loss Data: 3.204e-01, Loss Eqns: 6.155e+00, Loss Aux: 5.197e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1701, It: 0, Loss Data: 3.308e-01, Loss Eqns: 4.651e+00, Loss Aux: 5.810e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1702, It: 0, Loss Data: 2.715e-01, Loss Eqns: 6.051e+00, Loss Aux: 2.097e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1703, It: 0, Loss Data: 2.702e-01, Loss Eqns: 4.635e+00, Loss Aux: 8.389e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 1704, It: 0, Loss Data: 2.946e-01, Loss Eqns: 4.500e+00, Loss Aux: 9.615e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1705, It: 0, Loss Data: 2.617e-01, Loss Eqns: 3.858e+00, Loss Aux: 1.764e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 1706, It: 0, Loss Data: 3.456e-01, Loss Eqns: 4.195e+00, Loss Aux: 2.574e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 1707, It: 0, Loss Data: 2.257e-01, Loss Eqns: 3.944e+00, Loss Aux: 8.955e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1708, It: 0, Loss Data: 3.019e-01, Loss Eqns: 4.649e+00, Loss Aux: 1.076e-01, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1709, It: 0, Loss Data: 2.043e-01, Loss Eqns: 4.363e+00, Loss Aux: 1.082e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1710, It: 0, Loss Data: 2.980e-01, Loss Eqns: 4.521e+00, Loss Aux: 3.601e-02, Time: 0.251, Learning Rate: 1.0e-03\n",
      "Epoch: 1711, It: 0, Loss Data: 1.758e-01, Loss Eqns: 3.726e+00, Loss Aux: 3.064e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1712, It: 0, Loss Data: 2.247e-01, Loss Eqns: 4.219e+00, Loss Aux: 1.134e-01, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1713, It: 0, Loss Data: 1.858e-01, Loss Eqns: 3.858e+00, Loss Aux: 9.789e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1714, It: 0, Loss Data: 1.774e-01, Loss Eqns: 4.110e+00, Loss Aux: 2.779e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1715, It: 0, Loss Data: 1.983e-01, Loss Eqns: 4.311e+00, Loss Aux: 1.406e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1716, It: 0, Loss Data: 1.739e-01, Loss Eqns: 4.100e+00, Loss Aux: 1.944e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1717, It: 0, Loss Data: 1.754e-01, Loss Eqns: 4.106e+00, Loss Aux: 5.506e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1718, It: 0, Loss Data: 1.652e-01, Loss Eqns: 4.427e+00, Loss Aux: 5.767e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 1719, It: 0, Loss Data: 1.594e-01, Loss Eqns: 4.255e+00, Loss Aux: 2.847e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 1720, It: 0, Loss Data: 1.592e-01, Loss Eqns: 4.436e+00, Loss Aux: 1.843e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1721, It: 0, Loss Data: 1.450e-01, Loss Eqns: 4.113e+00, Loss Aux: 2.543e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 1722, It: 0, Loss Data: 1.448e-01, Loss Eqns: 4.176e+00, Loss Aux: 4.385e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1723, It: 0, Loss Data: 1.517e-01, Loss Eqns: 4.392e+00, Loss Aux: 4.613e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 1724, It: 0, Loss Data: 1.771e-01, Loss Eqns: 4.068e+00, Loss Aux: 4.259e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1725, It: 0, Loss Data: 1.555e-01, Loss Eqns: 3.952e+00, Loss Aux: 2.945e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1726, It: 0, Loss Data: 1.666e-01, Loss Eqns: 4.368e+00, Loss Aux: 2.664e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1727, It: 0, Loss Data: 1.404e-01, Loss Eqns: 4.467e+00, Loss Aux: 3.190e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1728, It: 0, Loss Data: 1.429e-01, Loss Eqns: 4.293e+00, Loss Aux: 2.947e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 1729, It: 0, Loss Data: 1.412e-01, Loss Eqns: 4.174e+00, Loss Aux: 2.846e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1730, It: 0, Loss Data: 1.414e-01, Loss Eqns: 4.026e+00, Loss Aux: 2.650e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 1731, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.185e+00, Loss Aux: 2.455e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 1732, It: 0, Loss Data: 1.649e-01, Loss Eqns: 4.113e+00, Loss Aux: 3.556e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1733, It: 0, Loss Data: 1.370e-01, Loss Eqns: 4.196e+00, Loss Aux: 2.049e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 1734, It: 0, Loss Data: 1.216e-01, Loss Eqns: 4.063e+00, Loss Aux: 1.006e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1735, It: 0, Loss Data: 1.426e-01, Loss Eqns: 4.045e+00, Loss Aux: 1.058e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1736, It: 0, Loss Data: 1.376e-01, Loss Eqns: 4.177e+00, Loss Aux: 2.771e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1737, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.314e+00, Loss Aux: 2.432e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 1738, It: 0, Loss Data: 1.211e-01, Loss Eqns: 4.052e+00, Loss Aux: 2.794e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1739, It: 0, Loss Data: 1.382e-01, Loss Eqns: 3.978e+00, Loss Aux: 2.127e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1740, It: 0, Loss Data: 1.208e-01, Loss Eqns: 4.248e+00, Loss Aux: 2.171e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1741, It: 0, Loss Data: 1.223e-01, Loss Eqns: 4.371e+00, Loss Aux: 4.383e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 1742, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.232e+00, Loss Aux: 1.437e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1743, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.982e+00, Loss Aux: 8.476e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1744, It: 0, Loss Data: 1.424e-01, Loss Eqns: 4.283e+00, Loss Aux: 1.166e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1745, It: 0, Loss Data: 1.163e-01, Loss Eqns: 4.213e+00, Loss Aux: 1.503e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1746, It: 0, Loss Data: 1.366e-01, Loss Eqns: 4.263e+00, Loss Aux: 1.515e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1747, It: 0, Loss Data: 1.145e-01, Loss Eqns: 4.213e+00, Loss Aux: 1.053e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1748, It: 0, Loss Data: 1.220e-01, Loss Eqns: 4.037e+00, Loss Aux: 1.016e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1749, It: 0, Loss Data: 9.986e-02, Loss Eqns: 4.277e+00, Loss Aux: 1.013e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 1750, It: 0, Loss Data: 1.104e-01, Loss Eqns: 4.293e+00, Loss Aux: 1.244e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1751, It: 0, Loss Data: 1.169e-01, Loss Eqns: 4.354e+00, Loss Aux: 1.406e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 1752, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.735e+00, Loss Aux: 2.126e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 1753, It: 0, Loss Data: 1.243e-01, Loss Eqns: 4.337e+00, Loss Aux: 2.384e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1754, It: 0, Loss Data: 1.234e-01, Loss Eqns: 4.118e+00, Loss Aux: 1.544e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1755, It: 0, Loss Data: 1.375e-01, Loss Eqns: 4.099e+00, Loss Aux: 1.040e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1756, It: 0, Loss Data: 1.351e-01, Loss Eqns: 4.375e+00, Loss Aux: 8.890e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1757, It: 0, Loss Data: 1.279e-01, Loss Eqns: 4.070e+00, Loss Aux: 1.148e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1758, It: 0, Loss Data: 1.239e-01, Loss Eqns: 4.083e+00, Loss Aux: 2.136e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1759, It: 0, Loss Data: 1.072e-01, Loss Eqns: 4.082e+00, Loss Aux: 2.433e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 1760, It: 0, Loss Data: 1.282e-01, Loss Eqns: 4.212e+00, Loss Aux: 1.360e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1761, It: 0, Loss Data: 1.364e-01, Loss Eqns: 4.024e+00, Loss Aux: 1.517e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1762, It: 0, Loss Data: 1.177e-01, Loss Eqns: 4.207e+00, Loss Aux: 1.155e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1763, It: 0, Loss Data: 1.272e-01, Loss Eqns: 4.216e+00, Loss Aux: 2.771e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1764, It: 0, Loss Data: 1.139e-01, Loss Eqns: 4.250e+00, Loss Aux: 2.169e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1765, It: 0, Loss Data: 1.340e-01, Loss Eqns: 3.805e+00, Loss Aux: 1.296e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1766, It: 0, Loss Data: 1.411e-01, Loss Eqns: 4.224e+00, Loss Aux: 1.523e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1767, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.267e+00, Loss Aux: 1.395e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1768, It: 0, Loss Data: 1.334e-01, Loss Eqns: 4.615e+00, Loss Aux: 8.282e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1769, It: 0, Loss Data: 1.400e-01, Loss Eqns: 4.487e+00, Loss Aux: 9.483e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1770, It: 0, Loss Data: 1.360e-01, Loss Eqns: 4.440e+00, Loss Aux: 1.321e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1771, It: 0, Loss Data: 1.171e-01, Loss Eqns: 4.369e+00, Loss Aux: 1.996e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1772, It: 0, Loss Data: 1.193e-01, Loss Eqns: 4.224e+00, Loss Aux: 1.951e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1773, It: 0, Loss Data: 1.290e-01, Loss Eqns: 4.275e+00, Loss Aux: 1.367e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1774, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.879e+00, Loss Aux: 9.442e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1775, It: 0, Loss Data: 1.297e-01, Loss Eqns: 3.905e+00, Loss Aux: 6.452e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1776, It: 0, Loss Data: 1.323e-01, Loss Eqns: 4.423e+00, Loss Aux: 1.081e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1777, It: 0, Loss Data: 1.159e-01, Loss Eqns: 4.523e+00, Loss Aux: 2.055e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1778, It: 0, Loss Data: 1.212e-01, Loss Eqns: 4.417e+00, Loss Aux: 1.387e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1779, It: 0, Loss Data: 1.248e-01, Loss Eqns: 4.184e+00, Loss Aux: 2.007e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1780, It: 0, Loss Data: 1.332e-01, Loss Eqns: 4.259e+00, Loss Aux: 1.583e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1781, It: 0, Loss Data: 1.347e-01, Loss Eqns: 4.601e+00, Loss Aux: 4.189e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1782, It: 0, Loss Data: 1.208e-01, Loss Eqns: 4.160e+00, Loss Aux: 1.275e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1783, It: 0, Loss Data: 1.158e-01, Loss Eqns: 3.969e+00, Loss Aux: 1.087e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1784, It: 0, Loss Data: 1.243e-01, Loss Eqns: 3.870e+00, Loss Aux: 1.070e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1785, It: 0, Loss Data: 1.397e-01, Loss Eqns: 4.030e+00, Loss Aux: 2.390e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1786, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.067e+00, Loss Aux: 1.401e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1787, It: 0, Loss Data: 1.226e-01, Loss Eqns: 4.324e+00, Loss Aux: 1.103e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1788, It: 0, Loss Data: 1.323e-01, Loss Eqns: 4.102e+00, Loss Aux: 8.851e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1789, It: 0, Loss Data: 1.304e-01, Loss Eqns: 4.880e+00, Loss Aux: 1.414e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1790, It: 0, Loss Data: 1.377e-01, Loss Eqns: 4.184e+00, Loss Aux: 1.573e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1791, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.109e+00, Loss Aux: 1.939e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1792, It: 0, Loss Data: 1.078e-01, Loss Eqns: 4.113e+00, Loss Aux: 1.984e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1793, It: 0, Loss Data: 1.334e-01, Loss Eqns: 4.104e+00, Loss Aux: 1.767e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1794, It: 0, Loss Data: 1.128e-01, Loss Eqns: 4.324e+00, Loss Aux: 1.484e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1795, It: 0, Loss Data: 1.182e-01, Loss Eqns: 4.383e+00, Loss Aux: 1.248e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 1796, It: 0, Loss Data: 1.178e-01, Loss Eqns: 4.019e+00, Loss Aux: 1.930e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1797, It: 0, Loss Data: 1.225e-01, Loss Eqns: 4.076e+00, Loss Aux: 1.062e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1798, It: 0, Loss Data: 1.080e-01, Loss Eqns: 4.198e+00, Loss Aux: 3.930e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1799, It: 0, Loss Data: 1.155e-01, Loss Eqns: 4.492e+00, Loss Aux: 3.121e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 1800, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.993e+00, Loss Aux: 1.396e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1801, It: 0, Loss Data: 1.186e-01, Loss Eqns: 4.312e+00, Loss Aux: 1.391e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1802, It: 0, Loss Data: 1.308e-01, Loss Eqns: 4.170e+00, Loss Aux: 1.416e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1803, It: 0, Loss Data: 1.242e-01, Loss Eqns: 4.183e+00, Loss Aux: 1.211e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 1804, It: 0, Loss Data: 1.110e-01, Loss Eqns: 4.361e+00, Loss Aux: 1.032e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1805, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.247e+00, Loss Aux: 1.107e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1806, It: 0, Loss Data: 1.240e-01, Loss Eqns: 4.374e+00, Loss Aux: 1.967e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1807, It: 0, Loss Data: 1.268e-01, Loss Eqns: 4.233e+00, Loss Aux: 1.329e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1808, It: 0, Loss Data: 1.208e-01, Loss Eqns: 4.299e+00, Loss Aux: 1.609e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1809, It: 0, Loss Data: 1.404e-01, Loss Eqns: 4.020e+00, Loss Aux: 1.407e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 1810, It: 0, Loss Data: 1.314e-01, Loss Eqns: 4.116e+00, Loss Aux: 2.977e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1811, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.353e+00, Loss Aux: 1.929e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1812, It: 0, Loss Data: 1.285e-01, Loss Eqns: 3.825e+00, Loss Aux: 8.525e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1813, It: 0, Loss Data: 1.103e-01, Loss Eqns: 4.025e+00, Loss Aux: 9.788e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1814, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.080e+00, Loss Aux: 8.668e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1815, It: 0, Loss Data: 1.154e-01, Loss Eqns: 4.056e+00, Loss Aux: 1.553e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1816, It: 0, Loss Data: 1.156e-01, Loss Eqns: 4.508e+00, Loss Aux: 2.528e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1817, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.479e+00, Loss Aux: 2.299e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1818, It: 0, Loss Data: 1.195e-01, Loss Eqns: 4.244e+00, Loss Aux: 1.255e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1819, It: 0, Loss Data: 1.171e-01, Loss Eqns: 4.450e+00, Loss Aux: 1.050e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1820, It: 0, Loss Data: 1.229e-01, Loss Eqns: 4.186e+00, Loss Aux: 9.838e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1821, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.917e+00, Loss Aux: 9.520e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1822, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.755e+00, Loss Aux: 1.055e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1823, It: 0, Loss Data: 1.142e-01, Loss Eqns: 4.030e+00, Loss Aux: 1.239e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1824, It: 0, Loss Data: 1.270e-01, Loss Eqns: 4.062e+00, Loss Aux: 1.557e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1825, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.870e+00, Loss Aux: 1.318e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1826, It: 0, Loss Data: 1.160e-01, Loss Eqns: 4.250e+00, Loss Aux: 1.482e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1827, It: 0, Loss Data: 1.169e-01, Loss Eqns: 4.221e+00, Loss Aux: 1.790e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1828, It: 0, Loss Data: 1.331e-01, Loss Eqns: 4.004e+00, Loss Aux: 1.401e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1829, It: 0, Loss Data: 1.329e-01, Loss Eqns: 4.045e+00, Loss Aux: 1.247e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1830, It: 0, Loss Data: 1.336e-01, Loss Eqns: 4.177e+00, Loss Aux: 1.358e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1831, It: 0, Loss Data: 1.144e-01, Loss Eqns: 4.350e+00, Loss Aux: 1.808e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1832, It: 0, Loss Data: 1.255e-01, Loss Eqns: 4.302e+00, Loss Aux: 4.908e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1833, It: 0, Loss Data: 1.313e-01, Loss Eqns: 4.247e+00, Loss Aux: 5.411e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1834, It: 0, Loss Data: 1.302e-01, Loss Eqns: 4.090e+00, Loss Aux: 1.250e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1835, It: 0, Loss Data: 1.062e-01, Loss Eqns: 4.397e+00, Loss Aux: 2.363e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1836, It: 0, Loss Data: 1.100e-01, Loss Eqns: 4.303e+00, Loss Aux: 2.146e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1837, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.895e+00, Loss Aux: 1.723e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1838, It: 0, Loss Data: 1.255e-01, Loss Eqns: 4.343e+00, Loss Aux: 1.196e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1839, It: 0, Loss Data: 1.116e-01, Loss Eqns: 4.004e+00, Loss Aux: 8.605e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1840, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.712e+00, Loss Aux: 1.344e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1841, It: 0, Loss Data: 1.292e-01, Loss Eqns: 4.115e+00, Loss Aux: 1.324e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1842, It: 0, Loss Data: 1.329e-01, Loss Eqns: 4.081e+00, Loss Aux: 1.002e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1843, It: 0, Loss Data: 1.125e-01, Loss Eqns: 4.311e+00, Loss Aux: 1.310e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1844, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.880e+00, Loss Aux: 1.827e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 1845, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.822e+00, Loss Aux: 1.123e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1846, It: 0, Loss Data: 1.367e-01, Loss Eqns: 3.957e+00, Loss Aux: 9.391e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1847, It: 0, Loss Data: 1.174e-01, Loss Eqns: 4.286e+00, Loss Aux: 9.685e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1848, It: 0, Loss Data: 1.212e-01, Loss Eqns: 4.555e+00, Loss Aux: 1.276e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1849, It: 0, Loss Data: 1.053e-01, Loss Eqns: 4.065e+00, Loss Aux: 1.850e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1850, It: 0, Loss Data: 1.040e-01, Loss Eqns: 4.182e+00, Loss Aux: 1.386e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1851, It: 0, Loss Data: 1.304e-01, Loss Eqns: 4.063e+00, Loss Aux: 1.162e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 1852, It: 0, Loss Data: 1.090e-01, Loss Eqns: 4.224e+00, Loss Aux: 1.826e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 1853, It: 0, Loss Data: 1.154e-01, Loss Eqns: 4.142e+00, Loss Aux: 3.388e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1854, It: 0, Loss Data: 1.276e-01, Loss Eqns: 4.023e+00, Loss Aux: 1.247e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1855, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.714e+00, Loss Aux: 2.312e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 1856, It: 0, Loss Data: 1.267e-01, Loss Eqns: 3.775e+00, Loss Aux: 1.105e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 1857, It: 0, Loss Data: 1.290e-01, Loss Eqns: 4.297e+00, Loss Aux: 3.262e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 1858, It: 0, Loss Data: 1.152e-01, Loss Eqns: 4.326e+00, Loss Aux: 2.686e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 1859, It: 0, Loss Data: 1.239e-01, Loss Eqns: 4.025e+00, Loss Aux: 1.652e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1860, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.944e+00, Loss Aux: 1.625e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1861, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.957e+00, Loss Aux: 1.690e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1862, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.315e+00, Loss Aux: 1.058e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 1863, It: 0, Loss Data: 1.269e-01, Loss Eqns: 4.129e+00, Loss Aux: 1.096e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1864, It: 0, Loss Data: 1.242e-01, Loss Eqns: 4.148e+00, Loss Aux: 8.408e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1865, It: 0, Loss Data: 1.145e-01, Loss Eqns: 4.952e+00, Loss Aux: 1.844e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1866, It: 0, Loss Data: 1.074e-01, Loss Eqns: 4.060e+00, Loss Aux: 1.797e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1867, It: 0, Loss Data: 1.126e-01, Loss Eqns: 4.498e+00, Loss Aux: 1.398e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1868, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.918e+00, Loss Aux: 1.417e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1869, It: 0, Loss Data: 1.342e-01, Loss Eqns: 3.950e+00, Loss Aux: 2.000e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1870, It: 0, Loss Data: 1.193e-01, Loss Eqns: 4.331e+00, Loss Aux: 1.895e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1871, It: 0, Loss Data: 1.176e-01, Loss Eqns: 4.490e+00, Loss Aux: 1.399e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1872, It: 0, Loss Data: 1.112e-01, Loss Eqns: 4.226e+00, Loss Aux: 1.935e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 1873, It: 0, Loss Data: 1.221e-01, Loss Eqns: 3.942e+00, Loss Aux: 8.754e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1874, It: 0, Loss Data: 1.262e-01, Loss Eqns: 4.039e+00, Loss Aux: 1.381e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1875, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.996e+00, Loss Aux: 1.064e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 1876, It: 0, Loss Data: 1.280e-01, Loss Eqns: 4.388e+00, Loss Aux: 1.287e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1877, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.199e+00, Loss Aux: 1.866e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 1878, It: 0, Loss Data: 1.141e-01, Loss Eqns: 4.246e+00, Loss Aux: 1.612e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1879, It: 0, Loss Data: 1.167e-01, Loss Eqns: 4.158e+00, Loss Aux: 1.461e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1880, It: 0, Loss Data: 1.262e-01, Loss Eqns: 4.186e+00, Loss Aux: 1.273e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 1881, It: 0, Loss Data: 1.326e-01, Loss Eqns: 4.342e+00, Loss Aux: 1.209e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1882, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.657e+00, Loss Aux: 1.515e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1883, It: 0, Loss Data: 1.079e-01, Loss Eqns: 4.097e+00, Loss Aux: 2.164e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1884, It: 0, Loss Data: 1.330e-01, Loss Eqns: 3.947e+00, Loss Aux: 3.503e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1885, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.923e+00, Loss Aux: 1.185e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1886, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.894e+00, Loss Aux: 8.577e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1887, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.825e+00, Loss Aux: 2.080e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1888, It: 0, Loss Data: 1.210e-01, Loss Eqns: 4.099e+00, Loss Aux: 1.363e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1889, It: 0, Loss Data: 1.243e-01, Loss Eqns: 4.161e+00, Loss Aux: 1.973e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1890, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.756e+00, Loss Aux: 9.685e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1891, It: 0, Loss Data: 1.241e-01, Loss Eqns: 4.010e+00, Loss Aux: 2.229e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 1892, It: 0, Loss Data: 1.172e-01, Loss Eqns: 4.432e+00, Loss Aux: 3.003e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1893, It: 0, Loss Data: 1.306e-01, Loss Eqns: 4.373e+00, Loss Aux: 1.613e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1894, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.999e+00, Loss Aux: 1.726e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1895, It: 0, Loss Data: 1.190e-01, Loss Eqns: 4.149e+00, Loss Aux: 1.314e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1896, It: 0, Loss Data: 1.235e-01, Loss Eqns: 4.273e+00, Loss Aux: 2.711e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1897, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.876e+00, Loss Aux: 2.320e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 1898, It: 0, Loss Data: 1.292e-01, Loss Eqns: 4.099e+00, Loss Aux: 7.686e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1899, It: 0, Loss Data: 1.128e-01, Loss Eqns: 4.307e+00, Loss Aux: 8.727e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1900, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.989e+00, Loss Aux: 1.752e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1901, It: 0, Loss Data: 1.250e-01, Loss Eqns: 4.139e+00, Loss Aux: 2.881e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1902, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.778e+00, Loss Aux: 1.808e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1903, It: 0, Loss Data: 1.257e-01, Loss Eqns: 3.760e+00, Loss Aux: 1.668e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1904, It: 0, Loss Data: 1.158e-01, Loss Eqns: 4.134e+00, Loss Aux: 1.465e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1905, It: 0, Loss Data: 1.138e-01, Loss Eqns: 4.583e+00, Loss Aux: 1.662e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 1906, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.715e+00, Loss Aux: 1.253e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1907, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.920e+00, Loss Aux: 9.192e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1908, It: 0, Loss Data: 1.142e-01, Loss Eqns: 4.515e+00, Loss Aux: 1.107e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1909, It: 0, Loss Data: 1.129e-01, Loss Eqns: 4.386e+00, Loss Aux: 1.380e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 1910, It: 0, Loss Data: 9.783e-02, Loss Eqns: 4.391e+00, Loss Aux: 1.320e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1911, It: 0, Loss Data: 1.207e-01, Loss Eqns: 4.246e+00, Loss Aux: 1.028e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1912, It: 0, Loss Data: 1.025e-01, Loss Eqns: 4.269e+00, Loss Aux: 1.053e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1913, It: 0, Loss Data: 1.210e-01, Loss Eqns: 4.202e+00, Loss Aux: 1.602e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1914, It: 0, Loss Data: 1.048e-01, Loss Eqns: 3.937e+00, Loss Aux: 1.189e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1915, It: 0, Loss Data: 1.163e-01, Loss Eqns: 4.284e+00, Loss Aux: 1.015e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1916, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.655e+00, Loss Aux: 8.313e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1917, It: 0, Loss Data: 1.333e-01, Loss Eqns: 4.090e+00, Loss Aux: 7.604e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 1918, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.977e+00, Loss Aux: 2.008e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 1919, It: 0, Loss Data: 1.192e-01, Loss Eqns: 4.261e+00, Loss Aux: 2.114e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 1920, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.019e+00, Loss Aux: 1.190e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1921, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.992e+00, Loss Aux: 1.122e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1922, It: 0, Loss Data: 1.195e-01, Loss Eqns: 4.093e+00, Loss Aux: 1.123e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 1923, It: 0, Loss Data: 1.056e-01, Loss Eqns: 4.340e+00, Loss Aux: 8.866e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 1924, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.201e+00, Loss Aux: 8.663e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 1925, It: 0, Loss Data: 1.255e-01, Loss Eqns: 4.411e+00, Loss Aux: 9.936e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 1926, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.996e+00, Loss Aux: 1.377e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1927, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.006e+00, Loss Aux: 1.397e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1928, It: 0, Loss Data: 1.115e-01, Loss Eqns: 4.246e+00, Loss Aux: 1.146e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1929, It: 0, Loss Data: 1.299e-01, Loss Eqns: 3.903e+00, Loss Aux: 6.484e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1930, It: 0, Loss Data: 1.077e-01, Loss Eqns: 4.004e+00, Loss Aux: 7.344e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 1931, It: 0, Loss Data: 1.425e-01, Loss Eqns: 3.953e+00, Loss Aux: 2.643e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1932, It: 0, Loss Data: 1.076e-01, Loss Eqns: 4.092e+00, Loss Aux: 1.157e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1933, It: 0, Loss Data: 1.282e-01, Loss Eqns: 4.272e+00, Loss Aux: 1.097e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1934, It: 0, Loss Data: 1.257e-01, Loss Eqns: 4.477e+00, Loss Aux: 1.094e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1935, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.932e+00, Loss Aux: 2.373e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 1936, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.961e+00, Loss Aux: 1.721e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 1937, It: 0, Loss Data: 1.323e-01, Loss Eqns: 3.752e+00, Loss Aux: 9.622e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 1938, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.964e+00, Loss Aux: 8.250e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1939, It: 0, Loss Data: 1.324e-01, Loss Eqns: 4.417e+00, Loss Aux: 2.170e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1940, It: 0, Loss Data: 1.200e-01, Loss Eqns: 4.209e+00, Loss Aux: 2.611e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 1941, It: 0, Loss Data: 1.114e-01, Loss Eqns: 4.046e+00, Loss Aux: 1.218e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 1942, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.917e+00, Loss Aux: 1.317e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 1943, It: 0, Loss Data: 1.108e-01, Loss Eqns: 4.084e+00, Loss Aux: 2.012e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 1944, It: 0, Loss Data: 1.248e-01, Loss Eqns: 4.280e+00, Loss Aux: 2.996e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 1945, It: 0, Loss Data: 1.083e-01, Loss Eqns: 4.494e+00, Loss Aux: 1.890e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1946, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.986e+00, Loss Aux: 1.286e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1947, It: 0, Loss Data: 1.308e-01, Loss Eqns: 4.105e+00, Loss Aux: 1.108e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1948, It: 0, Loss Data: 1.323e-01, Loss Eqns: 4.203e+00, Loss Aux: 1.213e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1949, It: 0, Loss Data: 1.277e-01, Loss Eqns: 4.249e+00, Loss Aux: 9.203e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 1950, It: 0, Loss Data: 1.266e-01, Loss Eqns: 4.210e+00, Loss Aux: 8.139e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1951, It: 0, Loss Data: 1.208e-01, Loss Eqns: 4.265e+00, Loss Aux: 8.536e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1952, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.237e+00, Loss Aux: 2.411e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 1953, It: 0, Loss Data: 1.548e-01, Loss Eqns: 4.222e+00, Loss Aux: 5.402e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 1954, It: 0, Loss Data: 2.378e-01, Loss Eqns: 5.422e+00, Loss Aux: 1.630e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 1955, It: 0, Loss Data: 1.471e-01, Loss Eqns: 4.812e+00, Loss Aux: 1.724e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1956, It: 0, Loss Data: 2.280e-01, Loss Eqns: 4.812e+00, Loss Aux: 3.818e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 1957, It: 0, Loss Data: 1.506e-01, Loss Eqns: 4.401e+00, Loss Aux: 5.444e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1958, It: 0, Loss Data: 1.822e-01, Loss Eqns: 5.162e+00, Loss Aux: 1.882e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 1959, It: 0, Loss Data: 1.394e-01, Loss Eqns: 4.146e+00, Loss Aux: 2.025e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 1960, It: 0, Loss Data: 1.848e-01, Loss Eqns: 4.169e+00, Loss Aux: 4.409e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1961, It: 0, Loss Data: 1.550e-01, Loss Eqns: 4.186e+00, Loss Aux: 1.825e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1962, It: 0, Loss Data: 1.857e-01, Loss Eqns: 4.146e+00, Loss Aux: 1.883e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 1963, It: 0, Loss Data: 1.232e-01, Loss Eqns: 4.067e+00, Loss Aux: 3.102e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 1964, It: 0, Loss Data: 1.518e-01, Loss Eqns: 4.166e+00, Loss Aux: 2.612e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1965, It: 0, Loss Data: 1.841e-01, Loss Eqns: 4.184e+00, Loss Aux: 1.796e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 1966, It: 0, Loss Data: 1.536e-01, Loss Eqns: 3.831e+00, Loss Aux: 1.000e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 1967, It: 0, Loss Data: 1.617e-01, Loss Eqns: 3.881e+00, Loss Aux: 6.298e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1968, It: 0, Loss Data: 1.383e-01, Loss Eqns: 4.093e+00, Loss Aux: 6.626e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 1969, It: 0, Loss Data: 1.325e-01, Loss Eqns: 4.424e+00, Loss Aux: 1.432e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1970, It: 0, Loss Data: 1.468e-01, Loss Eqns: 3.872e+00, Loss Aux: 8.820e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 1971, It: 0, Loss Data: 1.261e-01, Loss Eqns: 4.394e+00, Loss Aux: 1.622e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 1972, It: 0, Loss Data: 1.466e-01, Loss Eqns: 4.400e+00, Loss Aux: 1.767e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1973, It: 0, Loss Data: 1.518e-01, Loss Eqns: 4.323e+00, Loss Aux: 1.938e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 1974, It: 0, Loss Data: 1.364e-01, Loss Eqns: 4.243e+00, Loss Aux: 1.833e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 1975, It: 0, Loss Data: 1.327e-01, Loss Eqns: 4.204e+00, Loss Aux: 1.477e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 1976, It: 0, Loss Data: 1.251e-01, Loss Eqns: 4.169e+00, Loss Aux: 2.015e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1977, It: 0, Loss Data: 1.395e-01, Loss Eqns: 4.084e+00, Loss Aux: 1.879e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 1978, It: 0, Loss Data: 1.331e-01, Loss Eqns: 3.780e+00, Loss Aux: 1.330e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 1979, It: 0, Loss Data: 1.528e-01, Loss Eqns: 4.284e+00, Loss Aux: 1.096e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1980, It: 0, Loss Data: 1.169e-01, Loss Eqns: 4.087e+00, Loss Aux: 1.523e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1981, It: 0, Loss Data: 1.281e-01, Loss Eqns: 3.946e+00, Loss Aux: 2.261e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 1982, It: 0, Loss Data: 1.251e-01, Loss Eqns: 4.066e+00, Loss Aux: 1.632e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1983, It: 0, Loss Data: 1.231e-01, Loss Eqns: 4.313e+00, Loss Aux: 1.098e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1984, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.902e+00, Loss Aux: 1.037e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 1985, It: 0, Loss Data: 1.142e-01, Loss Eqns: 4.240e+00, Loss Aux: 2.369e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 1986, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.941e+00, Loss Aux: 2.719e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1987, It: 0, Loss Data: 1.082e-01, Loss Eqns: 4.081e+00, Loss Aux: 1.102e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 1988, It: 0, Loss Data: 1.151e-01, Loss Eqns: 4.203e+00, Loss Aux: 9.527e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 1989, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.946e+00, Loss Aux: 1.401e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 1990, It: 0, Loss Data: 1.323e-01, Loss Eqns: 3.934e+00, Loss Aux: 1.556e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 1991, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.859e+00, Loss Aux: 9.898e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1992, It: 0, Loss Data: 1.178e-01, Loss Eqns: 3.994e+00, Loss Aux: 9.431e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 1993, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.240e+00, Loss Aux: 9.564e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 1994, It: 0, Loss Data: 1.336e-01, Loss Eqns: 4.078e+00, Loss Aux: 1.223e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 1995, It: 0, Loss Data: 1.030e-01, Loss Eqns: 4.141e+00, Loss Aux: 1.889e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 1996, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.941e+00, Loss Aux: 2.160e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 1997, It: 0, Loss Data: 1.117e-01, Loss Eqns: 4.277e+00, Loss Aux: 8.693e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 1998, It: 0, Loss Data: 1.289e-01, Loss Eqns: 4.236e+00, Loss Aux: 7.057e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 1999, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.235e+00, Loss Aux: 6.374e-03, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 2000, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.123e+00, Loss Aux: 1.359e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2001, It: 0, Loss Data: 1.239e-01, Loss Eqns: 3.845e+00, Loss Aux: 1.121e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2002, It: 0, Loss Data: 1.215e-01, Loss Eqns: 4.234e+00, Loss Aux: 1.435e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2003, It: 0, Loss Data: 1.151e-01, Loss Eqns: 4.126e+00, Loss Aux: 1.828e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2004, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.207e+00, Loss Aux: 1.570e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2005, It: 0, Loss Data: 1.080e-01, Loss Eqns: 4.229e+00, Loss Aux: 1.184e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2006, It: 0, Loss Data: 1.303e-01, Loss Eqns: 3.873e+00, Loss Aux: 1.060e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2007, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.831e+00, Loss Aux: 1.031e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 2008, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.804e+00, Loss Aux: 7.213e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2009, It: 0, Loss Data: 1.252e-01, Loss Eqns: 4.438e+00, Loss Aux: 6.312e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2010, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.962e+00, Loss Aux: 1.572e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2011, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.904e+00, Loss Aux: 2.026e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2012, It: 0, Loss Data: 1.056e-01, Loss Eqns: 4.351e+00, Loss Aux: 9.903e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2013, It: 0, Loss Data: 1.084e-01, Loss Eqns: 4.457e+00, Loss Aux: 1.215e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2014, It: 0, Loss Data: 1.169e-01, Loss Eqns: 4.248e+00, Loss Aux: 2.191e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2015, It: 0, Loss Data: 1.203e-01, Loss Eqns: 4.293e+00, Loss Aux: 2.338e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2016, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.896e+00, Loss Aux: 8.668e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2017, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.973e+00, Loss Aux: 9.624e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2018, It: 0, Loss Data: 1.398e-01, Loss Eqns: 4.184e+00, Loss Aux: 8.730e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 2019, It: 0, Loss Data: 1.155e-01, Loss Eqns: 4.201e+00, Loss Aux: 1.064e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2020, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.868e+00, Loss Aux: 2.196e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2021, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.902e+00, Loss Aux: 1.955e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2022, It: 0, Loss Data: 1.589e-01, Loss Eqns: 4.031e+00, Loss Aux: 1.116e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2023, It: 0, Loss Data: 1.455e-01, Loss Eqns: 4.281e+00, Loss Aux: 2.145e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2024, It: 0, Loss Data: 1.374e-01, Loss Eqns: 4.145e+00, Loss Aux: 2.929e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2025, It: 0, Loss Data: 1.378e-01, Loss Eqns: 4.457e+00, Loss Aux: 1.338e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2026, It: 0, Loss Data: 1.469e-01, Loss Eqns: 4.104e+00, Loss Aux: 2.260e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2027, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.094e+00, Loss Aux: 1.105e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2028, It: 0, Loss Data: 1.174e-01, Loss Eqns: 4.305e+00, Loss Aux: 1.167e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2029, It: 0, Loss Data: 1.290e-01, Loss Eqns: 4.087e+00, Loss Aux: 1.549e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2030, It: 0, Loss Data: 1.357e-01, Loss Eqns: 4.197e+00, Loss Aux: 2.423e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2031, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.730e+00, Loss Aux: 1.431e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2032, It: 0, Loss Data: 1.502e-01, Loss Eqns: 3.549e+00, Loss Aux: 1.876e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2033, It: 0, Loss Data: 1.359e-01, Loss Eqns: 4.039e+00, Loss Aux: 3.474e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 2034, It: 0, Loss Data: 1.143e-01, Loss Eqns: 4.174e+00, Loss Aux: 1.987e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2035, It: 0, Loss Data: 1.141e-01, Loss Eqns: 4.680e+00, Loss Aux: 1.631e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2036, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.174e+00, Loss Aux: 2.470e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2037, It: 0, Loss Data: 1.379e-01, Loss Eqns: 3.956e+00, Loss Aux: 1.419e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2038, It: 0, Loss Data: 1.319e-01, Loss Eqns: 4.244e+00, Loss Aux: 3.280e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2039, It: 0, Loss Data: 1.289e-01, Loss Eqns: 3.819e+00, Loss Aux: 2.180e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 2040, It: 0, Loss Data: 1.289e-01, Loss Eqns: 4.024e+00, Loss Aux: 1.224e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2041, It: 0, Loss Data: 1.258e-01, Loss Eqns: 4.132e+00, Loss Aux: 9.460e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2042, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.712e+00, Loss Aux: 7.941e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2043, It: 0, Loss Data: 1.346e-01, Loss Eqns: 4.329e+00, Loss Aux: 1.332e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2044, It: 0, Loss Data: 1.062e-01, Loss Eqns: 4.079e+00, Loss Aux: 1.148e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2045, It: 0, Loss Data: 1.226e-01, Loss Eqns: 4.189e+00, Loss Aux: 2.780e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2046, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.055e+00, Loss Aux: 1.965e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2047, It: 0, Loss Data: 1.070e-01, Loss Eqns: 4.212e+00, Loss Aux: 1.295e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2048, It: 0, Loss Data: 9.996e-02, Loss Eqns: 3.877e+00, Loss Aux: 1.051e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2049, It: 0, Loss Data: 1.043e-01, Loss Eqns: 4.036e+00, Loss Aux: 1.077e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2050, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.830e+00, Loss Aux: 1.275e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2051, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.871e+00, Loss Aux: 8.311e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2052, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.967e+00, Loss Aux: 8.816e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2053, It: 0, Loss Data: 1.107e-01, Loss Eqns: 4.069e+00, Loss Aux: 1.467e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2054, It: 0, Loss Data: 1.057e-01, Loss Eqns: 4.367e+00, Loss Aux: 1.774e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2055, It: 0, Loss Data: 1.164e-01, Loss Eqns: 4.052e+00, Loss Aux: 1.243e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2056, It: 0, Loss Data: 1.086e-01, Loss Eqns: 3.901e+00, Loss Aux: 1.218e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2057, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.777e+00, Loss Aux: 1.317e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2058, It: 0, Loss Data: 1.160e-01, Loss Eqns: 4.238e+00, Loss Aux: 2.269e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2059, It: 0, Loss Data: 1.161e-01, Loss Eqns: 4.033e+00, Loss Aux: 8.770e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2060, It: 0, Loss Data: 1.262e-01, Loss Eqns: 4.030e+00, Loss Aux: 1.150e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2061, It: 0, Loss Data: 1.291e-01, Loss Eqns: 4.015e+00, Loss Aux: 5.923e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2062, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.639e+00, Loss Aux: 3.980e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2063, It: 0, Loss Data: 1.254e-01, Loss Eqns: 4.183e+00, Loss Aux: 4.349e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2064, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.635e+00, Loss Aux: 1.170e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2065, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.966e+00, Loss Aux: 8.714e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2066, It: 0, Loss Data: 1.288e-01, Loss Eqns: 4.034e+00, Loss Aux: 1.453e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2067, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.896e+00, Loss Aux: 1.308e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2068, It: 0, Loss Data: 1.079e-01, Loss Eqns: 4.081e+00, Loss Aux: 1.350e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2069, It: 0, Loss Data: 1.328e-01, Loss Eqns: 3.887e+00, Loss Aux: 9.828e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2070, It: 0, Loss Data: 1.302e-01, Loss Eqns: 4.223e+00, Loss Aux: 3.108e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2071, It: 0, Loss Data: 1.136e-01, Loss Eqns: 4.312e+00, Loss Aux: 4.356e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2072, It: 0, Loss Data: 1.256e-01, Loss Eqns: 4.345e+00, Loss Aux: 2.002e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2073, It: 0, Loss Data: 1.117e-01, Loss Eqns: 4.160e+00, Loss Aux: 1.516e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2074, It: 0, Loss Data: 9.744e-02, Loss Eqns: 4.162e+00, Loss Aux: 1.126e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2075, It: 0, Loss Data: 1.234e-01, Loss Eqns: 4.326e+00, Loss Aux: 2.675e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2076, It: 0, Loss Data: 1.309e-01, Loss Eqns: 4.046e+00, Loss Aux: 4.246e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2077, It: 0, Loss Data: 1.453e-01, Loss Eqns: 3.996e+00, Loss Aux: 1.582e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2078, It: 0, Loss Data: 1.194e-01, Loss Eqns: 4.205e+00, Loss Aux: 1.078e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2079, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.389e+00, Loss Aux: 1.460e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2080, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.083e+00, Loss Aux: 2.493e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2081, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.932e+00, Loss Aux: 2.173e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2082, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.860e+00, Loss Aux: 1.558e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2083, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.935e+00, Loss Aux: 2.644e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2084, It: 0, Loss Data: 1.055e-01, Loss Eqns: 4.224e+00, Loss Aux: 2.276e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 2085, It: 0, Loss Data: 9.501e-02, Loss Eqns: 3.936e+00, Loss Aux: 1.296e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2086, It: 0, Loss Data: 1.307e-01, Loss Eqns: 3.848e+00, Loss Aux: 1.834e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2087, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.628e+00, Loss Aux: 1.688e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2088, It: 0, Loss Data: 1.276e-01, Loss Eqns: 4.189e+00, Loss Aux: 3.489e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2089, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.564e+00, Loss Aux: 2.888e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2090, It: 0, Loss Data: 1.127e-01, Loss Eqns: 4.173e+00, Loss Aux: 7.527e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2091, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.932e+00, Loss Aux: 6.698e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2092, It: 0, Loss Data: 1.219e-01, Loss Eqns: 4.034e+00, Loss Aux: 1.130e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2093, It: 0, Loss Data: 1.123e-01, Loss Eqns: 4.087e+00, Loss Aux: 2.123e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2094, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.867e+00, Loss Aux: 2.321e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2095, It: 0, Loss Data: 1.271e-01, Loss Eqns: 4.005e+00, Loss Aux: 9.742e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2096, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.940e+00, Loss Aux: 7.602e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2097, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.991e+00, Loss Aux: 9.143e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2098, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.027e+00, Loss Aux: 1.000e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 2099, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.060e+00, Loss Aux: 1.279e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2100, It: 0, Loss Data: 1.179e-01, Loss Eqns: 4.096e+00, Loss Aux: 1.640e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2101, It: 0, Loss Data: 1.023e-01, Loss Eqns: 4.116e+00, Loss Aux: 2.634e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2102, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.831e+00, Loss Aux: 2.334e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2103, It: 0, Loss Data: 1.281e-01, Loss Eqns: 4.137e+00, Loss Aux: 1.556e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2104, It: 0, Loss Data: 1.147e-01, Loss Eqns: 4.138e+00, Loss Aux: 1.850e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2105, It: 0, Loss Data: 1.286e-01, Loss Eqns: 4.116e+00, Loss Aux: 2.709e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2106, It: 0, Loss Data: 1.349e-01, Loss Eqns: 4.296e+00, Loss Aux: 1.458e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2107, It: 0, Loss Data: 1.428e-01, Loss Eqns: 3.866e+00, Loss Aux: 1.549e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2108, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.893e+00, Loss Aux: 5.310e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2109, It: 0, Loss Data: 1.280e-01, Loss Eqns: 3.901e+00, Loss Aux: 2.199e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2110, It: 0, Loss Data: 1.387e-01, Loss Eqns: 4.355e+00, Loss Aux: 3.527e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 2111, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.865e+00, Loss Aux: 1.754e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2112, It: 0, Loss Data: 1.286e-01, Loss Eqns: 4.157e+00, Loss Aux: 1.182e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2113, It: 0, Loss Data: 1.177e-01, Loss Eqns: 4.087e+00, Loss Aux: 1.899e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2114, It: 0, Loss Data: 1.294e-01, Loss Eqns: 4.424e+00, Loss Aux: 1.478e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2115, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.879e+00, Loss Aux: 2.066e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2116, It: 0, Loss Data: 1.181e-01, Loss Eqns: 4.166e+00, Loss Aux: 7.790e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2117, It: 0, Loss Data: 1.196e-01, Loss Eqns: 4.290e+00, Loss Aux: 3.433e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2118, It: 0, Loss Data: 1.118e-01, Loss Eqns: 4.247e+00, Loss Aux: 7.579e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2119, It: 0, Loss Data: 9.737e-02, Loss Eqns: 4.525e+00, Loss Aux: 1.766e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2120, It: 0, Loss Data: 1.045e-01, Loss Eqns: 3.935e+00, Loss Aux: 1.883e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2121, It: 0, Loss Data: 1.217e-01, Loss Eqns: 4.360e+00, Loss Aux: 1.319e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2122, It: 0, Loss Data: 1.246e-01, Loss Eqns: 4.093e+00, Loss Aux: 1.254e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2123, It: 0, Loss Data: 1.233e-01, Loss Eqns: 4.119e+00, Loss Aux: 1.401e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2124, It: 0, Loss Data: 1.158e-01, Loss Eqns: 4.059e+00, Loss Aux: 1.080e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2125, It: 0, Loss Data: 1.231e-01, Loss Eqns: 4.209e+00, Loss Aux: 1.071e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 2126, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.302e+00, Loss Aux: 9.992e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2127, It: 0, Loss Data: 1.182e-01, Loss Eqns: 4.003e+00, Loss Aux: 2.599e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2128, It: 0, Loss Data: 1.244e-01, Loss Eqns: 4.095e+00, Loss Aux: 3.568e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 2129, It: 0, Loss Data: 1.111e-01, Loss Eqns: 4.018e+00, Loss Aux: 1.627e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2130, It: 0, Loss Data: 1.327e-01, Loss Eqns: 4.201e+00, Loss Aux: 6.827e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2131, It: 0, Loss Data: 1.110e-01, Loss Eqns: 4.334e+00, Loss Aux: 9.880e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2132, It: 0, Loss Data: 1.030e-01, Loss Eqns: 4.140e+00, Loss Aux: 1.275e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2133, It: 0, Loss Data: 1.369e-01, Loss Eqns: 3.974e+00, Loss Aux: 1.345e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2134, It: 0, Loss Data: 1.272e-01, Loss Eqns: 3.886e+00, Loss Aux: 1.567e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2135, It: 0, Loss Data: 1.364e-01, Loss Eqns: 4.064e+00, Loss Aux: 2.021e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2136, It: 0, Loss Data: 1.344e-01, Loss Eqns: 4.214e+00, Loss Aux: 2.291e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2137, It: 0, Loss Data: 1.327e-01, Loss Eqns: 4.072e+00, Loss Aux: 1.875e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2138, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.921e+00, Loss Aux: 1.995e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2139, It: 0, Loss Data: 1.098e-01, Loss Eqns: 4.099e+00, Loss Aux: 1.979e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2140, It: 0, Loss Data: 1.512e-01, Loss Eqns: 4.140e+00, Loss Aux: 1.127e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2141, It: 0, Loss Data: 1.138e-01, Loss Eqns: 4.232e+00, Loss Aux: 1.752e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 2142, It: 0, Loss Data: 1.255e-01, Loss Eqns: 4.507e+00, Loss Aux: 8.118e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 2143, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.887e+00, Loss Aux: 3.958e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2144, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.788e+00, Loss Aux: 1.978e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2145, It: 0, Loss Data: 1.510e-01, Loss Eqns: 3.988e+00, Loss Aux: 1.232e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 2146, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.864e+00, Loss Aux: 1.902e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2147, It: 0, Loss Data: 1.499e-01, Loss Eqns: 3.971e+00, Loss Aux: 2.907e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2148, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.882e+00, Loss Aux: 7.649e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2149, It: 0, Loss Data: 1.224e-01, Loss Eqns: 3.980e+00, Loss Aux: 1.554e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2150, It: 0, Loss Data: 1.336e-01, Loss Eqns: 3.824e+00, Loss Aux: 1.166e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2151, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.727e+00, Loss Aux: 1.690e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2152, It: 0, Loss Data: 1.229e-01, Loss Eqns: 4.560e+00, Loss Aux: 4.231e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2153, It: 0, Loss Data: 1.172e-01, Loss Eqns: 4.296e+00, Loss Aux: 2.976e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2154, It: 0, Loss Data: 1.409e-01, Loss Eqns: 4.458e+00, Loss Aux: 1.122e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2155, It: 0, Loss Data: 1.081e-01, Loss Eqns: 4.022e+00, Loss Aux: 6.982e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2156, It: 0, Loss Data: 1.501e-01, Loss Eqns: 4.059e+00, Loss Aux: 8.301e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2157, It: 0, Loss Data: 1.239e-01, Loss Eqns: 4.003e+00, Loss Aux: 1.555e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2158, It: 0, Loss Data: 1.357e-01, Loss Eqns: 3.963e+00, Loss Aux: 1.015e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2159, It: 0, Loss Data: 1.272e-01, Loss Eqns: 3.952e+00, Loss Aux: 1.147e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2160, It: 0, Loss Data: 1.341e-01, Loss Eqns: 3.907e+00, Loss Aux: 1.493e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2161, It: 0, Loss Data: 1.461e-01, Loss Eqns: 3.972e+00, Loss Aux: 2.847e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2162, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.992e+00, Loss Aux: 1.317e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2163, It: 0, Loss Data: 1.438e-01, Loss Eqns: 4.031e+00, Loss Aux: 9.046e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2164, It: 0, Loss Data: 1.224e-01, Loss Eqns: 4.188e+00, Loss Aux: 1.765e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2165, It: 0, Loss Data: 1.241e-01, Loss Eqns: 4.390e+00, Loss Aux: 1.995e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2166, It: 0, Loss Data: 1.202e-01, Loss Eqns: 4.021e+00, Loss Aux: 1.694e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2167, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.987e+00, Loss Aux: 1.624e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2168, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.259e+00, Loss Aux: 1.943e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2169, It: 0, Loss Data: 1.152e-01, Loss Eqns: 4.092e+00, Loss Aux: 1.044e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2170, It: 0, Loss Data: 1.129e-01, Loss Eqns: 4.229e+00, Loss Aux: 8.265e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2171, It: 0, Loss Data: 9.626e-02, Loss Eqns: 3.743e+00, Loss Aux: 1.342e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2172, It: 0, Loss Data: 1.358e-01, Loss Eqns: 3.777e+00, Loss Aux: 1.096e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2173, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.971e+00, Loss Aux: 1.267e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2174, It: 0, Loss Data: 1.029e-01, Loss Eqns: 3.993e+00, Loss Aux: 1.324e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2175, It: 0, Loss Data: 1.380e-01, Loss Eqns: 3.880e+00, Loss Aux: 1.043e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2176, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.885e+00, Loss Aux: 8.649e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2177, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.828e+00, Loss Aux: 1.257e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2178, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.369e+00, Loss Aux: 2.388e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2179, It: 0, Loss Data: 1.250e-01, Loss Eqns: 4.074e+00, Loss Aux: 2.581e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2180, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.861e+00, Loss Aux: 9.842e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2181, It: 0, Loss Data: 1.122e-01, Loss Eqns: 4.009e+00, Loss Aux: 7.369e-03, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2182, It: 0, Loss Data: 1.154e-01, Loss Eqns: 4.031e+00, Loss Aux: 9.489e-03, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2183, It: 0, Loss Data: 1.219e-01, Loss Eqns: 4.126e+00, Loss Aux: 1.266e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2184, It: 0, Loss Data: 1.029e-01, Loss Eqns: 4.277e+00, Loss Aux: 9.168e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2185, It: 0, Loss Data: 1.083e-01, Loss Eqns: 4.278e+00, Loss Aux: 1.245e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2186, It: 0, Loss Data: 1.180e-01, Loss Eqns: 4.405e+00, Loss Aux: 1.834e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2187, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.849e+00, Loss Aux: 1.512e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2188, It: 0, Loss Data: 1.156e-01, Loss Eqns: 4.304e+00, Loss Aux: 1.340e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2189, It: 0, Loss Data: 1.241e-01, Loss Eqns: 3.857e+00, Loss Aux: 8.990e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2190, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.973e+00, Loss Aux: 1.061e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2191, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.304e+00, Loss Aux: 7.403e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2192, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.957e+00, Loss Aux: 5.087e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2193, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.919e+00, Loss Aux: 9.757e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2194, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.830e+00, Loss Aux: 1.713e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2195, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.646e+00, Loss Aux: 1.453e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2196, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.959e+00, Loss Aux: 1.118e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 2197, It: 0, Loss Data: 1.021e-01, Loss Eqns: 4.165e+00, Loss Aux: 9.951e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2198, It: 0, Loss Data: 1.285e-01, Loss Eqns: 4.108e+00, Loss Aux: 7.533e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2199, It: 0, Loss Data: 1.226e-01, Loss Eqns: 4.149e+00, Loss Aux: 1.567e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2200, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.836e+00, Loss Aux: 1.000e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2201, It: 0, Loss Data: 1.040e-01, Loss Eqns: 3.953e+00, Loss Aux: 9.977e-03, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 2202, It: 0, Loss Data: 1.026e-01, Loss Eqns: 4.055e+00, Loss Aux: 9.443e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2203, It: 0, Loss Data: 1.074e-01, Loss Eqns: 4.017e+00, Loss Aux: 7.567e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2204, It: 0, Loss Data: 1.098e-01, Loss Eqns: 4.236e+00, Loss Aux: 1.109e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2205, It: 0, Loss Data: 1.253e-01, Loss Eqns: 4.167e+00, Loss Aux: 1.774e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2206, It: 0, Loss Data: 1.329e-01, Loss Eqns: 4.157e+00, Loss Aux: 3.200e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2207, It: 0, Loss Data: 1.335e-01, Loss Eqns: 4.173e+00, Loss Aux: 2.946e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2208, It: 0, Loss Data: 1.197e-01, Loss Eqns: 4.196e+00, Loss Aux: 1.162e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2209, It: 0, Loss Data: 1.186e-01, Loss Eqns: 4.206e+00, Loss Aux: 2.140e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2210, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.902e+00, Loss Aux: 8.591e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 2211, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.827e+00, Loss Aux: 1.870e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2212, It: 0, Loss Data: 1.106e-01, Loss Eqns: 3.726e+00, Loss Aux: 2.508e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2213, It: 0, Loss Data: 9.820e-02, Loss Eqns: 4.184e+00, Loss Aux: 1.432e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2214, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.915e+00, Loss Aux: 7.743e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2215, It: 0, Loss Data: 1.196e-01, Loss Eqns: 4.029e+00, Loss Aux: 7.763e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2216, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.842e+00, Loss Aux: 1.580e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2217, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.939e+00, Loss Aux: 1.717e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2218, It: 0, Loss Data: 1.203e-01, Loss Eqns: 4.059e+00, Loss Aux: 1.285e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2219, It: 0, Loss Data: 1.237e-01, Loss Eqns: 4.048e+00, Loss Aux: 1.235e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2220, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.733e+00, Loss Aux: 1.076e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2221, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.919e+00, Loss Aux: 8.053e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2222, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.890e+00, Loss Aux: 8.258e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2223, It: 0, Loss Data: 1.017e-01, Loss Eqns: 4.081e+00, Loss Aux: 1.712e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2224, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.267e+00, Loss Aux: 2.399e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2225, It: 0, Loss Data: 1.107e-01, Loss Eqns: 4.146e+00, Loss Aux: 1.363e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2226, It: 0, Loss Data: 1.132e-01, Loss Eqns: 4.052e+00, Loss Aux: 9.248e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2227, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.951e+00, Loss Aux: 8.703e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2228, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.944e+00, Loss Aux: 1.123e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2229, It: 0, Loss Data: 1.497e-01, Loss Eqns: 4.093e+00, Loss Aux: 2.212e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2230, It: 0, Loss Data: 1.181e-01, Loss Eqns: 4.012e+00, Loss Aux: 1.292e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2231, It: 0, Loss Data: 1.395e-01, Loss Eqns: 3.816e+00, Loss Aux: 1.991e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2232, It: 0, Loss Data: 1.181e-01, Loss Eqns: 4.220e+00, Loss Aux: 1.635e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2233, It: 0, Loss Data: 1.342e-01, Loss Eqns: 4.014e+00, Loss Aux: 5.109e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2234, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.956e+00, Loss Aux: 3.494e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2235, It: 0, Loss Data: 1.435e-01, Loss Eqns: 3.991e+00, Loss Aux: 7.004e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2236, It: 0, Loss Data: 1.118e-01, Loss Eqns: 4.271e+00, Loss Aux: 6.656e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2237, It: 0, Loss Data: 1.075e-01, Loss Eqns: 4.011e+00, Loss Aux: 1.264e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2238, It: 0, Loss Data: 1.266e-01, Loss Eqns: 4.301e+00, Loss Aux: 1.478e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 2239, It: 0, Loss Data: 1.232e-01, Loss Eqns: 4.223e+00, Loss Aux: 1.449e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2240, It: 0, Loss Data: 1.233e-01, Loss Eqns: 4.121e+00, Loss Aux: 1.521e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2241, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.172e+00, Loss Aux: 1.149e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2242, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.866e+00, Loss Aux: 2.874e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2243, It: 0, Loss Data: 1.228e-01, Loss Eqns: 4.227e+00, Loss Aux: 2.120e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2244, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.726e+00, Loss Aux: 5.623e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2245, It: 0, Loss Data: 1.096e-01, Loss Eqns: 3.963e+00, Loss Aux: 6.825e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2246, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.778e+00, Loss Aux: 1.562e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2247, It: 0, Loss Data: 1.476e-01, Loss Eqns: 3.931e+00, Loss Aux: 1.043e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2248, It: 0, Loss Data: 1.305e-01, Loss Eqns: 3.881e+00, Loss Aux: 9.759e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2249, It: 0, Loss Data: 1.127e-01, Loss Eqns: 4.171e+00, Loss Aux: 1.354e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2250, It: 0, Loss Data: 1.103e-01, Loss Eqns: 4.091e+00, Loss Aux: 3.087e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2251, It: 0, Loss Data: 1.290e-01, Loss Eqns: 4.280e+00, Loss Aux: 2.739e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2252, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.993e+00, Loss Aux: 1.201e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2253, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.970e+00, Loss Aux: 9.242e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2254, It: 0, Loss Data: 1.083e-01, Loss Eqns: 4.031e+00, Loss Aux: 7.432e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2255, It: 0, Loss Data: 1.012e-01, Loss Eqns: 4.023e+00, Loss Aux: 7.291e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2256, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.925e+00, Loss Aux: 1.562e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2257, It: 0, Loss Data: 1.004e-01, Loss Eqns: 3.913e+00, Loss Aux: 1.484e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2258, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.932e+00, Loss Aux: 8.681e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2259, It: 0, Loss Data: 1.033e-01, Loss Eqns: 4.039e+00, Loss Aux: 1.332e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2260, It: 0, Loss Data: 1.392e-01, Loss Eqns: 4.125e+00, Loss Aux: 1.423e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2261, It: 0, Loss Data: 1.097e-01, Loss Eqns: 4.119e+00, Loss Aux: 1.101e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2262, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.559e+00, Loss Aux: 1.191e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2263, It: 0, Loss Data: 1.324e-01, Loss Eqns: 3.982e+00, Loss Aux: 2.226e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 2264, It: 0, Loss Data: 1.387e-01, Loss Eqns: 3.514e+00, Loss Aux: 1.131e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2265, It: 0, Loss Data: 1.198e-01, Loss Eqns: 4.097e+00, Loss Aux: 8.326e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2266, It: 0, Loss Data: 1.140e-01, Loss Eqns: 4.115e+00, Loss Aux: 9.473e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2267, It: 0, Loss Data: 1.368e-01, Loss Eqns: 3.939e+00, Loss Aux: 2.066e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 2268, It: 0, Loss Data: 1.320e-01, Loss Eqns: 4.046e+00, Loss Aux: 2.134e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2269, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.916e+00, Loss Aux: 1.387e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2270, It: 0, Loss Data: 1.221e-01, Loss Eqns: 4.160e+00, Loss Aux: 9.287e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2271, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.714e+00, Loss Aux: 7.665e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2272, It: 0, Loss Data: 1.047e-01, Loss Eqns: 4.315e+00, Loss Aux: 8.515e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2273, It: 0, Loss Data: 1.089e-01, Loss Eqns: 3.918e+00, Loss Aux: 9.098e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2274, It: 0, Loss Data: 1.245e-01, Loss Eqns: 4.174e+00, Loss Aux: 8.702e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2275, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.710e+00, Loss Aux: 1.695e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2276, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.999e+00, Loss Aux: 3.282e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2277, It: 0, Loss Data: 1.271e-01, Loss Eqns: 4.206e+00, Loss Aux: 2.335e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2278, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.929e+00, Loss Aux: 8.779e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2279, It: 0, Loss Data: 1.157e-01, Loss Eqns: 4.184e+00, Loss Aux: 6.066e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2280, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.867e+00, Loss Aux: 1.644e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2281, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.869e+00, Loss Aux: 8.018e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2282, It: 0, Loss Data: 1.426e-01, Loss Eqns: 3.634e+00, Loss Aux: 9.455e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2283, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.917e+00, Loss Aux: 9.196e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2284, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.895e+00, Loss Aux: 4.234e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2285, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.680e+00, Loss Aux: 3.205e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2286, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.137e+00, Loss Aux: 1.543e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2287, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.617e+00, Loss Aux: 8.556e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2288, It: 0, Loss Data: 1.249e-01, Loss Eqns: 4.045e+00, Loss Aux: 7.792e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2289, It: 0, Loss Data: 1.062e-01, Loss Eqns: 4.245e+00, Loss Aux: 4.305e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2290, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.951e+00, Loss Aux: 6.710e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2291, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.900e+00, Loss Aux: 1.142e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2292, It: 0, Loss Data: 1.330e-01, Loss Eqns: 3.964e+00, Loss Aux: 3.082e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2293, It: 0, Loss Data: 1.295e-01, Loss Eqns: 3.862e+00, Loss Aux: 2.200e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2294, It: 0, Loss Data: 1.177e-01, Loss Eqns: 4.142e+00, Loss Aux: 1.046e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2295, It: 0, Loss Data: 1.209e-01, Loss Eqns: 4.139e+00, Loss Aux: 6.109e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2296, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.865e+00, Loss Aux: 9.872e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 2297, It: 0, Loss Data: 1.147e-01, Loss Eqns: 3.996e+00, Loss Aux: 1.715e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2298, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.664e+00, Loss Aux: 1.027e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2299, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.866e+00, Loss Aux: 2.151e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 2300, It: 0, Loss Data: 1.027e-01, Loss Eqns: 3.644e+00, Loss Aux: 1.624e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2301, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.917e+00, Loss Aux: 4.153e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2302, It: 0, Loss Data: 1.297e-01, Loss Eqns: 3.688e+00, Loss Aux: 1.577e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2303, It: 0, Loss Data: 1.160e-01, Loss Eqns: 4.124e+00, Loss Aux: 7.393e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2304, It: 0, Loss Data: 1.335e-01, Loss Eqns: 3.922e+00, Loss Aux: 1.038e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 2305, It: 0, Loss Data: 1.278e-01, Loss Eqns: 4.109e+00, Loss Aux: 1.064e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2306, It: 0, Loss Data: 1.019e-01, Loss Eqns: 4.099e+00, Loss Aux: 9.762e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2307, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.781e+00, Loss Aux: 1.136e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2308, It: 0, Loss Data: 1.210e-01, Loss Eqns: 4.254e+00, Loss Aux: 1.483e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2309, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.962e+00, Loss Aux: 2.631e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 2310, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.773e+00, Loss Aux: 1.991e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2311, It: 0, Loss Data: 1.062e-01, Loss Eqns: 3.836e+00, Loss Aux: 8.766e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2312, It: 0, Loss Data: 1.292e-01, Loss Eqns: 4.043e+00, Loss Aux: 9.600e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2313, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.799e+00, Loss Aux: 1.484e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2314, It: 0, Loss Data: 1.229e-01, Loss Eqns: 4.051e+00, Loss Aux: 1.588e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 2315, It: 0, Loss Data: 1.026e-01, Loss Eqns: 4.260e+00, Loss Aux: 8.631e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2316, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.912e+00, Loss Aux: 6.598e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2317, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.928e+00, Loss Aux: 1.226e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2318, It: 0, Loss Data: 1.220e-01, Loss Eqns: 4.169e+00, Loss Aux: 2.744e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2319, It: 0, Loss Data: 1.201e-01, Loss Eqns: 4.197e+00, Loss Aux: 2.810e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2320, It: 0, Loss Data: 1.066e-01, Loss Eqns: 3.744e+00, Loss Aux: 1.747e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2321, It: 0, Loss Data: 1.205e-01, Loss Eqns: 3.908e+00, Loss Aux: 1.199e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2322, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.535e+00, Loss Aux: 1.403e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2323, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.724e+00, Loss Aux: 1.169e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2324, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.872e+00, Loss Aux: 8.904e-03, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 2325, It: 0, Loss Data: 1.141e-01, Loss Eqns: 4.084e+00, Loss Aux: 1.263e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2326, It: 0, Loss Data: 1.129e-01, Loss Eqns: 4.243e+00, Loss Aux: 2.369e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2327, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.740e+00, Loss Aux: 4.800e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2328, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.849e+00, Loss Aux: 3.705e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2329, It: 0, Loss Data: 1.302e-01, Loss Eqns: 4.042e+00, Loss Aux: 2.404e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2330, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.606e+00, Loss Aux: 1.080e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2331, It: 0, Loss Data: 1.249e-01, Loss Eqns: 4.286e+00, Loss Aux: 4.813e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2332, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.779e+00, Loss Aux: 7.536e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2333, It: 0, Loss Data: 1.435e-01, Loss Eqns: 3.835e+00, Loss Aux: 1.062e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 2334, It: 0, Loss Data: 1.292e-01, Loss Eqns: 3.516e+00, Loss Aux: 1.195e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2335, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.844e+00, Loss Aux: 2.415e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2336, It: 0, Loss Data: 1.274e-01, Loss Eqns: 4.174e+00, Loss Aux: 2.528e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2337, It: 0, Loss Data: 1.134e-01, Loss Eqns: 3.973e+00, Loss Aux: 2.170e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2338, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.604e+00, Loss Aux: 2.076e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2339, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.838e+00, Loss Aux: 1.761e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2340, It: 0, Loss Data: 1.177e-01, Loss Eqns: 4.174e+00, Loss Aux: 9.388e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2341, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.868e+00, Loss Aux: 1.363e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2342, It: 0, Loss Data: 1.258e-01, Loss Eqns: 4.479e+00, Loss Aux: 1.295e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2343, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.910e+00, Loss Aux: 9.696e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2344, It: 0, Loss Data: 1.340e-01, Loss Eqns: 4.158e+00, Loss Aux: 1.382e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2345, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.868e+00, Loss Aux: 2.518e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2346, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.758e+00, Loss Aux: 2.729e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2347, It: 0, Loss Data: 1.064e-01, Loss Eqns: 4.022e+00, Loss Aux: 1.403e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2348, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.871e+00, Loss Aux: 7.225e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2349, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.770e+00, Loss Aux: 7.122e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2350, It: 0, Loss Data: 1.344e-01, Loss Eqns: 4.264e+00, Loss Aux: 1.823e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2351, It: 0, Loss Data: 1.862e-01, Loss Eqns: 4.880e+00, Loss Aux: 3.310e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2352, It: 0, Loss Data: 1.293e-01, Loss Eqns: 4.492e+00, Loss Aux: 2.002e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2353, It: 0, Loss Data: 1.351e-01, Loss Eqns: 4.334e+00, Loss Aux: 7.616e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2354, It: 0, Loss Data: 1.771e-01, Loss Eqns: 4.148e+00, Loss Aux: 1.522e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2355, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.934e+00, Loss Aux: 2.702e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2356, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.349e+00, Loss Aux: 1.581e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2357, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.817e+00, Loss Aux: 1.053e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2358, It: 0, Loss Data: 1.671e-01, Loss Eqns: 4.121e+00, Loss Aux: 8.797e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2359, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.791e+00, Loss Aux: 1.336e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2360, It: 0, Loss Data: 1.265e-01, Loss Eqns: 4.201e+00, Loss Aux: 1.356e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2361, It: 0, Loss Data: 1.415e-01, Loss Eqns: 3.878e+00, Loss Aux: 3.811e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2362, It: 0, Loss Data: 1.371e-01, Loss Eqns: 3.985e+00, Loss Aux: 4.273e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2363, It: 0, Loss Data: 1.539e-01, Loss Eqns: 4.529e+00, Loss Aux: 1.031e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2364, It: 0, Loss Data: 1.319e-01, Loss Eqns: 4.221e+00, Loss Aux: 9.204e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2365, It: 0, Loss Data: 1.532e-01, Loss Eqns: 3.743e+00, Loss Aux: 1.417e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2366, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.656e+00, Loss Aux: 9.254e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2367, It: 0, Loss Data: 1.552e-01, Loss Eqns: 4.019e+00, Loss Aux: 7.711e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2368, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.650e+00, Loss Aux: 1.561e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2369, It: 0, Loss Data: 1.554e-01, Loss Eqns: 4.429e+00, Loss Aux: 3.747e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2370, It: 0, Loss Data: 1.531e-01, Loss Eqns: 3.884e+00, Loss Aux: 1.623e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2371, It: 0, Loss Data: 1.281e-01, Loss Eqns: 4.071e+00, Loss Aux: 1.156e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2372, It: 0, Loss Data: 1.454e-01, Loss Eqns: 4.007e+00, Loss Aux: 1.648e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2373, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.797e+00, Loss Aux: 9.045e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2374, It: 0, Loss Data: 1.285e-01, Loss Eqns: 4.051e+00, Loss Aux: 1.574e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2375, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.846e+00, Loss Aux: 1.467e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2376, It: 0, Loss Data: 1.359e-01, Loss Eqns: 3.901e+00, Loss Aux: 2.547e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2377, It: 0, Loss Data: 1.306e-01, Loss Eqns: 4.116e+00, Loss Aux: 1.076e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2378, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.893e+00, Loss Aux: 8.905e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2379, It: 0, Loss Data: 1.248e-01, Loss Eqns: 4.020e+00, Loss Aux: 1.457e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2380, It: 0, Loss Data: 1.226e-01, Loss Eqns: 4.001e+00, Loss Aux: 1.346e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2381, It: 0, Loss Data: 1.193e-01, Loss Eqns: 4.165e+00, Loss Aux: 9.081e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2382, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.992e+00, Loss Aux: 7.972e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2383, It: 0, Loss Data: 1.332e-01, Loss Eqns: 4.028e+00, Loss Aux: 1.290e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2384, It: 0, Loss Data: 1.157e-01, Loss Eqns: 4.032e+00, Loss Aux: 8.300e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2385, It: 0, Loss Data: 1.114e-01, Loss Eqns: 4.078e+00, Loss Aux: 7.872e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2386, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.584e+00, Loss Aux: 1.400e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2387, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.939e+00, Loss Aux: 1.619e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2388, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.858e+00, Loss Aux: 9.270e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2389, It: 0, Loss Data: 1.072e-01, Loss Eqns: 3.964e+00, Loss Aux: 1.005e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2390, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.710e+00, Loss Aux: 1.232e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2391, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.717e+00, Loss Aux: 1.514e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2392, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.984e+00, Loss Aux: 9.216e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2393, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.870e+00, Loss Aux: 9.266e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2394, It: 0, Loss Data: 1.267e-01, Loss Eqns: 3.735e+00, Loss Aux: 1.652e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2395, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.673e+00, Loss Aux: 1.850e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2396, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.650e+00, Loss Aux: 9.922e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2397, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.760e+00, Loss Aux: 6.149e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2398, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.809e+00, Loss Aux: 4.703e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2399, It: 0, Loss Data: 1.240e-01, Loss Eqns: 3.884e+00, Loss Aux: 1.805e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2400, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.771e+00, Loss Aux: 1.736e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2401, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.682e+00, Loss Aux: 1.161e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2402, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.791e+00, Loss Aux: 1.393e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2403, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.768e+00, Loss Aux: 1.884e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2404, It: 0, Loss Data: 1.124e-01, Loss Eqns: 4.153e+00, Loss Aux: 9.370e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2405, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.808e+00, Loss Aux: 9.033e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2406, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.884e+00, Loss Aux: 8.154e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2407, It: 0, Loss Data: 1.106e-01, Loss Eqns: 4.082e+00, Loss Aux: 2.488e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2408, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.765e+00, Loss Aux: 1.428e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2409, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.875e+00, Loss Aux: 7.067e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2410, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.762e+00, Loss Aux: 6.047e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2411, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.988e+00, Loss Aux: 9.854e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2412, It: 0, Loss Data: 1.071e-01, Loss Eqns: 4.141e+00, Loss Aux: 1.924e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2413, It: 0, Loss Data: 1.273e-01, Loss Eqns: 4.015e+00, Loss Aux: 1.235e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2414, It: 0, Loss Data: 1.281e-01, Loss Eqns: 3.760e+00, Loss Aux: 1.103e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2415, It: 0, Loss Data: 1.239e-01, Loss Eqns: 3.882e+00, Loss Aux: 1.317e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2416, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.549e+00, Loss Aux: 9.293e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2417, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.462e+00, Loss Aux: 7.341e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2418, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.778e+00, Loss Aux: 1.155e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2419, It: 0, Loss Data: 1.187e-01, Loss Eqns: 4.068e+00, Loss Aux: 3.683e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2420, It: 0, Loss Data: 1.078e-01, Loss Eqns: 3.821e+00, Loss Aux: 3.609e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2421, It: 0, Loss Data: 1.187e-01, Loss Eqns: 4.035e+00, Loss Aux: 8.027e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2422, It: 0, Loss Data: 1.527e-01, Loss Eqns: 3.919e+00, Loss Aux: 2.659e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2423, It: 0, Loss Data: 1.241e-01, Loss Eqns: 3.912e+00, Loss Aux: 9.875e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2424, It: 0, Loss Data: 1.046e-01, Loss Eqns: 3.827e+00, Loss Aux: 2.247e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2425, It: 0, Loss Data: 1.271e-01, Loss Eqns: 3.877e+00, Loss Aux: 1.950e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2426, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.811e+00, Loss Aux: 1.920e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2427, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.925e+00, Loss Aux: 2.661e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2428, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.800e+00, Loss Aux: 1.819e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2429, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.679e+00, Loss Aux: 1.331e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2430, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.916e+00, Loss Aux: 1.174e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2431, It: 0, Loss Data: 1.152e-01, Loss Eqns: 4.016e+00, Loss Aux: 8.671e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2432, It: 0, Loss Data: 1.228e-01, Loss Eqns: 3.981e+00, Loss Aux: 6.057e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2433, It: 0, Loss Data: 1.185e-01, Loss Eqns: 4.176e+00, Loss Aux: 5.811e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2434, It: 0, Loss Data: 1.221e-01, Loss Eqns: 3.851e+00, Loss Aux: 1.788e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 2435, It: 0, Loss Data: 1.244e-01, Loss Eqns: 4.250e+00, Loss Aux: 1.865e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2436, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.939e+00, Loss Aux: 2.117e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2437, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.940e+00, Loss Aux: 1.394e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2438, It: 0, Loss Data: 1.295e-01, Loss Eqns: 3.684e+00, Loss Aux: 9.620e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2439, It: 0, Loss Data: 1.016e-01, Loss Eqns: 3.601e+00, Loss Aux: 6.914e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2440, It: 0, Loss Data: 1.329e-01, Loss Eqns: 4.275e+00, Loss Aux: 2.767e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2441, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.622e+00, Loss Aux: 2.430e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2442, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.716e+00, Loss Aux: 8.783e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2443, It: 0, Loss Data: 1.178e-01, Loss Eqns: 3.905e+00, Loss Aux: 1.290e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2444, It: 0, Loss Data: 1.109e-01, Loss Eqns: 4.058e+00, Loss Aux: 1.406e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2445, It: 0, Loss Data: 1.179e-01, Loss Eqns: 4.060e+00, Loss Aux: 1.270e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2446, It: 0, Loss Data: 1.038e-01, Loss Eqns: 4.041e+00, Loss Aux: 7.947e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2447, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.878e+00, Loss Aux: 1.339e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2448, It: 0, Loss Data: 1.016e-01, Loss Eqns: 3.829e+00, Loss Aux: 5.908e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2449, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.611e+00, Loss Aux: 1.020e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2450, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.842e+00, Loss Aux: 3.093e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2451, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.764e+00, Loss Aux: 1.417e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2452, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.980e+00, Loss Aux: 5.829e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2453, It: 0, Loss Data: 1.370e-01, Loss Eqns: 3.815e+00, Loss Aux: 1.061e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2454, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.766e+00, Loss Aux: 9.049e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2455, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.814e+00, Loss Aux: 7.711e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2456, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.674e+00, Loss Aux: 8.057e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2457, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.891e+00, Loss Aux: 1.433e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2458, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.862e+00, Loss Aux: 1.748e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2459, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.833e+00, Loss Aux: 1.231e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2460, It: 0, Loss Data: 1.153e-01, Loss Eqns: 4.143e+00, Loss Aux: 1.121e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2461, It: 0, Loss Data: 1.046e-01, Loss Eqns: 4.057e+00, Loss Aux: 1.292e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2462, It: 0, Loss Data: 1.154e-01, Loss Eqns: 4.263e+00, Loss Aux: 1.169e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2463, It: 0, Loss Data: 1.339e-01, Loss Eqns: 3.884e+00, Loss Aux: 6.347e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2464, It: 0, Loss Data: 1.331e-01, Loss Eqns: 3.835e+00, Loss Aux: 6.938e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2465, It: 0, Loss Data: 1.253e-01, Loss Eqns: 4.048e+00, Loss Aux: 2.036e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2466, It: 0, Loss Data: 1.066e-01, Loss Eqns: 4.076e+00, Loss Aux: 3.300e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2467, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.949e+00, Loss Aux: 1.904e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 2468, It: 0, Loss Data: 1.241e-01, Loss Eqns: 3.884e+00, Loss Aux: 9.603e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2469, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.672e+00, Loss Aux: 8.071e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2470, It: 0, Loss Data: 1.045e-01, Loss Eqns: 3.962e+00, Loss Aux: 1.172e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2471, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.960e+00, Loss Aux: 2.490e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2472, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.953e+00, Loss Aux: 1.516e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2473, It: 0, Loss Data: 1.076e-01, Loss Eqns: 4.131e+00, Loss Aux: 1.416e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2474, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.848e+00, Loss Aux: 1.586e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2475, It: 0, Loss Data: 1.034e-01, Loss Eqns: 3.998e+00, Loss Aux: 1.370e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2476, It: 0, Loss Data: 1.382e-01, Loss Eqns: 3.980e+00, Loss Aux: 9.327e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 2477, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.519e+00, Loss Aux: 8.739e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2478, It: 0, Loss Data: 1.158e-01, Loss Eqns: 4.032e+00, Loss Aux: 9.004e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2479, It: 0, Loss Data: 1.274e-01, Loss Eqns: 3.885e+00, Loss Aux: 9.480e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2480, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.849e+00, Loss Aux: 6.806e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2481, It: 0, Loss Data: 1.053e-01, Loss Eqns: 3.767e+00, Loss Aux: 7.637e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2482, It: 0, Loss Data: 1.153e-01, Loss Eqns: 3.810e+00, Loss Aux: 2.112e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2483, It: 0, Loss Data: 1.138e-01, Loss Eqns: 4.086e+00, Loss Aux: 5.880e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2484, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.974e+00, Loss Aux: 2.984e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2485, It: 0, Loss Data: 1.175e-01, Loss Eqns: 4.084e+00, Loss Aux: 7.962e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2486, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.725e+00, Loss Aux: 1.223e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2487, It: 0, Loss Data: 1.225e-01, Loss Eqns: 4.020e+00, Loss Aux: 1.072e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2488, It: 0, Loss Data: 1.026e-01, Loss Eqns: 3.695e+00, Loss Aux: 1.295e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2489, It: 0, Loss Data: 1.376e-01, Loss Eqns: 3.857e+00, Loss Aux: 1.723e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2490, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.932e+00, Loss Aux: 2.480e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2491, It: 0, Loss Data: 1.305e-01, Loss Eqns: 4.141e+00, Loss Aux: 1.814e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2492, It: 0, Loss Data: 1.051e-01, Loss Eqns: 4.114e+00, Loss Aux: 1.085e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2493, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.729e+00, Loss Aux: 7.944e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2494, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.935e+00, Loss Aux: 8.646e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2495, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.958e+00, Loss Aux: 1.453e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2496, It: 0, Loss Data: 1.353e-01, Loss Eqns: 3.944e+00, Loss Aux: 1.249e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2497, It: 0, Loss Data: 1.407e-01, Loss Eqns: 3.619e+00, Loss Aux: 6.802e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2498, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.880e+00, Loss Aux: 9.813e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2499, It: 0, Loss Data: 1.249e-01, Loss Eqns: 4.233e+00, Loss Aux: 1.876e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2500, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.888e+00, Loss Aux: 1.482e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2501, It: 0, Loss Data: 1.260e-01, Loss Eqns: 3.896e+00, Loss Aux: 8.468e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2502, It: 0, Loss Data: 1.406e-01, Loss Eqns: 3.891e+00, Loss Aux: 7.965e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2503, It: 0, Loss Data: 1.593e-01, Loss Eqns: 4.097e+00, Loss Aux: 1.935e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2504, It: 0, Loss Data: 2.410e-01, Loss Eqns: 5.349e+00, Loss Aux: 2.161e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2505, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.963e+00, Loss Aux: 1.171e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2506, It: 0, Loss Data: 1.840e-01, Loss Eqns: 4.361e+00, Loss Aux: 3.574e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2507, It: 0, Loss Data: 1.564e-01, Loss Eqns: 3.739e+00, Loss Aux: 1.123e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2508, It: 0, Loss Data: 2.009e-01, Loss Eqns: 4.268e+00, Loss Aux: 1.026e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2509, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.892e+00, Loss Aux: 3.105e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2510, It: 0, Loss Data: 1.802e-01, Loss Eqns: 4.398e+00, Loss Aux: 1.145e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 2511, It: 0, Loss Data: 1.906e-01, Loss Eqns: 4.230e+00, Loss Aux: 2.154e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2512, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.896e+00, Loss Aux: 1.045e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2513, It: 0, Loss Data: 2.084e-01, Loss Eqns: 4.679e+00, Loss Aux: 6.953e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2514, It: 0, Loss Data: 1.398e-01, Loss Eqns: 4.000e+00, Loss Aux: 2.723e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2515, It: 0, Loss Data: 1.753e-01, Loss Eqns: 4.685e+00, Loss Aux: 6.186e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2516, It: 0, Loss Data: 1.207e-01, Loss Eqns: 4.091e+00, Loss Aux: 1.551e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2517, It: 0, Loss Data: 1.988e-01, Loss Eqns: 4.228e+00, Loss Aux: 2.950e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2518, It: 0, Loss Data: 1.338e-01, Loss Eqns: 3.980e+00, Loss Aux: 1.509e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2519, It: 0, Loss Data: 1.727e-01, Loss Eqns: 3.675e+00, Loss Aux: 1.211e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2520, It: 0, Loss Data: 1.558e-01, Loss Eqns: 4.236e+00, Loss Aux: 3.428e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2521, It: 0, Loss Data: 1.377e-01, Loss Eqns: 3.666e+00, Loss Aux: 4.394e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2522, It: 0, Loss Data: 1.439e-01, Loss Eqns: 4.200e+00, Loss Aux: 2.014e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2523, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.052e+00, Loss Aux: 1.449e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2524, It: 0, Loss Data: 1.589e-01, Loss Eqns: 3.796e+00, Loss Aux: 2.303e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2525, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.301e+00, Loss Aux: 1.795e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2526, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.960e+00, Loss Aux: 1.055e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 2527, It: 0, Loss Data: 1.403e-01, Loss Eqns: 4.179e+00, Loss Aux: 1.039e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2528, It: 0, Loss Data: 1.296e-01, Loss Eqns: 3.907e+00, Loss Aux: 1.400e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2529, It: 0, Loss Data: 1.251e-01, Loss Eqns: 4.002e+00, Loss Aux: 1.521e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2530, It: 0, Loss Data: 1.091e-01, Loss Eqns: 4.026e+00, Loss Aux: 2.148e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2531, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.563e+00, Loss Aux: 2.279e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2532, It: 0, Loss Data: 1.341e-01, Loss Eqns: 3.888e+00, Loss Aux: 1.691e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2533, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.845e+00, Loss Aux: 1.124e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2534, It: 0, Loss Data: 1.274e-01, Loss Eqns: 4.026e+00, Loss Aux: 8.964e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 2535, It: 0, Loss Data: 1.287e-01, Loss Eqns: 3.843e+00, Loss Aux: 1.228e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2536, It: 0, Loss Data: 1.133e-01, Loss Eqns: 4.130e+00, Loss Aux: 7.884e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2537, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.878e+00, Loss Aux: 9.788e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2538, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.837e+00, Loss Aux: 1.977e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2539, It: 0, Loss Data: 1.387e-01, Loss Eqns: 3.838e+00, Loss Aux: 2.520e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2540, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.886e+00, Loss Aux: 9.082e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 2541, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.978e+00, Loss Aux: 6.224e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2542, It: 0, Loss Data: 1.311e-01, Loss Eqns: 3.834e+00, Loss Aux: 1.037e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2543, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.834e+00, Loss Aux: 7.688e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2544, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.944e+00, Loss Aux: 7.748e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2545, It: 0, Loss Data: 1.258e-01, Loss Eqns: 3.845e+00, Loss Aux: 8.137e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2546, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.999e+00, Loss Aux: 2.782e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2547, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.787e+00, Loss Aux: 2.632e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2548, It: 0, Loss Data: 1.184e-01, Loss Eqns: 4.038e+00, Loss Aux: 1.278e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2549, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.659e+00, Loss Aux: 1.176e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2550, It: 0, Loss Data: 1.348e-01, Loss Eqns: 4.073e+00, Loss Aux: 1.066e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2551, It: 0, Loss Data: 1.657e-01, Loss Eqns: 4.092e+00, Loss Aux: 3.633e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2552, It: 0, Loss Data: 1.102e-01, Loss Eqns: 4.062e+00, Loss Aux: 8.428e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2553, It: 0, Loss Data: 1.494e-01, Loss Eqns: 4.052e+00, Loss Aux: 9.908e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2554, It: 0, Loss Data: 1.399e-01, Loss Eqns: 3.608e+00, Loss Aux: 6.161e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 2555, It: 0, Loss Data: 1.690e-01, Loss Eqns: 4.019e+00, Loss Aux: 3.313e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2556, It: 0, Loss Data: 1.328e-01, Loss Eqns: 3.988e+00, Loss Aux: 9.979e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2557, It: 0, Loss Data: 1.233e-01, Loss Eqns: 4.149e+00, Loss Aux: 9.610e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2558, It: 0, Loss Data: 1.314e-01, Loss Eqns: 4.075e+00, Loss Aux: 2.125e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2559, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.549e+00, Loss Aux: 1.543e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2560, It: 0, Loss Data: 1.401e-01, Loss Eqns: 3.769e+00, Loss Aux: 1.158e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2561, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.698e+00, Loss Aux: 6.660e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2562, It: 0, Loss Data: 1.593e-01, Loss Eqns: 3.869e+00, Loss Aux: 1.214e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2563, It: 0, Loss Data: 1.161e-01, Loss Eqns: 3.889e+00, Loss Aux: 5.684e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2564, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.711e+00, Loss Aux: 6.368e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2565, It: 0, Loss Data: 1.250e-01, Loss Eqns: 3.881e+00, Loss Aux: 1.691e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2566, It: 0, Loss Data: 1.185e-01, Loss Eqns: 4.055e+00, Loss Aux: 2.721e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2567, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.315e+00, Loss Aux: 1.732e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2568, It: 0, Loss Data: 1.049e-01, Loss Eqns: 3.861e+00, Loss Aux: 1.157e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2569, It: 0, Loss Data: 1.222e-01, Loss Eqns: 4.090e+00, Loss Aux: 1.188e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 2570, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.326e+00, Loss Aux: 8.254e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2571, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.754e+00, Loss Aux: 1.332e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2572, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.930e+00, Loss Aux: 1.216e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2573, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.597e+00, Loss Aux: 1.957e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2574, It: 0, Loss Data: 9.456e-02, Loss Eqns: 3.802e+00, Loss Aux: 2.147e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2575, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.672e+00, Loss Aux: 1.567e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2576, It: 0, Loss Data: 1.230e-01, Loss Eqns: 3.741e+00, Loss Aux: 1.748e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2577, It: 0, Loss Data: 1.350e-01, Loss Eqns: 3.754e+00, Loss Aux: 2.188e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2578, It: 0, Loss Data: 1.374e-01, Loss Eqns: 3.667e+00, Loss Aux: 1.251e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2579, It: 0, Loss Data: 1.458e-01, Loss Eqns: 3.808e+00, Loss Aux: 1.269e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2580, It: 0, Loss Data: 1.801e-01, Loss Eqns: 4.600e+00, Loss Aux: 9.756e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2581, It: 0, Loss Data: 1.366e-01, Loss Eqns: 4.027e+00, Loss Aux: 5.162e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2582, It: 0, Loss Data: 1.788e-01, Loss Eqns: 3.949e+00, Loss Aux: 4.463e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2583, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.490e+00, Loss Aux: 4.347e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2584, It: 0, Loss Data: 1.663e-01, Loss Eqns: 4.089e+00, Loss Aux: 1.370e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2585, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.940e+00, Loss Aux: 1.588e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2586, It: 0, Loss Data: 1.435e-01, Loss Eqns: 3.967e+00, Loss Aux: 1.991e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2587, It: 0, Loss Data: 1.288e-01, Loss Eqns: 4.602e+00, Loss Aux: 1.108e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2588, It: 0, Loss Data: 1.299e-01, Loss Eqns: 4.235e+00, Loss Aux: 6.513e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2589, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.660e+00, Loss Aux: 9.566e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2590, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.547e+00, Loss Aux: 2.476e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2591, It: 0, Loss Data: 1.094e-01, Loss Eqns: 4.268e+00, Loss Aux: 2.266e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2592, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.852e+00, Loss Aux: 2.235e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2593, It: 0, Loss Data: 1.364e-01, Loss Eqns: 3.991e+00, Loss Aux: 1.841e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2594, It: 0, Loss Data: 1.384e-01, Loss Eqns: 3.957e+00, Loss Aux: 7.928e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2595, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.951e+00, Loss Aux: 8.883e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2596, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.970e+00, Loss Aux: 1.153e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2597, It: 0, Loss Data: 1.413e-01, Loss Eqns: 3.807e+00, Loss Aux: 1.108e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2598, It: 0, Loss Data: 1.423e-01, Loss Eqns: 3.955e+00, Loss Aux: 1.187e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2599, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.950e+00, Loss Aux: 1.729e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2600, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.552e+00, Loss Aux: 4.370e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2601, It: 0, Loss Data: 1.317e-01, Loss Eqns: 4.062e+00, Loss Aux: 1.938e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2602, It: 0, Loss Data: 1.275e-01, Loss Eqns: 4.238e+00, Loss Aux: 8.137e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2603, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.682e+00, Loss Aux: 5.770e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2604, It: 0, Loss Data: 1.475e-01, Loss Eqns: 3.874e+00, Loss Aux: 3.365e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2605, It: 0, Loss Data: 1.128e-01, Loss Eqns: 4.014e+00, Loss Aux: 2.074e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2606, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.876e+00, Loss Aux: 1.264e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2607, It: 0, Loss Data: 1.415e-01, Loss Eqns: 4.349e+00, Loss Aux: 1.286e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2608, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.997e+00, Loss Aux: 2.185e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2609, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.663e+00, Loss Aux: 2.903e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2610, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.622e+00, Loss Aux: 1.579e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2611, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.899e+00, Loss Aux: 1.264e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2612, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.839e+00, Loss Aux: 3.009e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2613, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.953e+00, Loss Aux: 3.044e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2614, It: 0, Loss Data: 1.562e-01, Loss Eqns: 3.652e+00, Loss Aux: 1.605e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2615, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.808e+00, Loss Aux: 8.417e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2616, It: 0, Loss Data: 1.390e-01, Loss Eqns: 3.933e+00, Loss Aux: 4.880e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2617, It: 0, Loss Data: 1.438e-01, Loss Eqns: 4.223e+00, Loss Aux: 4.589e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2618, It: 0, Loss Data: 1.409e-01, Loss Eqns: 3.809e+00, Loss Aux: 1.351e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2619, It: 0, Loss Data: 1.581e-01, Loss Eqns: 3.933e+00, Loss Aux: 1.840e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2620, It: 0, Loss Data: 1.517e-01, Loss Eqns: 3.702e+00, Loss Aux: 1.658e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2621, It: 0, Loss Data: 1.375e-01, Loss Eqns: 4.099e+00, Loss Aux: 2.071e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2622, It: 0, Loss Data: 1.325e-01, Loss Eqns: 4.047e+00, Loss Aux: 2.123e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2623, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.657e+00, Loss Aux: 2.334e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2624, It: 0, Loss Data: 1.529e-01, Loss Eqns: 4.397e+00, Loss Aux: 2.330e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2625, It: 0, Loss Data: 1.181e-01, Loss Eqns: 4.339e+00, Loss Aux: 2.488e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2626, It: 0, Loss Data: 1.284e-01, Loss Eqns: 4.161e+00, Loss Aux: 3.446e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2627, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.735e+00, Loss Aux: 1.886e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2628, It: 0, Loss Data: 1.595e-01, Loss Eqns: 3.978e+00, Loss Aux: 1.213e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2629, It: 0, Loss Data: 1.300e-01, Loss Eqns: 3.727e+00, Loss Aux: 5.747e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2630, It: 0, Loss Data: 1.433e-01, Loss Eqns: 4.187e+00, Loss Aux: 3.389e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2631, It: 0, Loss Data: 1.347e-01, Loss Eqns: 3.643e+00, Loss Aux: 3.911e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2632, It: 0, Loss Data: 1.362e-01, Loss Eqns: 3.905e+00, Loss Aux: 1.239e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2633, It: 0, Loss Data: 1.166e-01, Loss Eqns: 4.052e+00, Loss Aux: 1.482e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 2634, It: 0, Loss Data: 1.311e-01, Loss Eqns: 4.085e+00, Loss Aux: 3.263e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 2635, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.772e+00, Loss Aux: 1.934e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 2636, It: 0, Loss Data: 1.271e-01, Loss Eqns: 3.913e+00, Loss Aux: 1.236e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2637, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.982e+00, Loss Aux: 1.156e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2638, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.819e+00, Loss Aux: 1.820e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2639, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.767e+00, Loss Aux: 2.030e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 2640, It: 0, Loss Data: 1.348e-01, Loss Eqns: 3.952e+00, Loss Aux: 9.401e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2641, It: 0, Loss Data: 1.274e-01, Loss Eqns: 3.984e+00, Loss Aux: 7.431e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2642, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.850e+00, Loss Aux: 1.347e-02, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 2643, It: 0, Loss Data: 1.353e-01, Loss Eqns: 3.653e+00, Loss Aux: 2.431e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 2644, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.677e+00, Loss Aux: 2.073e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 2645, It: 0, Loss Data: 1.203e-01, Loss Eqns: 3.879e+00, Loss Aux: 9.991e-03, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 2646, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.930e+00, Loss Aux: 1.027e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 2647, It: 0, Loss Data: 1.750e-01, Loss Eqns: 3.996e+00, Loss Aux: 2.354e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2648, It: 0, Loss Data: 1.693e-01, Loss Eqns: 4.611e+00, Loss Aux: 1.058e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2649, It: 0, Loss Data: 1.704e-01, Loss Eqns: 4.952e+00, Loss Aux: 9.049e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2650, It: 0, Loss Data: 1.389e-01, Loss Eqns: 4.217e+00, Loss Aux: 1.648e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2651, It: 0, Loss Data: 1.770e-01, Loss Eqns: 4.371e+00, Loss Aux: 1.844e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2652, It: 0, Loss Data: 1.531e-01, Loss Eqns: 3.886e+00, Loss Aux: 1.123e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2653, It: 0, Loss Data: 1.715e-01, Loss Eqns: 4.530e+00, Loss Aux: 1.105e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2654, It: 0, Loss Data: 1.331e-01, Loss Eqns: 3.748e+00, Loss Aux: 1.809e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2655, It: 0, Loss Data: 1.604e-01, Loss Eqns: 4.137e+00, Loss Aux: 1.906e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2656, It: 0, Loss Data: 1.203e-01, Loss Eqns: 4.127e+00, Loss Aux: 1.047e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2657, It: 0, Loss Data: 1.425e-01, Loss Eqns: 4.088e+00, Loss Aux: 1.402e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 2658, It: 0, Loss Data: 1.577e-01, Loss Eqns: 3.730e+00, Loss Aux: 2.849e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2659, It: 0, Loss Data: 1.525e-01, Loss Eqns: 3.956e+00, Loss Aux: 1.374e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2660, It: 0, Loss Data: 1.359e-01, Loss Eqns: 3.996e+00, Loss Aux: 1.608e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2661, It: 0, Loss Data: 1.439e-01, Loss Eqns: 3.957e+00, Loss Aux: 1.215e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2662, It: 0, Loss Data: 1.388e-01, Loss Eqns: 3.741e+00, Loss Aux: 4.030e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2663, It: 0, Loss Data: 1.478e-01, Loss Eqns: 4.136e+00, Loss Aux: 1.871e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2664, It: 0, Loss Data: 1.498e-01, Loss Eqns: 3.855e+00, Loss Aux: 1.144e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 2665, It: 0, Loss Data: 1.355e-01, Loss Eqns: 3.838e+00, Loss Aux: 7.164e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2666, It: 0, Loss Data: 1.323e-01, Loss Eqns: 4.244e+00, Loss Aux: 4.044e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2667, It: 0, Loss Data: 1.011e-01, Loss Eqns: 4.085e+00, Loss Aux: 2.373e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2668, It: 0, Loss Data: 1.484e-01, Loss Eqns: 3.957e+00, Loss Aux: 9.811e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2669, It: 0, Loss Data: 1.294e-01, Loss Eqns: 4.259e+00, Loss Aux: 1.028e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2670, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.895e+00, Loss Aux: 1.641e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2671, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.710e+00, Loss Aux: 1.239e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2672, It: 0, Loss Data: 1.240e-01, Loss Eqns: 3.903e+00, Loss Aux: 1.200e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2673, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.608e+00, Loss Aux: 1.370e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2674, It: 0, Loss Data: 1.511e-01, Loss Eqns: 4.133e+00, Loss Aux: 2.757e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2675, It: 0, Loss Data: 1.146e-01, Loss Eqns: 4.032e+00, Loss Aux: 1.317e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2676, It: 0, Loss Data: 1.388e-01, Loss Eqns: 4.009e+00, Loss Aux: 8.234e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2677, It: 0, Loss Data: 1.312e-01, Loss Eqns: 3.876e+00, Loss Aux: 1.011e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2678, It: 0, Loss Data: 1.535e-01, Loss Eqns: 3.825e+00, Loss Aux: 2.583e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2679, It: 0, Loss Data: 1.234e-01, Loss Eqns: 3.613e+00, Loss Aux: 1.846e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2680, It: 0, Loss Data: 1.356e-01, Loss Eqns: 3.661e+00, Loss Aux: 7.701e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 2681, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.669e+00, Loss Aux: 6.282e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2682, It: 0, Loss Data: 1.458e-01, Loss Eqns: 3.723e+00, Loss Aux: 1.094e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2683, It: 0, Loss Data: 1.235e-01, Loss Eqns: 3.767e+00, Loss Aux: 1.717e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2684, It: 0, Loss Data: 1.303e-01, Loss Eqns: 3.900e+00, Loss Aux: 1.877e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2685, It: 0, Loss Data: 1.280e-01, Loss Eqns: 3.510e+00, Loss Aux: 2.498e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2686, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.839e+00, Loss Aux: 2.714e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2687, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.642e+00, Loss Aux: 1.133e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2688, It: 0, Loss Data: 1.238e-01, Loss Eqns: 4.046e+00, Loss Aux: 5.730e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2689, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.901e+00, Loss Aux: 5.140e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2690, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.985e+00, Loss Aux: 6.229e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2691, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.836e+00, Loss Aux: 8.425e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2692, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.911e+00, Loss Aux: 1.092e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 2693, It: 0, Loss Data: 1.240e-01, Loss Eqns: 3.713e+00, Loss Aux: 1.783e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2694, It: 0, Loss Data: 1.303e-01, Loss Eqns: 4.163e+00, Loss Aux: 1.447e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2695, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.935e+00, Loss Aux: 9.099e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2696, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.155e+00, Loss Aux: 7.239e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2697, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.627e+00, Loss Aux: 2.194e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2698, It: 0, Loss Data: 1.357e-01, Loss Eqns: 3.927e+00, Loss Aux: 3.067e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 2699, It: 0, Loss Data: 1.024e-01, Loss Eqns: 3.650e+00, Loss Aux: 8.417e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2700, It: 0, Loss Data: 1.360e-01, Loss Eqns: 3.873e+00, Loss Aux: 5.322e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2701, It: 0, Loss Data: 1.344e-01, Loss Eqns: 3.637e+00, Loss Aux: 7.203e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2702, It: 0, Loss Data: 1.190e-01, Loss Eqns: 4.012e+00, Loss Aux: 1.415e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 2703, It: 0, Loss Data: 1.243e-01, Loss Eqns: 3.786e+00, Loss Aux: 1.070e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2704, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.615e+00, Loss Aux: 1.089e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2705, It: 0, Loss Data: 1.311e-01, Loss Eqns: 3.895e+00, Loss Aux: 2.217e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2706, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.800e+00, Loss Aux: 1.195e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2707, It: 0, Loss Data: 1.432e-01, Loss Eqns: 4.104e+00, Loss Aux: 1.313e-02, Time: 0.252, Learning Rate: 1.0e-03\n",
      "Epoch: 2708, It: 0, Loss Data: 1.439e-01, Loss Eqns: 3.854e+00, Loss Aux: 1.555e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2709, It: 0, Loss Data: 1.171e-01, Loss Eqns: 4.042e+00, Loss Aux: 1.934e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 2710, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.793e+00, Loss Aux: 7.405e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2711, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.868e+00, Loss Aux: 5.859e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2712, It: 0, Loss Data: 1.348e-01, Loss Eqns: 3.609e+00, Loss Aux: 9.709e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2713, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.890e+00, Loss Aux: 6.628e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2714, It: 0, Loss Data: 1.345e-01, Loss Eqns: 4.197e+00, Loss Aux: 7.190e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2715, It: 0, Loss Data: 1.027e-01, Loss Eqns: 3.695e+00, Loss Aux: 8.813e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2716, It: 0, Loss Data: 1.174e-01, Loss Eqns: 4.017e+00, Loss Aux: 1.921e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2717, It: 0, Loss Data: 9.558e-02, Loss Eqns: 4.074e+00, Loss Aux: 2.290e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2718, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.750e+00, Loss Aux: 1.696e-02, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 2719, It: 0, Loss Data: 1.288e-01, Loss Eqns: 3.666e+00, Loss Aux: 1.217e-02, Time: 0.262, Learning Rate: 1.0e-03\n",
      "Epoch: 2720, It: 0, Loss Data: 1.408e-01, Loss Eqns: 3.555e+00, Loss Aux: 9.992e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2721, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.853e+00, Loss Aux: 1.323e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2722, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.619e+00, Loss Aux: 1.145e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2723, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.688e+00, Loss Aux: 4.915e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2724, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.905e+00, Loss Aux: 3.330e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2725, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.546e+00, Loss Aux: 4.776e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2726, It: 0, Loss Data: 1.016e-01, Loss Eqns: 3.921e+00, Loss Aux: 1.264e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2727, It: 0, Loss Data: 1.203e-01, Loss Eqns: 4.016e+00, Loss Aux: 1.345e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 2728, It: 0, Loss Data: 1.067e-01, Loss Eqns: 3.569e+00, Loss Aux: 1.187e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2729, It: 0, Loss Data: 1.012e-01, Loss Eqns: 3.877e+00, Loss Aux: 1.484e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 2730, It: 0, Loss Data: 1.252e-01, Loss Eqns: 3.926e+00, Loss Aux: 1.442e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 2731, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.861e+00, Loss Aux: 1.034e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2732, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.676e+00, Loss Aux: 6.080e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2733, It: 0, Loss Data: 1.099e-01, Loss Eqns: 4.000e+00, Loss Aux: 4.630e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 2734, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.916e+00, Loss Aux: 1.162e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 2735, It: 0, Loss Data: 1.103e-01, Loss Eqns: 3.525e+00, Loss Aux: 1.125e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2736, It: 0, Loss Data: 9.197e-02, Loss Eqns: 3.874e+00, Loss Aux: 1.007e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 2737, It: 0, Loss Data: 1.325e-01, Loss Eqns: 3.479e+00, Loss Aux: 8.815e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2738, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.718e+00, Loss Aux: 7.138e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2739, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.519e+00, Loss Aux: 7.311e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2740, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.831e+00, Loss Aux: 8.881e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2741, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.872e+00, Loss Aux: 9.432e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2742, It: 0, Loss Data: 1.411e-01, Loss Eqns: 3.814e+00, Loss Aux: 1.390e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2743, It: 0, Loss Data: 1.004e-01, Loss Eqns: 3.993e+00, Loss Aux: 1.518e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2744, It: 0, Loss Data: 1.095e-01, Loss Eqns: 4.120e+00, Loss Aux: 1.611e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2745, It: 0, Loss Data: 1.308e-01, Loss Eqns: 3.511e+00, Loss Aux: 1.018e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2746, It: 0, Loss Data: 1.186e-01, Loss Eqns: 4.055e+00, Loss Aux: 4.894e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2747, It: 0, Loss Data: 1.339e-01, Loss Eqns: 3.921e+00, Loss Aux: 5.297e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2748, It: 0, Loss Data: 1.041e-01, Loss Eqns: 3.998e+00, Loss Aux: 7.145e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2749, It: 0, Loss Data: 1.125e-01, Loss Eqns: 3.638e+00, Loss Aux: 1.167e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 2750, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.699e+00, Loss Aux: 6.750e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2751, It: 0, Loss Data: 9.333e-02, Loss Eqns: 3.607e+00, Loss Aux: 8.022e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2752, It: 0, Loss Data: 1.211e-01, Loss Eqns: 4.012e+00, Loss Aux: 1.532e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2753, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.836e+00, Loss Aux: 2.141e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2754, It: 0, Loss Data: 1.133e-01, Loss Eqns: 3.720e+00, Loss Aux: 6.849e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2755, It: 0, Loss Data: 1.199e-01, Loss Eqns: 3.946e+00, Loss Aux: 3.344e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2756, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.896e+00, Loss Aux: 5.046e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2757, It: 0, Loss Data: 1.248e-01, Loss Eqns: 3.842e+00, Loss Aux: 7.024e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2758, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.631e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2759, It: 0, Loss Data: 1.330e-01, Loss Eqns: 3.901e+00, Loss Aux: 2.195e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2760, It: 0, Loss Data: 1.335e-01, Loss Eqns: 3.781e+00, Loss Aux: 1.168e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2761, It: 0, Loss Data: 1.067e-01, Loss Eqns: 3.815e+00, Loss Aux: 1.159e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2762, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.615e+00, Loss Aux: 1.885e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2763, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.883e+00, Loss Aux: 9.950e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2764, It: 0, Loss Data: 1.342e-01, Loss Eqns: 3.827e+00, Loss Aux: 1.303e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2765, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.799e+00, Loss Aux: 8.499e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2766, It: 0, Loss Data: 1.521e-01, Loss Eqns: 3.893e+00, Loss Aux: 2.493e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2767, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.708e+00, Loss Aux: 1.926e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 2768, It: 0, Loss Data: 1.269e-01, Loss Eqns: 3.915e+00, Loss Aux: 7.461e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2769, It: 0, Loss Data: 1.205e-01, Loss Eqns: 3.812e+00, Loss Aux: 8.382e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 2770, It: 0, Loss Data: 1.307e-01, Loss Eqns: 4.088e+00, Loss Aux: 1.268e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 2771, It: 0, Loss Data: 1.023e-01, Loss Eqns: 3.825e+00, Loss Aux: 1.169e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2772, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.847e+00, Loss Aux: 6.086e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2773, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.767e+00, Loss Aux: 6.346e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 2774, It: 0, Loss Data: 1.414e-01, Loss Eqns: 3.780e+00, Loss Aux: 7.511e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2775, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.684e+00, Loss Aux: 6.723e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 2776, It: 0, Loss Data: 1.145e-01, Loss Eqns: 4.151e+00, Loss Aux: 7.053e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2777, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.913e+00, Loss Aux: 1.222e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2778, It: 0, Loss Data: 9.104e-02, Loss Eqns: 3.864e+00, Loss Aux: 1.619e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2779, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.904e+00, Loss Aux: 1.076e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2780, It: 0, Loss Data: 1.339e-01, Loss Eqns: 3.718e+00, Loss Aux: 1.552e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2781, It: 0, Loss Data: 1.125e-01, Loss Eqns: 3.724e+00, Loss Aux: 8.851e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2782, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.614e+00, Loss Aux: 7.773e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 2783, It: 0, Loss Data: 1.367e-01, Loss Eqns: 3.813e+00, Loss Aux: 3.297e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2784, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.836e+00, Loss Aux: 1.768e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2785, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.867e+00, Loss Aux: 1.379e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 2786, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.771e+00, Loss Aux: 1.033e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2787, It: 0, Loss Data: 1.324e-01, Loss Eqns: 3.684e+00, Loss Aux: 1.286e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2788, It: 0, Loss Data: 1.339e-01, Loss Eqns: 3.770e+00, Loss Aux: 2.311e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2789, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.907e+00, Loss Aux: 9.031e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2790, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.901e+00, Loss Aux: 4.894e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2791, It: 0, Loss Data: 1.320e-01, Loss Eqns: 4.187e+00, Loss Aux: 1.087e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2792, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.589e+00, Loss Aux: 1.139e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2793, It: 0, Loss Data: 1.363e-01, Loss Eqns: 3.855e+00, Loss Aux: 9.688e-03, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 2794, It: 0, Loss Data: 1.057e-01, Loss Eqns: 4.006e+00, Loss Aux: 1.068e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 2795, It: 0, Loss Data: 1.198e-01, Loss Eqns: 4.053e+00, Loss Aux: 1.373e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 2796, It: 0, Loss Data: 9.758e-02, Loss Eqns: 3.818e+00, Loss Aux: 2.189e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 2797, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.654e+00, Loss Aux: 2.581e-02, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 2798, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.910e+00, Loss Aux: 3.162e-02, Time: 0.260, Learning Rate: 1.0e-03\n",
      "Epoch: 2799, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.869e+00, Loss Aux: 1.629e-02, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 2800, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.602e+00, Loss Aux: 1.854e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 2801, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.912e+00, Loss Aux: 6.639e-03, Time: 0.280, Learning Rate: 1.0e-03\n",
      "Epoch: 2802, It: 0, Loss Data: 1.308e-01, Loss Eqns: 3.973e+00, Loss Aux: 1.900e-02, Time: 0.267, Learning Rate: 1.0e-03\n",
      "Epoch: 2803, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.728e+00, Loss Aux: 6.037e-03, Time: 0.263, Learning Rate: 1.0e-03\n",
      "Epoch: 2804, It: 0, Loss Data: 1.267e-01, Loss Eqns: 4.231e+00, Loss Aux: 4.599e-03, Time: 0.293, Learning Rate: 1.0e-03\n",
      "Epoch: 2805, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.886e+00, Loss Aux: 1.102e-02, Time: 0.298, Learning Rate: 1.0e-03\n",
      "Epoch: 2806, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.586e+00, Loss Aux: 1.887e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 2807, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.863e+00, Loss Aux: 1.221e-02, Time: 0.295, Learning Rate: 1.0e-03\n",
      "Epoch: 2808, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.600e+00, Loss Aux: 9.155e-03, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 2809, It: 0, Loss Data: 1.281e-01, Loss Eqns: 3.921e+00, Loss Aux: 8.946e-03, Time: 0.281, Learning Rate: 1.0e-03\n",
      "Epoch: 2810, It: 0, Loss Data: 9.193e-02, Loss Eqns: 3.889e+00, Loss Aux: 8.379e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2811, It: 0, Loss Data: 1.054e-01, Loss Eqns: 4.207e+00, Loss Aux: 8.668e-03, Time: 0.277, Learning Rate: 1.0e-03\n",
      "Epoch: 2812, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.968e+00, Loss Aux: 9.881e-03, Time: 0.281, Learning Rate: 1.0e-03\n",
      "Epoch: 2813, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.818e+00, Loss Aux: 1.213e-02, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 2814, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.748e+00, Loss Aux: 1.059e-02, Time: 0.267, Learning Rate: 1.0e-03\n",
      "Epoch: 2815, It: 0, Loss Data: 1.291e-01, Loss Eqns: 3.921e+00, Loss Aux: 1.150e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2816, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.460e+00, Loss Aux: 7.194e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2817, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.950e+00, Loss Aux: 5.975e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2818, It: 0, Loss Data: 1.319e-01, Loss Eqns: 3.718e+00, Loss Aux: 1.027e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 2819, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.832e+00, Loss Aux: 1.266e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2820, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.792e+00, Loss Aux: 1.143e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2821, It: 0, Loss Data: 1.125e-01, Loss Eqns: 4.258e+00, Loss Aux: 1.352e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 2822, It: 0, Loss Data: 9.623e-02, Loss Eqns: 3.919e+00, Loss Aux: 1.508e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2823, It: 0, Loss Data: 1.176e-01, Loss Eqns: 4.006e+00, Loss Aux: 1.576e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2824, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.875e+00, Loss Aux: 1.337e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 2825, It: 0, Loss Data: 9.693e-02, Loss Eqns: 3.661e+00, Loss Aux: 1.249e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2826, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.882e+00, Loss Aux: 1.075e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2827, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.585e+00, Loss Aux: 1.158e-02, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 2828, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.864e+00, Loss Aux: 7.280e-03, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 2829, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.838e+00, Loss Aux: 4.810e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2830, It: 0, Loss Data: 1.272e-01, Loss Eqns: 3.844e+00, Loss Aux: 1.021e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2831, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.796e+00, Loss Aux: 1.388e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 2832, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.503e+00, Loss Aux: 9.424e-03, Time: 0.282, Learning Rate: 1.0e-03\n",
      "Epoch: 2833, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.817e+00, Loss Aux: 8.990e-03, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 2834, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.620e+00, Loss Aux: 8.386e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2835, It: 0, Loss Data: 1.031e-01, Loss Eqns: 3.912e+00, Loss Aux: 1.914e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2836, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.843e+00, Loss Aux: 1.589e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2837, It: 0, Loss Data: 1.304e-01, Loss Eqns: 3.720e+00, Loss Aux: 5.821e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2838, It: 0, Loss Data: 1.249e-01, Loss Eqns: 4.017e+00, Loss Aux: 5.580e-03, Time: 0.304, Learning Rate: 1.0e-03\n",
      "Epoch: 2839, It: 0, Loss Data: 1.270e-01, Loss Eqns: 4.000e+00, Loss Aux: 7.137e-03, Time: 0.266, Learning Rate: 1.0e-03\n",
      "Epoch: 2840, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.756e+00, Loss Aux: 3.497e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 2841, It: 0, Loss Data: 1.128e-01, Loss Eqns: 4.060e+00, Loss Aux: 3.274e-03, Time: 0.263, Learning Rate: 1.0e-03\n",
      "Epoch: 2842, It: 0, Loss Data: 1.013e-01, Loss Eqns: 4.036e+00, Loss Aux: 1.343e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2843, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.832e+00, Loss Aux: 2.394e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 2844, It: 0, Loss Data: 1.156e-01, Loss Eqns: 4.140e+00, Loss Aux: 1.715e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2845, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.805e+00, Loss Aux: 1.277e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 2846, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.688e+00, Loss Aux: 9.966e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2847, It: 0, Loss Data: 9.922e-02, Loss Eqns: 3.947e+00, Loss Aux: 8.362e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2848, It: 0, Loss Data: 1.158e-01, Loss Eqns: 3.723e+00, Loss Aux: 9.799e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2849, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.491e+00, Loss Aux: 1.860e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2850, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.984e+00, Loss Aux: 1.087e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2851, It: 0, Loss Data: 1.309e-01, Loss Eqns: 3.659e+00, Loss Aux: 8.643e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 2852, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.857e+00, Loss Aux: 1.041e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2853, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.905e+00, Loss Aux: 8.813e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2854, It: 0, Loss Data: 1.315e-01, Loss Eqns: 3.764e+00, Loss Aux: 3.283e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 2855, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.916e+00, Loss Aux: 1.924e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2856, It: 0, Loss Data: 1.304e-01, Loss Eqns: 3.831e+00, Loss Aux: 7.800e-03, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 2857, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.980e+00, Loss Aux: 4.230e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2858, It: 0, Loss Data: 1.386e-01, Loss Eqns: 4.148e+00, Loss Aux: 2.377e-02, Time: 0.260, Learning Rate: 1.0e-03\n",
      "Epoch: 2859, It: 0, Loss Data: 1.112e-01, Loss Eqns: 4.260e+00, Loss Aux: 5.212e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2860, It: 0, Loss Data: 1.475e-01, Loss Eqns: 3.717e+00, Loss Aux: 5.700e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 2861, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.880e+00, Loss Aux: 3.165e-02, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 2862, It: 0, Loss Data: 1.329e-01, Loss Eqns: 3.613e+00, Loss Aux: 2.770e-02, Time: 0.269, Learning Rate: 1.0e-03\n",
      "Epoch: 2863, It: 0, Loss Data: 1.423e-01, Loss Eqns: 3.784e+00, Loss Aux: 9.447e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2864, It: 0, Loss Data: 1.462e-01, Loss Eqns: 3.872e+00, Loss Aux: 1.263e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 2865, It: 0, Loss Data: 1.549e-01, Loss Eqns: 4.158e+00, Loss Aux: 1.695e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2866, It: 0, Loss Data: 1.366e-01, Loss Eqns: 3.465e+00, Loss Aux: 1.838e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2867, It: 0, Loss Data: 1.612e-01, Loss Eqns: 3.805e+00, Loss Aux: 9.239e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2868, It: 0, Loss Data: 1.283e-01, Loss Eqns: 4.057e+00, Loss Aux: 1.194e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2869, It: 0, Loss Data: 1.474e-01, Loss Eqns: 3.962e+00, Loss Aux: 1.869e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2870, It: 0, Loss Data: 9.839e-02, Loss Eqns: 3.988e+00, Loss Aux: 1.180e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2871, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.869e+00, Loss Aux: 9.241e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2872, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.794e+00, Loss Aux: 1.848e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2873, It: 0, Loss Data: 1.292e-01, Loss Eqns: 4.119e+00, Loss Aux: 1.742e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2874, It: 0, Loss Data: 1.230e-01, Loss Eqns: 3.834e+00, Loss Aux: 1.035e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2875, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.795e+00, Loss Aux: 9.569e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2876, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.851e+00, Loss Aux: 7.844e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 2877, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.537e+00, Loss Aux: 5.987e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 2878, It: 0, Loss Data: 1.378e-01, Loss Eqns: 3.584e+00, Loss Aux: 8.829e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2879, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.955e+00, Loss Aux: 2.325e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2880, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.859e+00, Loss Aux: 2.162e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 2881, It: 0, Loss Data: 1.072e-01, Loss Eqns: 4.139e+00, Loss Aux: 7.216e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 2882, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.976e+00, Loss Aux: 7.582e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 2883, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.725e+00, Loss Aux: 9.259e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 2884, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.961e+00, Loss Aux: 1.559e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2885, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.911e+00, Loss Aux: 1.558e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 2886, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.744e+00, Loss Aux: 1.145e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 2887, It: 0, Loss Data: 1.042e-01, Loss Eqns: 3.486e+00, Loss Aux: 1.134e-02, Time: 0.280, Learning Rate: 1.0e-03\n",
      "Epoch: 2888, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.867e+00, Loss Aux: 1.232e-02, Time: 0.276, Learning Rate: 1.0e-03\n",
      "Epoch: 2889, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.756e+00, Loss Aux: 6.599e-03, Time: 0.301, Learning Rate: 1.0e-03\n",
      "Epoch: 2890, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.678e+00, Loss Aux: 6.638e-03, Time: 0.278, Learning Rate: 1.0e-03\n",
      "Epoch: 2891, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.819e+00, Loss Aux: 9.795e-03, Time: 0.255, Learning Rate: 1.0e-03\n",
      "Epoch: 2892, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.541e+00, Loss Aux: 1.289e-02, Time: 0.262, Learning Rate: 1.0e-03\n",
      "Epoch: 2893, It: 0, Loss Data: 1.269e-01, Loss Eqns: 3.769e+00, Loss Aux: 1.082e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2894, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.651e+00, Loss Aux: 9.559e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2895, It: 0, Loss Data: 1.293e-01, Loss Eqns: 3.967e+00, Loss Aux: 1.636e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2896, It: 0, Loss Data: 1.202e-01, Loss Eqns: 3.917e+00, Loss Aux: 1.964e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 2897, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.720e+00, Loss Aux: 8.582e-03, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 2898, It: 0, Loss Data: 1.260e-01, Loss Eqns: 3.487e+00, Loss Aux: 8.253e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2899, It: 0, Loss Data: 1.169e-01, Loss Eqns: 4.038e+00, Loss Aux: 4.481e-03, Time: 0.273, Learning Rate: 1.0e-03\n",
      "Epoch: 2900, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.755e+00, Loss Aux: 4.497e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 2901, It: 0, Loss Data: 9.793e-02, Loss Eqns: 3.646e+00, Loss Aux: 1.024e-02, Time: 0.288, Learning Rate: 1.0e-03\n",
      "Epoch: 2902, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.637e+00, Loss Aux: 1.472e-02, Time: 0.264, Learning Rate: 1.0e-03\n",
      "Epoch: 2903, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.870e+00, Loss Aux: 1.279e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 2904, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.775e+00, Loss Aux: 1.471e-02, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 2905, It: 0, Loss Data: 1.029e-01, Loss Eqns: 4.006e+00, Loss Aux: 1.316e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2906, It: 0, Loss Data: 1.343e-01, Loss Eqns: 4.064e+00, Loss Aux: 1.049e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 2907, It: 0, Loss Data: 1.287e-01, Loss Eqns: 3.499e+00, Loss Aux: 8.718e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2908, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.706e+00, Loss Aux: 4.938e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2909, It: 0, Loss Data: 1.314e-01, Loss Eqns: 3.901e+00, Loss Aux: 5.270e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 2910, It: 0, Loss Data: 1.077e-01, Loss Eqns: 4.006e+00, Loss Aux: 1.336e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 2911, It: 0, Loss Data: 1.012e-01, Loss Eqns: 3.776e+00, Loss Aux: 1.014e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 2912, It: 0, Loss Data: 1.191e-01, Loss Eqns: 4.000e+00, Loss Aux: 6.397e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 2913, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.677e+00, Loss Aux: 8.922e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2914, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.887e+00, Loss Aux: 1.068e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 2915, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.655e+00, Loss Aux: 5.386e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 2916, It: 0, Loss Data: 1.286e-01, Loss Eqns: 3.937e+00, Loss Aux: 4.930e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2917, It: 0, Loss Data: 9.293e-02, Loss Eqns: 3.647e+00, Loss Aux: 1.353e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 2918, It: 0, Loss Data: 9.728e-02, Loss Eqns: 3.941e+00, Loss Aux: 1.242e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 2919, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.680e+00, Loss Aux: 6.557e-03, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 2920, It: 0, Loss Data: 1.343e-01, Loss Eqns: 3.829e+00, Loss Aux: 5.806e-03, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 2921, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.831e+00, Loss Aux: 9.470e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 2922, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.593e+00, Loss Aux: 4.022e-03, Time: 0.252, Learning Rate: 1.0e-03\n",
      "Epoch: 2923, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.633e+00, Loss Aux: 5.020e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2924, It: 0, Loss Data: 1.089e-01, Loss Eqns: 3.929e+00, Loss Aux: 7.470e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 2925, It: 0, Loss Data: 1.250e-01, Loss Eqns: 3.861e+00, Loss Aux: 1.203e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2926, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.877e+00, Loss Aux: 2.900e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2927, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.672e+00, Loss Aux: 2.586e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2928, It: 0, Loss Data: 1.151e-01, Loss Eqns: 4.171e+00, Loss Aux: 7.728e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 2929, It: 0, Loss Data: 1.361e-01, Loss Eqns: 3.922e+00, Loss Aux: 5.336e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 2930, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.535e+00, Loss Aux: 7.669e-03, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 2931, It: 0, Loss Data: 9.861e-02, Loss Eqns: 3.739e+00, Loss Aux: 1.004e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2932, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.453e+00, Loss Aux: 1.096e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2933, It: 0, Loss Data: 1.351e-01, Loss Eqns: 3.565e+00, Loss Aux: 1.363e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 2934, It: 0, Loss Data: 1.337e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.823e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 2935, It: 0, Loss Data: 1.044e-01, Loss Eqns: 4.020e+00, Loss Aux: 1.997e-02, Time: 0.289, Learning Rate: 1.0e-03\n",
      "Epoch: 2936, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.943e+00, Loss Aux: 1.053e-02, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 2937, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.757e+00, Loss Aux: 1.262e-02, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2938, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.647e+00, Loss Aux: 8.088e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 2939, It: 0, Loss Data: 1.161e-01, Loss Eqns: 3.757e+00, Loss Aux: 1.984e-02, Time: 0.266, Learning Rate: 1.0e-03\n",
      "Epoch: 2940, It: 0, Loss Data: 1.203e-01, Loss Eqns: 3.989e+00, Loss Aux: 2.140e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 2941, It: 0, Loss Data: 1.031e-01, Loss Eqns: 4.027e+00, Loss Aux: 6.183e-03, Time: 0.278, Learning Rate: 1.0e-03\n",
      "Epoch: 2942, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.604e+00, Loss Aux: 7.412e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 2943, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.882e+00, Loss Aux: 1.741e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2944, It: 0, Loss Data: 9.450e-02, Loss Eqns: 3.925e+00, Loss Aux: 2.014e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2945, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.521e+00, Loss Aux: 8.206e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2946, It: 0, Loss Data: 1.412e-01, Loss Eqns: 3.798e+00, Loss Aux: 1.030e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 2947, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.491e+00, Loss Aux: 1.177e-02, Time: 0.289, Learning Rate: 1.0e-03\n",
      "Epoch: 2948, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.808e+00, Loss Aux: 1.133e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2949, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.984e+00, Loss Aux: 8.585e-03, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 2950, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.826e+00, Loss Aux: 9.072e-03, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 2951, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.510e+00, Loss Aux: 2.539e-02, Time: 0.264, Learning Rate: 1.0e-03\n",
      "Epoch: 2952, It: 0, Loss Data: 1.047e-01, Loss Eqns: 3.764e+00, Loss Aux: 1.704e-02, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2953, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.844e+00, Loss Aux: 7.498e-03, Time: 0.268, Learning Rate: 1.0e-03\n",
      "Epoch: 2954, It: 0, Loss Data: 1.326e-01, Loss Eqns: 4.045e+00, Loss Aux: 8.723e-03, Time: 0.280, Learning Rate: 1.0e-03\n",
      "Epoch: 2955, It: 0, Loss Data: 9.761e-02, Loss Eqns: 3.915e+00, Loss Aux: 6.269e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 2956, It: 0, Loss Data: 1.147e-01, Loss Eqns: 3.966e+00, Loss Aux: 1.800e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 2957, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.630e+00, Loss Aux: 2.976e-02, Time: 0.307, Learning Rate: 1.0e-03\n",
      "Epoch: 2958, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.819e+00, Loss Aux: 1.911e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2959, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.959e+00, Loss Aux: 5.855e-03, Time: 0.266, Learning Rate: 1.0e-03\n",
      "Epoch: 2960, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.441e+00, Loss Aux: 7.745e-03, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 2961, It: 0, Loss Data: 1.089e-01, Loss Eqns: 3.748e+00, Loss Aux: 6.059e-03, Time: 0.252, Learning Rate: 1.0e-03\n",
      "Epoch: 2962, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.561e+00, Loss Aux: 7.953e-03, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 2963, It: 0, Loss Data: 9.992e-02, Loss Eqns: 3.547e+00, Loss Aux: 1.320e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2964, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.777e+00, Loss Aux: 2.293e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2965, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.609e+00, Loss Aux: 3.269e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 2966, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.827e+00, Loss Aux: 2.048e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 2967, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.998e+00, Loss Aux: 1.036e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2968, It: 0, Loss Data: 1.148e-01, Loss Eqns: 4.107e+00, Loss Aux: 6.681e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 2969, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.757e+00, Loss Aux: 1.017e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2970, It: 0, Loss Data: 1.011e-01, Loss Eqns: 3.408e+00, Loss Aux: 1.082e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 2971, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.985e+00, Loss Aux: 6.285e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 2972, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.998e+00, Loss Aux: 1.780e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2973, It: 0, Loss Data: 1.120e-01, Loss Eqns: 4.080e+00, Loss Aux: 3.964e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 2974, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.971e+00, Loss Aux: 3.207e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 2975, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.872e+00, Loss Aux: 1.286e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 2976, It: 0, Loss Data: 1.016e-01, Loss Eqns: 4.130e+00, Loss Aux: 9.153e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 2977, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.901e+00, Loss Aux: 9.096e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 2978, It: 0, Loss Data: 1.036e-01, Loss Eqns: 3.568e+00, Loss Aux: 6.296e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 2979, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.734e+00, Loss Aux: 4.299e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 2980, It: 0, Loss Data: 9.941e-02, Loss Eqns: 3.748e+00, Loss Aux: 6.660e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 2981, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.649e+00, Loss Aux: 2.203e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 2982, It: 0, Loss Data: 1.309e-01, Loss Eqns: 3.794e+00, Loss Aux: 1.542e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 2983, It: 0, Loss Data: 1.248e-01, Loss Eqns: 3.760e+00, Loss Aux: 1.454e-02, Time: 0.297, Learning Rate: 1.0e-03\n",
      "Epoch: 2984, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.854e+00, Loss Aux: 1.790e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 2985, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.877e+00, Loss Aux: 1.184e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 2986, It: 0, Loss Data: 1.285e-01, Loss Eqns: 3.902e+00, Loss Aux: 4.930e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 2987, It: 0, Loss Data: 1.364e-01, Loss Eqns: 3.794e+00, Loss Aux: 4.507e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 2988, It: 0, Loss Data: 1.180e-01, Loss Eqns: 4.029e+00, Loss Aux: 4.250e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 2989, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.910e+00, Loss Aux: 8.494e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 2990, It: 0, Loss Data: 1.126e-01, Loss Eqns: 4.155e+00, Loss Aux: 1.597e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2991, It: 0, Loss Data: 9.641e-02, Loss Eqns: 3.644e+00, Loss Aux: 1.210e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 2992, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.848e+00, Loss Aux: 9.236e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 2993, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.730e+00, Loss Aux: 7.041e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 2994, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.641e+00, Loss Aux: 7.304e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 2995, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.876e+00, Loss Aux: 6.995e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 2996, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.662e+00, Loss Aux: 8.235e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 2997, It: 0, Loss Data: 1.072e-01, Loss Eqns: 3.799e+00, Loss Aux: 1.428e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 2998, It: 0, Loss Data: 1.872e-01, Loss Eqns: 4.497e+00, Loss Aux: 3.600e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 2999, It: 0, Loss Data: 1.880e-01, Loss Eqns: 4.550e+00, Loss Aux: 1.157e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3000, It: 0, Loss Data: 1.545e-01, Loss Eqns: 4.934e+00, Loss Aux: 1.160e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3001, It: 0, Loss Data: 1.698e-01, Loss Eqns: 4.051e+00, Loss Aux: 5.442e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3002, It: 0, Loss Data: 1.551e-01, Loss Eqns: 4.020e+00, Loss Aux: 2.457e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3003, It: 0, Loss Data: 2.083e-01, Loss Eqns: 4.023e+00, Loss Aux: 1.197e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3004, It: 0, Loss Data: 1.509e-01, Loss Eqns: 4.183e+00, Loss Aux: 5.694e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3005, It: 0, Loss Data: 1.610e-01, Loss Eqns: 3.949e+00, Loss Aux: 3.175e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 3006, It: 0, Loss Data: 1.258e-01, Loss Eqns: 3.931e+00, Loss Aux: 1.091e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3007, It: 0, Loss Data: 1.489e-01, Loss Eqns: 4.180e+00, Loss Aux: 1.640e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 3008, It: 0, Loss Data: 1.438e-01, Loss Eqns: 3.721e+00, Loss Aux: 1.706e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3009, It: 0, Loss Data: 1.741e-01, Loss Eqns: 3.890e+00, Loss Aux: 5.114e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3010, It: 0, Loss Data: 1.383e-01, Loss Eqns: 3.914e+00, Loss Aux: 3.033e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 3011, It: 0, Loss Data: 1.383e-01, Loss Eqns: 3.654e+00, Loss Aux: 9.642e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3012, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.480e+00, Loss Aux: 9.420e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3013, It: 0, Loss Data: 1.412e-01, Loss Eqns: 3.802e+00, Loss Aux: 2.124e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3014, It: 0, Loss Data: 1.380e-01, Loss Eqns: 3.553e+00, Loss Aux: 1.476e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3015, It: 0, Loss Data: 1.482e-01, Loss Eqns: 3.534e+00, Loss Aux: 1.140e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3016, It: 0, Loss Data: 1.358e-01, Loss Eqns: 3.690e+00, Loss Aux: 8.547e-03, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 3017, It: 0, Loss Data: 1.153e-01, Loss Eqns: 4.044e+00, Loss Aux: 3.505e-02, Time: 0.270, Learning Rate: 1.0e-03\n",
      "Epoch: 3018, It: 0, Loss Data: 1.285e-01, Loss Eqns: 3.912e+00, Loss Aux: 3.318e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3019, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.839e+00, Loss Aux: 1.624e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3020, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.692e+00, Loss Aux: 1.120e-02, Time: 0.279, Learning Rate: 1.0e-03\n",
      "Epoch: 3021, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.747e+00, Loss Aux: 1.270e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3022, It: 0, Loss Data: 1.340e-01, Loss Eqns: 4.242e+00, Loss Aux: 9.458e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3023, It: 0, Loss Data: 1.050e-01, Loss Eqns: 3.624e+00, Loss Aux: 8.619e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3024, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.990e+00, Loss Aux: 1.049e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3025, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.704e+00, Loss Aux: 5.253e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3026, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.964e+00, Loss Aux: 8.239e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3027, It: 0, Loss Data: 1.166e-01, Loss Eqns: 4.002e+00, Loss Aux: 1.319e-02, Time: 0.274, Learning Rate: 1.0e-03\n",
      "Epoch: 3028, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.847e+00, Loss Aux: 1.121e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3029, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.669e+00, Loss Aux: 1.025e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3030, It: 0, Loss Data: 1.347e-01, Loss Eqns: 3.810e+00, Loss Aux: 2.522e-02, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 3031, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.814e+00, Loss Aux: 2.395e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3032, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.821e+00, Loss Aux: 7.094e-03, Time: 0.264, Learning Rate: 1.0e-03\n",
      "Epoch: 3033, It: 0, Loss Data: 1.369e-01, Loss Eqns: 3.478e+00, Loss Aux: 7.837e-03, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 3034, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.776e+00, Loss Aux: 1.078e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3035, It: 0, Loss Data: 1.372e-01, Loss Eqns: 3.695e+00, Loss Aux: 1.182e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3036, It: 0, Loss Data: 9.332e-02, Loss Eqns: 3.842e+00, Loss Aux: 9.010e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3037, It: 0, Loss Data: 1.147e-01, Loss Eqns: 3.812e+00, Loss Aux: 9.651e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3038, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.973e+00, Loss Aux: 2.602e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3039, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.617e+00, Loss Aux: 1.767e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3040, It: 0, Loss Data: 1.433e-01, Loss Eqns: 3.588e+00, Loss Aux: 1.046e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3041, It: 0, Loss Data: 1.148e-01, Loss Eqns: 4.040e+00, Loss Aux: 6.564e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3042, It: 0, Loss Data: 1.288e-01, Loss Eqns: 3.723e+00, Loss Aux: 8.210e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3043, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.658e+00, Loss Aux: 6.680e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3044, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.537e+00, Loss Aux: 8.200e-03, Time: 0.266, Learning Rate: 1.0e-03\n",
      "Epoch: 3045, It: 0, Loss Data: 1.373e-01, Loss Eqns: 3.510e+00, Loss Aux: 1.799e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3046, It: 0, Loss Data: 9.443e-02, Loss Eqns: 3.765e+00, Loss Aux: 1.247e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3047, It: 0, Loss Data: 1.096e-01, Loss Eqns: 3.941e+00, Loss Aux: 6.460e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3048, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.779e+00, Loss Aux: 7.943e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 3049, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.713e+00, Loss Aux: 1.140e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3050, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.810e+00, Loss Aux: 6.600e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3051, It: 0, Loss Data: 1.178e-01, Loss Eqns: 3.932e+00, Loss Aux: 5.638e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3052, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.756e+00, Loss Aux: 1.456e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3053, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.771e+00, Loss Aux: 2.344e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3054, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.919e+00, Loss Aux: 1.139e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3055, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.950e+00, Loss Aux: 7.566e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3056, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.452e+00, Loss Aux: 1.025e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3057, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.976e+00, Loss Aux: 9.965e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3058, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.620e+00, Loss Aux: 8.005e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3059, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.712e+00, Loss Aux: 7.528e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3060, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.681e+00, Loss Aux: 6.426e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3061, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.847e+00, Loss Aux: 1.185e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3062, It: 0, Loss Data: 1.032e-01, Loss Eqns: 3.933e+00, Loss Aux: 1.830e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3063, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.765e+00, Loss Aux: 1.909e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3064, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.804e+00, Loss Aux: 8.026e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3065, It: 0, Loss Data: 1.072e-01, Loss Eqns: 3.635e+00, Loss Aux: 7.856e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3066, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.813e+00, Loss Aux: 8.421e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3067, It: 0, Loss Data: 1.230e-01, Loss Eqns: 3.846e+00, Loss Aux: 6.824e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3068, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.695e+00, Loss Aux: 2.610e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3069, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.671e+00, Loss Aux: 7.421e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3070, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.812e+00, Loss Aux: 4.094e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3071, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.752e+00, Loss Aux: 3.571e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3072, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.874e+00, Loss Aux: 1.899e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3073, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.940e+00, Loss Aux: 1.176e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3074, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.952e+00, Loss Aux: 1.173e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 3075, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.575e+00, Loss Aux: 9.696e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3076, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.741e+00, Loss Aux: 5.714e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3077, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.723e+00, Loss Aux: 6.923e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3078, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.731e+00, Loss Aux: 1.119e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3079, It: 0, Loss Data: 1.103e-01, Loss Eqns: 3.968e+00, Loss Aux: 1.095e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3080, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.809e+00, Loss Aux: 1.357e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3081, It: 0, Loss Data: 1.089e-01, Loss Eqns: 3.874e+00, Loss Aux: 1.587e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3082, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.885e+00, Loss Aux: 1.987e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3083, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.897e+00, Loss Aux: 2.121e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3084, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.809e+00, Loss Aux: 8.412e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3085, It: 0, Loss Data: 1.048e-01, Loss Eqns: 3.528e+00, Loss Aux: 3.657e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3086, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.714e+00, Loss Aux: 6.296e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3087, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.874e+00, Loss Aux: 1.186e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3088, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.606e+00, Loss Aux: 1.176e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3089, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.632e+00, Loss Aux: 6.900e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3090, It: 0, Loss Data: 9.965e-02, Loss Eqns: 3.637e+00, Loss Aux: 7.213e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3091, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.682e+00, Loss Aux: 1.205e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3092, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.690e+00, Loss Aux: 1.452e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3093, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.552e+00, Loss Aux: 1.160e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3094, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.591e+00, Loss Aux: 1.491e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3095, It: 0, Loss Data: 1.264e-01, Loss Eqns: 4.033e+00, Loss Aux: 1.162e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3096, It: 0, Loss Data: 1.035e-01, Loss Eqns: 3.875e+00, Loss Aux: 6.726e-03, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 3097, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.707e+00, Loss Aux: 5.211e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3098, It: 0, Loss Data: 1.157e-01, Loss Eqns: 3.604e+00, Loss Aux: 4.783e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 3099, It: 0, Loss Data: 1.199e-01, Loss Eqns: 4.078e+00, Loss Aux: 1.417e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 3100, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.690e+00, Loss Aux: 3.582e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 3101, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.896e+00, Loss Aux: 2.151e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3102, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.814e+00, Loss Aux: 9.368e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3103, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.638e+00, Loss Aux: 8.022e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3104, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.936e+00, Loss Aux: 7.128e-03, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 3105, It: 0, Loss Data: 1.006e-01, Loss Eqns: 3.694e+00, Loss Aux: 7.333e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3106, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.834e+00, Loss Aux: 8.246e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3107, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.825e+00, Loss Aux: 1.718e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3108, It: 0, Loss Data: 8.863e-02, Loss Eqns: 3.899e+00, Loss Aux: 1.477e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3109, It: 0, Loss Data: 1.053e-01, Loss Eqns: 3.725e+00, Loss Aux: 4.831e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3110, It: 0, Loss Data: 1.324e-01, Loss Eqns: 3.640e+00, Loss Aux: 4.528e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3111, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.478e+00, Loss Aux: 1.014e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3112, It: 0, Loss Data: 1.286e-01, Loss Eqns: 3.766e+00, Loss Aux: 6.480e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3113, It: 0, Loss Data: 1.297e-01, Loss Eqns: 3.520e+00, Loss Aux: 1.278e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3114, It: 0, Loss Data: 1.314e-01, Loss Eqns: 3.610e+00, Loss Aux: 9.278e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3115, It: 0, Loss Data: 1.277e-01, Loss Eqns: 3.965e+00, Loss Aux: 1.949e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3116, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.746e+00, Loss Aux: 3.939e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3117, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.828e+00, Loss Aux: 3.806e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3118, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.621e+00, Loss Aux: 2.874e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3119, It: 0, Loss Data: 1.057e-01, Loss Eqns: 3.623e+00, Loss Aux: 1.756e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3120, It: 0, Loss Data: 1.022e-01, Loss Eqns: 3.785e+00, Loss Aux: 8.820e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3121, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.492e+00, Loss Aux: 1.496e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3122, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.950e+00, Loss Aux: 1.318e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3123, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.693e+00, Loss Aux: 1.018e-02, Time: 0.271, Learning Rate: 1.0e-03\n",
      "Epoch: 3124, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.785e+00, Loss Aux: 2.524e-02, Time: 0.275, Learning Rate: 1.0e-03\n",
      "Epoch: 3125, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.545e+00, Loss Aux: 3.782e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3126, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.792e+00, Loss Aux: 2.458e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 3127, It: 0, Loss Data: 1.235e-01, Loss Eqns: 4.062e+00, Loss Aux: 1.977e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3128, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.827e+00, Loss Aux: 1.723e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3129, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.727e+00, Loss Aux: 1.274e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 3130, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.436e+00, Loss Aux: 9.352e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3131, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.575e+00, Loss Aux: 7.846e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3132, It: 0, Loss Data: 1.297e-01, Loss Eqns: 3.786e+00, Loss Aux: 8.656e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3133, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.704e+00, Loss Aux: 1.065e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3134, It: 0, Loss Data: 1.064e-01, Loss Eqns: 3.800e+00, Loss Aux: 1.065e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3135, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.563e+00, Loss Aux: 7.599e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3136, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.665e+00, Loss Aux: 7.328e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3137, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.846e+00, Loss Aux: 1.268e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3138, It: 0, Loss Data: 1.134e-01, Loss Eqns: 4.104e+00, Loss Aux: 1.023e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3139, It: 0, Loss Data: 1.430e-01, Loss Eqns: 4.253e+00, Loss Aux: 9.909e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3140, It: 0, Loss Data: 9.012e-02, Loss Eqns: 3.565e+00, Loss Aux: 1.698e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3141, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.934e+00, Loss Aux: 1.690e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3142, It: 0, Loss Data: 1.086e-01, Loss Eqns: 3.932e+00, Loss Aux: 5.348e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3143, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.945e+00, Loss Aux: 3.144e-03, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 3144, It: 0, Loss Data: 1.009e-01, Loss Eqns: 3.624e+00, Loss Aux: 4.817e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3145, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.865e+00, Loss Aux: 7.703e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3146, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.894e+00, Loss Aux: 6.696e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3147, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.761e+00, Loss Aux: 8.345e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3148, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.918e+00, Loss Aux: 9.516e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3149, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.604e+00, Loss Aux: 1.791e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 3150, It: 0, Loss Data: 1.030e-01, Loss Eqns: 3.772e+00, Loss Aux: 1.530e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3151, It: 0, Loss Data: 1.234e-01, Loss Eqns: 3.992e+00, Loss Aux: 9.098e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3152, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.654e+00, Loss Aux: 7.159e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3153, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.885e+00, Loss Aux: 8.228e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3154, It: 0, Loss Data: 1.291e-01, Loss Eqns: 3.816e+00, Loss Aux: 1.030e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3155, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.600e+00, Loss Aux: 9.553e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3156, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.448e+00, Loss Aux: 7.570e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3157, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.764e+00, Loss Aux: 9.984e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3158, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.824e+00, Loss Aux: 2.718e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3159, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.864e+00, Loss Aux: 2.490e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3160, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.613e+00, Loss Aux: 1.314e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 3161, It: 0, Loss Data: 1.271e-01, Loss Eqns: 3.751e+00, Loss Aux: 1.173e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3162, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.688e+00, Loss Aux: 6.780e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3163, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.793e+00, Loss Aux: 1.346e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3164, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.723e+00, Loss Aux: 1.908e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3165, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.764e+00, Loss Aux: 3.304e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3166, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.431e+00, Loss Aux: 6.982e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3167, It: 0, Loss Data: 1.431e-01, Loss Eqns: 3.556e+00, Loss Aux: 4.155e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3168, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.672e+00, Loss Aux: 1.789e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3169, It: 0, Loss Data: 1.327e-01, Loss Eqns: 3.716e+00, Loss Aux: 1.374e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3170, It: 0, Loss Data: 1.203e-01, Loss Eqns: 3.830e+00, Loss Aux: 7.458e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3171, It: 0, Loss Data: 1.352e-01, Loss Eqns: 3.929e+00, Loss Aux: 2.953e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3172, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.747e+00, Loss Aux: 2.201e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3173, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.760e+00, Loss Aux: 1.385e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3174, It: 0, Loss Data: 2.122e-01, Loss Eqns: 4.655e+00, Loss Aux: 3.788e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3175, It: 0, Loss Data: 2.431e-01, Loss Eqns: 5.321e+00, Loss Aux: 1.918e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3176, It: 0, Loss Data: 2.409e-01, Loss Eqns: 4.962e+00, Loss Aux: 1.963e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3177, It: 0, Loss Data: 1.750e-01, Loss Eqns: 4.757e+00, Loss Aux: 2.429e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3178, It: 0, Loss Data: 2.854e-01, Loss Eqns: 4.978e+00, Loss Aux: 3.499e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3179, It: 0, Loss Data: 1.561e-01, Loss Eqns: 4.040e+00, Loss Aux: 2.264e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3180, It: 0, Loss Data: 1.990e-01, Loss Eqns: 5.010e+00, Loss Aux: 5.901e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3181, It: 0, Loss Data: 1.925e-01, Loss Eqns: 3.755e+00, Loss Aux: 5.557e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3182, It: 0, Loss Data: 2.154e-01, Loss Eqns: 4.399e+00, Loss Aux: 5.357e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3183, It: 0, Loss Data: 1.892e-01, Loss Eqns: 3.754e+00, Loss Aux: 1.146e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3184, It: 0, Loss Data: 2.004e-01, Loss Eqns: 3.790e+00, Loss Aux: 1.167e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3185, It: 0, Loss Data: 1.950e-01, Loss Eqns: 3.528e+00, Loss Aux: 5.688e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3186, It: 0, Loss Data: 1.841e-01, Loss Eqns: 4.042e+00, Loss Aux: 3.756e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3187, It: 0, Loss Data: 1.773e-01, Loss Eqns: 3.431e+00, Loss Aux: 1.445e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3188, It: 0, Loss Data: 1.712e-01, Loss Eqns: 4.052e+00, Loss Aux: 1.074e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3189, It: 0, Loss Data: 1.709e-01, Loss Eqns: 3.911e+00, Loss Aux: 3.680e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3190, It: 0, Loss Data: 1.781e-01, Loss Eqns: 3.721e+00, Loss Aux: 4.688e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3191, It: 0, Loss Data: 1.497e-01, Loss Eqns: 3.555e+00, Loss Aux: 1.860e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3192, It: 0, Loss Data: 1.847e-01, Loss Eqns: 3.723e+00, Loss Aux: 1.360e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3193, It: 0, Loss Data: 1.386e-01, Loss Eqns: 3.538e+00, Loss Aux: 3.201e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3194, It: 0, Loss Data: 1.537e-01, Loss Eqns: 3.932e+00, Loss Aux: 3.894e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3195, It: 0, Loss Data: 1.155e-01, Loss Eqns: 4.102e+00, Loss Aux: 2.133e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3196, It: 0, Loss Data: 1.353e-01, Loss Eqns: 3.969e+00, Loss Aux: 1.729e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3197, It: 0, Loss Data: 1.387e-01, Loss Eqns: 3.889e+00, Loss Aux: 2.092e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3198, It: 0, Loss Data: 1.439e-01, Loss Eqns: 3.728e+00, Loss Aux: 3.615e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3199, It: 0, Loss Data: 1.337e-01, Loss Eqns: 3.871e+00, Loss Aux: 1.200e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3200, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.921e+00, Loss Aux: 9.865e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3201, It: 0, Loss Data: 1.676e-01, Loss Eqns: 3.950e+00, Loss Aux: 2.970e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3202, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.480e+00, Loss Aux: 1.653e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3203, It: 0, Loss Data: 1.572e-01, Loss Eqns: 3.713e+00, Loss Aux: 8.861e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3204, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.718e+00, Loss Aux: 8.731e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3205, It: 0, Loss Data: 1.535e-01, Loss Eqns: 4.000e+00, Loss Aux: 1.499e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3206, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.463e+00, Loss Aux: 1.535e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3207, It: 0, Loss Data: 1.513e-01, Loss Eqns: 3.983e+00, Loss Aux: 1.596e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3208, It: 0, Loss Data: 1.334e-01, Loss Eqns: 3.525e+00, Loss Aux: 2.506e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3209, It: 0, Loss Data: 1.502e-01, Loss Eqns: 3.513e+00, Loss Aux: 3.225e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3210, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.716e+00, Loss Aux: 1.643e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3211, It: 0, Loss Data: 1.158e-01, Loss Eqns: 3.922e+00, Loss Aux: 6.402e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3212, It: 0, Loss Data: 1.028e-01, Loss Eqns: 3.657e+00, Loss Aux: 6.543e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3213, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.813e+00, Loss Aux: 7.254e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3214, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.544e+00, Loss Aux: 8.752e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3215, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.039e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3216, It: 0, Loss Data: 9.233e-02, Loss Eqns: 3.646e+00, Loss Aux: 1.685e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3217, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.761e+00, Loss Aux: 2.174e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3218, It: 0, Loss Data: 9.270e-02, Loss Eqns: 3.941e+00, Loss Aux: 1.316e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3219, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.793e+00, Loss Aux: 6.500e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3220, It: 0, Loss Data: 1.106e-01, Loss Eqns: 3.843e+00, Loss Aux: 6.080e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3221, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.445e+00, Loss Aux: 7.669e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3222, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.741e+00, Loss Aux: 9.035e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3223, It: 0, Loss Data: 1.158e-01, Loss Eqns: 3.683e+00, Loss Aux: 1.176e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3224, It: 0, Loss Data: 1.295e-01, Loss Eqns: 3.725e+00, Loss Aux: 1.293e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3225, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.779e+00, Loss Aux: 8.316e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3226, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.560e+00, Loss Aux: 8.224e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3227, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.667e+00, Loss Aux: 1.218e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3228, It: 0, Loss Data: 1.358e-01, Loss Eqns: 3.475e+00, Loss Aux: 6.179e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3229, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.856e+00, Loss Aux: 5.469e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3230, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.879e+00, Loss Aux: 7.095e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3231, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.712e+00, Loss Aux: 1.499e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3232, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.958e+00, Loss Aux: 1.565e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3233, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.703e+00, Loss Aux: 1.391e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3234, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.882e+00, Loss Aux: 1.417e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3235, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.603e+00, Loss Aux: 8.364e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3236, It: 0, Loss Data: 1.024e-01, Loss Eqns: 3.800e+00, Loss Aux: 5.297e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3237, It: 0, Loss Data: 1.040e-01, Loss Eqns: 3.492e+00, Loss Aux: 4.268e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3238, It: 0, Loss Data: 1.319e-01, Loss Eqns: 3.896e+00, Loss Aux: 5.063e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3239, It: 0, Loss Data: 1.005e-01, Loss Eqns: 3.358e+00, Loss Aux: 6.706e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3240, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.840e+00, Loss Aux: 1.150e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3241, It: 0, Loss Data: 1.250e-01, Loss Eqns: 3.657e+00, Loss Aux: 1.662e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3242, It: 0, Loss Data: 1.346e-01, Loss Eqns: 3.826e+00, Loss Aux: 1.163e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3243, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.743e+00, Loss Aux: 9.574e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3244, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.761e+00, Loss Aux: 9.841e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3245, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.965e+00, Loss Aux: 8.303e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3246, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.545e+00, Loss Aux: 5.741e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3247, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.788e+00, Loss Aux: 6.715e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3248, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.580e+00, Loss Aux: 6.842e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3249, It: 0, Loss Data: 9.792e-02, Loss Eqns: 3.567e+00, Loss Aux: 9.869e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3250, It: 0, Loss Data: 1.205e-01, Loss Eqns: 3.841e+00, Loss Aux: 7.870e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3251, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.729e+00, Loss Aux: 5.279e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 3252, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.654e+00, Loss Aux: 7.745e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3253, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.875e+00, Loss Aux: 1.092e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3254, It: 0, Loss Data: 1.044e-01, Loss Eqns: 3.684e+00, Loss Aux: 1.291e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3255, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.786e+00, Loss Aux: 1.246e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3256, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.814e+00, Loss Aux: 1.148e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3257, It: 0, Loss Data: 1.044e-01, Loss Eqns: 3.752e+00, Loss Aux: 5.128e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3258, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.714e+00, Loss Aux: 4.592e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3259, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.804e+00, Loss Aux: 4.681e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3260, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.764e+00, Loss Aux: 5.847e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 3261, It: 0, Loss Data: 1.001e-01, Loss Eqns: 3.777e+00, Loss Aux: 7.827e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3262, It: 0, Loss Data: 1.336e-01, Loss Eqns: 3.680e+00, Loss Aux: 1.893e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3263, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.697e+00, Loss Aux: 3.699e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3264, It: 0, Loss Data: 1.021e-01, Loss Eqns: 3.724e+00, Loss Aux: 2.569e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3265, It: 0, Loss Data: 1.266e-01, Loss Eqns: 4.029e+00, Loss Aux: 9.545e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3266, It: 0, Loss Data: 1.049e-01, Loss Eqns: 3.687e+00, Loss Aux: 1.019e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3267, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.693e+00, Loss Aux: 1.034e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3268, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.566e+00, Loss Aux: 1.376e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3269, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.599e+00, Loss Aux: 9.928e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3270, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.690e+00, Loss Aux: 1.070e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3271, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.977e+00, Loss Aux: 2.356e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3272, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.738e+00, Loss Aux: 1.568e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3273, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.881e+00, Loss Aux: 4.399e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3274, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.692e+00, Loss Aux: 5.752e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3275, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.725e+00, Loss Aux: 9.644e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 3276, It: 0, Loss Data: 1.135e-01, Loss Eqns: 4.058e+00, Loss Aux: 1.154e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3277, It: 0, Loss Data: 1.066e-01, Loss Eqns: 3.626e+00, Loss Aux: 9.827e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3278, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.566e+00, Loss Aux: 1.050e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3279, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.548e+00, Loss Aux: 1.482e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3280, It: 0, Loss Data: 1.020e-01, Loss Eqns: 3.676e+00, Loss Aux: 1.858e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3281, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.600e+00, Loss Aux: 2.323e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 3282, It: 0, Loss Data: 1.320e-01, Loss Eqns: 3.648e+00, Loss Aux: 1.051e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3283, It: 0, Loss Data: 1.357e-01, Loss Eqns: 3.365e+00, Loss Aux: 5.527e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3284, It: 0, Loss Data: 1.096e-01, Loss Eqns: 3.924e+00, Loss Aux: 5.390e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3285, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.658e+00, Loss Aux: 5.096e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3286, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.839e+00, Loss Aux: 7.921e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3287, It: 0, Loss Data: 1.070e-01, Loss Eqns: 4.056e+00, Loss Aux: 1.228e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3288, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.854e+00, Loss Aux: 1.453e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 3289, It: 0, Loss Data: 1.045e-01, Loss Eqns: 4.023e+00, Loss Aux: 1.108e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3290, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.737e+00, Loss Aux: 1.031e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3291, It: 0, Loss Data: 8.332e-02, Loss Eqns: 3.753e+00, Loss Aux: 7.192e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3292, It: 0, Loss Data: 1.044e-01, Loss Eqns: 3.871e+00, Loss Aux: 6.009e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3293, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.579e+00, Loss Aux: 8.931e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3294, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.959e+00, Loss Aux: 1.204e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3295, It: 0, Loss Data: 9.780e-02, Loss Eqns: 3.795e+00, Loss Aux: 1.272e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3296, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.793e+00, Loss Aux: 8.227e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3297, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.896e+00, Loss Aux: 6.480e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 3298, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.840e+00, Loss Aux: 8.624e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3299, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.769e+00, Loss Aux: 1.423e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3300, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.299e+00, Loss Aux: 8.328e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3301, It: 0, Loss Data: 1.346e-01, Loss Eqns: 3.606e+00, Loss Aux: 7.975e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3302, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.519e+00, Loss Aux: 1.008e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3303, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.625e+00, Loss Aux: 7.211e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3304, It: 0, Loss Data: 1.258e-01, Loss Eqns: 3.542e+00, Loss Aux: 7.413e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3305, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.726e+00, Loss Aux: 8.582e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3306, It: 0, Loss Data: 9.857e-02, Loss Eqns: 3.586e+00, Loss Aux: 1.584e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3307, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.748e+00, Loss Aux: 2.871e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3308, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.630e+00, Loss Aux: 1.820e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3309, It: 0, Loss Data: 1.062e-01, Loss Eqns: 3.853e+00, Loss Aux: 1.110e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3310, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.535e+00, Loss Aux: 7.592e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3311, It: 0, Loss Data: 1.139e-01, Loss Eqns: 4.048e+00, Loss Aux: 1.628e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3312, It: 0, Loss Data: 9.577e-02, Loss Eqns: 3.787e+00, Loss Aux: 1.341e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3313, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.795e+00, Loss Aux: 4.653e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3314, It: 0, Loss Data: 1.312e-01, Loss Eqns: 3.458e+00, Loss Aux: 4.768e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3315, It: 0, Loss Data: 1.335e-01, Loss Eqns: 3.634e+00, Loss Aux: 2.557e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3316, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.594e+00, Loss Aux: 2.932e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3317, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.590e+00, Loss Aux: 9.412e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3318, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.591e+00, Loss Aux: 1.113e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3319, It: 0, Loss Data: 1.199e-01, Loss Eqns: 3.640e+00, Loss Aux: 1.304e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3320, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.502e+00, Loss Aux: 2.060e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3321, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.603e+00, Loss Aux: 8.955e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3322, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.888e+00, Loss Aux: 8.649e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3323, It: 0, Loss Data: 9.748e-02, Loss Eqns: 3.636e+00, Loss Aux: 1.131e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3324, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.748e+00, Loss Aux: 3.432e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3325, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.499e+00, Loss Aux: 2.386e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3326, It: 0, Loss Data: 1.306e-01, Loss Eqns: 4.105e+00, Loss Aux: 7.509e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3327, It: 0, Loss Data: 1.257e-01, Loss Eqns: 3.549e+00, Loss Aux: 4.801e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3328, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.763e+00, Loss Aux: 9.045e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3329, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.749e+00, Loss Aux: 1.157e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3330, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.769e+00, Loss Aux: 1.501e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3331, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.632e+00, Loss Aux: 2.019e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3332, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.515e+00, Loss Aux: 3.416e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3333, It: 0, Loss Data: 1.026e-01, Loss Eqns: 3.676e+00, Loss Aux: 2.315e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3334, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.789e+00, Loss Aux: 6.808e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3335, It: 0, Loss Data: 1.299e-01, Loss Eqns: 3.554e+00, Loss Aux: 6.505e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3336, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.687e+00, Loss Aux: 7.844e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3337, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.473e+00, Loss Aux: 8.916e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3338, It: 0, Loss Data: 1.147e-01, Loss Eqns: 3.622e+00, Loss Aux: 8.107e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3339, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.738e+00, Loss Aux: 1.277e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3340, It: 0, Loss Data: 9.263e-02, Loss Eqns: 3.876e+00, Loss Aux: 1.115e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3341, It: 0, Loss Data: 1.196e-01, Loss Eqns: 3.568e+00, Loss Aux: 1.175e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3342, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.711e+00, Loss Aux: 7.836e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3343, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.592e+00, Loss Aux: 6.708e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3344, It: 0, Loss Data: 1.346e-01, Loss Eqns: 3.777e+00, Loss Aux: 7.252e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3345, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.710e+00, Loss Aux: 8.067e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3346, It: 0, Loss Data: 1.038e-01, Loss Eqns: 3.858e+00, Loss Aux: 5.927e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3347, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.795e+00, Loss Aux: 4.531e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3348, It: 0, Loss Data: 1.048e-01, Loss Eqns: 3.603e+00, Loss Aux: 8.727e-03, Time: 0.255, Learning Rate: 1.0e-03\n",
      "Epoch: 3349, It: 0, Loss Data: 1.183e-01, Loss Eqns: 4.040e+00, Loss Aux: 1.399e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3350, It: 0, Loss Data: 1.034e-01, Loss Eqns: 3.668e+00, Loss Aux: 7.860e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3351, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.960e+00, Loss Aux: 8.032e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3352, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.673e+00, Loss Aux: 8.051e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3353, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.910e+00, Loss Aux: 1.236e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3354, It: 0, Loss Data: 1.034e-01, Loss Eqns: 3.546e+00, Loss Aux: 1.968e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 3355, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.953e+00, Loss Aux: 2.035e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3356, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.628e+00, Loss Aux: 8.032e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3357, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.919e+00, Loss Aux: 7.182e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 3358, It: 0, Loss Data: 1.233e-01, Loss Eqns: 3.746e+00, Loss Aux: 7.637e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3359, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.796e+00, Loss Aux: 7.207e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3360, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.911e+00, Loss Aux: 6.189e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3361, It: 0, Loss Data: 1.125e-01, Loss Eqns: 3.716e+00, Loss Aux: 8.801e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3362, It: 0, Loss Data: 9.820e-02, Loss Eqns: 3.680e+00, Loss Aux: 1.475e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3363, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.805e+00, Loss Aux: 1.756e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3364, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.381e+00, Loss Aux: 1.197e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3365, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.790e+00, Loss Aux: 7.145e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3366, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.547e+00, Loss Aux: 7.596e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3367, It: 0, Loss Data: 1.328e-01, Loss Eqns: 3.615e+00, Loss Aux: 9.093e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3368, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.671e+00, Loss Aux: 1.343e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3369, It: 0, Loss Data: 1.036e-01, Loss Eqns: 3.358e+00, Loss Aux: 8.192e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 3370, It: 0, Loss Data: 1.424e-01, Loss Eqns: 4.022e+00, Loss Aux: 6.782e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3371, It: 0, Loss Data: 1.516e-01, Loss Eqns: 4.150e+00, Loss Aux: 2.774e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3372, It: 0, Loss Data: 1.380e-01, Loss Eqns: 3.847e+00, Loss Aux: 1.203e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 3373, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.824e+00, Loss Aux: 1.186e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3374, It: 0, Loss Data: 1.432e-01, Loss Eqns: 3.414e+00, Loss Aux: 9.751e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3375, It: 0, Loss Data: 1.319e-01, Loss Eqns: 3.984e+00, Loss Aux: 8.392e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3376, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.895e+00, Loss Aux: 1.957e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3377, It: 0, Loss Data: 1.171e-01, Loss Eqns: 4.093e+00, Loss Aux: 1.515e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3378, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.830e+00, Loss Aux: 1.567e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3379, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.732e+00, Loss Aux: 1.743e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3380, It: 0, Loss Data: 1.327e-01, Loss Eqns: 3.640e+00, Loss Aux: 4.452e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3381, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.465e+00, Loss Aux: 6.067e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3382, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.660e+00, Loss Aux: 2.740e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3383, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.838e+00, Loss Aux: 1.063e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3384, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.816e+00, Loss Aux: 1.356e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3385, It: 0, Loss Data: 1.340e-01, Loss Eqns: 3.474e+00, Loss Aux: 1.342e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3386, It: 0, Loss Data: 1.483e-01, Loss Eqns: 3.544e+00, Loss Aux: 2.060e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3387, It: 0, Loss Data: 1.067e-01, Loss Eqns: 3.678e+00, Loss Aux: 1.156e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3388, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.944e+00, Loss Aux: 3.123e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3389, It: 0, Loss Data: 1.235e-01, Loss Eqns: 3.828e+00, Loss Aux: 5.020e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3390, It: 0, Loss Data: 1.260e-01, Loss Eqns: 3.469e+00, Loss Aux: 4.181e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3391, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.461e+00, Loss Aux: 2.464e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3392, It: 0, Loss Data: 1.293e-01, Loss Eqns: 3.553e+00, Loss Aux: 1.270e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3393, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.646e+00, Loss Aux: 1.382e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3394, It: 0, Loss Data: 1.315e-01, Loss Eqns: 3.727e+00, Loss Aux: 1.524e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3395, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.607e+00, Loss Aux: 1.365e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3396, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.856e+00, Loss Aux: 8.058e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3397, It: 0, Loss Data: 1.302e-01, Loss Eqns: 3.653e+00, Loss Aux: 1.112e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3398, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.835e+00, Loss Aux: 3.624e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3399, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.555e+00, Loss Aux: 3.863e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3400, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.722e+00, Loss Aux: 1.847e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3401, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.392e+00, Loss Aux: 8.038e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3402, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.726e+00, Loss Aux: 1.084e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3403, It: 0, Loss Data: 1.328e-01, Loss Eqns: 3.541e+00, Loss Aux: 1.133e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3404, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.708e+00, Loss Aux: 3.249e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3405, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.612e+00, Loss Aux: 6.814e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 3406, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.679e+00, Loss Aux: 1.629e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3407, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.645e+00, Loss Aux: 3.183e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3408, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.429e+00, Loss Aux: 1.424e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3409, It: 0, Loss Data: 1.287e-01, Loss Eqns: 3.535e+00, Loss Aux: 9.636e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3410, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.680e+00, Loss Aux: 1.287e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3411, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.680e+00, Loss Aux: 1.696e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3412, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.845e+00, Loss Aux: 9.356e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3413, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.681e+00, Loss Aux: 1.070e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3414, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.728e+00, Loss Aux: 1.520e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3415, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.784e+00, Loss Aux: 1.982e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3416, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.530e+00, Loss Aux: 1.048e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3417, It: 0, Loss Data: 1.046e-01, Loss Eqns: 3.638e+00, Loss Aux: 5.408e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3418, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.773e+00, Loss Aux: 7.008e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3419, It: 0, Loss Data: 1.085e-01, Loss Eqns: 4.026e+00, Loss Aux: 1.075e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3420, It: 0, Loss Data: 9.978e-02, Loss Eqns: 3.773e+00, Loss Aux: 1.130e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3421, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.548e+00, Loss Aux: 1.396e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3422, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.575e+00, Loss Aux: 1.233e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3423, It: 0, Loss Data: 1.228e-01, Loss Eqns: 3.690e+00, Loss Aux: 2.157e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3424, It: 0, Loss Data: 1.300e-01, Loss Eqns: 3.692e+00, Loss Aux: 3.855e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3425, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.474e+00, Loss Aux: 8.798e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3426, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.730e+00, Loss Aux: 5.396e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3427, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.714e+00, Loss Aux: 7.101e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3428, It: 0, Loss Data: 1.313e-01, Loss Eqns: 3.752e+00, Loss Aux: 1.722e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3429, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.744e+00, Loss Aux: 1.088e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3430, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.748e+00, Loss Aux: 5.488e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3431, It: 0, Loss Data: 8.254e-02, Loss Eqns: 3.682e+00, Loss Aux: 9.929e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3432, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.625e+00, Loss Aux: 1.360e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3433, It: 0, Loss Data: 1.234e-01, Loss Eqns: 3.586e+00, Loss Aux: 1.461e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3434, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.541e+00, Loss Aux: 1.480e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3435, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.427e+00, Loss Aux: 1.181e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3436, It: 0, Loss Data: 1.062e-01, Loss Eqns: 3.559e+00, Loss Aux: 9.073e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3437, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.749e+00, Loss Aux: 6.742e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3438, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.634e+00, Loss Aux: 7.674e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3439, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.607e+00, Loss Aux: 5.633e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3440, It: 0, Loss Data: 1.306e-01, Loss Eqns: 3.621e+00, Loss Aux: 6.891e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3441, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.548e+00, Loss Aux: 1.766e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3442, It: 0, Loss Data: 1.147e-01, Loss Eqns: 3.609e+00, Loss Aux: 2.248e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3443, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.320e+00, Loss Aux: 7.972e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3444, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.511e+00, Loss Aux: 6.345e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3445, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.633e+00, Loss Aux: 1.546e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3446, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.633e+00, Loss Aux: 2.471e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3447, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.422e+00, Loss Aux: 8.752e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3448, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.378e+00, Loss Aux: 3.923e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3449, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.309e+00, Loss Aux: 8.105e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3450, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.439e+00, Loss Aux: 1.050e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3451, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.652e+00, Loss Aux: 9.477e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3452, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.678e+00, Loss Aux: 8.061e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3453, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.635e+00, Loss Aux: 1.054e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3454, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.697e+00, Loss Aux: 1.135e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3455, It: 0, Loss Data: 1.236e-01, Loss Eqns: 3.962e+00, Loss Aux: 7.965e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3456, It: 0, Loss Data: 9.432e-02, Loss Eqns: 3.503e+00, Loss Aux: 7.059e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3457, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.270e+00, Loss Aux: 7.367e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 3458, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.492e+00, Loss Aux: 9.201e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3459, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.675e+00, Loss Aux: 1.700e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3460, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.356e+00, Loss Aux: 1.724e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3461, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.516e+00, Loss Aux: 6.143e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3462, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.542e+00, Loss Aux: 5.032e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3463, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.481e+00, Loss Aux: 9.271e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3464, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.701e+00, Loss Aux: 1.357e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3465, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.677e+00, Loss Aux: 1.265e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3466, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.688e+00, Loss Aux: 1.163e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3467, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.745e+00, Loss Aux: 9.955e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3468, It: 0, Loss Data: 8.805e-02, Loss Eqns: 3.518e+00, Loss Aux: 9.039e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3469, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.662e+00, Loss Aux: 8.379e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3470, It: 0, Loss Data: 9.606e-02, Loss Eqns: 3.577e+00, Loss Aux: 7.751e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3471, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.361e+00, Loss Aux: 8.467e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3472, It: 0, Loss Data: 1.362e-01, Loss Eqns: 3.750e+00, Loss Aux: 1.835e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3473, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.798e+00, Loss Aux: 1.280e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3474, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.524e+00, Loss Aux: 3.171e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3475, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.752e+00, Loss Aux: 4.035e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3476, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.674e+00, Loss Aux: 2.007e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3477, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.787e+00, Loss Aux: 1.123e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3478, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.817e+00, Loss Aux: 9.736e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3479, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.498e+00, Loss Aux: 1.066e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3480, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.709e+00, Loss Aux: 1.023e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3481, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.486e+00, Loss Aux: 8.225e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3482, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.629e+00, Loss Aux: 5.280e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3483, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.682e+00, Loss Aux: 5.210e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3484, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.857e+00, Loss Aux: 7.390e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3485, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.812e+00, Loss Aux: 2.185e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3486, It: 0, Loss Data: 1.367e-01, Loss Eqns: 3.692e+00, Loss Aux: 2.486e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3487, It: 0, Loss Data: 1.354e-01, Loss Eqns: 3.746e+00, Loss Aux: 1.533e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3488, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.554e+00, Loss Aux: 1.019e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3489, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.577e+00, Loss Aux: 1.075e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3490, It: 0, Loss Data: 9.758e-02, Loss Eqns: 3.465e+00, Loss Aux: 8.199e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3491, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.631e+00, Loss Aux: 1.409e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3492, It: 0, Loss Data: 1.033e-01, Loss Eqns: 3.661e+00, Loss Aux: 7.575e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3493, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.525e+00, Loss Aux: 1.527e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3494, It: 0, Loss Data: 1.179e-01, Loss Eqns: 3.546e+00, Loss Aux: 1.852e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3495, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.872e+00, Loss Aux: 9.646e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3496, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.609e+00, Loss Aux: 7.428e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3497, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.718e+00, Loss Aux: 7.244e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3498, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.462e+00, Loss Aux: 8.986e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3499, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.607e+00, Loss Aux: 8.547e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3500, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.516e+00, Loss Aux: 1.062e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3501, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.659e+00, Loss Aux: 1.270e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3502, It: 0, Loss Data: 1.028e-01, Loss Eqns: 3.707e+00, Loss Aux: 1.040e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3503, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.542e+00, Loss Aux: 9.465e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3504, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.640e+00, Loss Aux: 8.791e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3505, It: 0, Loss Data: 1.013e-01, Loss Eqns: 3.598e+00, Loss Aux: 9.422e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3506, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.483e+00, Loss Aux: 1.233e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3507, It: 0, Loss Data: 1.281e-01, Loss Eqns: 3.771e+00, Loss Aux: 8.655e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3508, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.657e+00, Loss Aux: 7.254e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3509, It: 0, Loss Data: 1.285e-01, Loss Eqns: 3.550e+00, Loss Aux: 1.038e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3510, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.632e+00, Loss Aux: 1.063e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3511, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.618e+00, Loss Aux: 9.275e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3512, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.948e+00, Loss Aux: 9.070e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3513, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.566e+00, Loss Aux: 1.490e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3514, It: 0, Loss Data: 1.003e-01, Loss Eqns: 4.121e+00, Loss Aux: 9.594e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3515, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.531e+00, Loss Aux: 7.263e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3516, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.500e+00, Loss Aux: 9.525e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3517, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.552e+00, Loss Aux: 7.447e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3518, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.670e+00, Loss Aux: 2.998e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3519, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.676e+00, Loss Aux: 5.539e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3520, It: 0, Loss Data: 9.596e-02, Loss Eqns: 3.819e+00, Loss Aux: 7.066e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3521, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.885e+00, Loss Aux: 9.328e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3522, It: 0, Loss Data: 9.816e-02, Loss Eqns: 3.737e+00, Loss Aux: 2.071e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3523, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.476e+00, Loss Aux: 2.384e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3524, It: 0, Loss Data: 1.099e-01, Loss Eqns: 4.068e+00, Loss Aux: 1.651e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3525, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.626e+00, Loss Aux: 7.047e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3526, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.666e+00, Loss Aux: 4.651e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3527, It: 0, Loss Data: 1.339e-01, Loss Eqns: 3.611e+00, Loss Aux: 5.781e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3528, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.536e+00, Loss Aux: 4.800e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3529, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.305e+00, Loss Aux: 7.224e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3530, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.504e+00, Loss Aux: 1.775e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3531, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.611e+00, Loss Aux: 1.063e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3532, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.788e+00, Loss Aux: 8.838e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3533, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.634e+00, Loss Aux: 1.253e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3534, It: 0, Loss Data: 1.067e-01, Loss Eqns: 3.933e+00, Loss Aux: 1.135e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3535, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.618e+00, Loss Aux: 8.901e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3536, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.512e+00, Loss Aux: 1.032e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 3537, It: 0, Loss Data: 9.396e-02, Loss Eqns: 3.370e+00, Loss Aux: 1.044e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3538, It: 0, Loss Data: 1.031e-01, Loss Eqns: 3.560e+00, Loss Aux: 1.195e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3539, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.839e+00, Loss Aux: 1.157e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3540, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.690e+00, Loss Aux: 1.319e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3541, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.501e+00, Loss Aux: 1.607e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3542, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.490e+00, Loss Aux: 9.366e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3543, It: 0, Loss Data: 1.258e-01, Loss Eqns: 3.273e+00, Loss Aux: 6.584e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3544, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.391e+00, Loss Aux: 7.510e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3545, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.310e+00, Loss Aux: 4.217e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3546, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.800e+00, Loss Aux: 5.160e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3547, It: 0, Loss Data: 1.267e-01, Loss Eqns: 3.692e+00, Loss Aux: 1.602e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3548, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.622e+00, Loss Aux: 1.291e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3549, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.579e+00, Loss Aux: 3.765e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3550, It: 0, Loss Data: 1.066e-01, Loss Eqns: 3.658e+00, Loss Aux: 3.452e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3551, It: 0, Loss Data: 1.236e-01, Loss Eqns: 3.537e+00, Loss Aux: 1.459e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3552, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.659e+00, Loss Aux: 1.611e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3553, It: 0, Loss Data: 1.363e-01, Loss Eqns: 3.606e+00, Loss Aux: 6.205e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3554, It: 0, Loss Data: 1.011e-01, Loss Eqns: 3.490e+00, Loss Aux: 7.061e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3555, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.535e+00, Loss Aux: 2.414e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3556, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.996e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3557, It: 0, Loss Data: 1.078e-01, Loss Eqns: 3.905e+00, Loss Aux: 5.951e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3558, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.756e+00, Loss Aux: 1.864e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3559, It: 0, Loss Data: 9.958e-02, Loss Eqns: 3.759e+00, Loss Aux: 6.553e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3560, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.504e+00, Loss Aux: 3.547e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3561, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.541e+00, Loss Aux: 3.035e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3562, It: 0, Loss Data: 1.306e-01, Loss Eqns: 3.629e+00, Loss Aux: 9.250e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3563, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.785e+00, Loss Aux: 8.214e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3564, It: 0, Loss Data: 1.274e-01, Loss Eqns: 3.765e+00, Loss Aux: 1.963e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3565, It: 0, Loss Data: 1.281e-01, Loss Eqns: 4.085e+00, Loss Aux: 1.240e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3566, It: 0, Loss Data: 1.296e-01, Loss Eqns: 3.539e+00, Loss Aux: 6.049e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3567, It: 0, Loss Data: 1.236e-01, Loss Eqns: 3.531e+00, Loss Aux: 6.642e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3568, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.584e+00, Loss Aux: 1.217e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3569, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.517e+00, Loss Aux: 9.368e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3570, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.526e+00, Loss Aux: 1.223e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3571, It: 0, Loss Data: 1.280e-01, Loss Eqns: 3.362e+00, Loss Aux: 1.879e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3572, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.648e+00, Loss Aux: 2.314e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 3573, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.444e+00, Loss Aux: 1.633e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3574, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.657e+00, Loss Aux: 7.787e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3575, It: 0, Loss Data: 1.073e-01, Loss Eqns: 3.302e+00, Loss Aux: 4.348e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3576, It: 0, Loss Data: 1.182e-01, Loss Eqns: 3.409e+00, Loss Aux: 6.258e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3577, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.742e+00, Loss Aux: 1.649e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3578, It: 0, Loss Data: 1.286e-01, Loss Eqns: 4.014e+00, Loss Aux: 1.913e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3579, It: 0, Loss Data: 1.392e-01, Loss Eqns: 3.392e+00, Loss Aux: 6.642e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3580, It: 0, Loss Data: 1.161e-01, Loss Eqns: 3.468e+00, Loss Aux: 7.916e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3581, It: 0, Loss Data: 1.433e-01, Loss Eqns: 3.746e+00, Loss Aux: 2.351e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3582, It: 0, Loss Data: 1.313e-01, Loss Eqns: 3.557e+00, Loss Aux: 7.892e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3583, It: 0, Loss Data: 1.185e-01, Loss Eqns: 3.717e+00, Loss Aux: 1.215e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3584, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.579e+00, Loss Aux: 1.245e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3585, It: 0, Loss Data: 1.370e-01, Loss Eqns: 3.843e+00, Loss Aux: 3.015e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3586, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.835e+00, Loss Aux: 1.478e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3587, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.596e+00, Loss Aux: 6.668e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3588, It: 0, Loss Data: 9.863e-02, Loss Eqns: 3.824e+00, Loss Aux: 7.217e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3589, It: 0, Loss Data: 1.346e-01, Loss Eqns: 3.566e+00, Loss Aux: 1.257e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3590, It: 0, Loss Data: 1.089e-01, Loss Eqns: 3.700e+00, Loss Aux: 3.105e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3591, It: 0, Loss Data: 1.463e-01, Loss Eqns: 3.508e+00, Loss Aux: 2.481e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3592, It: 0, Loss Data: 1.302e-01, Loss Eqns: 3.232e+00, Loss Aux: 8.975e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3593, It: 0, Loss Data: 1.371e-01, Loss Eqns: 3.556e+00, Loss Aux: 5.782e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3594, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.565e+00, Loss Aux: 1.264e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3595, It: 0, Loss Data: 1.287e-01, Loss Eqns: 3.957e+00, Loss Aux: 1.875e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3596, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.528e+00, Loss Aux: 1.318e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3597, It: 0, Loss Data: 1.453e-01, Loss Eqns: 3.712e+00, Loss Aux: 1.275e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3598, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.675e+00, Loss Aux: 1.453e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3599, It: 0, Loss Data: 1.301e-01, Loss Eqns: 3.706e+00, Loss Aux: 2.459e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3600, It: 0, Loss Data: 1.033e-01, Loss Eqns: 3.765e+00, Loss Aux: 1.092e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3601, It: 0, Loss Data: 1.230e-01, Loss Eqns: 4.021e+00, Loss Aux: 4.263e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3602, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.890e+00, Loss Aux: 7.388e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3603, It: 0, Loss Data: 1.157e-01, Loss Eqns: 3.673e+00, Loss Aux: 2.380e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3604, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.488e+00, Loss Aux: 9.523e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3605, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.468e+00, Loss Aux: 4.596e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3606, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.563e+00, Loss Aux: 3.321e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3607, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.636e+00, Loss Aux: 9.037e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3608, It: 0, Loss Data: 9.769e-02, Loss Eqns: 3.653e+00, Loss Aux: 1.153e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3609, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.440e+00, Loss Aux: 1.288e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3610, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.298e+00, Loss Aux: 1.496e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3611, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.579e+00, Loss Aux: 1.841e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3612, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.510e+00, Loss Aux: 1.146e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 3613, It: 0, Loss Data: 1.405e-01, Loss Eqns: 3.648e+00, Loss Aux: 5.389e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3614, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.308e+00, Loss Aux: 7.689e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3615, It: 0, Loss Data: 1.361e-01, Loss Eqns: 3.298e+00, Loss Aux: 1.069e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3616, It: 0, Loss Data: 1.205e-01, Loss Eqns: 3.675e+00, Loss Aux: 1.123e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3617, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.778e+00, Loss Aux: 1.422e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3618, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.712e+00, Loss Aux: 1.813e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 3619, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.412e+00, Loss Aux: 1.912e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3620, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.604e+00, Loss Aux: 1.916e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 3621, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.511e+00, Loss Aux: 1.827e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3622, It: 0, Loss Data: 1.232e-01, Loss Eqns: 3.399e+00, Loss Aux: 1.461e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 3623, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.570e+00, Loss Aux: 7.962e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3624, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.286e+00, Loss Aux: 1.973e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3625, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.438e+00, Loss Aux: 2.004e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 3626, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.683e+00, Loss Aux: 3.988e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3627, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.419e+00, Loss Aux: 4.001e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 3628, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.532e+00, Loss Aux: 1.464e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3629, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.670e+00, Loss Aux: 1.055e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3630, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.599e+00, Loss Aux: 8.705e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 3631, It: 0, Loss Data: 9.901e-02, Loss Eqns: 3.725e+00, Loss Aux: 5.691e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3632, It: 0, Loss Data: 9.465e-02, Loss Eqns: 3.873e+00, Loss Aux: 1.195e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3633, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.699e+00, Loss Aux: 1.254e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3634, It: 0, Loss Data: 1.305e-01, Loss Eqns: 3.436e+00, Loss Aux: 1.090e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3635, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.387e+00, Loss Aux: 9.412e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3636, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.524e+00, Loss Aux: 1.100e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3637, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.686e+00, Loss Aux: 1.152e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3638, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.484e+00, Loss Aux: 1.303e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3639, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.466e+00, Loss Aux: 8.444e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 3640, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.541e+00, Loss Aux: 7.815e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3641, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.549e+00, Loss Aux: 1.623e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3642, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.274e+00, Loss Aux: 1.118e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3643, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.658e+00, Loss Aux: 1.010e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 3644, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.778e+00, Loss Aux: 8.131e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3645, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.231e+00, Loss Aux: 1.759e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3646, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.542e+00, Loss Aux: 1.226e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3647, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.207e+00, Loss Aux: 7.554e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3648, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.399e+00, Loss Aux: 1.387e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3649, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.654e+00, Loss Aux: 2.023e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 3650, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.606e+00, Loss Aux: 1.173e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3651, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.424e+00, Loss Aux: 7.715e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3652, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.652e+00, Loss Aux: 4.935e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3653, It: 0, Loss Data: 1.046e-01, Loss Eqns: 3.813e+00, Loss Aux: 3.098e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3654, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.845e+00, Loss Aux: 7.910e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3655, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.918e+00, Loss Aux: 1.293e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3656, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.492e+00, Loss Aux: 8.772e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3657, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.928e+00, Loss Aux: 1.019e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3658, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.928e+00, Loss Aux: 1.915e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3659, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.481e+00, Loss Aux: 1.257e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3660, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.807e+00, Loss Aux: 7.731e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3661, It: 0, Loss Data: 1.221e-01, Loss Eqns: 3.394e+00, Loss Aux: 5.904e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3662, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.764e+00, Loss Aux: 1.226e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3663, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.675e+00, Loss Aux: 4.751e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3664, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.780e+00, Loss Aux: 4.469e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3665, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.316e+00, Loss Aux: 8.152e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3666, It: 0, Loss Data: 1.235e-01, Loss Eqns: 3.394e+00, Loss Aux: 9.370e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3667, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.453e+00, Loss Aux: 1.003e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3668, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.471e+00, Loss Aux: 1.489e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3669, It: 0, Loss Data: 1.241e-01, Loss Eqns: 3.396e+00, Loss Aux: 9.759e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3670, It: 0, Loss Data: 1.296e-01, Loss Eqns: 3.585e+00, Loss Aux: 1.423e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3671, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.344e+00, Loss Aux: 1.191e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3672, It: 0, Loss Data: 1.382e-01, Loss Eqns: 3.565e+00, Loss Aux: 2.157e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3673, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.481e+00, Loss Aux: 6.133e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3674, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.678e+00, Loss Aux: 4.098e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3675, It: 0, Loss Data: 1.252e-01, Loss Eqns: 4.013e+00, Loss Aux: 1.317e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 3676, It: 0, Loss Data: 1.017e-01, Loss Eqns: 3.444e+00, Loss Aux: 9.913e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3677, It: 0, Loss Data: 1.323e-01, Loss Eqns: 3.699e+00, Loss Aux: 1.120e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3678, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.976e+00, Loss Aux: 1.487e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3679, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.770e+00, Loss Aux: 2.162e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3680, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.878e+00, Loss Aux: 1.079e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3681, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.539e+00, Loss Aux: 7.420e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3682, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.784e+00, Loss Aux: 5.072e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3683, It: 0, Loss Data: 9.768e-02, Loss Eqns: 3.562e+00, Loss Aux: 6.069e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3684, It: 0, Loss Data: 1.227e-01, Loss Eqns: 3.589e+00, Loss Aux: 1.645e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3685, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.550e+00, Loss Aux: 1.812e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3686, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.669e+00, Loss Aux: 8.767e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3687, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.792e+00, Loss Aux: 1.912e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3688, It: 0, Loss Data: 1.240e-01, Loss Eqns: 3.272e+00, Loss Aux: 1.084e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3689, It: 0, Loss Data: 1.277e-01, Loss Eqns: 3.289e+00, Loss Aux: 1.840e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3690, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.472e+00, Loss Aux: 1.316e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3691, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.278e+00, Loss Aux: 1.042e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3692, It: 0, Loss Data: 1.298e-01, Loss Eqns: 3.392e+00, Loss Aux: 7.362e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3693, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.650e+00, Loss Aux: 7.356e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3694, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.425e+00, Loss Aux: 7.485e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3695, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.536e+00, Loss Aux: 8.907e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3696, It: 0, Loss Data: 1.134e-01, Loss Eqns: 3.708e+00, Loss Aux: 1.960e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3697, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.708e+00, Loss Aux: 2.679e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3698, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.490e+00, Loss Aux: 1.590e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3699, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.558e+00, Loss Aux: 8.913e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3700, It: 0, Loss Data: 9.760e-02, Loss Eqns: 3.798e+00, Loss Aux: 7.920e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3701, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.598e+00, Loss Aux: 1.420e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3702, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.455e+00, Loss Aux: 1.140e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3703, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.588e+00, Loss Aux: 9.580e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3704, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.596e+00, Loss Aux: 8.918e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3705, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.743e+00, Loss Aux: 9.477e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3706, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.828e+00, Loss Aux: 9.664e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3707, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.357e+00, Loss Aux: 1.307e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3708, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.467e+00, Loss Aux: 1.790e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3709, It: 0, Loss Data: 1.027e-01, Loss Eqns: 3.648e+00, Loss Aux: 2.259e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3710, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.398e+00, Loss Aux: 1.868e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3711, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.374e+00, Loss Aux: 8.813e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3712, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.419e+00, Loss Aux: 6.093e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3713, It: 0, Loss Data: 1.304e-01, Loss Eqns: 3.403e+00, Loss Aux: 5.934e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3714, It: 0, Loss Data: 9.959e-02, Loss Eqns: 3.577e+00, Loss Aux: 5.700e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3715, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.386e+00, Loss Aux: 5.758e-03, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 3716, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.574e+00, Loss Aux: 9.160e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3717, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.635e+00, Loss Aux: 1.366e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3718, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.532e+00, Loss Aux: 1.050e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3719, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.950e+00, Loss Aux: 6.195e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3720, It: 0, Loss Data: 9.739e-02, Loss Eqns: 3.479e+00, Loss Aux: 6.354e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3721, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.491e+00, Loss Aux: 9.185e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3722, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.583e+00, Loss Aux: 1.261e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3723, It: 0, Loss Data: 1.103e-01, Loss Eqns: 3.427e+00, Loss Aux: 4.738e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3724, It: 0, Loss Data: 1.133e-01, Loss Eqns: 3.672e+00, Loss Aux: 3.614e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3725, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.754e+00, Loss Aux: 8.685e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3726, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.454e+00, Loss Aux: 2.251e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3727, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.540e+00, Loss Aux: 1.236e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3728, It: 0, Loss Data: 1.307e-01, Loss Eqns: 3.409e+00, Loss Aux: 6.620e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3729, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.574e+00, Loss Aux: 8.260e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3730, It: 0, Loss Data: 9.125e-02, Loss Eqns: 3.549e+00, Loss Aux: 1.385e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3731, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.398e+00, Loss Aux: 6.608e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3732, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.607e+00, Loss Aux: 9.327e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3733, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.492e+00, Loss Aux: 1.852e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3734, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.455e+00, Loss Aux: 3.193e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3735, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.426e+00, Loss Aux: 1.312e-02, Time: 0.273, Learning Rate: 1.0e-03\n",
      "Epoch: 3736, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.397e+00, Loss Aux: 8.245e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3737, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.572e+00, Loss Aux: 1.052e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3738, It: 0, Loss Data: 1.073e-01, Loss Eqns: 3.519e+00, Loss Aux: 7.195e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3739, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.436e+00, Loss Aux: 8.151e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3740, It: 0, Loss Data: 1.196e-01, Loss Eqns: 3.461e+00, Loss Aux: 1.168e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3741, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.360e+00, Loss Aux: 1.700e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3742, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.490e+00, Loss Aux: 1.629e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3743, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.495e+00, Loss Aux: 9.401e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3744, It: 0, Loss Data: 8.653e-02, Loss Eqns: 3.680e+00, Loss Aux: 6.215e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3745, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.642e+00, Loss Aux: 5.341e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3746, It: 0, Loss Data: 1.027e-01, Loss Eqns: 3.594e+00, Loss Aux: 6.289e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3747, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.514e+00, Loss Aux: 9.907e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 3748, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.569e+00, Loss Aux: 9.592e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3749, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.669e+00, Loss Aux: 1.326e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 3750, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.499e+00, Loss Aux: 1.130e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3751, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.601e+00, Loss Aux: 5.291e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3752, It: 0, Loss Data: 9.999e-02, Loss Eqns: 3.525e+00, Loss Aux: 5.885e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3753, It: 0, Loss Data: 1.190e-01, Loss Eqns: 3.381e+00, Loss Aux: 1.764e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3754, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.300e+00, Loss Aux: 1.523e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3755, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.253e+00, Loss Aux: 7.358e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3756, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.585e+00, Loss Aux: 6.648e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3757, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.523e+00, Loss Aux: 9.566e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3758, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.599e+00, Loss Aux: 1.033e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 3759, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.528e+00, Loss Aux: 7.167e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3760, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.412e+00, Loss Aux: 9.279e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3761, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.624e+00, Loss Aux: 1.409e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3762, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.641e+00, Loss Aux: 1.583e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3763, It: 0, Loss Data: 1.008e-01, Loss Eqns: 3.542e+00, Loss Aux: 9.576e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3764, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.452e+00, Loss Aux: 1.251e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3765, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.405e+00, Loss Aux: 6.667e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3766, It: 0, Loss Data: 1.423e-01, Loss Eqns: 3.649e+00, Loss Aux: 1.846e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3767, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.321e+00, Loss Aux: 9.683e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3768, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.419e+00, Loss Aux: 5.842e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3769, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.864e+00, Loss Aux: 5.530e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3770, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.346e+00, Loss Aux: 1.254e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3771, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.357e+00, Loss Aux: 7.059e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3772, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.683e+00, Loss Aux: 4.820e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3773, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.469e+00, Loss Aux: 6.101e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3774, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.789e+00, Loss Aux: 8.676e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3775, It: 0, Loss Data: 1.078e-01, Loss Eqns: 3.751e+00, Loss Aux: 1.503e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3776, It: 0, Loss Data: 9.981e-02, Loss Eqns: 3.562e+00, Loss Aux: 2.108e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3777, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.267e+00, Loss Aux: 1.679e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3778, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.643e+00, Loss Aux: 1.565e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3779, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.417e+00, Loss Aux: 1.311e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3780, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.441e+00, Loss Aux: 4.063e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3781, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.340e+00, Loss Aux: 4.086e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3782, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.302e+00, Loss Aux: 6.589e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3783, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.805e+00, Loss Aux: 7.042e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3784, It: 0, Loss Data: 9.807e-02, Loss Eqns: 3.841e+00, Loss Aux: 6.718e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3785, It: 0, Loss Data: 1.005e-01, Loss Eqns: 3.523e+00, Loss Aux: 1.118e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3786, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.707e+00, Loss Aux: 1.904e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 3787, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.544e+00, Loss Aux: 2.120e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3788, It: 0, Loss Data: 9.948e-02, Loss Eqns: 3.467e+00, Loss Aux: 1.048e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3789, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.526e+00, Loss Aux: 9.137e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3790, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.556e+00, Loss Aux: 1.057e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3791, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.694e+00, Loss Aux: 5.648e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 3792, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.489e+00, Loss Aux: 6.738e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3793, It: 0, Loss Data: 1.086e-01, Loss Eqns: 3.447e+00, Loss Aux: 1.492e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3794, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.604e+00, Loss Aux: 1.357e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 3795, It: 0, Loss Data: 1.272e-01, Loss Eqns: 3.519e+00, Loss Aux: 1.004e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3796, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.566e+00, Loss Aux: 9.823e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3797, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.374e+00, Loss Aux: 9.162e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3798, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.362e+00, Loss Aux: 8.382e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3799, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.481e+00, Loss Aux: 7.757e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 3800, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.579e+00, Loss Aux: 6.506e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3801, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.563e+00, Loss Aux: 6.657e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3802, It: 0, Loss Data: 1.244e-01, Loss Eqns: 3.576e+00, Loss Aux: 1.052e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3803, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.736e+00, Loss Aux: 2.111e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3804, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.253e+00, Loss Aux: 1.449e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3805, It: 0, Loss Data: 1.010e-01, Loss Eqns: 3.428e+00, Loss Aux: 7.042e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3806, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.656e+00, Loss Aux: 6.132e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3807, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.830e+00, Loss Aux: 7.801e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3808, It: 0, Loss Data: 1.064e-01, Loss Eqns: 3.748e+00, Loss Aux: 9.801e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3809, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.703e+00, Loss Aux: 8.902e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3810, It: 0, Loss Data: 9.333e-02, Loss Eqns: 3.725e+00, Loss Aux: 8.958e-03, Time: 0.271, Learning Rate: 1.0e-03\n",
      "Epoch: 3811, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.654e+00, Loss Aux: 1.589e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3812, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.460e+00, Loss Aux: 1.631e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3813, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.281e+00, Loss Aux: 6.177e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 3814, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.369e+00, Loss Aux: 7.862e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3815, It: 0, Loss Data: 1.134e-01, Loss Eqns: 3.319e+00, Loss Aux: 1.060e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3816, It: 0, Loss Data: 1.273e-01, Loss Eqns: 3.422e+00, Loss Aux: 1.890e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3817, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.612e+00, Loss Aux: 8.511e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3818, It: 0, Loss Data: 1.320e-01, Loss Eqns: 3.425e+00, Loss Aux: 4.569e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 3819, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.597e+00, Loss Aux: 9.834e-03, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 3820, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.506e+00, Loss Aux: 2.337e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3821, It: 0, Loss Data: 9.781e-02, Loss Eqns: 3.440e+00, Loss Aux: 1.186e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3822, It: 0, Loss Data: 1.246e-01, Loss Eqns: 3.717e+00, Loss Aux: 1.210e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3823, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.561e+00, Loss Aux: 1.193e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3824, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.440e+00, Loss Aux: 1.453e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3825, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.565e+00, Loss Aux: 5.530e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3826, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.433e+00, Loss Aux: 5.943e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3827, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.786e+00, Loss Aux: 1.233e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3828, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.545e+00, Loss Aux: 2.959e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3829, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.414e+00, Loss Aux: 3.604e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3830, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.298e+00, Loss Aux: 1.733e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3831, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.771e+00, Loss Aux: 1.390e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3832, It: 0, Loss Data: 9.981e-02, Loss Eqns: 3.565e+00, Loss Aux: 9.930e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3833, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.510e+00, Loss Aux: 1.498e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3834, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.624e+00, Loss Aux: 1.398e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3835, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.434e+00, Loss Aux: 8.046e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3836, It: 0, Loss Data: 9.753e-02, Loss Eqns: 3.664e+00, Loss Aux: 2.530e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 3837, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.480e+00, Loss Aux: 3.047e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3838, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.689e+00, Loss Aux: 3.039e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3839, It: 0, Loss Data: 1.222e-01, Loss Eqns: 3.633e+00, Loss Aux: 1.920e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3840, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.713e+00, Loss Aux: 6.564e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3841, It: 0, Loss Data: 9.701e-02, Loss Eqns: 3.705e+00, Loss Aux: 5.327e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3842, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.652e+00, Loss Aux: 3.740e-03, Time: 0.276, Learning Rate: 1.0e-03\n",
      "Epoch: 3843, It: 0, Loss Data: 1.260e-01, Loss Eqns: 3.688e+00, Loss Aux: 4.782e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3844, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.482e+00, Loss Aux: 1.195e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3845, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.531e+00, Loss Aux: 3.131e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3846, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.593e+00, Loss Aux: 1.825e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3847, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.739e+00, Loss Aux: 1.447e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3848, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.399e+00, Loss Aux: 1.191e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 3849, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.420e+00, Loss Aux: 1.103e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 3850, It: 0, Loss Data: 1.239e-01, Loss Eqns: 3.452e+00, Loss Aux: 1.044e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3851, It: 0, Loss Data: 1.371e-01, Loss Eqns: 3.523e+00, Loss Aux: 1.092e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3852, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.358e+00, Loss Aux: 1.048e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3853, It: 0, Loss Data: 1.453e-01, Loss Eqns: 3.341e+00, Loss Aux: 6.427e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3854, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.477e+00, Loss Aux: 1.347e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3855, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.207e+00, Loss Aux: 1.861e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3856, It: 0, Loss Data: 1.305e-01, Loss Eqns: 3.529e+00, Loss Aux: 4.584e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3857, It: 0, Loss Data: 1.275e-01, Loss Eqns: 3.472e+00, Loss Aux: 6.608e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3858, It: 0, Loss Data: 1.235e-01, Loss Eqns: 3.642e+00, Loss Aux: 7.359e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3859, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.771e+00, Loss Aux: 1.678e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3860, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.771e+00, Loss Aux: 1.485e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3861, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.369e+00, Loss Aux: 9.151e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3862, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.605e+00, Loss Aux: 4.870e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 3863, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.488e+00, Loss Aux: 8.993e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3864, It: 0, Loss Data: 1.106e-01, Loss Eqns: 3.686e+00, Loss Aux: 1.243e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3865, It: 0, Loss Data: 1.327e-01, Loss Eqns: 3.473e+00, Loss Aux: 9.461e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3866, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.607e+00, Loss Aux: 8.342e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3867, It: 0, Loss Data: 1.312e-01, Loss Eqns: 3.606e+00, Loss Aux: 9.645e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3868, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.379e+00, Loss Aux: 1.986e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3869, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.351e+00, Loss Aux: 2.017e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3870, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.658e+00, Loss Aux: 1.480e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3871, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.642e+00, Loss Aux: 1.555e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 3872, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.883e+00, Loss Aux: 1.204e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3873, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.767e+00, Loss Aux: 8.623e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 3874, It: 0, Loss Data: 1.144e-01, Loss Eqns: 3.663e+00, Loss Aux: 1.034e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3875, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.709e+00, Loss Aux: 1.316e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 3876, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.635e+00, Loss Aux: 8.819e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3877, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.413e+00, Loss Aux: 2.741e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 3878, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.538e+00, Loss Aux: 1.811e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3879, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.447e+00, Loss Aux: 6.485e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3880, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.469e+00, Loss Aux: 1.289e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3881, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.444e+00, Loss Aux: 2.015e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3882, It: 0, Loss Data: 1.271e-01, Loss Eqns: 3.440e+00, Loss Aux: 1.051e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 3883, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.352e+00, Loss Aux: 9.075e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3884, It: 0, Loss Data: 9.927e-02, Loss Eqns: 3.559e+00, Loss Aux: 1.419e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3885, It: 0, Loss Data: 1.078e-01, Loss Eqns: 3.347e+00, Loss Aux: 1.472e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3886, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.541e+00, Loss Aux: 9.170e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3887, It: 0, Loss Data: 1.313e-01, Loss Eqns: 3.124e+00, Loss Aux: 1.083e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3888, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.255e+00, Loss Aux: 1.324e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 3889, It: 0, Loss Data: 1.178e-01, Loss Eqns: 3.427e+00, Loss Aux: 1.176e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3890, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.260e+00, Loss Aux: 9.375e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3891, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.310e+00, Loss Aux: 1.463e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 3892, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.455e+00, Loss Aux: 1.511e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3893, It: 0, Loss Data: 1.230e-01, Loss Eqns: 3.374e+00, Loss Aux: 1.557e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3894, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.461e+00, Loss Aux: 1.559e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 3895, It: 0, Loss Data: 1.044e-01, Loss Eqns: 3.467e+00, Loss Aux: 1.303e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 3896, It: 0, Loss Data: 1.032e-01, Loss Eqns: 3.384e+00, Loss Aux: 8.389e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 3897, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.283e+00, Loss Aux: 1.419e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3898, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.531e+00, Loss Aux: 1.285e-02, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 3899, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.491e+00, Loss Aux: 6.040e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 3900, It: 0, Loss Data: 9.725e-02, Loss Eqns: 3.416e+00, Loss Aux: 6.115e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3901, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.590e+00, Loss Aux: 1.043e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3902, It: 0, Loss Data: 1.161e-01, Loss Eqns: 3.431e+00, Loss Aux: 9.606e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3903, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.456e+00, Loss Aux: 5.664e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 3904, It: 0, Loss Data: 1.343e-01, Loss Eqns: 3.350e+00, Loss Aux: 4.422e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3905, It: 0, Loss Data: 9.887e-02, Loss Eqns: 3.380e+00, Loss Aux: 4.544e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 3906, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.417e+00, Loss Aux: 7.132e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3907, It: 0, Loss Data: 1.014e-01, Loss Eqns: 3.464e+00, Loss Aux: 9.079e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 3908, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.303e+00, Loss Aux: 7.294e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 3909, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.486e+00, Loss Aux: 9.584e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 3910, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.404e+00, Loss Aux: 1.564e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3911, It: 0, Loss Data: 9.413e-02, Loss Eqns: 3.273e+00, Loss Aux: 1.132e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3912, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.691e+00, Loss Aux: 7.468e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 3913, It: 0, Loss Data: 9.771e-02, Loss Eqns: 3.546e+00, Loss Aux: 9.142e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3914, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.439e+00, Loss Aux: 1.160e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3915, It: 0, Loss Data: 1.297e-01, Loss Eqns: 3.398e+00, Loss Aux: 1.328e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3916, It: 0, Loss Data: 1.267e-01, Loss Eqns: 3.245e+00, Loss Aux: 9.200e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3917, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.388e+00, Loss Aux: 8.888e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 3918, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.606e+00, Loss Aux: 1.253e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 3919, It: 0, Loss Data: 9.951e-02, Loss Eqns: 3.553e+00, Loss Aux: 7.401e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 3920, It: 0, Loss Data: 1.277e-01, Loss Eqns: 3.567e+00, Loss Aux: 8.645e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3921, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.492e+00, Loss Aux: 6.815e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 3922, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.614e+00, Loss Aux: 1.169e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3923, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.816e+00, Loss Aux: 5.583e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 3924, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.517e+00, Loss Aux: 5.946e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 3925, It: 0, Loss Data: 1.418e-01, Loss Eqns: 3.510e+00, Loss Aux: 2.900e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 3926, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.508e+00, Loss Aux: 1.470e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3927, It: 0, Loss Data: 1.433e-01, Loss Eqns: 3.228e+00, Loss Aux: 8.310e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 3928, It: 0, Loss Data: 1.258e-01, Loss Eqns: 3.508e+00, Loss Aux: 7.137e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3929, It: 0, Loss Data: 1.286e-01, Loss Eqns: 3.549e+00, Loss Aux: 4.565e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3930, It: 0, Loss Data: 1.359e-01, Loss Eqns: 3.468e+00, Loss Aux: 5.048e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 3931, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.596e+00, Loss Aux: 5.973e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3932, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.688e+00, Loss Aux: 9.458e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3933, It: 0, Loss Data: 1.001e-01, Loss Eqns: 3.442e+00, Loss Aux: 1.168e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3934, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.440e+00, Loss Aux: 4.351e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 3935, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.432e+00, Loss Aux: 2.158e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3936, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.433e+00, Loss Aux: 8.015e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 3937, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.367e+00, Loss Aux: 7.593e-03, Time: 0.283, Learning Rate: 1.0e-03\n",
      "Epoch: 3938, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.521e+00, Loss Aux: 1.602e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3939, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.479e+00, Loss Aux: 5.995e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 3940, It: 0, Loss Data: 1.391e-01, Loss Eqns: 3.481e+00, Loss Aux: 7.088e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3941, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.549e+00, Loss Aux: 1.159e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3942, It: 0, Loss Data: 1.004e-01, Loss Eqns: 3.533e+00, Loss Aux: 1.922e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 3943, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.536e+00, Loss Aux: 1.327e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3944, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.589e+00, Loss Aux: 1.344e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3945, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.690e+00, Loss Aux: 1.400e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3946, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.665e+00, Loss Aux: 8.202e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3947, It: 0, Loss Data: 1.267e-01, Loss Eqns: 3.571e+00, Loss Aux: 6.712e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 3948, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.310e+00, Loss Aux: 5.672e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3949, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.547e+00, Loss Aux: 5.483e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3950, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.446e+00, Loss Aux: 1.481e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3951, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.534e+00, Loss Aux: 1.802e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3952, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.506e+00, Loss Aux: 9.569e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 3953, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.429e+00, Loss Aux: 8.661e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 3954, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.482e+00, Loss Aux: 7.138e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3955, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.437e+00, Loss Aux: 7.243e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3956, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.553e+00, Loss Aux: 1.231e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 3957, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.478e+00, Loss Aux: 1.136e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 3958, It: 0, Loss Data: 1.091e-01, Loss Eqns: 3.233e+00, Loss Aux: 9.943e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3959, It: 0, Loss Data: 1.078e-01, Loss Eqns: 3.443e+00, Loss Aux: 8.776e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3960, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.361e+00, Loss Aux: 1.109e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3961, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.561e+00, Loss Aux: 1.130e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 3962, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.528e+00, Loss Aux: 7.523e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 3963, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.411e+00, Loss Aux: 1.037e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3964, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.293e+00, Loss Aux: 2.050e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 3965, It: 0, Loss Data: 1.073e-01, Loss Eqns: 3.746e+00, Loss Aux: 9.232e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3966, It: 0, Loss Data: 1.005e-01, Loss Eqns: 3.625e+00, Loss Aux: 1.017e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 3967, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.428e+00, Loss Aux: 8.354e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3968, It: 0, Loss Data: 1.278e-01, Loss Eqns: 3.437e+00, Loss Aux: 1.823e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 3969, It: 0, Loss Data: 1.049e-01, Loss Eqns: 3.265e+00, Loss Aux: 1.522e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3970, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.232e+00, Loss Aux: 9.359e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3971, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.438e+00, Loss Aux: 1.007e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 3972, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.404e+00, Loss Aux: 1.173e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 3973, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.595e+00, Loss Aux: 4.474e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 3974, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.580e+00, Loss Aux: 1.150e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 3975, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.473e+00, Loss Aux: 1.367e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 3976, It: 0, Loss Data: 1.026e-01, Loss Eqns: 3.287e+00, Loss Aux: 1.875e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 3977, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.429e+00, Loss Aux: 8.596e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 3978, It: 0, Loss Data: 9.782e-02, Loss Eqns: 3.154e+00, Loss Aux: 5.384e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 3979, It: 0, Loss Data: 1.292e-01, Loss Eqns: 3.492e+00, Loss Aux: 1.789e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 3980, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.417e+00, Loss Aux: 1.136e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 3981, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.309e+00, Loss Aux: 6.417e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 3982, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.332e+00, Loss Aux: 9.773e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3983, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.476e+00, Loss Aux: 8.303e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 3984, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.483e+00, Loss Aux: 9.775e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 3985, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.286e+00, Loss Aux: 1.031e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 3986, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.464e+00, Loss Aux: 2.222e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 3987, It: 0, Loss Data: 2.171e-01, Loss Eqns: 4.611e+00, Loss Aux: 1.144e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3988, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.613e+00, Loss Aux: 3.731e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3989, It: 0, Loss Data: 2.204e-01, Loss Eqns: 4.492e+00, Loss Aux: 2.756e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3990, It: 0, Loss Data: 1.909e-01, Loss Eqns: 4.391e+00, Loss Aux: 2.680e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 3991, It: 0, Loss Data: 1.528e-01, Loss Eqns: 4.303e+00, Loss Aux: 4.062e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3992, It: 0, Loss Data: 2.058e-01, Loss Eqns: 3.389e+00, Loss Aux: 4.989e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 3993, It: 0, Loss Data: 1.569e-01, Loss Eqns: 3.201e+00, Loss Aux: 2.205e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3994, It: 0, Loss Data: 2.390e-01, Loss Eqns: 3.768e+00, Loss Aux: 6.257e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 3995, It: 0, Loss Data: 1.498e-01, Loss Eqns: 3.776e+00, Loss Aux: 8.257e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 3996, It: 0, Loss Data: 2.302e-01, Loss Eqns: 4.052e+00, Loss Aux: 4.765e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 3997, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.550e+00, Loss Aux: 2.426e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 3998, It: 0, Loss Data: 1.933e-01, Loss Eqns: 3.664e+00, Loss Aux: 1.467e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 3999, It: 0, Loss Data: 1.517e-01, Loss Eqns: 3.101e+00, Loss Aux: 1.571e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4000, It: 0, Loss Data: 1.818e-01, Loss Eqns: 3.422e+00, Loss Aux: 2.978e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4001, It: 0, Loss Data: 1.760e-01, Loss Eqns: 3.635e+00, Loss Aux: 2.269e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4002, It: 0, Loss Data: 1.575e-01, Loss Eqns: 4.059e+00, Loss Aux: 1.411e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4003, It: 0, Loss Data: 1.269e-01, Loss Eqns: 3.229e+00, Loss Aux: 1.371e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4004, It: 0, Loss Data: 2.012e-01, Loss Eqns: 4.175e+00, Loss Aux: 9.562e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4005, It: 0, Loss Data: 1.425e-01, Loss Eqns: 3.347e+00, Loss Aux: 9.235e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4006, It: 0, Loss Data: 1.501e-01, Loss Eqns: 4.158e+00, Loss Aux: 1.395e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4007, It: 0, Loss Data: 1.460e-01, Loss Eqns: 3.316e+00, Loss Aux: 3.550e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4008, It: 0, Loss Data: 1.701e-01, Loss Eqns: 3.709e+00, Loss Aux: 2.879e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4009, It: 0, Loss Data: 1.949e-01, Loss Eqns: 3.357e+00, Loss Aux: 1.072e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4010, It: 0, Loss Data: 1.391e-01, Loss Eqns: 3.400e+00, Loss Aux: 1.573e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4011, It: 0, Loss Data: 1.697e-01, Loss Eqns: 3.462e+00, Loss Aux: 3.140e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4012, It: 0, Loss Data: 1.427e-01, Loss Eqns: 3.069e+00, Loss Aux: 1.337e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4013, It: 0, Loss Data: 1.725e-01, Loss Eqns: 3.219e+00, Loss Aux: 9.548e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4014, It: 0, Loss Data: 1.362e-01, Loss Eqns: 3.288e+00, Loss Aux: 9.007e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4015, It: 0, Loss Data: 1.593e-01, Loss Eqns: 3.470e+00, Loss Aux: 3.227e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4016, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.517e+00, Loss Aux: 2.719e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4017, It: 0, Loss Data: 1.268e-01, Loss Eqns: 3.439e+00, Loss Aux: 1.907e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4018, It: 0, Loss Data: 1.565e-01, Loss Eqns: 3.626e+00, Loss Aux: 1.556e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4019, It: 0, Loss Data: 1.466e-01, Loss Eqns: 3.379e+00, Loss Aux: 3.508e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4020, It: 0, Loss Data: 1.470e-01, Loss Eqns: 3.699e+00, Loss Aux: 2.959e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4021, It: 0, Loss Data: 1.378e-01, Loss Eqns: 3.603e+00, Loss Aux: 4.630e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4022, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.386e+00, Loss Aux: 8.050e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4023, It: 0, Loss Data: 1.382e-01, Loss Eqns: 3.431e+00, Loss Aux: 5.481e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4024, It: 0, Loss Data: 1.648e-01, Loss Eqns: 3.858e+00, Loss Aux: 1.023e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4025, It: 0, Loss Data: 1.368e-01, Loss Eqns: 3.434e+00, Loss Aux: 2.682e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4026, It: 0, Loss Data: 1.541e-01, Loss Eqns: 3.485e+00, Loss Aux: 3.059e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4027, It: 0, Loss Data: 1.390e-01, Loss Eqns: 3.260e+00, Loss Aux: 1.168e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4028, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.655e+00, Loss Aux: 1.222e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4029, It: 0, Loss Data: 1.390e-01, Loss Eqns: 3.324e+00, Loss Aux: 1.888e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4030, It: 0, Loss Data: 1.417e-01, Loss Eqns: 3.409e+00, Loss Aux: 2.144e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4031, It: 0, Loss Data: 1.296e-01, Loss Eqns: 3.411e+00, Loss Aux: 5.322e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4032, It: 0, Loss Data: 1.323e-01, Loss Eqns: 3.458e+00, Loss Aux: 4.841e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4033, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.264e+00, Loss Aux: 1.450e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4034, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.501e+00, Loss Aux: 2.091e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4035, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.228e+00, Loss Aux: 6.158e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4036, It: 0, Loss Data: 1.505e-01, Loss Eqns: 3.249e+00, Loss Aux: 6.586e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4037, It: 0, Loss Data: 1.359e-01, Loss Eqns: 3.715e+00, Loss Aux: 8.194e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4038, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.936e+00, Loss Aux: 2.153e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4039, It: 0, Loss Data: 1.383e-01, Loss Eqns: 3.878e+00, Loss Aux: 3.955e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4040, It: 0, Loss Data: 1.409e-01, Loss Eqns: 3.569e+00, Loss Aux: 1.179e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4041, It: 0, Loss Data: 1.519e-01, Loss Eqns: 3.466e+00, Loss Aux: 2.532e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4042, It: 0, Loss Data: 1.302e-01, Loss Eqns: 3.513e+00, Loss Aux: 5.159e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4043, It: 0, Loss Data: 1.448e-01, Loss Eqns: 3.469e+00, Loss Aux: 3.082e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 4044, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.336e+00, Loss Aux: 3.641e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4045, It: 0, Loss Data: 1.338e-01, Loss Eqns: 3.363e+00, Loss Aux: 1.939e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4046, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.402e+00, Loss Aux: 1.353e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 4047, It: 0, Loss Data: 1.519e-01, Loss Eqns: 3.512e+00, Loss Aux: 1.507e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4048, It: 0, Loss Data: 1.236e-01, Loss Eqns: 3.135e+00, Loss Aux: 1.623e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4049, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.487e+00, Loss Aux: 1.186e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4050, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.365e+00, Loss Aux: 1.647e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4051, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.346e+00, Loss Aux: 1.545e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4052, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.185e+00, Loss Aux: 1.622e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4053, It: 0, Loss Data: 1.319e-01, Loss Eqns: 3.378e+00, Loss Aux: 2.898e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4054, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.372e+00, Loss Aux: 4.052e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4055, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.417e+00, Loss Aux: 3.156e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4056, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.248e+00, Loss Aux: 1.042e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4057, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.303e+00, Loss Aux: 4.920e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4058, It: 0, Loss Data: 1.208e-01, Loss Eqns: 3.167e+00, Loss Aux: 8.414e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4059, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.245e+00, Loss Aux: 6.350e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4060, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.237e+00, Loss Aux: 3.233e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4061, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.167e+00, Loss Aux: 6.062e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4062, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.442e+00, Loss Aux: 1.831e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4063, It: 0, Loss Data: 1.220e-01, Loss Eqns: 3.510e+00, Loss Aux: 3.196e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4064, It: 0, Loss Data: 1.246e-01, Loss Eqns: 3.441e+00, Loss Aux: 2.058e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4065, It: 0, Loss Data: 1.145e-01, Loss Eqns: 3.353e+00, Loss Aux: 1.418e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4066, It: 0, Loss Data: 9.596e-02, Loss Eqns: 3.251e+00, Loss Aux: 1.352e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4067, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.413e+00, Loss Aux: 1.093e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 4068, It: 0, Loss Data: 1.058e-01, Loss Eqns: 3.426e+00, Loss Aux: 8.165e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4069, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.307e+00, Loss Aux: 7.361e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4070, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.462e+00, Loss Aux: 1.052e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4071, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.421e+00, Loss Aux: 1.399e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 4072, It: 0, Loss Data: 1.026e-01, Loss Eqns: 3.319e+00, Loss Aux: 1.110e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4073, It: 0, Loss Data: 1.015e-01, Loss Eqns: 3.089e+00, Loss Aux: 5.440e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4074, It: 0, Loss Data: 1.354e-01, Loss Eqns: 3.230e+00, Loss Aux: 1.011e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4075, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.290e+00, Loss Aux: 1.193e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4076, It: 0, Loss Data: 1.309e-01, Loss Eqns: 3.353e+00, Loss Aux: 8.765e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4077, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.446e+00, Loss Aux: 1.038e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4078, It: 0, Loss Data: 1.116e-01, Loss Eqns: 3.529e+00, Loss Aux: 1.222e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4079, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.430e+00, Loss Aux: 1.494e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4080, It: 0, Loss Data: 1.108e-01, Loss Eqns: 3.379e+00, Loss Aux: 1.370e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 4081, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.276e+00, Loss Aux: 1.095e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4082, It: 0, Loss Data: 1.305e-01, Loss Eqns: 3.429e+00, Loss Aux: 7.537e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4083, It: 0, Loss Data: 1.047e-01, Loss Eqns: 3.383e+00, Loss Aux: 6.418e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4084, It: 0, Loss Data: 1.028e-01, Loss Eqns: 3.656e+00, Loss Aux: 7.630e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 4085, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.444e+00, Loss Aux: 1.056e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4086, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.309e+00, Loss Aux: 1.095e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4087, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.241e+00, Loss Aux: 9.089e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4088, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.334e+00, Loss Aux: 1.021e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4089, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.356e+00, Loss Aux: 1.362e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4090, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.489e+00, Loss Aux: 9.213e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4091, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.408e+00, Loss Aux: 1.013e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 4092, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.398e+00, Loss Aux: 1.043e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 4093, It: 0, Loss Data: 1.017e-01, Loss Eqns: 3.460e+00, Loss Aux: 1.368e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 4094, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.290e+00, Loss Aux: 8.322e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4095, It: 0, Loss Data: 9.623e-02, Loss Eqns: 3.438e+00, Loss Aux: 4.411e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4096, It: 0, Loss Data: 8.815e-02, Loss Eqns: 3.427e+00, Loss Aux: 5.620e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4097, It: 0, Loss Data: 1.457e-01, Loss Eqns: 3.235e+00, Loss Aux: 1.250e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4098, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.354e+00, Loss Aux: 8.005e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4099, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.443e+00, Loss Aux: 1.047e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4100, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.293e+00, Loss Aux: 8.489e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4101, It: 0, Loss Data: 1.057e-01, Loss Eqns: 3.474e+00, Loss Aux: 7.523e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4102, It: 0, Loss Data: 1.291e-01, Loss Eqns: 3.593e+00, Loss Aux: 8.198e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4103, It: 0, Loss Data: 1.134e-01, Loss Eqns: 3.357e+00, Loss Aux: 7.326e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4104, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.475e+00, Loss Aux: 7.133e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4105, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.557e+00, Loss Aux: 1.011e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4106, It: 0, Loss Data: 1.015e-01, Loss Eqns: 3.412e+00, Loss Aux: 1.813e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 4107, It: 0, Loss Data: 9.516e-02, Loss Eqns: 3.284e+00, Loss Aux: 1.938e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4108, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.373e+00, Loss Aux: 8.460e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4109, It: 0, Loss Data: 1.125e-01, Loss Eqns: 3.413e+00, Loss Aux: 6.030e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4110, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.497e+00, Loss Aux: 6.497e-03, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 4111, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.492e+00, Loss Aux: 6.833e-03, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 4112, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.341e+00, Loss Aux: 6.796e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4113, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.442e+00, Loss Aux: 7.525e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4114, It: 0, Loss Data: 1.086e-01, Loss Eqns: 3.344e+00, Loss Aux: 1.316e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4115, It: 0, Loss Data: 1.124e-01, Loss Eqns: 3.328e+00, Loss Aux: 1.885e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4116, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.268e+00, Loss Aux: 1.373e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4117, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.407e+00, Loss Aux: 7.873e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4118, It: 0, Loss Data: 1.062e-01, Loss Eqns: 3.463e+00, Loss Aux: 6.492e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4119, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.276e+00, Loss Aux: 8.546e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4120, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.400e+00, Loss Aux: 1.087e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4121, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.345e+00, Loss Aux: 9.960e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4122, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.425e+00, Loss Aux: 9.989e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4123, It: 0, Loss Data: 1.050e-01, Loss Eqns: 3.388e+00, Loss Aux: 1.100e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4124, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.334e+00, Loss Aux: 1.459e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 4125, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.226e+00, Loss Aux: 9.320e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4126, It: 0, Loss Data: 1.048e-01, Loss Eqns: 3.293e+00, Loss Aux: 5.400e-03, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 4127, It: 0, Loss Data: 9.992e-02, Loss Eqns: 3.273e+00, Loss Aux: 5.050e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 4128, It: 0, Loss Data: 1.048e-01, Loss Eqns: 3.192e+00, Loss Aux: 1.374e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 4129, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.206e+00, Loss Aux: 1.385e-02, Time: 0.257, Learning Rate: 1.0e-03\n",
      "Epoch: 4130, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.172e+00, Loss Aux: 9.864e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4131, It: 0, Loss Data: 1.284e-01, Loss Eqns: 3.500e+00, Loss Aux: 1.068e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 4132, It: 0, Loss Data: 1.369e-01, Loss Eqns: 3.333e+00, Loss Aux: 1.543e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4133, It: 0, Loss Data: 1.058e-01, Loss Eqns: 3.265e+00, Loss Aux: 1.591e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4134, It: 0, Loss Data: 1.005e-01, Loss Eqns: 3.182e+00, Loss Aux: 1.072e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4135, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.435e+00, Loss Aux: 9.497e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4136, It: 0, Loss Data: 1.233e-01, Loss Eqns: 3.457e+00, Loss Aux: 2.058e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4137, It: 0, Loss Data: 1.046e-01, Loss Eqns: 3.401e+00, Loss Aux: 1.031e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4138, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.265e+00, Loss Aux: 5.893e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4139, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.299e+00, Loss Aux: 9.315e-03, Time: 0.257, Learning Rate: 1.0e-03\n",
      "Epoch: 4140, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.213e+00, Loss Aux: 1.099e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4141, It: 0, Loss Data: 1.143e-01, Loss Eqns: 3.388e+00, Loss Aux: 2.340e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4142, It: 0, Loss Data: 1.050e-01, Loss Eqns: 3.336e+00, Loss Aux: 2.289e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4143, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.306e+00, Loss Aux: 1.352e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4144, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.584e+00, Loss Aux: 8.515e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4145, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.431e+00, Loss Aux: 1.058e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4146, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.304e+00, Loss Aux: 1.275e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4147, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.454e+00, Loss Aux: 1.002e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4148, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.343e+00, Loss Aux: 1.272e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4149, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.638e+00, Loss Aux: 1.904e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4150, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.543e+00, Loss Aux: 2.054e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4151, It: 0, Loss Data: 9.038e-02, Loss Eqns: 3.211e+00, Loss Aux: 1.832e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 4152, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.243e+00, Loss Aux: 1.092e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4153, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.177e+00, Loss Aux: 8.322e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 4154, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.350e+00, Loss Aux: 6.105e-03, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 4155, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.344e+00, Loss Aux: 6.027e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4156, It: 0, Loss Data: 1.072e-01, Loss Eqns: 3.248e+00, Loss Aux: 9.578e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 4157, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.414e+00, Loss Aux: 1.647e-02, Time: 0.358, Learning Rate: 1.0e-03\n",
      "Epoch: 4158, It: 0, Loss Data: 1.057e-01, Loss Eqns: 3.192e+00, Loss Aux: 2.357e-02, Time: 0.357, Learning Rate: 1.0e-03\n",
      "Epoch: 4159, It: 0, Loss Data: 1.134e-01, Loss Eqns: 3.253e+00, Loss Aux: 1.607e-02, Time: 0.384, Learning Rate: 1.0e-03\n",
      "Epoch: 4160, It: 0, Loss Data: 1.252e-01, Loss Eqns: 3.315e+00, Loss Aux: 9.149e-03, Time: 0.311, Learning Rate: 1.0e-03\n",
      "Epoch: 4161, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.436e+00, Loss Aux: 1.195e-02, Time: 0.380, Learning Rate: 1.0e-03\n",
      "Epoch: 4162, It: 0, Loss Data: 1.375e-01, Loss Eqns: 3.238e+00, Loss Aux: 1.692e-02, Time: 0.357, Learning Rate: 1.0e-03\n",
      "Epoch: 4163, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.273e+00, Loss Aux: 9.250e-03, Time: 0.382, Learning Rate: 1.0e-03\n",
      "Epoch: 4164, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.147e+00, Loss Aux: 5.966e-03, Time: 0.371, Learning Rate: 1.0e-03\n",
      "Epoch: 4165, It: 0, Loss Data: 1.239e-01, Loss Eqns: 3.290e+00, Loss Aux: 4.834e-03, Time: 0.366, Learning Rate: 1.0e-03\n",
      "Epoch: 4166, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.414e+00, Loss Aux: 1.621e-02, Time: 0.330, Learning Rate: 1.0e-03\n",
      "Epoch: 4167, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.618e+00, Loss Aux: 1.752e-02, Time: 0.337, Learning Rate: 1.0e-03\n",
      "Epoch: 4168, It: 0, Loss Data: 9.547e-02, Loss Eqns: 3.746e+00, Loss Aux: 1.002e-02, Time: 0.319, Learning Rate: 1.0e-03\n",
      "Epoch: 4169, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.512e+00, Loss Aux: 1.224e-02, Time: 0.360, Learning Rate: 1.0e-03\n",
      "Epoch: 4170, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.432e+00, Loss Aux: 1.145e-02, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 4171, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.452e+00, Loss Aux: 8.327e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4172, It: 0, Loss Data: 1.035e-01, Loss Eqns: 3.452e+00, Loss Aux: 1.034e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 4173, It: 0, Loss Data: 1.374e-01, Loss Eqns: 3.244e+00, Loss Aux: 4.961e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4174, It: 0, Loss Data: 1.011e-01, Loss Eqns: 3.544e+00, Loss Aux: 1.683e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4175, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.269e+00, Loss Aux: 2.193e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4176, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.256e+00, Loss Aux: 1.331e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4177, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.262e+00, Loss Aux: 9.089e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4178, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.133e+00, Loss Aux: 8.047e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4179, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.392e+00, Loss Aux: 7.552e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4180, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.197e+00, Loss Aux: 8.156e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4181, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.393e+00, Loss Aux: 1.026e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4182, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.331e+00, Loss Aux: 7.635e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4183, It: 0, Loss Data: 1.162e-01, Loss Eqns: 3.515e+00, Loss Aux: 7.562e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4184, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.291e+00, Loss Aux: 7.190e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4185, It: 0, Loss Data: 1.318e-01, Loss Eqns: 3.297e+00, Loss Aux: 6.095e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4186, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.198e+00, Loss Aux: 8.229e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4187, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.343e+00, Loss Aux: 1.922e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4188, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.416e+00, Loss Aux: 2.235e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4189, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.328e+00, Loss Aux: 7.892e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4190, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.233e+00, Loss Aux: 5.722e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4191, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.266e+00, Loss Aux: 8.736e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4192, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.403e+00, Loss Aux: 1.300e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4193, It: 0, Loss Data: 9.299e-02, Loss Eqns: 3.419e+00, Loss Aux: 8.717e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 4194, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.327e+00, Loss Aux: 1.006e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4195, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.527e+00, Loss Aux: 1.140e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4196, It: 0, Loss Data: 1.390e-01, Loss Eqns: 3.277e+00, Loss Aux: 1.461e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4197, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.453e+00, Loss Aux: 1.060e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4198, It: 0, Loss Data: 1.014e-01, Loss Eqns: 3.192e+00, Loss Aux: 7.818e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4199, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.321e+00, Loss Aux: 8.432e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4200, It: 0, Loss Data: 1.106e-01, Loss Eqns: 3.171e+00, Loss Aux: 1.068e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4201, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.478e+00, Loss Aux: 1.196e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4202, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.215e+00, Loss Aux: 6.607e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4203, It: 0, Loss Data: 1.068e-01, Loss Eqns: 3.433e+00, Loss Aux: 6.127e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4204, It: 0, Loss Data: 1.255e-01, Loss Eqns: 3.356e+00, Loss Aux: 5.282e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4205, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.250e+00, Loss Aux: 2.383e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4206, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.204e+00, Loss Aux: 2.533e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4207, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.228e+00, Loss Aux: 8.727e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4208, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.222e+00, Loss Aux: 8.696e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4209, It: 0, Loss Data: 1.326e-01, Loss Eqns: 3.375e+00, Loss Aux: 1.412e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4210, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.168e+00, Loss Aux: 2.127e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4211, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.303e+00, Loss Aux: 1.822e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4212, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.224e+00, Loss Aux: 1.245e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4213, It: 0, Loss Data: 1.268e-01, Loss Eqns: 3.180e+00, Loss Aux: 1.034e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4214, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.297e+00, Loss Aux: 9.791e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4215, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.278e+00, Loss Aux: 1.141e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4216, It: 0, Loss Data: 1.299e-01, Loss Eqns: 3.291e+00, Loss Aux: 1.295e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4217, It: 0, Loss Data: 1.312e-01, Loss Eqns: 3.131e+00, Loss Aux: 9.353e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4218, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.230e+00, Loss Aux: 5.991e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4219, It: 0, Loss Data: 9.705e-02, Loss Eqns: 3.206e+00, Loss Aux: 6.497e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4220, It: 0, Loss Data: 1.153e-01, Loss Eqns: 3.446e+00, Loss Aux: 5.995e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4221, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.245e+00, Loss Aux: 6.675e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4222, It: 0, Loss Data: 1.024e-01, Loss Eqns: 3.217e+00, Loss Aux: 8.930e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4223, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.201e+00, Loss Aux: 2.527e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4224, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.209e+00, Loss Aux: 3.140e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4225, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.234e+00, Loss Aux: 1.443e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4226, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.103e+00, Loss Aux: 7.479e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4227, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.206e+00, Loss Aux: 6.123e-03, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 4228, It: 0, Loss Data: 1.125e-01, Loss Eqns: 3.241e+00, Loss Aux: 6.324e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4229, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.400e+00, Loss Aux: 7.720e-03, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 4230, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.158e+00, Loss Aux: 1.326e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4231, It: 0, Loss Data: 1.317e-01, Loss Eqns: 3.342e+00, Loss Aux: 2.070e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4232, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.239e+00, Loss Aux: 1.779e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4233, It: 0, Loss Data: 1.058e-01, Loss Eqns: 3.317e+00, Loss Aux: 1.430e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4234, It: 0, Loss Data: 9.477e-02, Loss Eqns: 3.248e+00, Loss Aux: 1.264e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4235, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.321e+00, Loss Aux: 1.299e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4236, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.312e+00, Loss Aux: 1.280e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4237, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.252e+00, Loss Aux: 1.138e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4238, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.371e+00, Loss Aux: 9.666e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4239, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.301e+00, Loss Aux: 5.183e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4240, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.305e+00, Loss Aux: 4.934e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4241, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.432e+00, Loss Aux: 1.656e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4242, It: 0, Loss Data: 9.801e-02, Loss Eqns: 3.124e+00, Loss Aux: 1.887e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4243, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.281e+00, Loss Aux: 1.005e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4244, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.379e+00, Loss Aux: 7.266e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4245, It: 0, Loss Data: 1.295e-01, Loss Eqns: 3.378e+00, Loss Aux: 6.748e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4246, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.152e+00, Loss Aux: 5.941e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4247, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.377e+00, Loss Aux: 6.956e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4248, It: 0, Loss Data: 1.288e-01, Loss Eqns: 3.323e+00, Loss Aux: 8.212e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4249, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.244e+00, Loss Aux: 1.357e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4250, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.366e+00, Loss Aux: 1.885e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4251, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.176e+00, Loss Aux: 1.642e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4252, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.323e+00, Loss Aux: 7.620e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4253, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.441e+00, Loss Aux: 4.855e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4254, It: 0, Loss Data: 8.968e-02, Loss Eqns: 3.317e+00, Loss Aux: 5.654e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4255, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.394e+00, Loss Aux: 6.177e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4256, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.282e+00, Loss Aux: 7.670e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4257, It: 0, Loss Data: 1.006e-01, Loss Eqns: 3.099e+00, Loss Aux: 8.533e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4258, It: 0, Loss Data: 1.010e-01, Loss Eqns: 3.295e+00, Loss Aux: 2.477e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4259, It: 0, Loss Data: 1.016e-01, Loss Eqns: 3.120e+00, Loss Aux: 3.127e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4260, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.373e+00, Loss Aux: 1.573e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 4261, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.219e+00, Loss Aux: 1.215e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4262, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.186e+00, Loss Aux: 1.531e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4263, It: 0, Loss Data: 1.030e-01, Loss Eqns: 3.359e+00, Loss Aux: 1.418e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4264, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.184e+00, Loss Aux: 9.395e-03, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 4265, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.207e+00, Loss Aux: 5.970e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4266, It: 0, Loss Data: 1.246e-01, Loss Eqns: 3.220e+00, Loss Aux: 1.179e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 4267, It: 0, Loss Data: 1.257e-01, Loss Eqns: 3.102e+00, Loss Aux: 1.649e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4268, It: 0, Loss Data: 1.008e-01, Loss Eqns: 3.308e+00, Loss Aux: 9.287e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4269, It: 0, Loss Data: 1.212e-01, Loss Eqns: 3.308e+00, Loss Aux: 9.749e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4270, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.168e+00, Loss Aux: 1.233e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4271, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.185e+00, Loss Aux: 2.066e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 4272, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.143e+00, Loss Aux: 1.153e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4273, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.417e+00, Loss Aux: 5.455e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4274, It: 0, Loss Data: 1.030e-01, Loss Eqns: 3.297e+00, Loss Aux: 7.167e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4275, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.172e+00, Loss Aux: 1.151e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4276, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.330e+00, Loss Aux: 2.159e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4277, It: 0, Loss Data: 9.230e-02, Loss Eqns: 3.319e+00, Loss Aux: 1.172e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 4278, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.257e+00, Loss Aux: 7.506e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4279, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.128e+00, Loss Aux: 6.356e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4280, It: 0, Loss Data: 1.105e-01, Loss Eqns: 3.299e+00, Loss Aux: 7.411e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4281, It: 0, Loss Data: 1.183e-01, Loss Eqns: 3.276e+00, Loss Aux: 6.942e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4282, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.129e+00, Loss Aux: 4.974e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4283, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.215e+00, Loss Aux: 5.794e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4284, It: 0, Loss Data: 9.867e-02, Loss Eqns: 3.369e+00, Loss Aux: 1.447e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4285, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.350e+00, Loss Aux: 1.864e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4286, It: 0, Loss Data: 9.980e-02, Loss Eqns: 3.359e+00, Loss Aux: 1.535e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4287, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.335e+00, Loss Aux: 1.603e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4288, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.256e+00, Loss Aux: 1.474e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 4289, It: 0, Loss Data: 1.243e-01, Loss Eqns: 3.214e+00, Loss Aux: 1.082e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4290, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.226e+00, Loss Aux: 6.779e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4291, It: 0, Loss Data: 1.010e-01, Loss Eqns: 3.368e+00, Loss Aux: 5.001e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4292, It: 0, Loss Data: 9.577e-02, Loss Eqns: 3.446e+00, Loss Aux: 5.238e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4293, It: 0, Loss Data: 1.027e-01, Loss Eqns: 3.241e+00, Loss Aux: 8.363e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4294, It: 0, Loss Data: 1.344e-01, Loss Eqns: 3.176e+00, Loss Aux: 1.161e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4295, It: 0, Loss Data: 1.153e-01, Loss Eqns: 3.128e+00, Loss Aux: 1.212e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4296, It: 0, Loss Data: 9.699e-02, Loss Eqns: 3.007e+00, Loss Aux: 9.528e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4297, It: 0, Loss Data: 1.329e-01, Loss Eqns: 3.229e+00, Loss Aux: 9.496e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4298, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.233e+00, Loss Aux: 9.605e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4299, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.117e+00, Loss Aux: 9.262e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4300, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.285e+00, Loss Aux: 1.133e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4301, It: 0, Loss Data: 1.207e-01, Loss Eqns: 3.080e+00, Loss Aux: 1.263e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4302, It: 0, Loss Data: 1.031e-01, Loss Eqns: 3.446e+00, Loss Aux: 2.524e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4303, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.549e+00, Loss Aux: 3.040e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4304, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.234e+00, Loss Aux: 7.083e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4305, It: 0, Loss Data: 1.060e-01, Loss Eqns: 3.042e+00, Loss Aux: 4.104e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4306, It: 0, Loss Data: 1.121e-01, Loss Eqns: 3.357e+00, Loss Aux: 6.038e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4307, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.203e+00, Loss Aux: 1.032e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4308, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.200e+00, Loss Aux: 5.632e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 4309, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.337e+00, Loss Aux: 7.767e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4310, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.285e+00, Loss Aux: 1.391e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 4311, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.254e+00, Loss Aux: 2.013e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 4312, It: 0, Loss Data: 1.236e-01, Loss Eqns: 3.292e+00, Loss Aux: 1.874e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4313, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.151e+00, Loss Aux: 9.794e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 4314, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.251e+00, Loss Aux: 9.313e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 4315, It: 0, Loss Data: 1.109e-01, Loss Eqns: 3.187e+00, Loss Aux: 6.695e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4316, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.373e+00, Loss Aux: 4.683e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4317, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.202e+00, Loss Aux: 6.918e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4318, It: 0, Loss Data: 1.135e-01, Loss Eqns: 3.075e+00, Loss Aux: 1.036e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4319, It: 0, Loss Data: 1.206e-01, Loss Eqns: 3.253e+00, Loss Aux: 1.059e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 4320, It: 0, Loss Data: 1.071e-01, Loss Eqns: 3.282e+00, Loss Aux: 8.551e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 4321, It: 0, Loss Data: 9.136e-02, Loss Eqns: 3.422e+00, Loss Aux: 8.441e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4322, It: 0, Loss Data: 1.013e-01, Loss Eqns: 3.483e+00, Loss Aux: 9.425e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4323, It: 0, Loss Data: 8.938e-02, Loss Eqns: 3.291e+00, Loss Aux: 9.446e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4324, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.245e+00, Loss Aux: 1.175e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4325, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.095e+00, Loss Aux: 1.163e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4326, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.253e+00, Loss Aux: 1.038e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4327, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.222e+00, Loss Aux: 8.997e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4328, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.439e+00, Loss Aux: 1.751e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4329, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.238e+00, Loss Aux: 1.360e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4330, It: 0, Loss Data: 1.024e-01, Loss Eqns: 3.370e+00, Loss Aux: 1.029e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4331, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.316e+00, Loss Aux: 1.120e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 4332, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.090e+00, Loss Aux: 6.136e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4333, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.420e+00, Loss Aux: 6.637e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4334, It: 0, Loss Data: 1.057e-01, Loss Eqns: 3.293e+00, Loss Aux: 6.219e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4335, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.190e+00, Loss Aux: 7.800e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4336, It: 0, Loss Data: 1.139e-01, Loss Eqns: 3.153e+00, Loss Aux: 9.851e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 4337, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.204e+00, Loss Aux: 1.439e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4338, It: 0, Loss Data: 1.274e-01, Loss Eqns: 3.091e+00, Loss Aux: 2.923e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4339, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.130e+00, Loss Aux: 2.245e-02, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 4340, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.348e+00, Loss Aux: 1.078e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4341, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.214e+00, Loss Aux: 7.911e-03, Time: 0.255, Learning Rate: 1.0e-03\n",
      "Epoch: 4342, It: 0, Loss Data: 9.681e-02, Loss Eqns: 3.168e+00, Loss Aux: 6.269e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4343, It: 0, Loss Data: 1.157e-01, Loss Eqns: 3.203e+00, Loss Aux: 7.238e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4344, It: 0, Loss Data: 1.047e-01, Loss Eqns: 3.197e+00, Loss Aux: 8.023e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4345, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.155e+00, Loss Aux: 8.381e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4346, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.216e+00, Loss Aux: 1.243e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4347, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.273e+00, Loss Aux: 1.527e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4348, It: 0, Loss Data: 9.904e-02, Loss Eqns: 3.257e+00, Loss Aux: 1.175e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4349, It: 0, Loss Data: 1.168e-01, Loss Eqns: 3.275e+00, Loss Aux: 6.698e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4350, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.152e+00, Loss Aux: 8.574e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4351, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.122e+00, Loss Aux: 1.278e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4352, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.285e+00, Loss Aux: 8.786e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4353, It: 0, Loss Data: 1.003e-01, Loss Eqns: 3.188e+00, Loss Aux: 8.609e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4354, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.123e+00, Loss Aux: 9.646e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4355, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.184e+00, Loss Aux: 9.595e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4356, It: 0, Loss Data: 1.022e-01, Loss Eqns: 3.230e+00, Loss Aux: 8.938e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4357, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.058e+00, Loss Aux: 6.433e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4358, It: 0, Loss Data: 1.234e-01, Loss Eqns: 3.097e+00, Loss Aux: 6.312e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4359, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.184e+00, Loss Aux: 9.210e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4360, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.236e+00, Loss Aux: 1.257e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4361, It: 0, Loss Data: 9.484e-02, Loss Eqns: 3.306e+00, Loss Aux: 7.056e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4362, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.208e+00, Loss Aux: 4.628e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4363, It: 0, Loss Data: 9.826e-02, Loss Eqns: 3.201e+00, Loss Aux: 7.742e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4364, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.124e+00, Loss Aux: 1.367e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4365, It: 0, Loss Data: 1.257e-01, Loss Eqns: 3.218e+00, Loss Aux: 9.000e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4366, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.192e+00, Loss Aux: 8.757e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4367, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.371e+00, Loss Aux: 8.459e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4368, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.052e+00, Loss Aux: 1.258e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4369, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.416e+00, Loss Aux: 2.032e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4370, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.258e+00, Loss Aux: 1.032e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4371, It: 0, Loss Data: 1.195e-01, Loss Eqns: 3.186e+00, Loss Aux: 6.090e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4372, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.994e+00, Loss Aux: 1.195e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4373, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.238e+00, Loss Aux: 2.018e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4374, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.004e+00, Loss Aux: 7.881e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4375, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.162e+00, Loss Aux: 6.829e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4376, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.930e+00, Loss Aux: 8.253e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4377, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.169e+00, Loss Aux: 1.486e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4378, It: 0, Loss Data: 1.247e-01, Loss Eqns: 2.982e+00, Loss Aux: 9.558e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4379, It: 0, Loss Data: 1.262e-01, Loss Eqns: 3.046e+00, Loss Aux: 8.847e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4380, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.259e+00, Loss Aux: 1.172e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4381, It: 0, Loss Data: 9.548e-02, Loss Eqns: 3.282e+00, Loss Aux: 2.281e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4382, It: 0, Loss Data: 1.239e-01, Loss Eqns: 3.166e+00, Loss Aux: 2.001e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4383, It: 0, Loss Data: 1.187e-01, Loss Eqns: 3.185e+00, Loss Aux: 1.269e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4384, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.194e+00, Loss Aux: 1.047e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4385, It: 0, Loss Data: 1.058e-01, Loss Eqns: 3.425e+00, Loss Aux: 9.766e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4386, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.258e+00, Loss Aux: 6.623e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4387, It: 0, Loss Data: 1.064e-01, Loss Eqns: 3.080e+00, Loss Aux: 6.124e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4388, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.334e+00, Loss Aux: 6.333e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4389, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.104e+00, Loss Aux: 1.350e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4390, It: 0, Loss Data: 1.130e-01, Loss Eqns: 3.303e+00, Loss Aux: 2.250e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4391, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.068e+00, Loss Aux: 1.190e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4392, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.394e+00, Loss Aux: 6.870e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4393, It: 0, Loss Data: 1.035e-01, Loss Eqns: 3.426e+00, Loss Aux: 6.885e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4394, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.229e+00, Loss Aux: 6.633e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4395, It: 0, Loss Data: 1.044e-01, Loss Eqns: 3.348e+00, Loss Aux: 6.646e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4396, It: 0, Loss Data: 1.054e-01, Loss Eqns: 3.126e+00, Loss Aux: 8.590e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4397, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.053e+00, Loss Aux: 1.546e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4398, It: 0, Loss Data: 1.283e-01, Loss Eqns: 3.453e+00, Loss Aux: 1.080e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4399, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.082e+00, Loss Aux: 8.310e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4400, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.147e+00, Loss Aux: 7.921e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4401, It: 0, Loss Data: 1.072e-01, Loss Eqns: 3.144e+00, Loss Aux: 1.183e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4402, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.295e+00, Loss Aux: 1.765e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4403, It: 0, Loss Data: 8.067e-02, Loss Eqns: 3.179e+00, Loss Aux: 1.441e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4404, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.189e+00, Loss Aux: 7.939e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4405, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.262e+00, Loss Aux: 5.921e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4406, It: 0, Loss Data: 1.223e-01, Loss Eqns: 3.142e+00, Loss Aux: 6.982e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4407, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.145e+00, Loss Aux: 6.313e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4408, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.331e+00, Loss Aux: 6.361e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4409, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.267e+00, Loss Aux: 7.156e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4410, It: 0, Loss Data: 1.028e-01, Loss Eqns: 3.416e+00, Loss Aux: 8.612e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4411, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.206e+00, Loss Aux: 1.088e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4412, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.207e+00, Loss Aux: 9.638e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4413, It: 0, Loss Data: 9.673e-02, Loss Eqns: 3.211e+00, Loss Aux: 9.072e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4414, It: 0, Loss Data: 8.396e-02, Loss Eqns: 3.239e+00, Loss Aux: 5.974e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4415, It: 0, Loss Data: 9.932e-02, Loss Eqns: 3.098e+00, Loss Aux: 5.774e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4416, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.161e+00, Loss Aux: 8.635e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4417, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.203e+00, Loss Aux: 9.411e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4418, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.051e+00, Loss Aux: 1.058e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4419, It: 0, Loss Data: 1.096e-01, Loss Eqns: 3.126e+00, Loss Aux: 1.234e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4420, It: 0, Loss Data: 1.188e-01, Loss Eqns: 3.246e+00, Loss Aux: 1.071e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4421, It: 0, Loss Data: 1.013e-01, Loss Eqns: 3.057e+00, Loss Aux: 9.586e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4422, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.329e+00, Loss Aux: 9.544e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4423, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.252e+00, Loss Aux: 7.642e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4424, It: 0, Loss Data: 1.196e-01, Loss Eqns: 3.307e+00, Loss Aux: 8.639e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4425, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.142e+00, Loss Aux: 9.462e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4426, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.160e+00, Loss Aux: 5.380e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4427, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.171e+00, Loss Aux: 5.476e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4428, It: 0, Loss Data: 1.037e-01, Loss Eqns: 3.230e+00, Loss Aux: 1.085e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4429, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.298e+00, Loss Aux: 1.971e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4430, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.113e+00, Loss Aux: 1.673e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4431, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.964e+00, Loss Aux: 1.130e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4432, It: 0, Loss Data: 1.006e-01, Loss Eqns: 3.246e+00, Loss Aux: 1.062e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4433, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.220e+00, Loss Aux: 9.329e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4434, It: 0, Loss Data: 8.745e-02, Loss Eqns: 3.208e+00, Loss Aux: 6.565e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4435, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.266e+00, Loss Aux: 6.151e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4436, It: 0, Loss Data: 1.015e-01, Loss Eqns: 3.168e+00, Loss Aux: 7.834e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4437, It: 0, Loss Data: 1.303e-01, Loss Eqns: 3.069e+00, Loss Aux: 1.710e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4438, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.018e+00, Loss Aux: 9.958e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4439, It: 0, Loss Data: 1.133e-01, Loss Eqns: 3.324e+00, Loss Aux: 9.685e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4440, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.410e+00, Loss Aux: 1.812e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4441, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.590e+00, Loss Aux: 1.729e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4442, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.240e+00, Loss Aux: 1.730e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4443, It: 0, Loss Data: 1.629e-01, Loss Eqns: 3.360e+00, Loss Aux: 1.280e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4444, It: 0, Loss Data: 1.299e-01, Loss Eqns: 3.046e+00, Loss Aux: 9.223e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4445, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.164e+00, Loss Aux: 8.314e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4446, It: 0, Loss Data: 1.484e-01, Loss Eqns: 3.105e+00, Loss Aux: 1.214e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4447, It: 0, Loss Data: 1.167e-01, Loss Eqns: 3.128e+00, Loss Aux: 7.352e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4448, It: 0, Loss Data: 1.340e-01, Loss Eqns: 3.120e+00, Loss Aux: 8.904e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 4449, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.300e+00, Loss Aux: 1.550e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4450, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.337e+00, Loss Aux: 2.991e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4451, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.351e+00, Loss Aux: 2.155e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4452, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.213e+00, Loss Aux: 1.064e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4453, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.167e+00, Loss Aux: 9.612e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4454, It: 0, Loss Data: 8.974e-02, Loss Eqns: 3.327e+00, Loss Aux: 7.794e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4455, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.420e+00, Loss Aux: 5.546e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4456, It: 0, Loss Data: 1.032e-01, Loss Eqns: 3.381e+00, Loss Aux: 5.203e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4457, It: 0, Loss Data: 1.140e-01, Loss Eqns: 3.220e+00, Loss Aux: 6.932e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4458, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.316e+00, Loss Aux: 9.175e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4459, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.211e+00, Loss Aux: 1.863e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4460, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.077e+00, Loss Aux: 2.056e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4461, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.986e+00, Loss Aux: 1.491e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4462, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.158e+00, Loss Aux: 1.131e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4463, It: 0, Loss Data: 9.454e-02, Loss Eqns: 3.224e+00, Loss Aux: 7.829e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4464, It: 0, Loss Data: 9.830e-02, Loss Eqns: 3.137e+00, Loss Aux: 5.819e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4465, It: 0, Loss Data: 1.191e-01, Loss Eqns: 3.181e+00, Loss Aux: 4.780e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4466, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.271e+00, Loss Aux: 8.757e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4467, It: 0, Loss Data: 9.910e-02, Loss Eqns: 3.220e+00, Loss Aux: 1.018e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4468, It: 0, Loss Data: 1.215e-01, Loss Eqns: 3.137e+00, Loss Aux: 8.059e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4469, It: 0, Loss Data: 1.000e-01, Loss Eqns: 3.193e+00, Loss Aux: 8.040e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4470, It: 0, Loss Data: 1.049e-01, Loss Eqns: 3.132e+00, Loss Aux: 1.135e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4471, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.259e+00, Loss Aux: 1.208e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4472, It: 0, Loss Data: 1.161e-01, Loss Eqns: 3.177e+00, Loss Aux: 9.136e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4473, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.105e+00, Loss Aux: 7.173e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4474, It: 0, Loss Data: 1.123e-01, Loss Eqns: 3.037e+00, Loss Aux: 5.993e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4475, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.102e+00, Loss Aux: 1.021e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4476, It: 0, Loss Data: 1.141e-01, Loss Eqns: 3.125e+00, Loss Aux: 8.763e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4477, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.115e+00, Loss Aux: 6.084e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4478, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.264e+00, Loss Aux: 8.093e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4479, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.285e+00, Loss Aux: 1.324e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4480, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.351e+00, Loss Aux: 1.500e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4481, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.333e+00, Loss Aux: 1.045e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4482, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.273e+00, Loss Aux: 1.048e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 4483, It: 0, Loss Data: 1.018e-01, Loss Eqns: 3.346e+00, Loss Aux: 1.051e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4484, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.225e+00, Loss Aux: 1.126e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4485, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.188e+00, Loss Aux: 9.490e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4486, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.985e+00, Loss Aux: 9.996e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4487, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.409e+00, Loss Aux: 1.002e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4488, It: 0, Loss Data: 1.011e-01, Loss Eqns: 3.194e+00, Loss Aux: 7.531e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4489, It: 0, Loss Data: 1.009e-01, Loss Eqns: 3.138e+00, Loss Aux: 5.006e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4490, It: 0, Loss Data: 9.418e-02, Loss Eqns: 3.037e+00, Loss Aux: 6.543e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4491, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.172e+00, Loss Aux: 9.793e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4492, It: 0, Loss Data: 1.160e-01, Loss Eqns: 3.144e+00, Loss Aux: 9.494e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4493, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.066e+00, Loss Aux: 6.841e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4494, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.161e+00, Loss Aux: 6.605e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4495, It: 0, Loss Data: 1.214e-01, Loss Eqns: 3.068e+00, Loss Aux: 1.042e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4496, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.122e+00, Loss Aux: 9.641e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4497, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.001e+00, Loss Aux: 7.365e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 4498, It: 0, Loss Data: 1.017e-01, Loss Eqns: 3.191e+00, Loss Aux: 1.280e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4499, It: 0, Loss Data: 1.047e-01, Loss Eqns: 3.260e+00, Loss Aux: 1.162e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4500, It: 0, Loss Data: 9.778e-02, Loss Eqns: 3.216e+00, Loss Aux: 8.278e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4501, It: 0, Loss Data: 1.156e-01, Loss Eqns: 3.098e+00, Loss Aux: 6.449e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4502, It: 0, Loss Data: 9.622e-02, Loss Eqns: 3.324e+00, Loss Aux: 5.166e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4503, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.214e+00, Loss Aux: 8.851e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4504, It: 0, Loss Data: 1.117e-01, Loss Eqns: 3.367e+00, Loss Aux: 1.410e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4505, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.257e+00, Loss Aux: 4.193e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4506, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.285e+00, Loss Aux: 4.110e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4507, It: 0, Loss Data: 1.003e-01, Loss Eqns: 3.226e+00, Loss Aux: 5.888e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4508, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.134e+00, Loss Aux: 1.416e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4509, It: 0, Loss Data: 1.101e-01, Loss Eqns: 3.120e+00, Loss Aux: 7.639e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4510, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.078e+00, Loss Aux: 8.126e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4511, It: 0, Loss Data: 1.080e-01, Loss Eqns: 3.061e+00, Loss Aux: 1.504e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4512, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.258e+00, Loss Aux: 1.214e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4513, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.050e+00, Loss Aux: 1.143e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4514, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.162e+00, Loss Aux: 1.063e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4515, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.064e+00, Loss Aux: 9.007e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4516, It: 0, Loss Data: 1.038e-01, Loss Eqns: 3.110e+00, Loss Aux: 1.250e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4517, It: 0, Loss Data: 1.261e-01, Loss Eqns: 3.124e+00, Loss Aux: 1.313e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4518, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.270e+00, Loss Aux: 6.002e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4519, It: 0, Loss Data: 1.159e-01, Loss Eqns: 3.364e+00, Loss Aux: 6.348e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4520, It: 0, Loss Data: 1.096e-01, Loss Eqns: 3.225e+00, Loss Aux: 8.919e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4521, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.187e+00, Loss Aux: 5.965e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4522, It: 0, Loss Data: 9.840e-02, Loss Eqns: 3.147e+00, Loss Aux: 4.886e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4523, It: 0, Loss Data: 9.893e-02, Loss Eqns: 3.226e+00, Loss Aux: 6.380e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4524, It: 0, Loss Data: 9.124e-02, Loss Eqns: 3.213e+00, Loss Aux: 1.066e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4525, It: 0, Loss Data: 1.035e-01, Loss Eqns: 3.147e+00, Loss Aux: 1.491e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4526, It: 0, Loss Data: 1.021e-01, Loss Eqns: 3.120e+00, Loss Aux: 1.468e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4527, It: 0, Loss Data: 9.917e-02, Loss Eqns: 3.163e+00, Loss Aux: 1.207e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4528, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.025e+00, Loss Aux: 9.882e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4529, It: 0, Loss Data: 1.220e-01, Loss Eqns: 2.991e+00, Loss Aux: 7.764e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4530, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.161e+00, Loss Aux: 6.179e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4531, It: 0, Loss Data: 1.289e-01, Loss Eqns: 3.004e+00, Loss Aux: 5.744e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4532, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.009e+00, Loss Aux: 5.605e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4533, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.131e+00, Loss Aux: 1.193e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4534, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.256e+00, Loss Aux: 1.495e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4535, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.088e+00, Loss Aux: 8.559e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4536, It: 0, Loss Data: 1.004e-01, Loss Eqns: 3.057e+00, Loss Aux: 8.454e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4537, It: 0, Loss Data: 1.209e-01, Loss Eqns: 3.131e+00, Loss Aux: 1.523e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4538, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.490e+00, Loss Aux: 9.852e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4539, It: 0, Loss Data: 1.034e-01, Loss Eqns: 3.228e+00, Loss Aux: 6.849e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4540, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.278e+00, Loss Aux: 6.843e-03, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 4541, It: 0, Loss Data: 9.996e-02, Loss Eqns: 3.105e+00, Loss Aux: 7.522e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4542, It: 0, Loss Data: 1.308e-01, Loss Eqns: 3.076e+00, Loss Aux: 1.460e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 4543, It: 0, Loss Data: 3.004e-01, Loss Eqns: 4.574e+00, Loss Aux: 2.077e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4544, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.508e+00, Loss Aux: 2.506e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4545, It: 0, Loss Data: 2.855e-01, Loss Eqns: 4.523e+00, Loss Aux: 4.670e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 4546, It: 0, Loss Data: 1.619e-01, Loss Eqns: 3.984e+00, Loss Aux: 9.813e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4547, It: 0, Loss Data: 2.359e-01, Loss Eqns: 4.768e+00, Loss Aux: 5.881e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4548, It: 0, Loss Data: 1.642e-01, Loss Eqns: 3.234e+00, Loss Aux: 1.484e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4549, It: 0, Loss Data: 2.545e-01, Loss Eqns: 4.082e+00, Loss Aux: 2.304e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4550, It: 0, Loss Data: 1.457e-01, Loss Eqns: 3.021e+00, Loss Aux: 6.334e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 4551, It: 0, Loss Data: 2.026e-01, Loss Eqns: 3.723e+00, Loss Aux: 9.434e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4552, It: 0, Loss Data: 1.741e-01, Loss Eqns: 2.959e+00, Loss Aux: 3.498e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4553, It: 0, Loss Data: 1.706e-01, Loss Eqns: 2.765e+00, Loss Aux: 2.647e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4554, It: 0, Loss Data: 1.871e-01, Loss Eqns: 3.010e+00, Loss Aux: 1.179e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4555, It: 0, Loss Data: 1.523e-01, Loss Eqns: 2.975e+00, Loss Aux: 1.217e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4556, It: 0, Loss Data: 1.383e-01, Loss Eqns: 2.863e+00, Loss Aux: 1.617e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4557, It: 0, Loss Data: 1.503e-01, Loss Eqns: 2.842e+00, Loss Aux: 1.431e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4558, It: 0, Loss Data: 1.286e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.125e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4559, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.031e+00, Loss Aux: 1.235e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4560, It: 0, Loss Data: 1.480e-01, Loss Eqns: 3.033e+00, Loss Aux: 1.771e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4561, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.011e+00, Loss Aux: 1.569e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4562, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.080e+00, Loss Aux: 1.032e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4563, It: 0, Loss Data: 1.281e-01, Loss Eqns: 2.959e+00, Loss Aux: 1.033e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4564, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.235e+00, Loss Aux: 1.621e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4565, It: 0, Loss Data: 8.812e-02, Loss Eqns: 3.407e+00, Loss Aux: 1.555e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4566, It: 0, Loss Data: 1.099e-01, Loss Eqns: 3.420e+00, Loss Aux: 9.887e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4567, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.134e+00, Loss Aux: 7.783e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4568, It: 0, Loss Data: 8.630e-02, Loss Eqns: 3.193e+00, Loss Aux: 6.773e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4569, It: 0, Loss Data: 1.175e-01, Loss Eqns: 3.225e+00, Loss Aux: 6.922e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4570, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.102e+00, Loss Aux: 7.890e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4571, It: 0, Loss Data: 1.127e-01, Loss Eqns: 3.294e+00, Loss Aux: 7.970e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4572, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.182e+00, Loss Aux: 7.889e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4573, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.265e+00, Loss Aux: 1.131e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4574, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.985e+00, Loss Aux: 1.177e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4575, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.008e+00, Loss Aux: 7.024e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4576, It: 0, Loss Data: 1.252e-01, Loss Eqns: 2.955e+00, Loss Aux: 6.703e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4577, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.085e+00, Loss Aux: 1.455e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4578, It: 0, Loss Data: 1.155e-01, Loss Eqns: 3.110e+00, Loss Aux: 1.698e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4579, It: 0, Loss Data: 1.200e-01, Loss Eqns: 3.028e+00, Loss Aux: 6.597e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4580, It: 0, Loss Data: 1.237e-01, Loss Eqns: 3.108e+00, Loss Aux: 9.394e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4581, It: 0, Loss Data: 1.094e-01, Loss Eqns: 3.060e+00, Loss Aux: 7.367e-03, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 4582, It: 0, Loss Data: 1.189e-01, Loss Eqns: 3.278e+00, Loss Aux: 8.644e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4583, It: 0, Loss Data: 1.017e-01, Loss Eqns: 3.160e+00, Loss Aux: 1.524e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4584, It: 0, Loss Data: 9.825e-02, Loss Eqns: 3.127e+00, Loss Aux: 1.706e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4585, It: 0, Loss Data: 1.087e-01, Loss Eqns: 3.065e+00, Loss Aux: 9.062e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 4586, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.176e+00, Loss Aux: 8.568e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4587, It: 0, Loss Data: 1.049e-01, Loss Eqns: 3.109e+00, Loss Aux: 9.391e-03, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 4588, It: 0, Loss Data: 1.126e-01, Loss Eqns: 3.194e+00, Loss Aux: 8.798e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4589, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.297e+00, Loss Aux: 7.326e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4590, It: 0, Loss Data: 1.133e-01, Loss Eqns: 3.025e+00, Loss Aux: 8.385e-03, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 4591, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.046e+00, Loss Aux: 1.258e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4592, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.169e+00, Loss Aux: 1.467e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4593, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.259e+00, Loss Aux: 1.291e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4594, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.969e+00, Loss Aux: 1.483e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4595, It: 0, Loss Data: 9.133e-02, Loss Eqns: 3.112e+00, Loss Aux: 1.605e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4596, It: 0, Loss Data: 1.104e-01, Loss Eqns: 3.061e+00, Loss Aux: 7.552e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4597, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.099e+00, Loss Aux: 6.081e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4598, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.970e+00, Loss Aux: 7.956e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4599, It: 0, Loss Data: 9.973e-02, Loss Eqns: 3.006e+00, Loss Aux: 1.003e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4600, It: 0, Loss Data: 1.238e-01, Loss Eqns: 3.134e+00, Loss Aux: 1.065e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4601, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.197e+00, Loss Aux: 1.402e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4602, It: 0, Loss Data: 1.129e-01, Loss Eqns: 2.987e+00, Loss Aux: 1.486e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 4603, It: 0, Loss Data: 1.085e-01, Loss Eqns: 3.042e+00, Loss Aux: 1.031e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4604, It: 0, Loss Data: 1.205e-01, Loss Eqns: 2.956e+00, Loss Aux: 9.023e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4605, It: 0, Loss Data: 1.235e-01, Loss Eqns: 2.977e+00, Loss Aux: 9.797e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4606, It: 0, Loss Data: 1.083e-01, Loss Eqns: 3.200e+00, Loss Aux: 9.318e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4607, It: 0, Loss Data: 1.225e-01, Loss Eqns: 3.097e+00, Loss Aux: 5.095e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4608, It: 0, Loss Data: 1.257e-01, Loss Eqns: 2.887e+00, Loss Aux: 4.422e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4609, It: 0, Loss Data: 1.023e-01, Loss Eqns: 3.148e+00, Loss Aux: 5.889e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4610, It: 0, Loss Data: 8.615e-02, Loss Eqns: 3.127e+00, Loss Aux: 6.277e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4611, It: 0, Loss Data: 1.003e-01, Loss Eqns: 3.206e+00, Loss Aux: 9.488e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4612, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.216e+00, Loss Aux: 1.535e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4613, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.198e+00, Loss Aux: 1.422e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4614, It: 0, Loss Data: 9.452e-02, Loss Eqns: 3.316e+00, Loss Aux: 9.685e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4615, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.973e+00, Loss Aux: 6.934e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4616, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.201e+00, Loss Aux: 6.394e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4617, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.010e+00, Loss Aux: 6.353e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4618, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.123e+00, Loss Aux: 5.055e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4619, It: 0, Loss Data: 9.551e-02, Loss Eqns: 2.975e+00, Loss Aux: 6.733e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4620, It: 0, Loss Data: 1.587e-01, Loss Eqns: 3.814e+00, Loss Aux: 2.671e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4621, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.306e+00, Loss Aux: 1.728e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4622, It: 0, Loss Data: 1.252e-01, Loss Eqns: 3.641e+00, Loss Aux: 9.857e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4623, It: 0, Loss Data: 2.071e-01, Loss Eqns: 3.308e+00, Loss Aux: 1.702e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4624, It: 0, Loss Data: 1.442e-01, Loss Eqns: 3.073e+00, Loss Aux: 1.804e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4625, It: 0, Loss Data: 1.573e-01, Loss Eqns: 3.267e+00, Loss Aux: 2.128e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4626, It: 0, Loss Data: 1.444e-01, Loss Eqns: 2.975e+00, Loss Aux: 2.510e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4627, It: 0, Loss Data: 1.674e-01, Loss Eqns: 3.241e+00, Loss Aux: 5.265e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4628, It: 0, Loss Data: 1.371e-01, Loss Eqns: 3.119e+00, Loss Aux: 2.662e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4629, It: 0, Loss Data: 1.821e-01, Loss Eqns: 2.907e+00, Loss Aux: 1.531e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4630, It: 0, Loss Data: 1.444e-01, Loss Eqns: 2.906e+00, Loss Aux: 1.717e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4631, It: 0, Loss Data: 1.387e-01, Loss Eqns: 3.107e+00, Loss Aux: 1.335e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4632, It: 0, Loss Data: 1.173e-01, Loss Eqns: 3.039e+00, Loss Aux: 8.399e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4633, It: 0, Loss Data: 1.401e-01, Loss Eqns: 3.013e+00, Loss Aux: 8.777e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4634, It: 0, Loss Data: 1.277e-01, Loss Eqns: 3.187e+00, Loss Aux: 1.669e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4635, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.853e+00, Loss Aux: 2.968e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4636, It: 0, Loss Data: 1.285e-01, Loss Eqns: 3.049e+00, Loss Aux: 3.126e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4637, It: 0, Loss Data: 1.280e-01, Loss Eqns: 3.167e+00, Loss Aux: 2.630e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4638, It: 0, Loss Data: 1.577e-01, Loss Eqns: 3.164e+00, Loss Aux: 2.084e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4639, It: 0, Loss Data: 1.079e-01, Loss Eqns: 3.030e+00, Loss Aux: 1.229e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4640, It: 0, Loss Data: 1.165e-01, Loss Eqns: 3.182e+00, Loss Aux: 8.306e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4641, It: 0, Loss Data: 1.179e-01, Loss Eqns: 2.931e+00, Loss Aux: 6.299e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4642, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.052e+00, Loss Aux: 6.760e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4643, It: 0, Loss Data: 1.216e-01, Loss Eqns: 3.129e+00, Loss Aux: 8.260e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4644, It: 0, Loss Data: 1.314e-01, Loss Eqns: 3.146e+00, Loss Aux: 1.001e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4645, It: 0, Loss Data: 9.473e-02, Loss Eqns: 3.077e+00, Loss Aux: 1.505e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4646, It: 0, Loss Data: 1.052e-01, Loss Eqns: 3.080e+00, Loss Aux: 1.284e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4647, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.128e+00, Loss Aux: 9.176e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4648, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.909e+00, Loss Aux: 1.091e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 4649, It: 0, Loss Data: 1.120e-01, Loss Eqns: 3.215e+00, Loss Aux: 1.485e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4650, It: 0, Loss Data: 1.092e-01, Loss Eqns: 3.078e+00, Loss Aux: 1.222e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4651, It: 0, Loss Data: 1.265e-01, Loss Eqns: 3.037e+00, Loss Aux: 8.729e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4652, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.068e+00, Loss Aux: 7.295e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4653, It: 0, Loss Data: 1.038e-01, Loss Eqns: 3.041e+00, Loss Aux: 7.055e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4654, It: 0, Loss Data: 1.186e-01, Loss Eqns: 3.073e+00, Loss Aux: 6.961e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4655, It: 0, Loss Data: 1.269e-01, Loss Eqns: 2.999e+00, Loss Aux: 6.460e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4656, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.922e+00, Loss Aux: 7.020e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 4657, It: 0, Loss Data: 1.219e-01, Loss Eqns: 3.114e+00, Loss Aux: 5.759e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4658, It: 0, Loss Data: 9.992e-02, Loss Eqns: 3.083e+00, Loss Aux: 5.995e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4659, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.040e+00, Loss Aux: 1.064e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4660, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.932e+00, Loss Aux: 1.326e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4661, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.998e+00, Loss Aux: 9.542e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4662, It: 0, Loss Data: 1.026e-01, Loss Eqns: 3.023e+00, Loss Aux: 8.550e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4663, It: 0, Loss Data: 1.095e-01, Loss Eqns: 3.046e+00, Loss Aux: 8.564e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4664, It: 0, Loss Data: 9.394e-02, Loss Eqns: 3.175e+00, Loss Aux: 9.245e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4665, It: 0, Loss Data: 1.082e-01, Loss Eqns: 3.051e+00, Loss Aux: 6.834e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 4666, It: 0, Loss Data: 9.388e-02, Loss Eqns: 3.010e+00, Loss Aux: 7.238e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4667, It: 0, Loss Data: 9.788e-02, Loss Eqns: 3.073e+00, Loss Aux: 1.139e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4668, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.965e+00, Loss Aux: 1.547e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 4669, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.983e+00, Loss Aux: 1.199e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4670, It: 0, Loss Data: 1.040e-01, Loss Eqns: 3.046e+00, Loss Aux: 4.644e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4671, It: 0, Loss Data: 1.263e-01, Loss Eqns: 2.936e+00, Loss Aux: 4.702e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4672, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.987e+00, Loss Aux: 7.718e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4673, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.064e+00, Loss Aux: 1.259e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4674, It: 0, Loss Data: 1.112e-01, Loss Eqns: 3.057e+00, Loss Aux: 1.280e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4675, It: 0, Loss Data: 1.122e-01, Loss Eqns: 3.112e+00, Loss Aux: 1.284e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4676, It: 0, Loss Data: 1.164e-01, Loss Eqns: 3.152e+00, Loss Aux: 1.727e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4677, It: 0, Loss Data: 1.283e-01, Loss Eqns: 2.892e+00, Loss Aux: 1.546e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4678, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.048e+00, Loss Aux: 5.823e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4679, It: 0, Loss Data: 1.029e-01, Loss Eqns: 3.101e+00, Loss Aux: 5.958e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4680, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.993e+00, Loss Aux: 4.168e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4681, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.009e+00, Loss Aux: 1.897e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4682, It: 0, Loss Data: 1.081e-01, Loss Eqns: 3.002e+00, Loss Aux: 3.398e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4683, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.919e+00, Loss Aux: 2.086e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4684, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.217e+00, Loss Aux: 1.058e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4685, It: 0, Loss Data: 9.821e-02, Loss Eqns: 3.213e+00, Loss Aux: 9.416e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4686, It: 0, Loss Data: 1.055e-01, Loss Eqns: 3.007e+00, Loss Aux: 1.088e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4687, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.093e+00, Loss Aux: 1.061e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4688, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.095e+00, Loss Aux: 9.895e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4689, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.930e+00, Loss Aux: 9.911e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4690, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.752e+00, Loss Aux: 1.451e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4691, It: 0, Loss Data: 1.250e-01, Loss Eqns: 2.940e+00, Loss Aux: 1.845e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4692, It: 0, Loss Data: 1.439e-01, Loss Eqns: 3.078e+00, Loss Aux: 1.848e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4693, It: 0, Loss Data: 1.468e-01, Loss Eqns: 3.367e+00, Loss Aux: 3.987e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4694, It: 0, Loss Data: 1.295e-01, Loss Eqns: 3.199e+00, Loss Aux: 4.387e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4695, It: 0, Loss Data: 1.383e-01, Loss Eqns: 3.604e+00, Loss Aux: 1.686e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4696, It: 0, Loss Data: 1.323e-01, Loss Eqns: 3.250e+00, Loss Aux: 1.004e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4697, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.073e+00, Loss Aux: 1.530e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4698, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.062e+00, Loss Aux: 2.108e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4699, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.953e+00, Loss Aux: 1.391e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4700, It: 0, Loss Data: 1.324e-01, Loss Eqns: 3.137e+00, Loss Aux: 1.032e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4701, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.880e+00, Loss Aux: 1.122e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4702, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.137e+00, Loss Aux: 1.054e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4703, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.795e+00, Loss Aux: 7.435e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4704, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.902e+00, Loss Aux: 6.944e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4705, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.986e+00, Loss Aux: 1.282e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4706, It: 0, Loss Data: 1.231e-01, Loss Eqns: 3.028e+00, Loss Aux: 2.094e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4707, It: 0, Loss Data: 9.464e-02, Loss Eqns: 3.043e+00, Loss Aux: 8.218e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4708, It: 0, Loss Data: 1.266e-01, Loss Eqns: 3.067e+00, Loss Aux: 3.518e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4709, It: 0, Loss Data: 9.802e-02, Loss Eqns: 3.230e+00, Loss Aux: 3.317e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4710, It: 0, Loss Data: 1.136e-01, Loss Eqns: 2.945e+00, Loss Aux: 5.296e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4711, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.007e+00, Loss Aux: 6.506e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4712, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.881e+00, Loss Aux: 9.441e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4713, It: 0, Loss Data: 1.245e-01, Loss Eqns: 3.019e+00, Loss Aux: 1.735e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4714, It: 0, Loss Data: 1.115e-01, Loss Eqns: 3.237e+00, Loss Aux: 1.638e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4715, It: 0, Loss Data: 9.854e-02, Loss Eqns: 2.990e+00, Loss Aux: 1.068e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4716, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.891e+00, Loss Aux: 8.706e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4717, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.956e+00, Loss Aux: 9.022e-03, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 4718, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.932e+00, Loss Aux: 5.476e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4719, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.102e+00, Loss Aux: 3.309e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 4720, It: 0, Loss Data: 9.559e-02, Loss Eqns: 3.038e+00, Loss Aux: 2.846e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4721, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.052e+00, Loss Aux: 3.973e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4722, It: 0, Loss Data: 1.302e-01, Loss Eqns: 2.965e+00, Loss Aux: 6.292e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4723, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.081e+00, Loss Aux: 1.187e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4724, It: 0, Loss Data: 1.203e-01, Loss Eqns: 3.106e+00, Loss Aux: 2.007e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4725, It: 0, Loss Data: 1.151e-01, Loss Eqns: 3.028e+00, Loss Aux: 1.708e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4726, It: 0, Loss Data: 1.242e-01, Loss Eqns: 3.097e+00, Loss Aux: 1.206e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4727, It: 0, Loss Data: 9.636e-02, Loss Eqns: 2.970e+00, Loss Aux: 1.032e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4728, It: 0, Loss Data: 1.050e-01, Loss Eqns: 3.182e+00, Loss Aux: 8.225e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4729, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.116e+00, Loss Aux: 7.194e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4730, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.277e+00, Loss Aux: 5.848e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4731, It: 0, Loss Data: 9.806e-02, Loss Eqns: 3.041e+00, Loss Aux: 1.150e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4732, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.947e+00, Loss Aux: 1.392e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4733, It: 0, Loss Data: 1.298e-01, Loss Eqns: 2.961e+00, Loss Aux: 9.803e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4734, It: 0, Loss Data: 1.107e-01, Loss Eqns: 3.087e+00, Loss Aux: 7.347e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4735, It: 0, Loss Data: 1.007e-01, Loss Eqns: 3.066e+00, Loss Aux: 7.587e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4736, It: 0, Loss Data: 1.050e-01, Loss Eqns: 3.001e+00, Loss Aux: 7.573e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4737, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.114e+00, Loss Aux: 6.863e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4738, It: 0, Loss Data: 1.070e-01, Loss Eqns: 3.054e+00, Loss Aux: 9.882e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 4739, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.153e+00, Loss Aux: 1.143e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4740, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.936e+00, Loss Aux: 9.766e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4741, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.999e+00, Loss Aux: 8.468e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4742, It: 0, Loss Data: 9.267e-02, Loss Eqns: 3.178e+00, Loss Aux: 9.071e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4743, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.958e+00, Loss Aux: 8.736e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4744, It: 0, Loss Data: 1.267e-01, Loss Eqns: 2.968e+00, Loss Aux: 9.632e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4745, It: 0, Loss Data: 1.136e-01, Loss Eqns: 3.034e+00, Loss Aux: 9.342e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 4746, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.856e+00, Loss Aux: 1.064e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4747, It: 0, Loss Data: 1.062e-01, Loss Eqns: 3.008e+00, Loss Aux: 1.037e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4748, It: 0, Loss Data: 1.102e-01, Loss Eqns: 3.081e+00, Loss Aux: 9.521e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4749, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.962e+00, Loss Aux: 6.694e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4750, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.000e+00, Loss Aux: 5.454e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4751, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.943e+00, Loss Aux: 7.183e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4752, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.076e+00, Loss Aux: 1.260e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4753, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.160e+00, Loss Aux: 1.253e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4754, It: 0, Loss Data: 9.891e-02, Loss Eqns: 3.065e+00, Loss Aux: 7.243e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4755, It: 0, Loss Data: 9.921e-02, Loss Eqns: 3.025e+00, Loss Aux: 6.964e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4756, It: 0, Loss Data: 1.254e-01, Loss Eqns: 2.932e+00, Loss Aux: 9.684e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 4757, It: 0, Loss Data: 1.061e-01, Loss Eqns: 3.069e+00, Loss Aux: 9.754e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4758, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.878e+00, Loss Aux: 1.014e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4759, It: 0, Loss Data: 1.191e-01, Loss Eqns: 2.957e+00, Loss Aux: 8.511e-03, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 4760, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.947e+00, Loss Aux: 6.169e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4761, It: 0, Loss Data: 1.036e-01, Loss Eqns: 3.026e+00, Loss Aux: 3.836e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4762, It: 0, Loss Data: 9.908e-02, Loss Eqns: 3.037e+00, Loss Aux: 3.765e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4763, It: 0, Loss Data: 9.671e-02, Loss Eqns: 3.018e+00, Loss Aux: 7.567e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4764, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.894e+00, Loss Aux: 1.480e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4765, It: 0, Loss Data: 9.856e-02, Loss Eqns: 3.082e+00, Loss Aux: 1.403e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4766, It: 0, Loss Data: 1.229e-01, Loss Eqns: 2.974e+00, Loss Aux: 1.139e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 4767, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.982e+00, Loss Aux: 1.103e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 4768, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.984e+00, Loss Aux: 1.086e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 4769, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.899e+00, Loss Aux: 8.954e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4770, It: 0, Loss Data: 9.264e-02, Loss Eqns: 2.936e+00, Loss Aux: 5.953e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4771, It: 0, Loss Data: 1.056e-01, Loss Eqns: 3.018e+00, Loss Aux: 5.137e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4772, It: 0, Loss Data: 9.924e-02, Loss Eqns: 2.879e+00, Loss Aux: 9.007e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4773, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.963e+00, Loss Aux: 1.479e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4774, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.911e+00, Loss Aux: 1.467e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 4775, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.037e+00, Loss Aux: 8.293e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4776, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.994e+00, Loss Aux: 6.206e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4777, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.903e+00, Loss Aux: 6.827e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4778, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.924e+00, Loss Aux: 6.575e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4779, It: 0, Loss Data: 1.129e-01, Loss Eqns: 3.065e+00, Loss Aux: 6.548e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 4780, It: 0, Loss Data: 1.158e-01, Loss Eqns: 3.053e+00, Loss Aux: 8.648e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4781, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.023e+00, Loss Aux: 1.634e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 4782, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.999e+00, Loss Aux: 1.493e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4783, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.981e+00, Loss Aux: 7.102e-03, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 4784, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.076e+00, Loss Aux: 4.173e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4785, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.908e+00, Loss Aux: 5.795e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4786, It: 0, Loss Data: 1.198e-01, Loss Eqns: 2.972e+00, Loss Aux: 1.257e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4787, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.943e+00, Loss Aux: 8.745e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 4788, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.959e+00, Loss Aux: 6.729e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4789, It: 0, Loss Data: 1.133e-01, Loss Eqns: 3.046e+00, Loss Aux: 8.406e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4790, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.105e+00, Loss Aux: 9.007e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 4791, It: 0, Loss Data: 1.051e-01, Loss Eqns: 3.098e+00, Loss Aux: 9.507e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 4792, It: 0, Loss Data: 9.786e-02, Loss Eqns: 3.125e+00, Loss Aux: 9.929e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4793, It: 0, Loss Data: 1.194e-01, Loss Eqns: 3.049e+00, Loss Aux: 1.168e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4794, It: 0, Loss Data: 1.173e-01, Loss Eqns: 2.995e+00, Loss Aux: 1.760e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4795, It: 0, Loss Data: 1.036e-01, Loss Eqns: 3.133e+00, Loss Aux: 1.874e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4796, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.032e+00, Loss Aux: 1.157e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4797, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.017e+00, Loss Aux: 5.200e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4798, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.951e+00, Loss Aux: 8.106e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 4799, It: 0, Loss Data: 1.100e-01, Loss Eqns: 3.044e+00, Loss Aux: 1.199e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4800, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.917e+00, Loss Aux: 9.350e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4801, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.879e+00, Loss Aux: 5.760e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4802, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.909e+00, Loss Aux: 6.085e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4803, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.910e+00, Loss Aux: 1.066e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4804, It: 0, Loss Data: 1.284e-01, Loss Eqns: 2.974e+00, Loss Aux: 1.573e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4805, It: 0, Loss Data: 1.174e-01, Loss Eqns: 3.070e+00, Loss Aux: 1.234e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4806, It: 0, Loss Data: 1.132e-01, Loss Eqns: 3.051e+00, Loss Aux: 1.024e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4807, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.037e+00, Loss Aux: 9.715e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4808, It: 0, Loss Data: 1.064e-01, Loss Eqns: 3.172e+00, Loss Aux: 8.032e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4809, It: 0, Loss Data: 1.039e-01, Loss Eqns: 3.128e+00, Loss Aux: 6.617e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4810, It: 0, Loss Data: 9.868e-02, Loss Eqns: 2.909e+00, Loss Aux: 8.127e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4811, It: 0, Loss Data: 1.091e-01, Loss Eqns: 3.035e+00, Loss Aux: 1.065e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4812, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.945e+00, Loss Aux: 8.884e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4813, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.997e+00, Loss Aux: 9.416e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4814, It: 0, Loss Data: 1.030e-01, Loss Eqns: 3.092e+00, Loss Aux: 9.467e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4815, It: 0, Loss Data: 1.024e-01, Loss Eqns: 3.095e+00, Loss Aux: 7.218e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4816, It: 0, Loss Data: 1.137e-01, Loss Eqns: 3.061e+00, Loss Aux: 6.683e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4817, It: 0, Loss Data: 1.106e-01, Loss Eqns: 3.041e+00, Loss Aux: 7.593e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4818, It: 0, Loss Data: 1.020e-01, Loss Eqns: 3.207e+00, Loss Aux: 9.460e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4819, It: 0, Loss Data: 1.004e-01, Loss Eqns: 3.134e+00, Loss Aux: 6.171e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4820, It: 0, Loss Data: 9.690e-02, Loss Eqns: 3.102e+00, Loss Aux: 3.206e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4821, It: 0, Loss Data: 9.328e-02, Loss Eqns: 3.015e+00, Loss Aux: 4.256e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4822, It: 0, Loss Data: 1.240e-01, Loss Eqns: 2.914e+00, Loss Aux: 7.464e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 4823, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.916e+00, Loss Aux: 1.206e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4824, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.988e+00, Loss Aux: 1.132e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4825, It: 0, Loss Data: 1.181e-01, Loss Eqns: 2.988e+00, Loss Aux: 9.351e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4826, It: 0, Loss Data: 1.150e-01, Loss Eqns: 3.072e+00, Loss Aux: 1.005e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4827, It: 0, Loss Data: 9.857e-02, Loss Eqns: 2.938e+00, Loss Aux: 1.407e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4828, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.923e+00, Loss Aux: 1.397e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4829, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.884e+00, Loss Aux: 9.969e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4830, It: 0, Loss Data: 9.626e-02, Loss Eqns: 2.976e+00, Loss Aux: 5.517e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4831, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.916e+00, Loss Aux: 4.476e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4832, It: 0, Loss Data: 1.162e-01, Loss Eqns: 2.871e+00, Loss Aux: 5.533e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4833, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.951e+00, Loss Aux: 4.091e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4834, It: 0, Loss Data: 9.542e-02, Loss Eqns: 2.875e+00, Loss Aux: 3.746e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4835, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.033e+00, Loss Aux: 6.575e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4836, It: 0, Loss Data: 1.031e-01, Loss Eqns: 3.047e+00, Loss Aux: 1.099e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4837, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.990e+00, Loss Aux: 1.167e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4838, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.966e+00, Loss Aux: 1.076e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4839, It: 0, Loss Data: 1.176e-01, Loss Eqns: 3.120e+00, Loss Aux: 1.255e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4840, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.990e+00, Loss Aux: 1.235e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4841, It: 0, Loss Data: 1.288e-01, Loss Eqns: 2.969e+00, Loss Aux: 1.113e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4842, It: 0, Loss Data: 1.098e-01, Loss Eqns: 3.021e+00, Loss Aux: 5.386e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4843, It: 0, Loss Data: 1.170e-01, Loss Eqns: 2.969e+00, Loss Aux: 3.054e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4844, It: 0, Loss Data: 1.309e-01, Loss Eqns: 2.886e+00, Loss Aux: 5.594e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4845, It: 0, Loss Data: 1.011e-01, Loss Eqns: 3.070e+00, Loss Aux: 1.299e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4846, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.996e+00, Loss Aux: 1.494e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 4847, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.866e+00, Loss Aux: 1.004e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4848, It: 0, Loss Data: 9.182e-02, Loss Eqns: 3.044e+00, Loss Aux: 1.070e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4849, It: 0, Loss Data: 1.154e-01, Loss Eqns: 3.121e+00, Loss Aux: 1.086e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4850, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.980e+00, Loss Aux: 9.007e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4851, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.981e+00, Loss Aux: 4.617e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4852, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.809e+00, Loss Aux: 6.759e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4853, It: 0, Loss Data: 1.093e-01, Loss Eqns: 3.018e+00, Loss Aux: 1.440e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4854, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.900e+00, Loss Aux: 1.352e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4855, It: 0, Loss Data: 1.021e-01, Loss Eqns: 3.002e+00, Loss Aux: 8.640e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4856, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.855e+00, Loss Aux: 5.116e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 4857, It: 0, Loss Data: 1.301e-01, Loss Eqns: 2.821e+00, Loss Aux: 5.067e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4858, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.994e+00, Loss Aux: 6.734e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4859, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.926e+00, Loss Aux: 8.228e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4860, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.962e+00, Loss Aux: 9.501e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4861, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.942e+00, Loss Aux: 1.362e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 4862, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.832e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4863, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.858e+00, Loss Aux: 1.649e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 4864, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.915e+00, Loss Aux: 9.781e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 4865, It: 0, Loss Data: 1.180e-01, Loss Eqns: 3.004e+00, Loss Aux: 7.450e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4866, It: 0, Loss Data: 1.111e-01, Loss Eqns: 3.064e+00, Loss Aux: 7.320e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 4867, It: 0, Loss Data: 1.043e-01, Loss Eqns: 3.078e+00, Loss Aux: 1.090e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4868, It: 0, Loss Data: 1.006e-01, Loss Eqns: 3.122e+00, Loss Aux: 1.318e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4869, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.939e+00, Loss Aux: 1.595e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4870, It: 0, Loss Data: 1.211e-01, Loss Eqns: 3.099e+00, Loss Aux: 1.644e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 4871, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.966e+00, Loss Aux: 1.415e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 4872, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.980e+00, Loss Aux: 9.718e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4873, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.958e+00, Loss Aux: 8.287e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 4874, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.040e+00, Loss Aux: 8.208e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4875, It: 0, Loss Data: 1.274e-01, Loss Eqns: 3.082e+00, Loss Aux: 7.117e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4876, It: 0, Loss Data: 1.113e-01, Loss Eqns: 3.053e+00, Loss Aux: 9.267e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4877, It: 0, Loss Data: 1.128e-01, Loss Eqns: 3.386e+00, Loss Aux: 1.494e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4878, It: 0, Loss Data: 1.157e-01, Loss Eqns: 3.364e+00, Loss Aux: 1.164e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4879, It: 0, Loss Data: 9.826e-02, Loss Eqns: 3.312e+00, Loss Aux: 9.902e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4880, It: 0, Loss Data: 1.073e-01, Loss Eqns: 3.269e+00, Loss Aux: 1.395e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4881, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.003e+00, Loss Aux: 1.520e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 4882, It: 0, Loss Data: 1.021e-01, Loss Eqns: 3.002e+00, Loss Aux: 5.999e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4883, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.978e+00, Loss Aux: 4.306e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4884, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.036e+00, Loss Aux: 8.292e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 4885, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.961e+00, Loss Aux: 9.125e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4886, It: 0, Loss Data: 1.256e-01, Loss Eqns: 3.043e+00, Loss Aux: 6.168e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4887, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.910e+00, Loss Aux: 6.704e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4888, It: 0, Loss Data: 1.230e-01, Loss Eqns: 2.930e+00, Loss Aux: 8.667e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4889, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.898e+00, Loss Aux: 8.962e-03, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 4890, It: 0, Loss Data: 1.263e-01, Loss Eqns: 3.033e+00, Loss Aux: 8.176e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4891, It: 0, Loss Data: 1.138e-01, Loss Eqns: 3.047e+00, Loss Aux: 7.342e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 4892, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.848e+00, Loss Aux: 7.231e-03, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 4893, It: 0, Loss Data: 1.034e-01, Loss Eqns: 3.108e+00, Loss Aux: 5.754e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4894, It: 0, Loss Data: 1.148e-01, Loss Eqns: 3.031e+00, Loss Aux: 7.312e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4895, It: 0, Loss Data: 1.074e-01, Loss Eqns: 3.198e+00, Loss Aux: 8.066e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 4896, It: 0, Loss Data: 9.543e-02, Loss Eqns: 3.123e+00, Loss Aux: 4.464e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4897, It: 0, Loss Data: 1.131e-01, Loss Eqns: 3.088e+00, Loss Aux: 4.880e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4898, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.000e+00, Loss Aux: 1.032e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4899, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.164e+00, Loss Aux: 6.207e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4900, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.913e+00, Loss Aux: 5.476e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4901, It: 0, Loss Data: 9.942e-02, Loss Eqns: 2.970e+00, Loss Aux: 1.009e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 4902, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.943e+00, Loss Aux: 2.075e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 4903, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.955e+00, Loss Aux: 1.382e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4904, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.974e+00, Loss Aux: 6.692e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4905, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.880e+00, Loss Aux: 6.013e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4906, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.017e+00, Loss Aux: 6.599e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4907, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.990e+00, Loss Aux: 7.388e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4908, It: 0, Loss Data: 9.236e-02, Loss Eqns: 2.956e+00, Loss Aux: 1.049e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4909, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.899e+00, Loss Aux: 1.585e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4910, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.966e+00, Loss Aux: 1.849e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4911, It: 0, Loss Data: 9.988e-02, Loss Eqns: 2.930e+00, Loss Aux: 1.529e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4912, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.988e+00, Loss Aux: 1.210e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 4913, It: 0, Loss Data: 1.286e-01, Loss Eqns: 2.854e+00, Loss Aux: 5.812e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 4914, It: 0, Loss Data: 1.155e-01, Loss Eqns: 2.933e+00, Loss Aux: 2.935e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4915, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.872e+00, Loss Aux: 3.452e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4916, It: 0, Loss Data: 9.213e-02, Loss Eqns: 2.984e+00, Loss Aux: 5.641e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4917, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.872e+00, Loss Aux: 8.812e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 4918, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.938e+00, Loss Aux: 1.419e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4919, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.858e+00, Loss Aux: 1.817e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4920, It: 0, Loss Data: 9.808e-02, Loss Eqns: 2.943e+00, Loss Aux: 1.875e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4921, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.933e+00, Loss Aux: 1.232e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4922, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.844e+00, Loss Aux: 8.623e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 4923, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.894e+00, Loss Aux: 6.804e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4924, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.866e+00, Loss Aux: 6.161e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4925, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.840e+00, Loss Aux: 6.282e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4926, It: 0, Loss Data: 1.556e-01, Loss Eqns: 3.209e+00, Loss Aux: 1.243e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4927, It: 0, Loss Data: 1.776e-01, Loss Eqns: 3.777e+00, Loss Aux: 4.980e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4928, It: 0, Loss Data: 1.474e-01, Loss Eqns: 3.947e+00, Loss Aux: 1.221e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 4929, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.703e+00, Loss Aux: 1.894e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4930, It: 0, Loss Data: 1.826e-01, Loss Eqns: 4.291e+00, Loss Aux: 1.542e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4931, It: 0, Loss Data: 1.728e-01, Loss Eqns: 3.394e+00, Loss Aux: 1.149e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 4932, It: 0, Loss Data: 2.022e-01, Loss Eqns: 3.677e+00, Loss Aux: 1.052e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 4933, It: 0, Loss Data: 1.378e-01, Loss Eqns: 3.113e+00, Loss Aux: 2.121e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4934, It: 0, Loss Data: 1.808e-01, Loss Eqns: 3.433e+00, Loss Aux: 2.829e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4935, It: 0, Loss Data: 1.681e-01, Loss Eqns: 3.213e+00, Loss Aux: 1.218e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 4936, It: 0, Loss Data: 1.338e-01, Loss Eqns: 3.293e+00, Loss Aux: 5.158e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4937, It: 0, Loss Data: 1.584e-01, Loss Eqns: 2.916e+00, Loss Aux: 1.231e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 4938, It: 0, Loss Data: 1.887e-01, Loss Eqns: 2.962e+00, Loss Aux: 1.398e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4939, It: 0, Loss Data: 1.539e-01, Loss Eqns: 2.824e+00, Loss Aux: 9.018e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 4940, It: 0, Loss Data: 1.708e-01, Loss Eqns: 2.809e+00, Loss Aux: 7.586e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4941, It: 0, Loss Data: 1.440e-01, Loss Eqns: 2.921e+00, Loss Aux: 3.112e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4942, It: 0, Loss Data: 1.659e-01, Loss Eqns: 2.862e+00, Loss Aux: 3.933e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4943, It: 0, Loss Data: 1.170e-01, Loss Eqns: 3.084e+00, Loss Aux: 1.811e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 4944, It: 0, Loss Data: 1.485e-01, Loss Eqns: 2.933e+00, Loss Aux: 1.079e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 4945, It: 0, Loss Data: 1.588e-01, Loss Eqns: 3.004e+00, Loss Aux: 1.517e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4946, It: 0, Loss Data: 1.379e-01, Loss Eqns: 2.849e+00, Loss Aux: 1.637e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 4947, It: 0, Loss Data: 1.345e-01, Loss Eqns: 3.102e+00, Loss Aux: 7.511e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4948, It: 0, Loss Data: 1.260e-01, Loss Eqns: 3.076e+00, Loss Aux: 5.032e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 4949, It: 0, Loss Data: 1.358e-01, Loss Eqns: 3.102e+00, Loss Aux: 1.016e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4950, It: 0, Loss Data: 1.200e-01, Loss Eqns: 2.700e+00, Loss Aux: 9.468e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4951, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.980e+00, Loss Aux: 7.158e-03, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 4952, It: 0, Loss Data: 1.405e-01, Loss Eqns: 2.891e+00, Loss Aux: 9.062e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4953, It: 0, Loss Data: 1.259e-01, Loss Eqns: 2.922e+00, Loss Aux: 1.125e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4954, It: 0, Loss Data: 1.204e-01, Loss Eqns: 3.004e+00, Loss Aux: 1.262e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4955, It: 0, Loss Data: 1.196e-01, Loss Eqns: 2.944e+00, Loss Aux: 1.323e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4956, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.988e+00, Loss Aux: 1.258e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4957, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.929e+00, Loss Aux: 7.569e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4958, It: 0, Loss Data: 1.295e-01, Loss Eqns: 2.871e+00, Loss Aux: 6.761e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4959, It: 0, Loss Data: 9.392e-02, Loss Eqns: 3.084e+00, Loss Aux: 8.774e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4960, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.994e+00, Loss Aux: 9.713e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4961, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.781e+00, Loss Aux: 7.813e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 4962, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.782e+00, Loss Aux: 6.354e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 4963, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.819e+00, Loss Aux: 6.516e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 4964, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.906e+00, Loss Aux: 7.354e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 4965, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.216e+00, Loss Aux: 5.145e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 4966, It: 0, Loss Data: 1.253e-01, Loss Eqns: 3.095e+00, Loss Aux: 1.191e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 4967, It: 0, Loss Data: 1.358e-01, Loss Eqns: 2.979e+00, Loss Aux: 1.649e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 4968, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.812e+00, Loss Aux: 1.239e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 4969, It: 0, Loss Data: 1.662e-01, Loss Eqns: 3.412e+00, Loss Aux: 6.851e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 4970, It: 0, Loss Data: 1.423e-01, Loss Eqns: 3.189e+00, Loss Aux: 6.400e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 4971, It: 0, Loss Data: 2.693e-01, Loss Eqns: 4.468e+00, Loss Aux: 2.436e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 4972, It: 0, Loss Data: 1.076e-01, Loss Eqns: 3.058e+00, Loss Aux: 8.119e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 4973, It: 0, Loss Data: 1.814e-01, Loss Eqns: 3.752e+00, Loss Aux: 6.024e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 4974, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.352e+00, Loss Aux: 8.458e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 4975, It: 0, Loss Data: 1.802e-01, Loss Eqns: 3.291e+00, Loss Aux: 2.537e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 4976, It: 0, Loss Data: 1.216e-01, Loss Eqns: 2.961e+00, Loss Aux: 1.135e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 4977, It: 0, Loss Data: 1.940e-01, Loss Eqns: 3.123e+00, Loss Aux: 6.914e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4978, It: 0, Loss Data: 1.364e-01, Loss Eqns: 2.961e+00, Loss Aux: 7.506e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 4979, It: 0, Loss Data: 1.847e-01, Loss Eqns: 3.023e+00, Loss Aux: 2.161e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 4980, It: 0, Loss Data: 1.492e-01, Loss Eqns: 2.706e+00, Loss Aux: 1.780e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4981, It: 0, Loss Data: 1.615e-01, Loss Eqns: 2.916e+00, Loss Aux: 7.349e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 4982, It: 0, Loss Data: 1.339e-01, Loss Eqns: 2.796e+00, Loss Aux: 8.408e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 4983, It: 0, Loss Data: 2.319e-01, Loss Eqns: 3.556e+00, Loss Aux: 2.605e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 4984, It: 0, Loss Data: 1.483e-01, Loss Eqns: 3.365e+00, Loss Aux: 1.482e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4985, It: 0, Loss Data: 1.928e-01, Loss Eqns: 3.963e+00, Loss Aux: 9.510e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 4986, It: 0, Loss Data: 1.169e-01, Loss Eqns: 3.143e+00, Loss Aux: 1.173e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 4987, It: 0, Loss Data: 1.966e-01, Loss Eqns: 3.688e+00, Loss Aux: 1.272e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 4988, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.826e+00, Loss Aux: 7.610e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 4989, It: 0, Loss Data: 1.642e-01, Loss Eqns: 3.445e+00, Loss Aux: 8.119e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4990, It: 0, Loss Data: 1.850e-01, Loss Eqns: 3.515e+00, Loss Aux: 7.913e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 4991, It: 0, Loss Data: 2.749e-01, Loss Eqns: 4.043e+00, Loss Aux: 3.310e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 4992, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.872e+00, Loss Aux: 3.180e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 4993, It: 0, Loss Data: 1.861e-01, Loss Eqns: 3.676e+00, Loss Aux: 1.636e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 4994, It: 0, Loss Data: 1.643e-01, Loss Eqns: 3.626e+00, Loss Aux: 1.584e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 4995, It: 0, Loss Data: 1.617e-01, Loss Eqns: 2.968e+00, Loss Aux: 1.998e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 4996, It: 0, Loss Data: 1.648e-01, Loss Eqns: 3.112e+00, Loss Aux: 8.653e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 4997, It: 0, Loss Data: 1.386e-01, Loss Eqns: 2.811e+00, Loss Aux: 4.464e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 4998, It: 0, Loss Data: 1.610e-01, Loss Eqns: 3.022e+00, Loss Aux: 4.273e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 4999, It: 0, Loss Data: 1.619e-01, Loss Eqns: 2.941e+00, Loss Aux: 1.630e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5000, It: 0, Loss Data: 1.659e-01, Loss Eqns: 2.870e+00, Loss Aux: 3.313e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5001, It: 0, Loss Data: 1.259e-01, Loss Eqns: 2.936e+00, Loss Aux: 1.929e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5002, It: 0, Loss Data: 1.541e-01, Loss Eqns: 2.772e+00, Loss Aux: 1.202e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5003, It: 0, Loss Data: 1.492e-01, Loss Eqns: 2.713e+00, Loss Aux: 1.163e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5004, It: 0, Loss Data: 1.417e-01, Loss Eqns: 2.769e+00, Loss Aux: 2.379e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5005, It: 0, Loss Data: 1.314e-01, Loss Eqns: 2.838e+00, Loss Aux: 1.883e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5006, It: 0, Loss Data: 1.314e-01, Loss Eqns: 2.805e+00, Loss Aux: 5.514e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5007, It: 0, Loss Data: 1.781e-01, Loss Eqns: 2.707e+00, Loss Aux: 4.071e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5008, It: 0, Loss Data: 1.262e-01, Loss Eqns: 2.815e+00, Loss Aux: 4.759e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5009, It: 0, Loss Data: 1.515e-01, Loss Eqns: 2.875e+00, Loss Aux: 1.785e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5010, It: 0, Loss Data: 1.063e-01, Loss Eqns: 3.080e+00, Loss Aux: 1.930e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5011, It: 0, Loss Data: 1.443e-01, Loss Eqns: 2.952e+00, Loss Aux: 1.131e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5012, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.948e+00, Loss Aux: 1.172e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5013, It: 0, Loss Data: 1.193e-01, Loss Eqns: 3.080e+00, Loss Aux: 1.981e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5014, It: 0, Loss Data: 1.201e-01, Loss Eqns: 3.039e+00, Loss Aux: 2.199e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5015, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.923e+00, Loss Aux: 1.492e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5016, It: 0, Loss Data: 1.167e-01, Loss Eqns: 2.997e+00, Loss Aux: 1.803e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5017, It: 0, Loss Data: 9.698e-02, Loss Eqns: 2.954e+00, Loss Aux: 1.417e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5018, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.894e+00, Loss Aux: 2.419e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5019, It: 0, Loss Data: 1.202e-01, Loss Eqns: 2.933e+00, Loss Aux: 3.138e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5020, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.871e+00, Loss Aux: 2.332e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5021, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.893e+00, Loss Aux: 1.167e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5022, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.874e+00, Loss Aux: 4.816e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5023, It: 0, Loss Data: 1.186e-01, Loss Eqns: 2.801e+00, Loss Aux: 6.029e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5024, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.982e+00, Loss Aux: 1.196e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5025, It: 0, Loss Data: 1.308e-01, Loss Eqns: 2.801e+00, Loss Aux: 1.052e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5026, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.866e+00, Loss Aux: 9.661e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5027, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.766e+00, Loss Aux: 1.236e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5028, It: 0, Loss Data: 9.219e-02, Loss Eqns: 2.918e+00, Loss Aux: 1.785e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5029, It: 0, Loss Data: 1.218e-01, Loss Eqns: 2.999e+00, Loss Aux: 2.347e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 5030, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.994e+00, Loss Aux: 1.706e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5031, It: 0, Loss Data: 1.216e-01, Loss Eqns: 2.823e+00, Loss Aux: 6.874e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5032, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.924e+00, Loss Aux: 4.207e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5033, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.749e+00, Loss Aux: 7.343e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5034, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.767e+00, Loss Aux: 7.546e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5035, It: 0, Loss Data: 1.239e-01, Loss Eqns: 2.846e+00, Loss Aux: 4.967e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5036, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.849e+00, Loss Aux: 4.572e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5037, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.955e+00, Loss Aux: 6.897e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5038, It: 0, Loss Data: 9.721e-02, Loss Eqns: 2.901e+00, Loss Aux: 1.588e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 5039, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.877e+00, Loss Aux: 2.003e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5040, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.892e+00, Loss Aux: 1.344e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 5041, It: 0, Loss Data: 1.219e-01, Loss Eqns: 2.911e+00, Loss Aux: 8.990e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5042, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.868e+00, Loss Aux: 1.131e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5043, It: 0, Loss Data: 1.239e-01, Loss Eqns: 2.887e+00, Loss Aux: 1.482e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5044, It: 0, Loss Data: 1.149e-01, Loss Eqns: 3.027e+00, Loss Aux: 1.018e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5045, It: 0, Loss Data: 1.204e-01, Loss Eqns: 2.905e+00, Loss Aux: 6.171e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5046, It: 0, Loss Data: 1.019e-01, Loss Eqns: 3.061e+00, Loss Aux: 4.982e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5047, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.981e+00, Loss Aux: 7.757e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5048, It: 0, Loss Data: 1.084e-01, Loss Eqns: 3.164e+00, Loss Aux: 1.141e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5049, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.975e+00, Loss Aux: 1.616e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5050, It: 0, Loss Data: 1.114e-01, Loss Eqns: 3.096e+00, Loss Aux: 1.789e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5051, It: 0, Loss Data: 8.760e-02, Loss Eqns: 3.050e+00, Loss Aux: 1.627e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5052, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.900e+00, Loss Aux: 1.242e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5053, It: 0, Loss Data: 1.015e-01, Loss Eqns: 3.020e+00, Loss Aux: 1.061e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5054, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.895e+00, Loss Aux: 7.637e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5055, It: 0, Loss Data: 1.119e-01, Loss Eqns: 3.092e+00, Loss Aux: 5.625e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5056, It: 0, Loss Data: 1.036e-01, Loss Eqns: 3.015e+00, Loss Aux: 4.835e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5057, It: 0, Loss Data: 9.909e-02, Loss Eqns: 2.984e+00, Loss Aux: 4.876e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5058, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.944e+00, Loss Aux: 8.735e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5059, It: 0, Loss Data: 8.870e-02, Loss Eqns: 2.796e+00, Loss Aux: 9.336e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5060, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.761e+00, Loss Aux: 8.739e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 5061, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.804e+00, Loss Aux: 1.275e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5062, It: 0, Loss Data: 1.283e-01, Loss Eqns: 2.861e+00, Loss Aux: 1.969e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5063, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.697e+00, Loss Aux: 1.388e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5064, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.748e+00, Loss Aux: 8.660e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5065, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.696e+00, Loss Aux: 7.136e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5066, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.763e+00, Loss Aux: 7.623e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5067, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.827e+00, Loss Aux: 1.190e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5068, It: 0, Loss Data: 1.155e-01, Loss Eqns: 2.826e+00, Loss Aux: 1.312e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5069, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.879e+00, Loss Aux: 1.465e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5070, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.844e+00, Loss Aux: 1.653e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5071, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.844e+00, Loss Aux: 1.032e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5072, It: 0, Loss Data: 9.852e-02, Loss Eqns: 2.932e+00, Loss Aux: 5.589e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5073, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.909e+00, Loss Aux: 5.972e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5074, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.880e+00, Loss Aux: 7.311e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5075, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.929e+00, Loss Aux: 8.312e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5076, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.898e+00, Loss Aux: 9.274e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5077, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.862e+00, Loss Aux: 1.303e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5078, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.958e+00, Loss Aux: 1.769e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5079, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.830e+00, Loss Aux: 1.850e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5080, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.885e+00, Loss Aux: 1.283e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5081, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.938e+00, Loss Aux: 7.091e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5082, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.852e+00, Loss Aux: 3.526e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5083, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.903e+00, Loss Aux: 3.187e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5084, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.892e+00, Loss Aux: 3.307e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5085, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.809e+00, Loss Aux: 5.187e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5086, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.890e+00, Loss Aux: 1.054e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5087, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.834e+00, Loss Aux: 1.648e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5088, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.820e+00, Loss Aux: 1.506e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5089, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.774e+00, Loss Aux: 9.704e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 5090, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.750e+00, Loss Aux: 6.578e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5091, It: 0, Loss Data: 9.426e-02, Loss Eqns: 2.791e+00, Loss Aux: 6.854e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5092, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.955e+00, Loss Aux: 8.380e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5093, It: 0, Loss Data: 1.207e-01, Loss Eqns: 2.889e+00, Loss Aux: 5.362e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5094, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.858e+00, Loss Aux: 7.413e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5095, It: 0, Loss Data: 9.482e-02, Loss Eqns: 2.943e+00, Loss Aux: 1.579e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5096, It: 0, Loss Data: 1.283e-01, Loss Eqns: 2.953e+00, Loss Aux: 2.327e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5097, It: 0, Loss Data: 9.989e-02, Loss Eqns: 2.825e+00, Loss Aux: 1.330e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5098, It: 0, Loss Data: 9.569e-02, Loss Eqns: 2.951e+00, Loss Aux: 5.988e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5099, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.856e+00, Loss Aux: 5.770e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5100, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.922e+00, Loss Aux: 7.164e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5101, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.941e+00, Loss Aux: 7.028e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5102, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.980e+00, Loss Aux: 6.371e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5103, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.762e+00, Loss Aux: 8.869e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 5104, It: 0, Loss Data: 8.971e-02, Loss Eqns: 2.925e+00, Loss Aux: 1.351e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5105, It: 0, Loss Data: 9.232e-02, Loss Eqns: 2.926e+00, Loss Aux: 1.741e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 5106, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.787e+00, Loss Aux: 1.632e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5107, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.795e+00, Loss Aux: 1.024e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5108, It: 0, Loss Data: 9.522e-02, Loss Eqns: 2.820e+00, Loss Aux: 5.946e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5109, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.871e+00, Loss Aux: 5.632e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5110, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.786e+00, Loss Aux: 6.369e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5111, It: 0, Loss Data: 9.925e-02, Loss Eqns: 2.865e+00, Loss Aux: 7.321e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5112, It: 0, Loss Data: 1.136e-01, Loss Eqns: 2.858e+00, Loss Aux: 1.100e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 5113, It: 0, Loss Data: 1.170e-01, Loss Eqns: 2.745e+00, Loss Aux: 1.363e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5114, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.780e+00, Loss Aux: 1.434e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5115, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.742e+00, Loss Aux: 1.515e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5116, It: 0, Loss Data: 1.158e-01, Loss Eqns: 2.770e+00, Loss Aux: 1.212e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5117, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.975e+00, Loss Aux: 6.174e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5118, It: 0, Loss Data: 9.648e-02, Loss Eqns: 2.806e+00, Loss Aux: 3.406e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5119, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.840e+00, Loss Aux: 5.182e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5120, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.828e+00, Loss Aux: 8.959e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5121, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.933e+00, Loss Aux: 1.116e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5122, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.874e+00, Loss Aux: 1.303e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5123, It: 0, Loss Data: 1.191e-01, Loss Eqns: 2.863e+00, Loss Aux: 1.482e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5124, It: 0, Loss Data: 8.641e-02, Loss Eqns: 2.825e+00, Loss Aux: 1.331e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5125, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.826e+00, Loss Aux: 9.161e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5126, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.945e+00, Loss Aux: 7.847e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5127, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.793e+00, Loss Aux: 6.816e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5128, It: 0, Loss Data: 9.071e-02, Loss Eqns: 2.799e+00, Loss Aux: 8.343e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5129, It: 0, Loss Data: 9.297e-02, Loss Eqns: 2.879e+00, Loss Aux: 1.202e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5130, It: 0, Loss Data: 9.919e-02, Loss Eqns: 2.912e+00, Loss Aux: 1.413e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5131, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.887e+00, Loss Aux: 1.161e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5132, It: 0, Loss Data: 1.165e-01, Loss Eqns: 2.938e+00, Loss Aux: 8.478e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5133, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.873e+00, Loss Aux: 5.136e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5134, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.849e+00, Loss Aux: 5.199e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5135, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.730e+00, Loss Aux: 8.158e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5136, It: 0, Loss Data: 9.848e-02, Loss Eqns: 2.858e+00, Loss Aux: 1.295e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5137, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.844e+00, Loss Aux: 1.639e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 5138, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.906e+00, Loss Aux: 1.150e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5139, It: 0, Loss Data: 9.990e-02, Loss Eqns: 2.826e+00, Loss Aux: 7.072e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5140, It: 0, Loss Data: 9.602e-02, Loss Eqns: 2.854e+00, Loss Aux: 6.756e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5141, It: 0, Loss Data: 9.396e-02, Loss Eqns: 2.941e+00, Loss Aux: 8.254e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5142, It: 0, Loss Data: 9.909e-02, Loss Eqns: 2.823e+00, Loss Aux: 1.033e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5143, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.866e+00, Loss Aux: 1.007e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5144, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.814e+00, Loss Aux: 8.343e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5145, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.854e+00, Loss Aux: 8.065e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5146, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.789e+00, Loss Aux: 1.127e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 5147, It: 0, Loss Data: 1.449e-01, Loss Eqns: 3.144e+00, Loss Aux: 5.342e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5148, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.824e+00, Loss Aux: 8.787e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5149, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.385e+00, Loss Aux: 6.867e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5150, It: 0, Loss Data: 1.784e-01, Loss Eqns: 3.768e+00, Loss Aux: 5.111e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5151, It: 0, Loss Data: 1.202e-01, Loss Eqns: 3.583e+00, Loss Aux: 1.316e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5152, It: 0, Loss Data: 1.652e-01, Loss Eqns: 3.370e+00, Loss Aux: 3.071e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5153, It: 0, Loss Data: 1.335e-01, Loss Eqns: 3.223e+00, Loss Aux: 1.695e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5154, It: 0, Loss Data: 1.401e-01, Loss Eqns: 2.863e+00, Loss Aux: 5.255e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5155, It: 0, Loss Data: 1.485e-01, Loss Eqns: 3.051e+00, Loss Aux: 5.003e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5156, It: 0, Loss Data: 1.494e-01, Loss Eqns: 2.944e+00, Loss Aux: 1.474e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5157, It: 0, Loss Data: 1.313e-01, Loss Eqns: 2.720e+00, Loss Aux: 1.729e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5158, It: 0, Loss Data: 1.596e-01, Loss Eqns: 2.650e+00, Loss Aux: 7.627e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 5159, It: 0, Loss Data: 1.524e-01, Loss Eqns: 2.977e+00, Loss Aux: 7.917e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5160, It: 0, Loss Data: 1.467e-01, Loss Eqns: 2.805e+00, Loss Aux: 1.066e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5161, It: 0, Loss Data: 1.511e-01, Loss Eqns: 2.871e+00, Loss Aux: 1.241e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5162, It: 0, Loss Data: 1.239e-01, Loss Eqns: 2.916e+00, Loss Aux: 7.218e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5163, It: 0, Loss Data: 1.500e-01, Loss Eqns: 2.947e+00, Loss Aux: 5.622e-03, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 5164, It: 0, Loss Data: 1.279e-01, Loss Eqns: 3.091e+00, Loss Aux: 1.445e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5165, It: 0, Loss Data: 1.230e-01, Loss Eqns: 2.922e+00, Loss Aux: 2.777e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 5166, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.993e+00, Loss Aux: 1.720e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 5167, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.047e+00, Loss Aux: 6.027e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5168, It: 0, Loss Data: 1.436e-01, Loss Eqns: 2.946e+00, Loss Aux: 3.632e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5169, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.865e+00, Loss Aux: 4.643e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5170, It: 0, Loss Data: 1.303e-01, Loss Eqns: 2.870e+00, Loss Aux: 9.124e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5171, It: 0, Loss Data: 1.474e-01, Loss Eqns: 3.161e+00, Loss Aux: 8.006e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5172, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.960e+00, Loss Aux: 1.066e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5173, It: 0, Loss Data: 1.226e-01, Loss Eqns: 3.093e+00, Loss Aux: 1.880e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5174, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.839e+00, Loss Aux: 2.060e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5175, It: 0, Loss Data: 1.275e-01, Loss Eqns: 2.963e+00, Loss Aux: 1.386e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5176, It: 0, Loss Data: 1.226e-01, Loss Eqns: 2.776e+00, Loss Aux: 1.494e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5177, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.848e+00, Loss Aux: 1.054e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5178, It: 0, Loss Data: 1.225e-01, Loss Eqns: 2.828e+00, Loss Aux: 8.588e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5179, It: 0, Loss Data: 1.203e-01, Loss Eqns: 2.941e+00, Loss Aux: 9.184e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5180, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.857e+00, Loss Aux: 1.057e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5181, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.944e+00, Loss Aux: 1.159e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5182, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.080e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5183, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.940e+00, Loss Aux: 1.124e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5184, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.952e+00, Loss Aux: 1.100e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5185, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.926e+00, Loss Aux: 8.578e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5186, It: 0, Loss Data: 1.214e-01, Loss Eqns: 2.928e+00, Loss Aux: 6.219e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 5187, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.916e+00, Loss Aux: 6.071e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5188, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.859e+00, Loss Aux: 7.393e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5189, It: 0, Loss Data: 9.835e-02, Loss Eqns: 2.864e+00, Loss Aux: 8.074e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5190, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.873e+00, Loss Aux: 5.627e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5191, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.922e+00, Loss Aux: 4.999e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5192, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.942e+00, Loss Aux: 7.971e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5193, It: 0, Loss Data: 9.994e-02, Loss Eqns: 2.901e+00, Loss Aux: 1.314e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5194, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.876e+00, Loss Aux: 1.172e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5195, It: 0, Loss Data: 9.752e-02, Loss Eqns: 2.842e+00, Loss Aux: 6.595e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5196, It: 0, Loss Data: 9.684e-02, Loss Eqns: 2.928e+00, Loss Aux: 5.293e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5197, It: 0, Loss Data: 1.228e-01, Loss Eqns: 2.899e+00, Loss Aux: 7.203e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5198, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.778e+00, Loss Aux: 1.196e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5199, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.857e+00, Loss Aux: 1.248e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5200, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.786e+00, Loss Aux: 9.085e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5201, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.740e+00, Loss Aux: 8.098e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5202, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.833e+00, Loss Aux: 1.365e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5203, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.897e+00, Loss Aux: 1.742e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5204, It: 0, Loss Data: 9.541e-02, Loss Eqns: 2.806e+00, Loss Aux: 6.119e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 5205, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.869e+00, Loss Aux: 5.864e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5206, It: 0, Loss Data: 1.136e-01, Loss Eqns: 2.778e+00, Loss Aux: 6.543e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5207, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.753e+00, Loss Aux: 7.362e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5208, It: 0, Loss Data: 1.234e-01, Loss Eqns: 2.876e+00, Loss Aux: 1.493e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5209, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.850e+00, Loss Aux: 1.493e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5210, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.878e+00, Loss Aux: 1.249e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5211, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.768e+00, Loss Aux: 1.362e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5212, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.859e+00, Loss Aux: 1.164e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5213, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.818e+00, Loss Aux: 4.165e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5214, It: 0, Loss Data: 1.198e-01, Loss Eqns: 2.884e+00, Loss Aux: 2.397e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5215, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.808e+00, Loss Aux: 6.750e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5216, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.754e+00, Loss Aux: 1.441e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5217, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.884e+00, Loss Aux: 1.508e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5218, It: 0, Loss Data: 1.257e-01, Loss Eqns: 2.701e+00, Loss Aux: 9.429e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 5219, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.867e+00, Loss Aux: 7.804e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5220, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.889e+00, Loss Aux: 8.751e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 5221, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.846e+00, Loss Aux: 1.213e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5222, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.818e+00, Loss Aux: 1.082e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5223, It: 0, Loss Data: 1.210e-01, Loss Eqns: 2.853e+00, Loss Aux: 5.084e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 5224, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.840e+00, Loss Aux: 2.945e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5225, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.856e+00, Loss Aux: 5.113e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5226, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.248e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5227, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.801e+00, Loss Aux: 1.331e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5228, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.846e+00, Loss Aux: 9.794e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5229, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.752e+00, Loss Aux: 1.018e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5230, It: 0, Loss Data: 1.202e-01, Loss Eqns: 3.033e+00, Loss Aux: 1.341e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5231, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.953e+00, Loss Aux: 1.126e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5232, It: 0, Loss Data: 9.452e-02, Loss Eqns: 3.017e+00, Loss Aux: 6.033e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5233, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.902e+00, Loss Aux: 4.983e-03, Time: 0.250, Learning Rate: 1.0e-03\n",
      "Epoch: 5234, It: 0, Loss Data: 9.769e-02, Loss Eqns: 3.060e+00, Loss Aux: 6.673e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 5235, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.926e+00, Loss Aux: 7.894e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 5236, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.976e+00, Loss Aux: 7.956e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5237, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.861e+00, Loss Aux: 9.654e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5238, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.929e+00, Loss Aux: 9.330e-03, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 5239, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.847e+00, Loss Aux: 9.984e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5240, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.826e+00, Loss Aux: 1.164e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 5241, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.856e+00, Loss Aux: 1.326e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 5242, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.859e+00, Loss Aux: 8.961e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5243, It: 0, Loss Data: 1.194e-01, Loss Eqns: 2.852e+00, Loss Aux: 5.976e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5244, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.837e+00, Loss Aux: 6.230e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5245, It: 0, Loss Data: 9.939e-02, Loss Eqns: 2.791e+00, Loss Aux: 6.611e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5246, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.844e+00, Loss Aux: 5.201e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5247, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.767e+00, Loss Aux: 5.623e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5248, It: 0, Loss Data: 9.835e-02, Loss Eqns: 2.846e+00, Loss Aux: 1.011e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5249, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.700e+00, Loss Aux: 1.230e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5250, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.694e+00, Loss Aux: 9.099e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5251, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.784e+00, Loss Aux: 7.578e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5252, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.849e+00, Loss Aux: 8.165e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5253, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.853e+00, Loss Aux: 9.977e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5254, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.788e+00, Loss Aux: 9.518e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5255, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.892e+00, Loss Aux: 1.072e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5256, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.772e+00, Loss Aux: 9.638e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5257, It: 0, Loss Data: 9.919e-02, Loss Eqns: 2.884e+00, Loss Aux: 5.950e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5258, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.887e+00, Loss Aux: 4.077e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5259, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.775e+00, Loss Aux: 4.540e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5260, It: 0, Loss Data: 9.874e-02, Loss Eqns: 2.870e+00, Loss Aux: 8.038e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5261, It: 0, Loss Data: 9.137e-02, Loss Eqns: 2.768e+00, Loss Aux: 1.124e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5262, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.765e+00, Loss Aux: 1.073e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5263, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.703e+00, Loss Aux: 9.070e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5264, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.688e+00, Loss Aux: 9.144e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5265, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.737e+00, Loss Aux: 9.024e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5266, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.745e+00, Loss Aux: 6.077e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5267, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.697e+00, Loss Aux: 4.720e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5268, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.703e+00, Loss Aux: 5.090e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5269, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.715e+00, Loss Aux: 9.173e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5270, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.230e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 5271, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.157e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5272, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.755e+00, Loss Aux: 9.549e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5273, It: 0, Loss Data: 1.222e-01, Loss Eqns: 2.846e+00, Loss Aux: 8.692e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5274, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.844e+00, Loss Aux: 8.570e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5275, It: 0, Loss Data: 1.175e-01, Loss Eqns: 2.835e+00, Loss Aux: 8.528e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5276, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.753e+00, Loss Aux: 8.127e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5277, It: 0, Loss Data: 9.964e-02, Loss Eqns: 2.828e+00, Loss Aux: 9.865e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5278, It: 0, Loss Data: 7.823e-02, Loss Eqns: 2.811e+00, Loss Aux: 1.328e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5279, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.786e+00, Loss Aux: 1.406e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5280, It: 0, Loss Data: 9.385e-02, Loss Eqns: 2.782e+00, Loss Aux: 9.768e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5281, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.821e+00, Loss Aux: 6.396e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5282, It: 0, Loss Data: 9.676e-02, Loss Eqns: 2.785e+00, Loss Aux: 5.427e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5283, It: 0, Loss Data: 9.302e-02, Loss Eqns: 2.832e+00, Loss Aux: 7.294e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5284, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.757e+00, Loss Aux: 8.684e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5285, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.730e+00, Loss Aux: 1.230e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5286, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.772e+00, Loss Aux: 1.134e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5287, It: 0, Loss Data: 8.110e-02, Loss Eqns: 2.774e+00, Loss Aux: 8.286e-03, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 5288, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.749e+00, Loss Aux: 7.121e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5289, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.798e+00, Loss Aux: 9.004e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 5290, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.649e+00, Loss Aux: 8.492e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5291, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.677e+00, Loss Aux: 5.818e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5292, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.676e+00, Loss Aux: 5.220e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 5293, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.689e+00, Loss Aux: 6.662e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5294, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.901e+00, Loss Aux: 1.139e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5295, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.802e+00, Loss Aux: 1.222e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5296, It: 0, Loss Data: 8.809e-02, Loss Eqns: 2.762e+00, Loss Aux: 8.076e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5297, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.867e+00, Loss Aux: 5.915e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5298, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.838e+00, Loss Aux: 5.794e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5299, It: 0, Loss Data: 9.457e-02, Loss Eqns: 2.833e+00, Loss Aux: 5.654e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5300, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.929e+00, Loss Aux: 6.361e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5301, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.850e+00, Loss Aux: 7.565e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5302, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.832e+00, Loss Aux: 7.045e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5303, It: 0, Loss Data: 9.617e-02, Loss Eqns: 2.734e+00, Loss Aux: 8.765e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5304, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.799e+00, Loss Aux: 1.074e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5305, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.826e+00, Loss Aux: 9.544e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5306, It: 0, Loss Data: 9.494e-02, Loss Eqns: 2.844e+00, Loss Aux: 7.682e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5307, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.839e+00, Loss Aux: 8.784e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5308, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.802e+00, Loss Aux: 7.147e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5309, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.812e+00, Loss Aux: 5.731e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 5310, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.831e+00, Loss Aux: 7.727e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5311, It: 0, Loss Data: 9.487e-02, Loss Eqns: 2.801e+00, Loss Aux: 1.051e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5312, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.987e+00, Loss Aux: 1.434e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5313, It: 0, Loss Data: 9.563e-02, Loss Eqns: 2.824e+00, Loss Aux: 1.630e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5314, It: 0, Loss Data: 9.954e-02, Loss Eqns: 2.898e+00, Loss Aux: 1.526e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5315, It: 0, Loss Data: 9.854e-02, Loss Eqns: 2.946e+00, Loss Aux: 1.047e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5316, It: 0, Loss Data: 9.896e-02, Loss Eqns: 2.775e+00, Loss Aux: 8.125e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5317, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.881e+00, Loss Aux: 6.700e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5318, It: 0, Loss Data: 9.913e-02, Loss Eqns: 2.827e+00, Loss Aux: 6.332e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5319, It: 0, Loss Data: 1.277e-01, Loss Eqns: 2.857e+00, Loss Aux: 3.048e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5320, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.754e+00, Loss Aux: 2.939e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5321, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.785e+00, Loss Aux: 6.086e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5322, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.816e+00, Loss Aux: 1.148e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5323, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.778e+00, Loss Aux: 1.598e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5324, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.813e+00, Loss Aux: 1.524e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5325, It: 0, Loss Data: 9.860e-02, Loss Eqns: 2.867e+00, Loss Aux: 1.205e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5326, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.887e+00, Loss Aux: 8.976e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5327, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.855e+00, Loss Aux: 7.249e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5328, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.832e+00, Loss Aux: 5.541e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5329, It: 0, Loss Data: 9.777e-02, Loss Eqns: 2.835e+00, Loss Aux: 6.987e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5330, It: 0, Loss Data: 9.389e-02, Loss Eqns: 2.812e+00, Loss Aux: 1.178e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5331, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.633e+00, Loss Aux: 1.399e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5332, It: 0, Loss Data: 9.039e-02, Loss Eqns: 2.646e+00, Loss Aux: 1.089e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5333, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.793e+00, Loss Aux: 8.891e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5334, It: 0, Loss Data: 9.965e-02, Loss Eqns: 2.753e+00, Loss Aux: 7.289e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5335, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.762e+00, Loss Aux: 6.247e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5336, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.846e+00, Loss Aux: 5.633e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5337, It: 0, Loss Data: 9.223e-02, Loss Eqns: 2.875e+00, Loss Aux: 6.525e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5338, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.804e+00, Loss Aux: 8.763e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5339, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.318e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5340, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.647e+00, Loss Aux: 1.633e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5341, It: 0, Loss Data: 1.188e-01, Loss Eqns: 2.809e+00, Loss Aux: 1.359e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5342, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.256e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5343, It: 0, Loss Data: 9.365e-02, Loss Eqns: 2.794e+00, Loss Aux: 1.033e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5344, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.812e+00, Loss Aux: 7.301e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 5345, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.765e+00, Loss Aux: 3.390e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5346, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.790e+00, Loss Aux: 3.144e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5347, It: 0, Loss Data: 9.926e-02, Loss Eqns: 2.779e+00, Loss Aux: 3.827e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5348, It: 0, Loss Data: 9.260e-02, Loss Eqns: 2.891e+00, Loss Aux: 5.372e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5349, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.845e+00, Loss Aux: 8.050e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 5350, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.811e+00, Loss Aux: 1.092e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 5351, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.776e+00, Loss Aux: 1.451e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5352, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.827e+00, Loss Aux: 1.553e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5353, It: 0, Loss Data: 1.294e-01, Loss Eqns: 2.834e+00, Loss Aux: 1.352e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5354, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.891e+00, Loss Aux: 9.743e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5355, It: 0, Loss Data: 9.864e-02, Loss Eqns: 2.772e+00, Loss Aux: 7.571e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 5356, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.888e+00, Loss Aux: 5.580e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5357, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.895e+00, Loss Aux: 4.678e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5358, It: 0, Loss Data: 9.449e-02, Loss Eqns: 2.870e+00, Loss Aux: 5.488e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5359, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.855e+00, Loss Aux: 1.134e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5360, It: 0, Loss Data: 9.882e-02, Loss Eqns: 2.843e+00, Loss Aux: 1.447e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5361, It: 0, Loss Data: 1.088e-01, Loss Eqns: 3.006e+00, Loss Aux: 1.539e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5362, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.903e+00, Loss Aux: 9.868e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5363, It: 0, Loss Data: 9.252e-02, Loss Eqns: 2.877e+00, Loss Aux: 6.981e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5364, It: 0, Loss Data: 9.984e-02, Loss Eqns: 2.802e+00, Loss Aux: 7.936e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5365, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.813e+00, Loss Aux: 7.690e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5366, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.829e+00, Loss Aux: 5.068e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5367, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.975e+00, Loss Aux: 3.919e-03, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 5368, It: 0, Loss Data: 8.854e-02, Loss Eqns: 2.953e+00, Loss Aux: 6.947e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5369, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.782e+00, Loss Aux: 1.020e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5370, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.727e+00, Loss Aux: 9.828e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5371, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.825e+00, Loss Aux: 1.036e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5372, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.792e+00, Loss Aux: 8.798e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5373, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.660e+00, Loss Aux: 6.888e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5374, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.783e+00, Loss Aux: 6.556e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 5375, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.842e+00, Loss Aux: 6.257e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5376, It: 0, Loss Data: 9.524e-02, Loss Eqns: 2.798e+00, Loss Aux: 8.548e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5377, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.744e+00, Loss Aux: 1.292e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5378, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.039e+00, Loss Aux: 6.390e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5379, It: 0, Loss Data: 1.392e-01, Loss Eqns: 3.459e+00, Loss Aux: 1.226e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5380, It: 0, Loss Data: 9.808e-02, Loss Eqns: 2.885e+00, Loss Aux: 6.082e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5381, It: 0, Loss Data: 1.163e-01, Loss Eqns: 3.438e+00, Loss Aux: 4.327e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5382, It: 0, Loss Data: 1.097e-01, Loss Eqns: 3.054e+00, Loss Aux: 5.211e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5383, It: 0, Loss Data: 1.184e-01, Loss Eqns: 3.166e+00, Loss Aux: 9.638e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5384, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.872e+00, Loss Aux: 1.039e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5385, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.925e+00, Loss Aux: 1.124e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5386, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.888e+00, Loss Aux: 1.493e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5387, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.999e+00, Loss Aux: 1.415e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5388, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.812e+00, Loss Aux: 9.186e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5389, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.915e+00, Loss Aux: 6.889e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5390, It: 0, Loss Data: 1.175e-01, Loss Eqns: 2.799e+00, Loss Aux: 7.991e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5391, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.832e+00, Loss Aux: 6.574e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5392, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.868e+00, Loss Aux: 6.159e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5393, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.880e+00, Loss Aux: 6.483e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5394, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.982e+00, Loss Aux: 1.163e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5395, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.744e+00, Loss Aux: 1.449e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5396, It: 0, Loss Data: 1.077e-01, Loss Eqns: 3.024e+00, Loss Aux: 9.062e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 5397, It: 0, Loss Data: 1.159e-01, Loss Eqns: 2.830e+00, Loss Aux: 6.233e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5398, It: 0, Loss Data: 1.182e-01, Loss Eqns: 2.984e+00, Loss Aux: 6.851e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5399, It: 0, Loss Data: 9.228e-02, Loss Eqns: 2.839e+00, Loss Aux: 4.943e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5400, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.818e+00, Loss Aux: 4.767e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5401, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.833e+00, Loss Aux: 8.234e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 5402, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.909e+00, Loss Aux: 1.371e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5403, It: 0, Loss Data: 1.166e-01, Loss Eqns: 3.066e+00, Loss Aux: 1.445e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5404, It: 0, Loss Data: 9.571e-02, Loss Eqns: 3.149e+00, Loss Aux: 1.579e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5405, It: 0, Loss Data: 1.129e-01, Loss Eqns: 2.932e+00, Loss Aux: 1.459e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5406, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.909e+00, Loss Aux: 1.092e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5407, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.937e+00, Loss Aux: 1.175e-02, Time: 0.253, Learning Rate: 1.0e-03\n",
      "Epoch: 5408, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.789e+00, Loss Aux: 1.197e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5409, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.857e+00, Loss Aux: 1.717e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5410, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.632e+00, Loss Aux: 1.267e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5411, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.585e+00, Loss Aux: 8.137e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5412, It: 0, Loss Data: 1.226e-01, Loss Eqns: 2.676e+00, Loss Aux: 6.175e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5413, It: 0, Loss Data: 1.165e-01, Loss Eqns: 2.703e+00, Loss Aux: 7.036e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5414, It: 0, Loss Data: 1.276e-01, Loss Eqns: 2.723e+00, Loss Aux: 3.763e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5415, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.736e+00, Loss Aux: 2.686e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5416, It: 0, Loss Data: 9.146e-02, Loss Eqns: 2.860e+00, Loss Aux: 9.905e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5417, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.844e+00, Loss Aux: 2.241e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5418, It: 0, Loss Data: 9.417e-02, Loss Eqns: 2.877e+00, Loss Aux: 2.182e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 5419, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.814e+00, Loss Aux: 1.535e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5420, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.836e+00, Loss Aux: 6.914e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5421, It: 0, Loss Data: 9.583e-02, Loss Eqns: 2.947e+00, Loss Aux: 3.735e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5422, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.977e+00, Loss Aux: 5.093e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5423, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.910e+00, Loss Aux: 7.631e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5424, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.843e+00, Loss Aux: 5.009e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5425, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.738e+00, Loss Aux: 3.862e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5426, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.675e+00, Loss Aux: 1.086e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5427, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.759e+00, Loss Aux: 1.601e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 5428, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.761e+00, Loss Aux: 1.159e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5429, It: 0, Loss Data: 9.656e-02, Loss Eqns: 2.775e+00, Loss Aux: 6.579e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5430, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.760e+00, Loss Aux: 6.019e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5431, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.855e+00, Loss Aux: 5.426e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5432, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.726e+00, Loss Aux: 6.632e-03, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 5433, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.912e+00, Loss Aux: 1.202e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5434, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.627e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5435, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.867e+00, Loss Aux: 1.584e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5436, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.854e+00, Loss Aux: 1.078e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5437, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.754e+00, Loss Aux: 5.160e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5438, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.812e+00, Loss Aux: 3.179e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5439, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.802e+00, Loss Aux: 3.351e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5440, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.727e+00, Loss Aux: 5.815e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5441, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.757e+00, Loss Aux: 7.557e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5442, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.865e+00, Loss Aux: 7.234e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5443, It: 0, Loss Data: 9.615e-02, Loss Eqns: 2.793e+00, Loss Aux: 1.079e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5444, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.764e+00, Loss Aux: 1.422e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5445, It: 0, Loss Data: 1.175e-01, Loss Eqns: 2.803e+00, Loss Aux: 1.428e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5446, It: 0, Loss Data: 9.725e-02, Loss Eqns: 2.728e+00, Loss Aux: 1.070e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5447, It: 0, Loss Data: 1.212e-01, Loss Eqns: 2.852e+00, Loss Aux: 8.612e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5448, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.809e+00, Loss Aux: 7.346e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5449, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.755e+00, Loss Aux: 8.143e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5450, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.735e+00, Loss Aux: 1.354e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5451, It: 0, Loss Data: 8.898e-02, Loss Eqns: 2.820e+00, Loss Aux: 1.656e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5452, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.775e+00, Loss Aux: 1.640e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5453, It: 0, Loss Data: 9.963e-02, Loss Eqns: 2.798e+00, Loss Aux: 1.077e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5454, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.939e+00, Loss Aux: 6.172e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5455, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.832e+00, Loss Aux: 3.945e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5456, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.800e+00, Loss Aux: 4.156e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5457, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.717e+00, Loss Aux: 4.992e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5458, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.767e+00, Loss Aux: 8.020e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5459, It: 0, Loss Data: 9.575e-02, Loss Eqns: 2.732e+00, Loss Aux: 1.348e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5460, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.732e+00, Loss Aux: 1.017e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5461, It: 0, Loss Data: 1.215e-01, Loss Eqns: 2.766e+00, Loss Aux: 6.732e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5462, It: 0, Loss Data: 9.167e-02, Loss Eqns: 2.836e+00, Loss Aux: 6.459e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5463, It: 0, Loss Data: 9.543e-02, Loss Eqns: 2.812e+00, Loss Aux: 6.888e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5464, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.895e+00, Loss Aux: 6.882e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5465, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.880e+00, Loss Aux: 1.104e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5466, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.481e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5467, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.791e+00, Loss Aux: 1.713e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5468, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.819e+00, Loss Aux: 1.521e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5469, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.658e+00, Loss Aux: 1.183e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5470, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.749e+00, Loss Aux: 8.981e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5471, It: 0, Loss Data: 9.676e-02, Loss Eqns: 2.792e+00, Loss Aux: 6.827e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5472, It: 0, Loss Data: 9.217e-02, Loss Eqns: 2.827e+00, Loss Aux: 7.338e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5473, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.842e+00, Loss Aux: 7.072e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5474, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.901e+00, Loss Aux: 9.243e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5475, It: 0, Loss Data: 9.291e-02, Loss Eqns: 2.805e+00, Loss Aux: 1.884e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5476, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.769e+00, Loss Aux: 1.936e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5477, It: 0, Loss Data: 1.188e-01, Loss Eqns: 2.852e+00, Loss Aux: 1.472e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5478, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.839e+00, Loss Aux: 8.767e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5479, It: 0, Loss Data: 9.259e-02, Loss Eqns: 2.793e+00, Loss Aux: 5.740e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5480, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.879e+00, Loss Aux: 6.005e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5481, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.775e+00, Loss Aux: 5.532e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5482, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.805e+00, Loss Aux: 5.778e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5483, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.748e+00, Loss Aux: 8.428e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5484, It: 0, Loss Data: 9.602e-02, Loss Eqns: 2.870e+00, Loss Aux: 8.633e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5485, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.823e+00, Loss Aux: 1.049e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5486, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.828e+00, Loss Aux: 1.348e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5487, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.830e+00, Loss Aux: 1.616e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5488, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.842e+00, Loss Aux: 1.672e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5489, It: 0, Loss Data: 9.966e-02, Loss Eqns: 2.867e+00, Loss Aux: 1.348e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5490, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.845e+00, Loss Aux: 8.094e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5491, It: 0, Loss Data: 8.624e-02, Loss Eqns: 2.876e+00, Loss Aux: 5.014e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5492, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.871e+00, Loss Aux: 5.430e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5493, It: 0, Loss Data: 9.856e-02, Loss Eqns: 2.791e+00, Loss Aux: 6.668e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5494, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.750e+00, Loss Aux: 7.063e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5495, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.667e+00, Loss Aux: 1.226e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5496, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.698e+00, Loss Aux: 1.734e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5497, It: 0, Loss Data: 9.433e-02, Loss Eqns: 2.731e+00, Loss Aux: 1.552e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5498, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.727e+00, Loss Aux: 8.262e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5499, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.760e+00, Loss Aux: 3.136e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5500, It: 0, Loss Data: 9.808e-02, Loss Eqns: 2.810e+00, Loss Aux: 2.595e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5501, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.753e+00, Loss Aux: 2.816e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5502, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.820e+00, Loss Aux: 3.283e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5503, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.812e+00, Loss Aux: 5.145e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5504, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.803e+00, Loss Aux: 1.334e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5505, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.730e+00, Loss Aux: 2.619e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5506, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.714e+00, Loss Aux: 2.727e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5507, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.719e+00, Loss Aux: 1.344e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5508, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.705e+00, Loss Aux: 5.731e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5509, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.721e+00, Loss Aux: 4.820e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5510, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.657e+00, Loss Aux: 5.622e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5511, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.669e+00, Loss Aux: 6.652e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5512, It: 0, Loss Data: 9.991e-02, Loss Eqns: 2.783e+00, Loss Aux: 7.167e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5513, It: 0, Loss Data: 9.865e-02, Loss Eqns: 2.652e+00, Loss Aux: 6.694e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5514, It: 0, Loss Data: 9.625e-02, Loss Eqns: 2.724e+00, Loss Aux: 9.125e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5515, It: 0, Loss Data: 9.873e-02, Loss Eqns: 2.720e+00, Loss Aux: 1.049e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5516, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.695e+00, Loss Aux: 7.264e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5517, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.714e+00, Loss Aux: 4.686e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5518, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.605e+00, Loss Aux: 7.601e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5519, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.591e+00, Loss Aux: 1.265e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5520, It: 0, Loss Data: 9.089e-02, Loss Eqns: 2.614e+00, Loss Aux: 8.350e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5521, It: 0, Loss Data: 1.307e-01, Loss Eqns: 2.695e+00, Loss Aux: 6.781e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5522, It: 0, Loss Data: 9.707e-02, Loss Eqns: 2.735e+00, Loss Aux: 8.888e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5523, It: 0, Loss Data: 9.671e-02, Loss Eqns: 2.729e+00, Loss Aux: 1.614e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5524, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.503e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5525, It: 0, Loss Data: 9.662e-02, Loss Eqns: 2.773e+00, Loss Aux: 9.033e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5526, It: 0, Loss Data: 1.162e-01, Loss Eqns: 2.829e+00, Loss Aux: 6.393e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5527, It: 0, Loss Data: 9.850e-02, Loss Eqns: 2.824e+00, Loss Aux: 5.917e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5528, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.684e+00, Loss Aux: 5.091e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5529, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.729e+00, Loss Aux: 5.629e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5530, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.745e+00, Loss Aux: 8.402e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5531, It: 0, Loss Data: 9.319e-02, Loss Eqns: 2.757e+00, Loss Aux: 1.419e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5532, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.844e+00, Loss Aux: 1.534e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5533, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.863e+00, Loss Aux: 1.190e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5534, It: 0, Loss Data: 8.546e-02, Loss Eqns: 2.673e+00, Loss Aux: 7.822e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5535, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.807e+00, Loss Aux: 8.357e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5536, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.799e+00, Loss Aux: 7.812e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5537, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.653e+00, Loss Aux: 4.353e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5538, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.804e+00, Loss Aux: 5.572e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5539, It: 0, Loss Data: 1.184e-01, Loss Eqns: 2.748e+00, Loss Aux: 1.022e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5540, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.787e+00, Loss Aux: 1.073e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5541, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.952e+00, Loss Aux: 6.345e-03, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5542, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.955e+00, Loss Aux: 5.726e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5543, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.795e+00, Loss Aux: 7.856e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5544, It: 0, Loss Data: 9.625e-02, Loss Eqns: 2.836e+00, Loss Aux: 1.898e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5545, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.748e+00, Loss Aux: 1.845e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5546, It: 0, Loss Data: 9.857e-02, Loss Eqns: 2.803e+00, Loss Aux: 8.104e-03, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5547, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.598e+00, Loss Aux: 5.279e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5548, It: 0, Loss Data: 9.588e-02, Loss Eqns: 2.825e+00, Loss Aux: 7.200e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5549, It: 0, Loss Data: 1.385e-01, Loss Eqns: 2.725e+00, Loss Aux: 1.098e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5550, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.689e+00, Loss Aux: 8.129e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5551, It: 0, Loss Data: 1.187e-01, Loss Eqns: 2.763e+00, Loss Aux: 6.705e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5552, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.809e+00, Loss Aux: 9.758e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5553, It: 0, Loss Data: 1.205e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.092e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5554, It: 0, Loss Data: 9.834e-02, Loss Eqns: 2.866e+00, Loss Aux: 5.502e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5555, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.711e+00, Loss Aux: 5.023e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5556, It: 0, Loss Data: 9.992e-02, Loss Eqns: 2.721e+00, Loss Aux: 8.051e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5557, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.831e+00, Loss Aux: 1.240e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5558, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.753e+00, Loss Aux: 1.253e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5559, It: 0, Loss Data: 9.765e-02, Loss Eqns: 2.897e+00, Loss Aux: 1.095e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 5560, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.843e+00, Loss Aux: 1.122e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5561, It: 0, Loss Data: 9.661e-02, Loss Eqns: 2.941e+00, Loss Aux: 1.226e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 5562, It: 0, Loss Data: 8.508e-02, Loss Eqns: 2.857e+00, Loss Aux: 1.024e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5563, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.749e+00, Loss Aux: 6.276e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5564, It: 0, Loss Data: 9.362e-02, Loss Eqns: 2.711e+00, Loss Aux: 5.177e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5565, It: 0, Loss Data: 9.795e-02, Loss Eqns: 2.787e+00, Loss Aux: 8.747e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5566, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.147e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5567, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.758e+00, Loss Aux: 9.283e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5568, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.713e+00, Loss Aux: 7.631e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5569, It: 0, Loss Data: 1.218e-01, Loss Eqns: 2.755e+00, Loss Aux: 1.127e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5570, It: 0, Loss Data: 9.312e-02, Loss Eqns: 2.770e+00, Loss Aux: 1.554e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5571, It: 0, Loss Data: 9.550e-02, Loss Eqns: 2.775e+00, Loss Aux: 5.025e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5572, It: 0, Loss Data: 1.186e-01, Loss Eqns: 2.763e+00, Loss Aux: 7.843e-04, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5573, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.843e+00, Loss Aux: 1.991e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5574, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.666e+00, Loss Aux: 7.899e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 5575, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.619e+00, Loss Aux: 8.171e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5576, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.598e+00, Loss Aux: 7.422e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5577, It: 0, Loss Data: 1.129e-01, Loss Eqns: 2.604e+00, Loss Aux: 8.728e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5578, It: 0, Loss Data: 9.825e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.145e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5579, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.777e+00, Loss Aux: 1.254e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 5580, It: 0, Loss Data: 9.953e-02, Loss Eqns: 2.791e+00, Loss Aux: 7.444e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5581, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.813e+00, Loss Aux: 5.780e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 5582, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.796e+00, Loss Aux: 9.890e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5583, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.735e+00, Loss Aux: 1.174e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5584, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.758e+00, Loss Aux: 4.601e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5585, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.868e+00, Loss Aux: 2.980e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5586, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.804e+00, Loss Aux: 4.443e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5587, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.758e+00, Loss Aux: 1.598e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5588, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.721e+00, Loss Aux: 2.270e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5589, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.734e+00, Loss Aux: 1.594e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5590, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.751e+00, Loss Aux: 9.721e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5591, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.751e+00, Loss Aux: 9.296e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5592, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.604e+00, Loss Aux: 1.453e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5593, It: 0, Loss Data: 1.373e-01, Loss Eqns: 3.101e+00, Loss Aux: 2.914e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 5594, It: 0, Loss Data: 3.084e-01, Loss Eqns: 4.027e+00, Loss Aux: 3.310e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 5595, It: 0, Loss Data: 1.511e-01, Loss Eqns: 3.348e+00, Loss Aux: 6.168e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5596, It: 0, Loss Data: 2.278e-01, Loss Eqns: 3.687e+00, Loss Aux: 2.715e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5597, It: 0, Loss Data: 1.738e-01, Loss Eqns: 2.858e+00, Loss Aux: 1.629e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5598, It: 0, Loss Data: 2.054e-01, Loss Eqns: 3.235e+00, Loss Aux: 4.582e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5599, It: 0, Loss Data: 1.895e-01, Loss Eqns: 3.166e+00, Loss Aux: 5.008e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5600, It: 0, Loss Data: 1.518e-01, Loss Eqns: 3.644e+00, Loss Aux: 1.338e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5601, It: 0, Loss Data: 1.395e-01, Loss Eqns: 3.100e+00, Loss Aux: 1.832e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 5602, It: 0, Loss Data: 1.496e-01, Loss Eqns: 3.300e+00, Loss Aux: 1.930e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5603, It: 0, Loss Data: 1.313e-01, Loss Eqns: 3.141e+00, Loss Aux: 2.169e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5604, It: 0, Loss Data: 1.758e-01, Loss Eqns: 3.157e+00, Loss Aux: 1.946e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5605, It: 0, Loss Data: 1.403e-01, Loss Eqns: 3.127e+00, Loss Aux: 1.255e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5606, It: 0, Loss Data: 1.414e-01, Loss Eqns: 2.990e+00, Loss Aux: 9.780e-03, Time: 0.260, Learning Rate: 1.0e-03\n",
      "Epoch: 5607, It: 0, Loss Data: 1.502e-01, Loss Eqns: 2.730e+00, Loss Aux: 1.054e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5608, It: 0, Loss Data: 1.197e-01, Loss Eqns: 2.994e+00, Loss Aux: 2.144e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5609, It: 0, Loss Data: 1.193e-01, Loss Eqns: 2.891e+00, Loss Aux: 2.882e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5610, It: 0, Loss Data: 1.325e-01, Loss Eqns: 2.920e+00, Loss Aux: 2.225e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5611, It: 0, Loss Data: 1.414e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.063e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5612, It: 0, Loss Data: 1.432e-01, Loss Eqns: 2.788e+00, Loss Aux: 4.642e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5613, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.804e+00, Loss Aux: 4.418e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5614, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.843e+00, Loss Aux: 9.688e-03, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 5615, It: 0, Loss Data: 1.350e-01, Loss Eqns: 2.846e+00, Loss Aux: 2.139e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5616, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.768e+00, Loss Aux: 2.681e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5617, It: 0, Loss Data: 1.170e-01, Loss Eqns: 2.677e+00, Loss Aux: 1.799e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5618, It: 0, Loss Data: 1.243e-01, Loss Eqns: 2.816e+00, Loss Aux: 1.215e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5619, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.846e+00, Loss Aux: 1.152e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5620, It: 0, Loss Data: 1.246e-01, Loss Eqns: 2.910e+00, Loss Aux: 8.001e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5621, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.821e+00, Loss Aux: 3.190e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5622, It: 0, Loss Data: 1.193e-01, Loss Eqns: 2.763e+00, Loss Aux: 3.198e-03, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 5623, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.658e+00, Loss Aux: 1.018e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5624, It: 0, Loss Data: 1.169e-01, Loss Eqns: 2.815e+00, Loss Aux: 1.891e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5625, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.794e+00, Loss Aux: 1.714e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5626, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.803e+00, Loss Aux: 1.246e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5627, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.833e+00, Loss Aux: 1.178e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5628, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.794e+00, Loss Aux: 1.140e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5629, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.604e+00, Loss Aux: 6.489e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5630, It: 0, Loss Data: 9.968e-02, Loss Eqns: 2.751e+00, Loss Aux: 3.842e-03, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 5631, It: 0, Loss Data: 9.061e-02, Loss Eqns: 2.704e+00, Loss Aux: 4.487e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5632, It: 0, Loss Data: 9.633e-02, Loss Eqns: 2.715e+00, Loss Aux: 8.451e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5633, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.665e+00, Loss Aux: 1.772e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5634, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.649e+00, Loss Aux: 1.816e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5635, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.609e+00, Loss Aux: 1.280e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5636, It: 0, Loss Data: 1.113e-01, Loss Eqns: 2.692e+00, Loss Aux: 1.126e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5637, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.720e+00, Loss Aux: 1.253e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5638, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.811e+00, Loss Aux: 1.363e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5639, It: 0, Loss Data: 9.878e-02, Loss Eqns: 2.656e+00, Loss Aux: 1.001e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5640, It: 0, Loss Data: 1.185e-01, Loss Eqns: 2.609e+00, Loss Aux: 7.134e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5641, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.714e+00, Loss Aux: 9.659e-03, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5642, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.677e+00, Loss Aux: 1.439e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5643, It: 0, Loss Data: 8.014e-02, Loss Eqns: 2.751e+00, Loss Aux: 1.457e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5644, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.698e+00, Loss Aux: 1.269e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5645, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.660e+00, Loss Aux: 1.218e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5646, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.532e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5647, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.711e+00, Loss Aux: 1.671e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5648, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.688e+00, Loss Aux: 1.558e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5649, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.721e+00, Loss Aux: 1.110e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5650, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.698e+00, Loss Aux: 7.429e-03, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 5651, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.590e+00, Loss Aux: 7.067e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5652, It: 0, Loss Data: 9.976e-02, Loss Eqns: 2.641e+00, Loss Aux: 8.185e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5653, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.717e+00, Loss Aux: 7.143e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5654, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.712e+00, Loss Aux: 4.447e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5655, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.758e+00, Loss Aux: 6.807e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5656, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.676e+00, Loss Aux: 1.507e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5657, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.727e+00, Loss Aux: 1.592e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5658, It: 0, Loss Data: 9.918e-02, Loss Eqns: 2.633e+00, Loss Aux: 1.044e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5659, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.699e+00, Loss Aux: 8.239e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5660, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.772e+00, Loss Aux: 9.021e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5661, It: 0, Loss Data: 1.254e-01, Loss Eqns: 2.676e+00, Loss Aux: 1.036e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5662, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.818e+00, Loss Aux: 6.572e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5663, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.765e+00, Loss Aux: 4.792e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5664, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.752e+00, Loss Aux: 5.624e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5665, It: 0, Loss Data: 9.424e-02, Loss Eqns: 2.843e+00, Loss Aux: 7.867e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5666, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.809e+00, Loss Aux: 1.080e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5667, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.687e+00, Loss Aux: 1.034e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5668, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.638e+00, Loss Aux: 7.556e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5669, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.734e+00, Loss Aux: 9.597e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5670, It: 0, Loss Data: 9.424e-02, Loss Eqns: 2.719e+00, Loss Aux: 1.667e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5671, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.813e+00, Loss Aux: 1.707e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5672, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.828e+00, Loss Aux: 9.994e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5673, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.796e+00, Loss Aux: 6.326e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5674, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.757e+00, Loss Aux: 6.221e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5675, It: 0, Loss Data: 9.763e-02, Loss Eqns: 2.834e+00, Loss Aux: 7.163e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5676, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.725e+00, Loss Aux: 1.387e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5677, It: 0, Loss Data: 1.374e-01, Loss Eqns: 2.849e+00, Loss Aux: 7.919e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5678, It: 0, Loss Data: 1.217e-01, Loss Eqns: 2.866e+00, Loss Aux: 1.050e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 5679, It: 0, Loss Data: 1.320e-01, Loss Eqns: 2.931e+00, Loss Aux: 2.220e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5680, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.719e+00, Loss Aux: 1.610e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5681, It: 0, Loss Data: 1.366e-01, Loss Eqns: 2.788e+00, Loss Aux: 8.131e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5682, It: 0, Loss Data: 1.770e-01, Loss Eqns: 2.915e+00, Loss Aux: 6.150e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5683, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.757e+00, Loss Aux: 1.195e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5684, It: 0, Loss Data: 2.373e-01, Loss Eqns: 4.150e+00, Loss Aux: 3.566e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5685, It: 0, Loss Data: 1.651e-01, Loss Eqns: 3.728e+00, Loss Aux: 2.340e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5686, It: 0, Loss Data: 2.775e-01, Loss Eqns: 4.613e+00, Loss Aux: 1.068e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5687, It: 0, Loss Data: 1.647e-01, Loss Eqns: 4.025e+00, Loss Aux: 1.439e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5688, It: 0, Loss Data: 2.186e-01, Loss Eqns: 4.424e+00, Loss Aux: 1.704e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5689, It: 0, Loss Data: 1.789e-01, Loss Eqns: 3.690e+00, Loss Aux: 5.159e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5690, It: 0, Loss Data: 2.049e-01, Loss Eqns: 4.135e+00, Loss Aux: 9.130e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5691, It: 0, Loss Data: 2.194e-01, Loss Eqns: 3.699e+00, Loss Aux: 4.192e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5692, It: 0, Loss Data: 1.740e-01, Loss Eqns: 3.410e+00, Loss Aux: 2.514e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5693, It: 0, Loss Data: 2.804e-01, Loss Eqns: 5.082e+00, Loss Aux: 4.755e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5694, It: 0, Loss Data: 1.790e-01, Loss Eqns: 3.202e+00, Loss Aux: 4.833e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5695, It: 0, Loss Data: 2.826e-01, Loss Eqns: 4.082e+00, Loss Aux: 3.042e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5696, It: 0, Loss Data: 1.800e-01, Loss Eqns: 3.456e+00, Loss Aux: 2.085e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5697, It: 0, Loss Data: 2.269e-01, Loss Eqns: 3.302e+00, Loss Aux: 3.006e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5698, It: 0, Loss Data: 1.686e-01, Loss Eqns: 3.542e+00, Loss Aux: 1.881e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 5699, It: 0, Loss Data: 1.826e-01, Loss Eqns: 3.028e+00, Loss Aux: 1.010e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5700, It: 0, Loss Data: 1.799e-01, Loss Eqns: 3.110e+00, Loss Aux: 9.799e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5701, It: 0, Loss Data: 1.642e-01, Loss Eqns: 2.912e+00, Loss Aux: 1.696e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5702, It: 0, Loss Data: 1.778e-01, Loss Eqns: 2.823e+00, Loss Aux: 2.543e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5703, It: 0, Loss Data: 1.520e-01, Loss Eqns: 2.998e+00, Loss Aux: 2.653e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5704, It: 0, Loss Data: 1.447e-01, Loss Eqns: 2.940e+00, Loss Aux: 1.884e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5705, It: 0, Loss Data: 1.441e-01, Loss Eqns: 2.905e+00, Loss Aux: 1.585e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5706, It: 0, Loss Data: 1.351e-01, Loss Eqns: 3.019e+00, Loss Aux: 2.118e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5707, It: 0, Loss Data: 1.601e-01, Loss Eqns: 2.859e+00, Loss Aux: 1.842e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5708, It: 0, Loss Data: 1.332e-01, Loss Eqns: 2.957e+00, Loss Aux: 5.479e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5709, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.054e+00, Loss Aux: 4.299e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5710, It: 0, Loss Data: 1.315e-01, Loss Eqns: 2.971e+00, Loss Aux: 7.755e-03, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5711, It: 0, Loss Data: 1.401e-01, Loss Eqns: 3.152e+00, Loss Aux: 3.197e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5712, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.031e+00, Loss Aux: 4.354e-02, Time: 0.249, Learning Rate: 1.0e-03\n",
      "Epoch: 5713, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.006e+00, Loss Aux: 3.185e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 5714, It: 0, Loss Data: 1.368e-01, Loss Eqns: 2.950e+00, Loss Aux: 2.083e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5715, It: 0, Loss Data: 1.619e-01, Loss Eqns: 3.184e+00, Loss Aux: 1.743e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 5716, It: 0, Loss Data: 1.171e-01, Loss Eqns: 3.464e+00, Loss Aux: 1.390e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5717, It: 0, Loss Data: 1.407e-01, Loss Eqns: 3.265e+00, Loss Aux: 1.205e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5718, It: 0, Loss Data: 1.332e-01, Loss Eqns: 3.054e+00, Loss Aux: 3.690e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5719, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.812e+00, Loss Aux: 8.025e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5720, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.954e+00, Loss Aux: 1.380e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5721, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.908e+00, Loss Aux: 2.197e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5722, It: 0, Loss Data: 1.152e-01, Loss Eqns: 3.037e+00, Loss Aux: 2.488e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5723, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.997e+00, Loss Aux: 1.462e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5724, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.919e+00, Loss Aux: 8.174e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5725, It: 0, Loss Data: 1.372e-01, Loss Eqns: 2.841e+00, Loss Aux: 7.013e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 5726, It: 0, Loss Data: 9.157e-02, Loss Eqns: 3.018e+00, Loss Aux: 8.461e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5727, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.876e+00, Loss Aux: 1.539e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5728, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.975e+00, Loss Aux: 2.127e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5729, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.788e+00, Loss Aux: 2.051e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5730, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.792e+00, Loss Aux: 1.676e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5731, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.901e+00, Loss Aux: 1.436e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5732, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.778e+00, Loss Aux: 1.300e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5733, It: 0, Loss Data: 1.228e-01, Loss Eqns: 2.855e+00, Loss Aux: 1.024e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 5734, It: 0, Loss Data: 1.153e-01, Loss Eqns: 3.038e+00, Loss Aux: 1.349e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5735, It: 0, Loss Data: 1.234e-01, Loss Eqns: 2.890e+00, Loss Aux: 9.340e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5736, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.883e+00, Loss Aux: 1.039e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5737, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.896e+00, Loss Aux: 1.417e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5738, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.882e+00, Loss Aux: 1.634e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5739, It: 0, Loss Data: 9.931e-02, Loss Eqns: 2.867e+00, Loss Aux: 1.395e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5740, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.919e+00, Loss Aux: 1.104e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5741, It: 0, Loss Data: 9.962e-02, Loss Eqns: 2.752e+00, Loss Aux: 1.194e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5742, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.876e+00, Loss Aux: 1.076e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5743, It: 0, Loss Data: 9.732e-02, Loss Eqns: 2.724e+00, Loss Aux: 8.964e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5744, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.924e+00, Loss Aux: 8.570e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5745, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.819e+00, Loss Aux: 1.026e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5746, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.968e+00, Loss Aux: 1.318e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 5747, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.847e+00, Loss Aux: 1.186e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5748, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.921e+00, Loss Aux: 1.049e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5749, It: 0, Loss Data: 8.781e-02, Loss Eqns: 3.012e+00, Loss Aux: 1.249e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 5750, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.862e+00, Loss Aux: 1.617e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 5751, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.849e+00, Loss Aux: 1.229e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5752, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.855e+00, Loss Aux: 7.719e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5753, It: 0, Loss Data: 8.867e-02, Loss Eqns: 2.910e+00, Loss Aux: 6.731e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 5754, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.813e+00, Loss Aux: 1.020e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5755, It: 0, Loss Data: 8.953e-02, Loss Eqns: 2.722e+00, Loss Aux: 1.366e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5756, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.774e+00, Loss Aux: 1.639e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5757, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.752e+00, Loss Aux: 1.674e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5758, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.770e+00, Loss Aux: 1.563e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5759, It: 0, Loss Data: 9.682e-02, Loss Eqns: 2.673e+00, Loss Aux: 1.103e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5760, It: 0, Loss Data: 8.988e-02, Loss Eqns: 2.707e+00, Loss Aux: 1.030e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5761, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.760e+00, Loss Aux: 1.139e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 5762, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.216e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5763, It: 0, Loss Data: 1.199e-01, Loss Eqns: 2.891e+00, Loss Aux: 9.538e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5764, It: 0, Loss Data: 1.235e-01, Loss Eqns: 2.714e+00, Loss Aux: 7.924e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5765, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.663e+00, Loss Aux: 9.852e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5766, It: 0, Loss Data: 9.550e-02, Loss Eqns: 2.898e+00, Loss Aux: 1.406e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5767, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.864e+00, Loss Aux: 1.249e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5768, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.878e+00, Loss Aux: 8.809e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5769, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.923e+00, Loss Aux: 1.456e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5770, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.925e+00, Loss Aux: 2.289e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5771, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.908e+00, Loss Aux: 1.726e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5772, It: 0, Loss Data: 1.182e-01, Loss Eqns: 2.845e+00, Loss Aux: 8.654e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5773, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.944e+00, Loss Aux: 7.947e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5774, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.860e+00, Loss Aux: 1.296e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5775, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.928e+00, Loss Aux: 1.579e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5776, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.826e+00, Loss Aux: 1.254e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5777, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.795e+00, Loss Aux: 9.783e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5778, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.930e+00, Loss Aux: 1.095e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5779, It: 0, Loss Data: 1.210e-01, Loss Eqns: 2.976e+00, Loss Aux: 1.328e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5780, It: 0, Loss Data: 9.611e-02, Loss Eqns: 2.952e+00, Loss Aux: 1.389e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5781, It: 0, Loss Data: 1.059e-01, Loss Eqns: 3.054e+00, Loss Aux: 1.584e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5782, It: 0, Loss Data: 8.036e-02, Loss Eqns: 2.818e+00, Loss Aux: 1.809e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5783, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.778e+00, Loss Aux: 1.701e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 5784, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.804e+00, Loss Aux: 1.722e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5785, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.692e+00, Loss Aux: 1.530e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 5786, It: 0, Loss Data: 1.171e-01, Loss Eqns: 2.709e+00, Loss Aux: 1.152e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 5787, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.778e+00, Loss Aux: 1.350e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5788, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.734e+00, Loss Aux: 2.126e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5789, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.693e+00, Loss Aux: 2.400e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5790, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.771e+00, Loss Aux: 2.010e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5791, It: 0, Loss Data: 1.158e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.108e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5792, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.974e+00, Loss Aux: 5.923e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5793, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.861e+00, Loss Aux: 6.615e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5794, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.957e+00, Loss Aux: 1.099e-02, Time: 0.257, Learning Rate: 1.0e-03\n",
      "Epoch: 5795, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.857e+00, Loss Aux: 1.596e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5796, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.809e+00, Loss Aux: 1.888e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5797, It: 0, Loss Data: 9.221e-02, Loss Eqns: 2.794e+00, Loss Aux: 1.583e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5798, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.861e+00, Loss Aux: 1.325e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 5799, It: 0, Loss Data: 9.503e-02, Loss Eqns: 2.821e+00, Loss Aux: 1.329e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 5800, It: 0, Loss Data: 9.899e-02, Loss Eqns: 2.821e+00, Loss Aux: 1.448e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5801, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.811e+00, Loss Aux: 1.151e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5802, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.804e+00, Loss Aux: 1.123e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5803, It: 0, Loss Data: 9.146e-02, Loss Eqns: 2.676e+00, Loss Aux: 1.474e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5804, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.757e+00, Loss Aux: 1.661e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5805, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.823e+00, Loss Aux: 1.025e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5806, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.756e+00, Loss Aux: 5.432e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5807, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.813e+00, Loss Aux: 5.399e-03, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 5808, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.901e+00, Loss Aux: 1.302e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 5809, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.768e+00, Loss Aux: 1.934e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 5810, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.882e+00, Loss Aux: 2.051e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5811, It: 0, Loss Data: 9.818e-02, Loss Eqns: 2.884e+00, Loss Aux: 2.263e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5812, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.905e+00, Loss Aux: 2.325e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5813, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.939e+00, Loss Aux: 1.486e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5814, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.888e+00, Loss Aux: 8.655e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5815, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.872e+00, Loss Aux: 6.639e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5816, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.713e+00, Loss Aux: 9.678e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5817, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.647e+00, Loss Aux: 1.533e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5818, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.708e+00, Loss Aux: 1.356e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5819, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.299e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5820, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.730e+00, Loss Aux: 1.985e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5821, It: 0, Loss Data: 9.544e-02, Loss Eqns: 2.866e+00, Loss Aux: 2.645e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5822, It: 0, Loss Data: 9.434e-02, Loss Eqns: 2.769e+00, Loss Aux: 2.326e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5823, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.780e+00, Loss Aux: 1.549e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5824, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.730e+00, Loss Aux: 1.572e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5825, It: 0, Loss Data: 9.952e-02, Loss Eqns: 2.741e+00, Loss Aux: 1.831e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5826, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.707e+00, Loss Aux: 1.529e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5827, It: 0, Loss Data: 1.173e-01, Loss Eqns: 2.784e+00, Loss Aux: 1.061e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 5828, It: 0, Loss Data: 9.918e-02, Loss Eqns: 2.686e+00, Loss Aux: 9.887e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5829, It: 0, Loss Data: 1.203e-01, Loss Eqns: 2.801e+00, Loss Aux: 9.846e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5830, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.710e+00, Loss Aux: 9.854e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5831, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.737e+00, Loss Aux: 1.174e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5832, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.729e+00, Loss Aux: 1.704e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5833, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.783e+00, Loss Aux: 1.476e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5834, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.818e+00, Loss Aux: 8.517e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5835, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.891e+00, Loss Aux: 1.008e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 5836, It: 0, Loss Data: 9.506e-02, Loss Eqns: 2.672e+00, Loss Aux: 1.657e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5837, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.867e+00, Loss Aux: 1.938e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5838, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.731e+00, Loss Aux: 1.838e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5839, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.769e+00, Loss Aux: 1.579e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5840, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.769e+00, Loss Aux: 1.931e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5841, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.935e+00, Loss Aux: 2.107e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5842, It: 0, Loss Data: 9.856e-02, Loss Eqns: 2.835e+00, Loss Aux: 1.254e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 5843, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.838e+00, Loss Aux: 6.010e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5844, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.708e+00, Loss Aux: 6.999e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5845, It: 0, Loss Data: 1.187e-01, Loss Eqns: 2.843e+00, Loss Aux: 1.378e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5846, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.788e+00, Loss Aux: 1.561e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5847, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.765e+00, Loss Aux: 1.366e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5848, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.784e+00, Loss Aux: 1.521e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5849, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.764e+00, Loss Aux: 1.721e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5850, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.767e+00, Loss Aux: 1.825e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5851, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.798e+00, Loss Aux: 2.358e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5852, It: 0, Loss Data: 1.174e-01, Loss Eqns: 2.908e+00, Loss Aux: 2.202e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5853, It: 0, Loss Data: 9.507e-02, Loss Eqns: 2.861e+00, Loss Aux: 1.506e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5854, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.767e+00, Loss Aux: 5.991e-03, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 5855, It: 0, Loss Data: 9.872e-02, Loss Eqns: 2.901e+00, Loss Aux: 3.946e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5856, It: 0, Loss Data: 9.932e-02, Loss Eqns: 2.859e+00, Loss Aux: 1.015e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5857, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.981e+00, Loss Aux: 2.512e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5858, It: 0, Loss Data: 9.527e-02, Loss Eqns: 2.933e+00, Loss Aux: 2.355e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5859, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.758e+00, Loss Aux: 2.279e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5860, It: 0, Loss Data: 9.875e-02, Loss Eqns: 2.740e+00, Loss Aux: 2.024e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5861, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.863e+00, Loss Aux: 1.452e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5862, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.732e+00, Loss Aux: 1.064e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 5863, It: 0, Loss Data: 9.993e-02, Loss Eqns: 2.627e+00, Loss Aux: 1.014e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5864, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.721e+00, Loss Aux: 1.078e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5865, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.730e+00, Loss Aux: 2.081e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5866, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.590e+00, Loss Aux: 1.735e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 5867, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.718e+00, Loss Aux: 1.174e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5868, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.719e+00, Loss Aux: 1.029e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5869, It: 0, Loss Data: 1.167e-01, Loss Eqns: 2.645e+00, Loss Aux: 1.120e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5870, It: 0, Loss Data: 9.194e-02, Loss Eqns: 2.667e+00, Loss Aux: 1.278e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5871, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.625e+00, Loss Aux: 1.322e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5872, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.545e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5873, It: 0, Loss Data: 8.895e-02, Loss Eqns: 2.764e+00, Loss Aux: 1.508e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5874, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.685e+00, Loss Aux: 9.701e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5875, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.787e+00, Loss Aux: 7.525e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5876, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.770e+00, Loss Aux: 9.760e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5877, It: 0, Loss Data: 9.822e-02, Loss Eqns: 2.782e+00, Loss Aux: 1.230e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5878, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.697e+00, Loss Aux: 1.333e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5879, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.762e+00, Loss Aux: 1.475e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5880, It: 0, Loss Data: 1.210e-01, Loss Eqns: 2.677e+00, Loss Aux: 1.557e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5881, It: 0, Loss Data: 9.994e-02, Loss Eqns: 2.843e+00, Loss Aux: 1.239e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 5882, It: 0, Loss Data: 8.886e-02, Loss Eqns: 2.805e+00, Loss Aux: 7.432e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 5883, It: 0, Loss Data: 9.181e-02, Loss Eqns: 2.635e+00, Loss Aux: 5.039e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 5884, It: 0, Loss Data: 8.588e-02, Loss Eqns: 2.816e+00, Loss Aux: 1.022e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5885, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.796e+00, Loss Aux: 2.389e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5886, It: 0, Loss Data: 1.204e-01, Loss Eqns: 2.770e+00, Loss Aux: 2.781e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 5887, It: 0, Loss Data: 9.975e-02, Loss Eqns: 2.748e+00, Loss Aux: 1.868e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 5888, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.666e+00, Loss Aux: 1.124e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 5889, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.839e+00, Loss Aux: 9.405e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5890, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.806e+00, Loss Aux: 1.106e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5891, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.750e+00, Loss Aux: 1.166e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 5892, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.863e+00, Loss Aux: 1.190e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5893, It: 0, Loss Data: 8.682e-02, Loss Eqns: 2.760e+00, Loss Aux: 1.220e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5894, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.733e+00, Loss Aux: 1.263e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5895, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.780e+00, Loss Aux: 1.182e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5896, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.704e+00, Loss Aux: 1.225e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5897, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.755e+00, Loss Aux: 1.389e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5898, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.689e+00, Loss Aux: 1.393e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5899, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.728e+00, Loss Aux: 1.236e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5900, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.705e+00, Loss Aux: 1.566e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5901, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.742e+00, Loss Aux: 1.843e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 5902, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.757e+00, Loss Aux: 1.525e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 5903, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.840e+00, Loss Aux: 1.231e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5904, It: 0, Loss Data: 9.961e-02, Loss Eqns: 2.750e+00, Loss Aux: 9.899e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5905, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.732e+00, Loss Aux: 9.378e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5906, It: 0, Loss Data: 8.571e-02, Loss Eqns: 2.733e+00, Loss Aux: 1.269e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5907, It: 0, Loss Data: 9.834e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.367e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5908, It: 0, Loss Data: 9.583e-02, Loss Eqns: 2.730e+00, Loss Aux: 1.411e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5909, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.282e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5910, It: 0, Loss Data: 9.396e-02, Loss Eqns: 2.680e+00, Loss Aux: 1.500e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5911, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.749e+00, Loss Aux: 1.669e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5912, It: 0, Loss Data: 1.564e-01, Loss Eqns: 3.276e+00, Loss Aux: 2.284e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5913, It: 0, Loss Data: 1.361e-01, Loss Eqns: 3.305e+00, Loss Aux: 9.220e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5914, It: 0, Loss Data: 1.561e-01, Loss Eqns: 3.314e+00, Loss Aux: 7.467e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 5915, It: 0, Loss Data: 1.469e-01, Loss Eqns: 3.099e+00, Loss Aux: 1.971e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5916, It: 0, Loss Data: 1.635e-01, Loss Eqns: 3.276e+00, Loss Aux: 1.838e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 5917, It: 0, Loss Data: 1.447e-01, Loss Eqns: 2.917e+00, Loss Aux: 7.325e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 5918, It: 0, Loss Data: 1.842e-01, Loss Eqns: 3.050e+00, Loss Aux: 6.145e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5919, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.900e+00, Loss Aux: 1.922e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5920, It: 0, Loss Data: 1.518e-01, Loss Eqns: 3.106e+00, Loss Aux: 2.606e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5921, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.829e+00, Loss Aux: 1.843e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 5922, It: 0, Loss Data: 1.410e-01, Loss Eqns: 3.087e+00, Loss Aux: 1.625e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5923, It: 0, Loss Data: 1.287e-01, Loss Eqns: 2.572e+00, Loss Aux: 2.168e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5924, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.723e+00, Loss Aux: 1.232e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5925, It: 0, Loss Data: 1.313e-01, Loss Eqns: 2.897e+00, Loss Aux: 1.152e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5926, It: 0, Loss Data: 1.229e-01, Loss Eqns: 2.615e+00, Loss Aux: 8.837e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 5927, It: 0, Loss Data: 1.395e-01, Loss Eqns: 2.663e+00, Loss Aux: 9.304e-03, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 5928, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.625e+00, Loss Aux: 1.710e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5929, It: 0, Loss Data: 1.257e-01, Loss Eqns: 2.922e+00, Loss Aux: 2.831e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5930, It: 0, Loss Data: 8.288e-02, Loss Eqns: 2.733e+00, Loss Aux: 2.442e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5931, It: 0, Loss Data: 1.329e-01, Loss Eqns: 2.823e+00, Loss Aux: 1.506e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5932, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.675e+00, Loss Aux: 1.170e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 5933, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.774e+00, Loss Aux: 1.182e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 5934, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.926e+00, Loss Aux: 1.006e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 5935, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.667e+00, Loss Aux: 1.160e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5936, It: 0, Loss Data: 1.236e-01, Loss Eqns: 2.782e+00, Loss Aux: 1.688e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5937, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.781e+00, Loss Aux: 2.363e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5938, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.919e+00, Loss Aux: 2.379e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5939, It: 0, Loss Data: 1.220e-01, Loss Eqns: 2.945e+00, Loss Aux: 1.381e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5940, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.798e+00, Loss Aux: 9.339e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 5941, It: 0, Loss Data: 9.156e-02, Loss Eqns: 2.874e+00, Loss Aux: 9.774e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 5942, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.747e+00, Loss Aux: 8.533e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5943, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.683e+00, Loss Aux: 8.765e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5944, It: 0, Loss Data: 1.186e-01, Loss Eqns: 2.684e+00, Loss Aux: 1.576e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5945, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.747e+00, Loss Aux: 2.582e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5946, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.818e+00, Loss Aux: 2.823e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5947, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.834e+00, Loss Aux: 2.215e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5948, It: 0, Loss Data: 9.932e-02, Loss Eqns: 2.821e+00, Loss Aux: 1.387e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5949, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.813e+00, Loss Aux: 7.138e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5950, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.716e+00, Loss Aux: 5.324e-03, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 5951, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.666e+00, Loss Aux: 1.129e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5952, It: 0, Loss Data: 9.465e-02, Loss Eqns: 2.635e+00, Loss Aux: 2.102e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5953, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.763e+00, Loss Aux: 2.586e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5954, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.809e+00, Loss Aux: 2.005e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 5955, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.704e+00, Loss Aux: 1.355e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 5956, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.710e+00, Loss Aux: 1.128e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 5957, It: 0, Loss Data: 9.340e-02, Loss Eqns: 2.670e+00, Loss Aux: 1.081e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5958, It: 0, Loss Data: 9.906e-02, Loss Eqns: 2.673e+00, Loss Aux: 7.937e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5959, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.626e+00, Loss Aux: 1.038e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5960, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.669e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 5961, It: 0, Loss Data: 9.907e-02, Loss Eqns: 2.795e+00, Loss Aux: 2.186e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5962, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.712e+00, Loss Aux: 1.587e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 5963, It: 0, Loss Data: 1.181e-01, Loss Eqns: 2.699e+00, Loss Aux: 1.073e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5964, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.707e+00, Loss Aux: 1.052e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5965, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.753e+00, Loss Aux: 1.197e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 5966, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.790e+00, Loss Aux: 1.213e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5967, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.711e+00, Loss Aux: 1.210e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 5968, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.875e+00, Loss Aux: 1.356e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5969, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.806e+00, Loss Aux: 1.515e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5970, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.645e+00, Loss Aux: 1.736e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 5971, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.747e+00, Loss Aux: 1.888e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5972, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.666e+00, Loss Aux: 2.013e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 5973, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.640e+00, Loss Aux: 1.700e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5974, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.657e+00, Loss Aux: 1.238e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 5975, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.707e+00, Loss Aux: 1.017e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5976, It: 0, Loss Data: 9.799e-02, Loss Eqns: 2.729e+00, Loss Aux: 1.242e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 5977, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.679e+00, Loss Aux: 1.423e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 5978, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.757e+00, Loss Aux: 1.324e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 5979, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.774e+00, Loss Aux: 1.192e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 5980, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.800e+00, Loss Aux: 1.237e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5981, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.768e+00, Loss Aux: 1.321e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 5982, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.660e+00, Loss Aux: 1.226e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 5983, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.646e+00, Loss Aux: 1.189e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 5984, It: 0, Loss Data: 9.627e-02, Loss Eqns: 2.812e+00, Loss Aux: 1.156e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 5985, It: 0, Loss Data: 8.335e-02, Loss Eqns: 2.696e+00, Loss Aux: 1.078e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 5986, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.667e+00, Loss Aux: 9.278e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 5987, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.659e+00, Loss Aux: 1.165e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 5988, It: 0, Loss Data: 9.543e-02, Loss Eqns: 2.760e+00, Loss Aux: 1.319e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 5989, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.752e+00, Loss Aux: 1.354e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5990, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.751e+00, Loss Aux: 1.314e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 5991, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.685e+00, Loss Aux: 1.494e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 5992, It: 0, Loss Data: 9.736e-02, Loss Eqns: 2.754e+00, Loss Aux: 1.608e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 5993, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.623e+00, Loss Aux: 1.599e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 5994, It: 0, Loss Data: 1.228e-01, Loss Eqns: 2.742e+00, Loss Aux: 1.691e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 5995, It: 0, Loss Data: 9.446e-02, Loss Eqns: 2.819e+00, Loss Aux: 1.261e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 5996, It: 0, Loss Data: 9.800e-02, Loss Eqns: 2.791e+00, Loss Aux: 1.167e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 5997, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.779e+00, Loss Aux: 1.050e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 5998, It: 0, Loss Data: 9.735e-02, Loss Eqns: 2.822e+00, Loss Aux: 1.198e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 5999, It: 0, Loss Data: 8.104e-02, Loss Eqns: 2.723e+00, Loss Aux: 1.591e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6000, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.855e+00, Loss Aux: 1.940e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6001, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.763e+00, Loss Aux: 1.273e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6002, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.763e+00, Loss Aux: 7.842e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6003, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.645e+00, Loss Aux: 9.202e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6004, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.753e+00, Loss Aux: 1.242e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6005, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.771e+00, Loss Aux: 1.052e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 6006, It: 0, Loss Data: 9.475e-02, Loss Eqns: 2.660e+00, Loss Aux: 6.998e-03, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6007, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.657e+00, Loss Aux: 1.185e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6008, It: 0, Loss Data: 9.819e-02, Loss Eqns: 2.732e+00, Loss Aux: 2.050e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6009, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.659e+00, Loss Aux: 1.991e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6010, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.705e+00, Loss Aux: 1.611e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6011, It: 0, Loss Data: 9.864e-02, Loss Eqns: 2.782e+00, Loss Aux: 1.553e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6012, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.704e+00, Loss Aux: 1.493e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6013, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.748e+00, Loss Aux: 1.767e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6014, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.959e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6015, It: 0, Loss Data: 9.582e-02, Loss Eqns: 2.697e+00, Loss Aux: 1.496e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6016, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.712e+00, Loss Aux: 1.082e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6017, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.606e+00, Loss Aux: 1.271e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6018, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.723e+00, Loss Aux: 1.598e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6019, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.622e+00, Loss Aux: 1.356e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6020, It: 0, Loss Data: 9.492e-02, Loss Eqns: 2.573e+00, Loss Aux: 9.480e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6021, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.678e+00, Loss Aux: 1.071e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 6022, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.734e+00, Loss Aux: 1.178e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6023, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.685e+00, Loss Aux: 1.249e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6024, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.686e+00, Loss Aux: 1.228e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6025, It: 0, Loss Data: 8.255e-02, Loss Eqns: 2.624e+00, Loss Aux: 1.464e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6026, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.797e+00, Loss Aux: 1.723e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6027, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.789e+00, Loss Aux: 2.213e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6028, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.862e+00, Loss Aux: 1.967e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6029, It: 0, Loss Data: 8.084e-02, Loss Eqns: 2.746e+00, Loss Aux: 1.491e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6030, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.779e+00, Loss Aux: 1.205e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 6031, It: 0, Loss Data: 9.396e-02, Loss Eqns: 2.659e+00, Loss Aux: 1.222e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6032, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.688e+00, Loss Aux: 1.241e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6033, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.678e+00, Loss Aux: 1.380e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6034, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.680e+00, Loss Aux: 1.556e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6035, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.666e+00, Loss Aux: 1.453e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6036, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.648e+00, Loss Aux: 1.286e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6037, It: 0, Loss Data: 9.099e-02, Loss Eqns: 2.682e+00, Loss Aux: 1.501e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6038, It: 0, Loss Data: 9.988e-02, Loss Eqns: 2.686e+00, Loss Aux: 1.592e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6039, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.581e+00, Loss Aux: 1.126e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6040, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.747e+00, Loss Aux: 9.036e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6041, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.651e+00, Loss Aux: 9.056e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6042, It: 0, Loss Data: 9.707e-02, Loss Eqns: 2.580e+00, Loss Aux: 1.000e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 6043, It: 0, Loss Data: 8.799e-02, Loss Eqns: 2.754e+00, Loss Aux: 1.221e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 6044, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.627e+00, Loss Aux: 1.670e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6045, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.673e+00, Loss Aux: 1.762e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6046, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.633e+00, Loss Aux: 1.472e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6047, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.703e+00, Loss Aux: 1.012e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 6048, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.747e+00, Loss Aux: 7.871e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6049, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.691e+00, Loss Aux: 9.361e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6050, It: 0, Loss Data: 9.146e-02, Loss Eqns: 2.768e+00, Loss Aux: 1.158e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6051, It: 0, Loss Data: 9.908e-02, Loss Eqns: 2.731e+00, Loss Aux: 1.317e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6052, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.681e+00, Loss Aux: 1.803e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6053, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.731e+00, Loss Aux: 1.784e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6054, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.670e+00, Loss Aux: 1.426e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6055, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.735e+00, Loss Aux: 1.164e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6056, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.702e+00, Loss Aux: 1.056e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6057, It: 0, Loss Data: 1.174e-01, Loss Eqns: 2.644e+00, Loss Aux: 1.141e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6058, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.670e+00, Loss Aux: 1.641e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6059, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.735e+00, Loss Aux: 1.709e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6060, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.625e+00, Loss Aux: 1.289e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6061, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.627e+00, Loss Aux: 8.865e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6062, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.687e+00, Loss Aux: 1.328e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6063, It: 0, Loss Data: 9.446e-02, Loss Eqns: 2.774e+00, Loss Aux: 1.932e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6064, It: 0, Loss Data: 9.252e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.610e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6065, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.715e+00, Loss Aux: 1.204e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6066, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.638e+00, Loss Aux: 1.460e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6067, It: 0, Loss Data: 8.735e-02, Loss Eqns: 2.710e+00, Loss Aux: 1.422e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6068, It: 0, Loss Data: 9.842e-02, Loss Eqns: 2.813e+00, Loss Aux: 7.457e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6069, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.745e+00, Loss Aux: 6.137e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6070, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.798e+00, Loss Aux: 1.205e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6071, It: 0, Loss Data: 9.331e-02, Loss Eqns: 2.749e+00, Loss Aux: 2.450e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6072, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.680e+00, Loss Aux: 1.999e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6073, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.637e+00, Loss Aux: 1.333e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6074, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.738e+00, Loss Aux: 1.279e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6075, It: 0, Loss Data: 9.813e-02, Loss Eqns: 2.676e+00, Loss Aux: 1.372e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6076, It: 0, Loss Data: 8.478e-02, Loss Eqns: 2.789e+00, Loss Aux: 9.972e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6077, It: 0, Loss Data: 1.216e-01, Loss Eqns: 2.645e+00, Loss Aux: 9.879e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6078, It: 0, Loss Data: 9.280e-02, Loss Eqns: 2.733e+00, Loss Aux: 1.095e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6079, It: 0, Loss Data: 9.461e-02, Loss Eqns: 2.719e+00, Loss Aux: 1.058e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6080, It: 0, Loss Data: 9.411e-02, Loss Eqns: 2.666e+00, Loss Aux: 9.511e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6081, It: 0, Loss Data: 9.399e-02, Loss Eqns: 2.600e+00, Loss Aux: 8.587e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6082, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.694e+00, Loss Aux: 1.076e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6083, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.624e+00, Loss Aux: 1.401e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6084, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.659e+00, Loss Aux: 1.623e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6085, It: 0, Loss Data: 9.799e-02, Loss Eqns: 2.775e+00, Loss Aux: 2.010e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6086, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.736e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6087, It: 0, Loss Data: 8.408e-02, Loss Eqns: 2.718e+00, Loss Aux: 1.284e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6088, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.708e+00, Loss Aux: 1.237e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6089, It: 0, Loss Data: 9.071e-02, Loss Eqns: 2.762e+00, Loss Aux: 1.128e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6090, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.690e+00, Loss Aux: 1.202e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6091, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.606e+00, Loss Aux: 1.375e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6092, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.614e+00, Loss Aux: 1.412e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6093, It: 0, Loss Data: 8.981e-02, Loss Eqns: 2.586e+00, Loss Aux: 1.151e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6094, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.578e+00, Loss Aux: 1.012e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6095, It: 0, Loss Data: 9.926e-02, Loss Eqns: 2.637e+00, Loss Aux: 7.862e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6096, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.583e+00, Loss Aux: 8.656e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6097, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.630e+00, Loss Aux: 1.242e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6098, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.701e+00, Loss Aux: 1.676e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6099, It: 0, Loss Data: 9.940e-02, Loss Eqns: 2.590e+00, Loss Aux: 1.912e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6100, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.725e+00, Loss Aux: 1.937e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6101, It: 0, Loss Data: 9.586e-02, Loss Eqns: 2.681e+00, Loss Aux: 1.332e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6102, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.667e+00, Loss Aux: 1.311e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6103, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.637e+00, Loss Aux: 1.230e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6104, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.626e+00, Loss Aux: 1.042e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6105, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.571e+00, Loss Aux: 8.912e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6106, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.629e+00, Loss Aux: 1.640e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6107, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.704e+00, Loss Aux: 2.132e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6108, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.641e+00, Loss Aux: 1.431e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6109, It: 0, Loss Data: 9.026e-02, Loss Eqns: 2.761e+00, Loss Aux: 1.132e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6110, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.671e+00, Loss Aux: 1.805e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6111, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.654e+00, Loss Aux: 2.209e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6112, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.662e+00, Loss Aux: 1.236e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6113, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.559e+00, Loss Aux: 9.298e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6114, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.692e+00, Loss Aux: 9.882e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6115, It: 0, Loss Data: 1.180e-01, Loss Eqns: 2.679e+00, Loss Aux: 1.512e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6116, It: 0, Loss Data: 1.179e-01, Loss Eqns: 2.540e+00, Loss Aux: 1.614e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6117, It: 0, Loss Data: 8.636e-02, Loss Eqns: 2.703e+00, Loss Aux: 1.014e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6118, It: 0, Loss Data: 9.001e-02, Loss Eqns: 2.751e+00, Loss Aux: 8.608e-03, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6119, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.669e+00, Loss Aux: 1.089e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6120, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.691e+00, Loss Aux: 1.210e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6121, It: 0, Loss Data: 9.893e-02, Loss Eqns: 2.725e+00, Loss Aux: 8.778e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6122, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.724e+00, Loss Aux: 5.517e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6123, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.690e+00, Loss Aux: 9.459e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6124, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.717e+00, Loss Aux: 2.172e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6125, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.625e+00, Loss Aux: 2.467e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6126, It: 0, Loss Data: 9.796e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.755e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6127, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.782e+00, Loss Aux: 1.532e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6128, It: 0, Loss Data: 9.911e-02, Loss Eqns: 2.822e+00, Loss Aux: 1.647e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6129, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.727e+00, Loss Aux: 1.941e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6130, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.733e+00, Loss Aux: 1.530e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6131, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.763e+00, Loss Aux: 1.018e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6132, It: 0, Loss Data: 9.936e-02, Loss Eqns: 2.596e+00, Loss Aux: 1.109e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6133, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.622e+00, Loss Aux: 1.254e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6134, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.755e+00, Loss Aux: 1.116e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6135, It: 0, Loss Data: 8.922e-02, Loss Eqns: 2.681e+00, Loss Aux: 9.479e-03, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6136, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.728e+00, Loss Aux: 1.179e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6137, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.709e+00, Loss Aux: 1.255e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6138, It: 0, Loss Data: 1.163e-01, Loss Eqns: 2.660e+00, Loss Aux: 1.309e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6139, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.701e+00, Loss Aux: 1.628e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6140, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.708e+00, Loss Aux: 1.637e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6141, It: 0, Loss Data: 9.933e-02, Loss Eqns: 2.661e+00, Loss Aux: 1.452e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6142, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.599e+00, Loss Aux: 1.274e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6143, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.770e+00, Loss Aux: 1.222e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6144, It: 0, Loss Data: 9.605e-02, Loss Eqns: 2.640e+00, Loss Aux: 8.940e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6145, It: 0, Loss Data: 9.271e-02, Loss Eqns: 2.659e+00, Loss Aux: 8.566e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6146, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.706e+00, Loss Aux: 1.211e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6147, It: 0, Loss Data: 8.799e-02, Loss Eqns: 2.576e+00, Loss Aux: 1.247e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6148, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.700e+00, Loss Aux: 9.108e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6149, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.647e+00, Loss Aux: 1.013e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6150, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.751e+00, Loss Aux: 1.476e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6151, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.595e+00, Loss Aux: 1.633e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6152, It: 0, Loss Data: 9.764e-02, Loss Eqns: 2.593e+00, Loss Aux: 1.755e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6153, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.637e+00, Loss Aux: 1.715e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6154, It: 0, Loss Data: 9.538e-02, Loss Eqns: 2.668e+00, Loss Aux: 1.283e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6155, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.844e+00, Loss Aux: 8.182e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6156, It: 0, Loss Data: 8.701e-02, Loss Eqns: 2.746e+00, Loss Aux: 1.024e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6157, It: 0, Loss Data: 9.664e-02, Loss Eqns: 2.710e+00, Loss Aux: 1.100e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6158, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.690e+00, Loss Aux: 1.400e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6159, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.768e+00, Loss Aux: 1.247e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6160, It: 0, Loss Data: 8.478e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.012e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6161, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.694e+00, Loss Aux: 1.049e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6162, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.633e+00, Loss Aux: 6.687e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6163, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.507e+00, Loss Aux: 7.215e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6164, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.715e+00, Loss Aux: 1.196e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6165, It: 0, Loss Data: 1.248e-01, Loss Eqns: 2.588e+00, Loss Aux: 1.109e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6166, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.762e+00, Loss Aux: 1.003e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6167, It: 0, Loss Data: 9.910e-02, Loss Eqns: 2.699e+00, Loss Aux: 1.017e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6168, It: 0, Loss Data: 9.622e-02, Loss Eqns: 2.714e+00, Loss Aux: 1.207e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6169, It: 0, Loss Data: 9.262e-02, Loss Eqns: 2.765e+00, Loss Aux: 1.695e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 6170, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.707e+00, Loss Aux: 1.872e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6171, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.838e+00, Loss Aux: 1.785e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6172, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.816e+00, Loss Aux: 1.619e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6173, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.693e+00, Loss Aux: 1.545e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6174, It: 0, Loss Data: 8.966e-02, Loss Eqns: 2.777e+00, Loss Aux: 1.218e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6175, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.788e+00, Loss Aux: 1.065e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6176, It: 0, Loss Data: 8.404e-02, Loss Eqns: 2.762e+00, Loss Aux: 1.189e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 6177, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.606e+00, Loss Aux: 1.192e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6178, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.722e+00, Loss Aux: 8.405e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6179, It: 0, Loss Data: 9.970e-02, Loss Eqns: 2.655e+00, Loss Aux: 8.323e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6180, It: 0, Loss Data: 8.484e-02, Loss Eqns: 2.673e+00, Loss Aux: 9.304e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6181, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.553e+00, Loss Aux: 1.198e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 6182, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.621e+00, Loss Aux: 1.102e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6183, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.582e+00, Loss Aux: 9.152e-03, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6184, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.574e+00, Loss Aux: 1.166e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6185, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.581e+00, Loss Aux: 1.227e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6186, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.639e+00, Loss Aux: 9.599e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6187, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.650e+00, Loss Aux: 9.482e-03, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6188, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.740e+00, Loss Aux: 1.067e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6189, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.630e+00, Loss Aux: 1.322e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6190, It: 0, Loss Data: 9.086e-02, Loss Eqns: 2.740e+00, Loss Aux: 1.068e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6191, It: 0, Loss Data: 9.935e-02, Loss Eqns: 2.720e+00, Loss Aux: 7.238e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6192, It: 0, Loss Data: 9.060e-02, Loss Eqns: 2.778e+00, Loss Aux: 7.017e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6193, It: 0, Loss Data: 1.290e-01, Loss Eqns: 2.770e+00, Loss Aux: 4.498e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6194, It: 0, Loss Data: 1.334e-01, Loss Eqns: 3.034e+00, Loss Aux: 2.105e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6195, It: 0, Loss Data: 8.506e-02, Loss Eqns: 2.758e+00, Loss Aux: 2.639e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6196, It: 0, Loss Data: 1.244e-01, Loss Eqns: 2.997e+00, Loss Aux: 1.972e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6197, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.728e+00, Loss Aux: 1.870e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6198, It: 0, Loss Data: 1.308e-01, Loss Eqns: 3.112e+00, Loss Aux: 1.983e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6199, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.743e+00, Loss Aux: 1.024e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6200, It: 0, Loss Data: 1.244e-01, Loss Eqns: 2.789e+00, Loss Aux: 7.684e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6201, It: 0, Loss Data: 1.162e-01, Loss Eqns: 2.753e+00, Loss Aux: 1.102e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6202, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.750e+00, Loss Aux: 1.240e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6203, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.839e+00, Loss Aux: 1.202e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6204, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.796e+00, Loss Aux: 1.364e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6205, It: 0, Loss Data: 8.723e-02, Loss Eqns: 2.755e+00, Loss Aux: 1.914e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6206, It: 0, Loss Data: 9.655e-02, Loss Eqns: 2.641e+00, Loss Aux: 1.840e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6207, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.697e+00, Loss Aux: 1.855e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6208, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.653e+00, Loss Aux: 1.366e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6209, It: 0, Loss Data: 9.816e-02, Loss Eqns: 2.667e+00, Loss Aux: 7.806e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6210, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.599e+00, Loss Aux: 8.505e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6211, It: 0, Loss Data: 9.664e-02, Loss Eqns: 2.613e+00, Loss Aux: 1.081e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6212, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.575e+00, Loss Aux: 1.530e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6213, It: 0, Loss Data: 1.317e-01, Loss Eqns: 2.616e+00, Loss Aux: 1.950e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 6214, It: 0, Loss Data: 8.773e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.266e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6215, It: 0, Loss Data: 9.957e-02, Loss Eqns: 2.634e+00, Loss Aux: 2.732e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6216, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.624e+00, Loss Aux: 2.953e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6217, It: 0, Loss Data: 8.940e-02, Loss Eqns: 2.666e+00, Loss Aux: 1.941e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6218, It: 0, Loss Data: 1.229e-01, Loss Eqns: 2.579e+00, Loss Aux: 8.791e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6219, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.632e+00, Loss Aux: 5.026e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6220, It: 0, Loss Data: 8.148e-02, Loss Eqns: 2.647e+00, Loss Aux: 6.603e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6221, It: 0, Loss Data: 9.731e-02, Loss Eqns: 2.639e+00, Loss Aux: 9.316e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6222, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.558e+00, Loss Aux: 1.118e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6223, It: 0, Loss Data: 9.755e-02, Loss Eqns: 2.574e+00, Loss Aux: 1.132e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6224, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.609e+00, Loss Aux: 1.141e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6225, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.610e+00, Loss Aux: 1.529e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6226, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.629e+00, Loss Aux: 1.961e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6227, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.567e+00, Loss Aux: 1.653e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6228, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.628e+00, Loss Aux: 1.199e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6229, It: 0, Loss Data: 1.187e-01, Loss Eqns: 2.608e+00, Loss Aux: 1.085e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6230, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.734e+00, Loss Aux: 9.451e-03, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6231, It: 0, Loss Data: 9.449e-02, Loss Eqns: 2.695e+00, Loss Aux: 5.797e-03, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6232, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.827e+00, Loss Aux: 6.146e-03, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6233, It: 0, Loss Data: 8.975e-02, Loss Eqns: 2.721e+00, Loss Aux: 9.767e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6234, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.621e+00, Loss Aux: 9.634e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6235, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.660e+00, Loss Aux: 9.335e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6236, It: 0, Loss Data: 9.138e-02, Loss Eqns: 2.720e+00, Loss Aux: 1.168e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 6237, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.669e+00, Loss Aux: 1.027e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6238, It: 0, Loss Data: 9.506e-02, Loss Eqns: 2.635e+00, Loss Aux: 1.208e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6239, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.823e+00, Loss Aux: 1.598e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 6240, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.719e+00, Loss Aux: 1.475e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 6241, It: 0, Loss Data: 9.726e-02, Loss Eqns: 2.693e+00, Loss Aux: 1.350e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 6242, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.722e+00, Loss Aux: 1.493e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6243, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.817e+00, Loss Aux: 1.529e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6244, It: 0, Loss Data: 8.984e-02, Loss Eqns: 2.737e+00, Loss Aux: 1.130e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6245, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.717e+00, Loss Aux: 1.059e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6246, It: 0, Loss Data: 9.734e-02, Loss Eqns: 2.695e+00, Loss Aux: 9.573e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6247, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.725e+00, Loss Aux: 9.909e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6248, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.845e+00, Loss Aux: 8.288e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6249, It: 0, Loss Data: 9.286e-02, Loss Eqns: 2.672e+00, Loss Aux: 8.279e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6250, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.794e+00, Loss Aux: 1.239e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6251, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.768e+00, Loss Aux: 1.061e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 6252, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.739e+00, Loss Aux: 1.018e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6253, It: 0, Loss Data: 1.146e-01, Loss Eqns: 2.635e+00, Loss Aux: 1.259e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6254, It: 0, Loss Data: 9.923e-02, Loss Eqns: 2.710e+00, Loss Aux: 1.917e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6255, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.736e+00, Loss Aux: 1.969e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 6256, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.692e+00, Loss Aux: 1.221e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 6257, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.674e+00, Loss Aux: 8.817e-03, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 6258, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.715e+00, Loss Aux: 1.020e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6259, It: 0, Loss Data: 8.746e-02, Loss Eqns: 2.664e+00, Loss Aux: 7.862e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6260, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.663e+00, Loss Aux: 8.278e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6261, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.604e+00, Loss Aux: 1.210e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6262, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.703e+00, Loss Aux: 8.205e-03, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 6263, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.749e+00, Loss Aux: 8.538e-03, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 6264, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.663e+00, Loss Aux: 1.468e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6265, It: 0, Loss Data: 9.792e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.813e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6266, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.681e+00, Loss Aux: 1.542e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6267, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.683e+00, Loss Aux: 1.198e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6268, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.724e+00, Loss Aux: 1.386e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6269, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.572e+00, Loss Aux: 1.224e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6270, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.603e+00, Loss Aux: 7.990e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6271, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.674e+00, Loss Aux: 9.190e-03, Time: 0.264, Learning Rate: 1.0e-03\n",
      "Epoch: 6272, It: 0, Loss Data: 9.725e-02, Loss Eqns: 2.618e+00, Loss Aux: 1.495e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6273, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.618e+00, Loss Aux: 1.738e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6274, It: 0, Loss Data: 8.920e-02, Loss Eqns: 2.634e+00, Loss Aux: 1.474e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6275, It: 0, Loss Data: 9.782e-02, Loss Eqns: 2.737e+00, Loss Aux: 1.105e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6276, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.542e+00, Loss Aux: 1.148e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6277, It: 0, Loss Data: 8.749e-02, Loss Eqns: 2.580e+00, Loss Aux: 1.165e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6278, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.667e+00, Loss Aux: 1.123e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6279, It: 0, Loss Data: 9.407e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.115e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6280, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.633e+00, Loss Aux: 1.116e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6281, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.685e+00, Loss Aux: 1.278e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6282, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.637e+00, Loss Aux: 1.818e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 6283, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.576e+00, Loss Aux: 1.641e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6284, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.592e+00, Loss Aux: 1.483e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6285, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.533e+00, Loss Aux: 1.269e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6286, It: 0, Loss Data: 9.721e-02, Loss Eqns: 2.674e+00, Loss Aux: 1.111e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 6287, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.619e+00, Loss Aux: 1.000e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6288, It: 0, Loss Data: 9.622e-02, Loss Eqns: 2.663e+00, Loss Aux: 8.656e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6289, It: 0, Loss Data: 8.514e-02, Loss Eqns: 2.689e+00, Loss Aux: 1.452e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6290, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.580e+00, Loss Aux: 1.978e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6291, It: 0, Loss Data: 9.114e-02, Loss Eqns: 2.600e+00, Loss Aux: 1.679e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6292, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.620e+00, Loss Aux: 9.917e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6293, It: 0, Loss Data: 9.826e-02, Loss Eqns: 2.597e+00, Loss Aux: 9.230e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6294, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.650e+00, Loss Aux: 9.535e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6295, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.637e+00, Loss Aux: 8.073e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6296, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.687e+00, Loss Aux: 7.436e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6297, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.770e+00, Loss Aux: 1.392e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6298, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.779e+00, Loss Aux: 1.643e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6299, It: 0, Loss Data: 9.996e-02, Loss Eqns: 2.645e+00, Loss Aux: 1.077e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6300, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.618e+00, Loss Aux: 8.196e-03, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6301, It: 0, Loss Data: 9.949e-02, Loss Eqns: 2.571e+00, Loss Aux: 9.703e-03, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 6302, It: 0, Loss Data: 1.302e-01, Loss Eqns: 2.874e+00, Loss Aux: 2.578e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6303, It: 0, Loss Data: 2.469e-01, Loss Eqns: 3.592e+00, Loss Aux: 7.686e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6304, It: 0, Loss Data: 1.005e-01, Loss Eqns: 3.052e+00, Loss Aux: 2.131e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6305, It: 0, Loss Data: 2.401e-01, Loss Eqns: 3.344e+00, Loss Aux: 3.630e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6306, It: 0, Loss Data: 1.342e-01, Loss Eqns: 2.645e+00, Loss Aux: 1.507e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6307, It: 0, Loss Data: 2.125e-01, Loss Eqns: 3.274e+00, Loss Aux: 3.990e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6308, It: 0, Loss Data: 1.405e-01, Loss Eqns: 2.793e+00, Loss Aux: 4.362e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6309, It: 0, Loss Data: 1.798e-01, Loss Eqns: 4.155e+00, Loss Aux: 1.436e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6310, It: 0, Loss Data: 1.483e-01, Loss Eqns: 3.044e+00, Loss Aux: 1.762e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6311, It: 0, Loss Data: 1.793e-01, Loss Eqns: 3.623e+00, Loss Aux: 1.983e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6312, It: 0, Loss Data: 1.486e-01, Loss Eqns: 3.354e+00, Loss Aux: 1.965e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6313, It: 0, Loss Data: 1.743e-01, Loss Eqns: 3.562e+00, Loss Aux: 1.735e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6314, It: 0, Loss Data: 1.392e-01, Loss Eqns: 3.123e+00, Loss Aux: 1.280e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6315, It: 0, Loss Data: 1.503e-01, Loss Eqns: 3.073e+00, Loss Aux: 1.401e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 6316, It: 0, Loss Data: 1.554e-01, Loss Eqns: 3.023e+00, Loss Aux: 2.752e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6317, It: 0, Loss Data: 1.522e-01, Loss Eqns: 3.278e+00, Loss Aux: 3.471e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6318, It: 0, Loss Data: 1.217e-01, Loss Eqns: 3.023e+00, Loss Aux: 1.762e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6319, It: 0, Loss Data: 1.335e-01, Loss Eqns: 2.981e+00, Loss Aux: 5.607e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6320, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.025e+00, Loss Aux: 8.592e-03, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6321, It: 0, Loss Data: 1.360e-01, Loss Eqns: 2.651e+00, Loss Aux: 1.184e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6322, It: 0, Loss Data: 1.304e-01, Loss Eqns: 2.769e+00, Loss Aux: 6.664e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6323, It: 0, Loss Data: 1.749e-01, Loss Eqns: 2.850e+00, Loss Aux: 5.520e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6324, It: 0, Loss Data: 1.185e-01, Loss Eqns: 2.807e+00, Loss Aux: 1.117e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6325, It: 0, Loss Data: 1.396e-01, Loss Eqns: 2.697e+00, Loss Aux: 3.173e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6326, It: 0, Loss Data: 1.203e-01, Loss Eqns: 2.753e+00, Loss Aux: 3.010e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6327, It: 0, Loss Data: 1.258e-01, Loss Eqns: 2.830e+00, Loss Aux: 2.351e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6328, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.675e+00, Loss Aux: 2.628e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6329, It: 0, Loss Data: 1.429e-01, Loss Eqns: 2.871e+00, Loss Aux: 2.801e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6330, It: 0, Loss Data: 1.226e-01, Loss Eqns: 2.715e+00, Loss Aux: 1.019e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 6331, It: 0, Loss Data: 1.436e-01, Loss Eqns: 2.802e+00, Loss Aux: 6.590e-03, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6332, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.838e+00, Loss Aux: 7.410e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6333, It: 0, Loss Data: 1.110e-01, Loss Eqns: 3.000e+00, Loss Aux: 1.904e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 6334, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.841e+00, Loss Aux: 2.571e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6335, It: 0, Loss Data: 1.246e-01, Loss Eqns: 2.984e+00, Loss Aux: 2.026e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6336, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.774e+00, Loss Aux: 1.776e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6337, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.991e+00, Loss Aux: 2.029e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6338, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.820e+00, Loss Aux: 1.774e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6339, It: 0, Loss Data: 1.212e-01, Loss Eqns: 2.727e+00, Loss Aux: 1.047e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6340, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.621e+00, Loss Aux: 1.172e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6341, It: 0, Loss Data: 9.713e-02, Loss Eqns: 2.849e+00, Loss Aux: 2.164e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6342, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.808e+00, Loss Aux: 2.362e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6343, It: 0, Loss Data: 1.293e-01, Loss Eqns: 2.799e+00, Loss Aux: 1.985e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6344, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.758e+00, Loss Aux: 1.501e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6345, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.799e+00, Loss Aux: 1.165e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6346, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.735e+00, Loss Aux: 9.638e-03, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6347, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.775e+00, Loss Aux: 8.306e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6348, It: 0, Loss Data: 9.387e-02, Loss Eqns: 2.967e+00, Loss Aux: 1.137e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6349, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.814e+00, Loss Aux: 1.534e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6350, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.839e+00, Loss Aux: 1.803e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6351, It: 0, Loss Data: 9.335e-02, Loss Eqns: 2.659e+00, Loss Aux: 1.687e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 6352, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.651e+00, Loss Aux: 2.068e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6353, It: 0, Loss Data: 8.975e-02, Loss Eqns: 2.674e+00, Loss Aux: 1.867e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6354, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.659e+00, Loss Aux: 1.276e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6355, It: 0, Loss Data: 9.978e-02, Loss Eqns: 2.618e+00, Loss Aux: 1.184e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6356, It: 0, Loss Data: 1.262e-01, Loss Eqns: 2.601e+00, Loss Aux: 1.433e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6357, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.607e+00, Loss Aux: 1.682e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6358, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.676e+00, Loss Aux: 1.473e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6359, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.749e+00, Loss Aux: 9.931e-03, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6360, It: 0, Loss Data: 9.612e-02, Loss Eqns: 2.774e+00, Loss Aux: 1.006e-02, Time: 0.246, Learning Rate: 1.0e-03\n",
      "Epoch: 6361, It: 0, Loss Data: 8.754e-02, Loss Eqns: 2.590e+00, Loss Aux: 1.184e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 6362, It: 0, Loss Data: 8.560e-02, Loss Eqns: 2.669e+00, Loss Aux: 1.368e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6363, It: 0, Loss Data: 9.754e-02, Loss Eqns: 2.663e+00, Loss Aux: 1.744e-02, Time: 0.278, Learning Rate: 1.0e-03\n",
      "Epoch: 6364, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.707e+00, Loss Aux: 1.959e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 6365, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.615e+00, Loss Aux: 2.012e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6366, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.723e+00, Loss Aux: 2.007e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6367, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.751e+00, Loss Aux: 1.620e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6368, It: 0, Loss Data: 9.503e-02, Loss Eqns: 2.743e+00, Loss Aux: 1.162e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6369, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.688e+00, Loss Aux: 1.160e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6370, It: 0, Loss Data: 9.895e-02, Loss Eqns: 2.739e+00, Loss Aux: 1.524e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6371, It: 0, Loss Data: 9.607e-02, Loss Eqns: 2.799e+00, Loss Aux: 1.192e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6372, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.619e+00, Loss Aux: 6.657e-03, Time: 0.255, Learning Rate: 1.0e-03\n",
      "Epoch: 6373, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.693e+00, Loss Aux: 1.124e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 6374, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.614e+00, Loss Aux: 2.519e-02, Time: 0.265, Learning Rate: 1.0e-03\n",
      "Epoch: 6375, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.662e+00, Loss Aux: 3.187e-02, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 6376, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.626e+00, Loss Aux: 2.741e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 6377, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.662e+00, Loss Aux: 1.752e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 6378, It: 0, Loss Data: 9.554e-02, Loss Eqns: 2.694e+00, Loss Aux: 1.311e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6379, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.723e+00, Loss Aux: 1.447e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6380, It: 0, Loss Data: 9.665e-02, Loss Eqns: 2.699e+00, Loss Aux: 1.067e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6381, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.648e+00, Loss Aux: 8.870e-03, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 6382, It: 0, Loss Data: 8.624e-02, Loss Eqns: 2.624e+00, Loss Aux: 1.457e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6383, It: 0, Loss Data: 8.495e-02, Loss Eqns: 2.635e+00, Loss Aux: 2.028e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 6384, It: 0, Loss Data: 9.984e-02, Loss Eqns: 2.695e+00, Loss Aux: 2.160e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6385, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.733e+00, Loss Aux: 1.812e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6386, It: 0, Loss Data: 9.623e-02, Loss Eqns: 2.672e+00, Loss Aux: 1.349e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6387, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.733e+00, Loss Aux: 1.315e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6388, It: 0, Loss Data: 9.441e-02, Loss Eqns: 2.617e+00, Loss Aux: 1.396e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6389, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.707e+00, Loss Aux: 1.331e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6390, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.672e+00, Loss Aux: 1.052e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6391, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.582e+00, Loss Aux: 9.010e-03, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6392, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.646e+00, Loss Aux: 1.027e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6393, It: 0, Loss Data: 9.938e-02, Loss Eqns: 2.679e+00, Loss Aux: 1.359e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6394, It: 0, Loss Data: 9.399e-02, Loss Eqns: 2.657e+00, Loss Aux: 1.609e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6395, It: 0, Loss Data: 9.931e-02, Loss Eqns: 2.704e+00, Loss Aux: 1.578e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6396, It: 0, Loss Data: 8.927e-02, Loss Eqns: 2.724e+00, Loss Aux: 2.025e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6397, It: 0, Loss Data: 9.602e-02, Loss Eqns: 2.619e+00, Loss Aux: 2.084e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6398, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.653e+00, Loss Aux: 1.785e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6399, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.618e+00, Loss Aux: 1.398e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6400, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.666e+00, Loss Aux: 7.668e-03, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6401, It: 0, Loss Data: 9.368e-02, Loss Eqns: 2.639e+00, Loss Aux: 7.218e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6402, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.612e+00, Loss Aux: 1.262e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6403, It: 0, Loss Data: 9.952e-02, Loss Eqns: 2.728e+00, Loss Aux: 1.349e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6404, It: 0, Loss Data: 8.415e-02, Loss Eqns: 2.771e+00, Loss Aux: 1.270e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6405, It: 0, Loss Data: 9.872e-02, Loss Eqns: 2.729e+00, Loss Aux: 1.375e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6406, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.728e+00, Loss Aux: 1.229e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6407, It: 0, Loss Data: 9.215e-02, Loss Eqns: 2.645e+00, Loss Aux: 1.386e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6408, It: 0, Loss Data: 9.509e-02, Loss Eqns: 2.577e+00, Loss Aux: 1.345e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6409, It: 0, Loss Data: 9.428e-02, Loss Eqns: 2.641e+00, Loss Aux: 9.287e-03, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6410, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.556e+00, Loss Aux: 9.181e-03, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 6411, It: 0, Loss Data: 9.664e-02, Loss Eqns: 2.644e+00, Loss Aux: 1.441e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6412, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.457e+00, Loss Aux: 1.382e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6413, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.633e+00, Loss Aux: 9.623e-03, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6414, It: 0, Loss Data: 9.628e-02, Loss Eqns: 2.520e+00, Loss Aux: 1.316e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6415, It: 0, Loss Data: 8.624e-02, Loss Eqns: 2.576e+00, Loss Aux: 2.164e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6416, It: 0, Loss Data: 9.286e-02, Loss Eqns: 2.596e+00, Loss Aux: 2.084e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6417, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.566e+00, Loss Aux: 1.538e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6418, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.684e+00, Loss Aux: 1.060e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6419, It: 0, Loss Data: 8.749e-02, Loss Eqns: 2.592e+00, Loss Aux: 9.582e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6420, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.788e+00, Loss Aux: 1.124e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6421, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.636e+00, Loss Aux: 1.463e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6422, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.671e+00, Loss Aux: 1.374e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6423, It: 0, Loss Data: 9.813e-02, Loss Eqns: 2.612e+00, Loss Aux: 1.453e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6424, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.612e+00, Loss Aux: 1.381e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 6425, It: 0, Loss Data: 9.764e-02, Loss Eqns: 2.672e+00, Loss Aux: 1.465e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6426, It: 0, Loss Data: 9.246e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.450e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6427, It: 0, Loss Data: 8.660e-02, Loss Eqns: 2.738e+00, Loss Aux: 1.308e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6428, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.615e+00, Loss Aux: 1.339e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6429, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.613e+00, Loss Aux: 1.532e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6430, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.536e+00, Loss Aux: 1.469e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6431, It: 0, Loss Data: 9.469e-02, Loss Eqns: 2.705e+00, Loss Aux: 1.213e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6432, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.784e+00, Loss Aux: 1.280e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6433, It: 0, Loss Data: 9.996e-02, Loss Eqns: 2.629e+00, Loss Aux: 1.844e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6434, It: 0, Loss Data: 8.836e-02, Loss Eqns: 2.655e+00, Loss Aux: 2.305e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 6435, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.663e+00, Loss Aux: 2.370e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6436, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.624e+00, Loss Aux: 2.092e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6437, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.769e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6438, It: 0, Loss Data: 9.715e-02, Loss Eqns: 2.687e+00, Loss Aux: 1.612e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6439, It: 0, Loss Data: 9.090e-02, Loss Eqns: 2.763e+00, Loss Aux: 1.130e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6440, It: 0, Loss Data: 8.333e-02, Loss Eqns: 2.705e+00, Loss Aux: 1.075e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6441, It: 0, Loss Data: 8.902e-02, Loss Eqns: 2.632e+00, Loss Aux: 1.136e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6442, It: 0, Loss Data: 8.577e-02, Loss Eqns: 2.582e+00, Loss Aux: 1.023e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6443, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.623e+00, Loss Aux: 1.124e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6444, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.646e+00, Loss Aux: 1.467e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6445, It: 0, Loss Data: 8.993e-02, Loss Eqns: 2.670e+00, Loss Aux: 1.450e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6446, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.619e+00, Loss Aux: 1.548e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6447, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.567e+00, Loss Aux: 1.840e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6448, It: 0, Loss Data: 9.744e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.876e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6449, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.595e+00, Loss Aux: 1.367e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6450, It: 0, Loss Data: 8.024e-02, Loss Eqns: 2.539e+00, Loss Aux: 8.669e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6451, It: 0, Loss Data: 9.186e-02, Loss Eqns: 2.556e+00, Loss Aux: 7.672e-03, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6452, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.608e+00, Loss Aux: 9.122e-03, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6453, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.494e+00, Loss Aux: 1.081e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6454, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.456e+00, Loss Aux: 1.150e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6455, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.525e+00, Loss Aux: 1.138e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6456, It: 0, Loss Data: 9.610e-02, Loss Eqns: 2.574e+00, Loss Aux: 1.305e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6457, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.340e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6458, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.654e+00, Loss Aux: 1.113e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6459, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.644e+00, Loss Aux: 1.228e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6460, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.630e+00, Loss Aux: 1.568e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6461, It: 0, Loss Data: 9.923e-02, Loss Eqns: 2.622e+00, Loss Aux: 2.130e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6462, It: 0, Loss Data: 8.056e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.323e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6463, It: 0, Loss Data: 8.951e-02, Loss Eqns: 2.653e+00, Loss Aux: 1.747e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6464, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.633e+00, Loss Aux: 1.403e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6465, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.556e+00, Loss Aux: 1.366e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6466, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.696e+00, Loss Aux: 1.253e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6467, It: 0, Loss Data: 9.433e-02, Loss Eqns: 2.657e+00, Loss Aux: 9.700e-03, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 6468, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.527e+00, Loss Aux: 8.409e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6469, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.678e+00, Loss Aux: 9.283e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6470, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.629e+00, Loss Aux: 9.885e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6471, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.673e+00, Loss Aux: 8.392e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6472, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.674e+00, Loss Aux: 7.356e-03, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6473, It: 0, Loss Data: 8.655e-02, Loss Eqns: 2.608e+00, Loss Aux: 9.499e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6474, It: 0, Loss Data: 9.752e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.596e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6475, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.701e+00, Loss Aux: 2.264e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6476, It: 0, Loss Data: 9.317e-02, Loss Eqns: 2.592e+00, Loss Aux: 2.189e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6477, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.541e+00, Loss Aux: 1.907e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 6478, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.657e+00, Loss Aux: 1.984e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6479, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.631e+00, Loss Aux: 1.610e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6480, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.794e+00, Loss Aux: 8.715e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6481, It: 0, Loss Data: 1.191e-01, Loss Eqns: 2.761e+00, Loss Aux: 4.247e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6482, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.775e+00, Loss Aux: 1.047e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6483, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.804e+00, Loss Aux: 1.588e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6484, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.703e+00, Loss Aux: 1.281e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6485, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.881e+00, Loss Aux: 1.679e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6486, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.656e+00, Loss Aux: 2.391e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6487, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.643e+00, Loss Aux: 1.764e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6488, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.636e+00, Loss Aux: 9.111e-03, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 6489, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.488e+00, Loss Aux: 1.113e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6490, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.594e+00, Loss Aux: 2.361e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6491, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.652e+00, Loss Aux: 2.029e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6492, It: 0, Loss Data: 9.683e-02, Loss Eqns: 2.544e+00, Loss Aux: 9.369e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6493, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.567e+00, Loss Aux: 9.101e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6494, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.505e+00, Loss Aux: 1.837e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6495, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.620e+00, Loss Aux: 1.588e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6496, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.884e+00, Loss Aux: 1.104e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6497, It: 0, Loss Data: 1.552e-01, Loss Eqns: 2.866e+00, Loss Aux: 5.321e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6498, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.855e+00, Loss Aux: 1.599e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6499, It: 0, Loss Data: 1.418e-01, Loss Eqns: 2.857e+00, Loss Aux: 2.589e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6500, It: 0, Loss Data: 1.171e-01, Loss Eqns: 2.710e+00, Loss Aux: 9.314e-03, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6501, It: 0, Loss Data: 1.435e-01, Loss Eqns: 2.726e+00, Loss Aux: 5.282e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6502, It: 0, Loss Data: 9.937e-02, Loss Eqns: 2.619e+00, Loss Aux: 9.858e-03, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6503, It: 0, Loss Data: 1.311e-01, Loss Eqns: 2.916e+00, Loss Aux: 2.945e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6504, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.649e+00, Loss Aux: 2.578e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6505, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.816e+00, Loss Aux: 1.670e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6506, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.551e+00, Loss Aux: 1.543e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6507, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.651e+00, Loss Aux: 1.368e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6508, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.667e+00, Loss Aux: 7.547e-03, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6509, It: 0, Loss Data: 1.200e-01, Loss Eqns: 2.589e+00, Loss Aux: 4.944e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6510, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.817e+00, Loss Aux: 1.079e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6511, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.602e+00, Loss Aux: 1.378e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6512, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.745e+00, Loss Aux: 1.454e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6513, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.605e+00, Loss Aux: 1.613e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6514, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.615e+00, Loss Aux: 1.208e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6515, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.573e+00, Loss Aux: 9.493e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6516, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.639e+00, Loss Aux: 1.793e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6517, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.551e+00, Loss Aux: 2.387e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6518, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.652e+00, Loss Aux: 1.710e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6519, It: 0, Loss Data: 1.309e-01, Loss Eqns: 2.563e+00, Loss Aux: 9.065e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6520, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.559e+00, Loss Aux: 1.056e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6521, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.763e+00, Loss Aux: 1.494e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6522, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.730e+00, Loss Aux: 1.319e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6523, It: 0, Loss Data: 9.899e-02, Loss Eqns: 2.664e+00, Loss Aux: 1.221e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6524, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.706e+00, Loss Aux: 1.576e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6525, It: 0, Loss Data: 9.395e-02, Loss Eqns: 2.643e+00, Loss Aux: 1.862e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6526, It: 0, Loss Data: 9.074e-02, Loss Eqns: 2.590e+00, Loss Aux: 1.401e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6527, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.546e+00, Loss Aux: 1.275e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6528, It: 0, Loss Data: 9.991e-02, Loss Eqns: 2.619e+00, Loss Aux: 1.894e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6529, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.601e+00, Loss Aux: 1.942e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6530, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.694e+00, Loss Aux: 1.106e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6531, It: 0, Loss Data: 8.713e-02, Loss Eqns: 2.715e+00, Loss Aux: 7.839e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6532, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.694e+00, Loss Aux: 9.340e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6533, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.634e+00, Loss Aux: 8.929e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6534, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.541e+00, Loss Aux: 1.518e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6535, It: 0, Loss Data: 1.172e-01, Loss Eqns: 2.699e+00, Loss Aux: 2.258e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6536, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.678e+00, Loss Aux: 2.270e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6537, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.544e+00, Loss Aux: 1.501e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6538, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.266e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6539, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.642e+00, Loss Aux: 1.507e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6540, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.612e+00, Loss Aux: 1.466e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6541, It: 0, Loss Data: 9.377e-02, Loss Eqns: 2.478e+00, Loss Aux: 1.086e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6542, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.695e+00, Loss Aux: 7.975e-03, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6543, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.726e+00, Loss Aux: 1.116e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6544, It: 0, Loss Data: 9.464e-02, Loss Eqns: 2.658e+00, Loss Aux: 1.235e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6545, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.594e+00, Loss Aux: 1.073e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6546, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.576e+00, Loss Aux: 1.247e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6547, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.585e+00, Loss Aux: 1.486e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6548, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.631e+00, Loss Aux: 1.389e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6549, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.594e+00, Loss Aux: 1.558e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6550, It: 0, Loss Data: 9.845e-02, Loss Eqns: 2.620e+00, Loss Aux: 1.854e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6551, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.486e+00, Loss Aux: 1.432e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6552, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.608e+00, Loss Aux: 1.430e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6553, It: 0, Loss Data: 9.570e-02, Loss Eqns: 2.706e+00, Loss Aux: 1.335e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6554, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.777e+00, Loss Aux: 8.873e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6555, It: 0, Loss Data: 9.970e-02, Loss Eqns: 2.661e+00, Loss Aux: 7.927e-03, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6556, It: 0, Loss Data: 8.990e-02, Loss Eqns: 2.651e+00, Loss Aux: 1.071e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6557, It: 0, Loss Data: 1.183e-01, Loss Eqns: 2.653e+00, Loss Aux: 1.481e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6558, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.695e+00, Loss Aux: 1.333e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6559, It: 0, Loss Data: 9.630e-02, Loss Eqns: 2.558e+00, Loss Aux: 1.205e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6560, It: 0, Loss Data: 8.730e-02, Loss Eqns: 2.710e+00, Loss Aux: 1.514e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6561, It: 0, Loss Data: 8.731e-02, Loss Eqns: 2.738e+00, Loss Aux: 1.716e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6562, It: 0, Loss Data: 9.723e-02, Loss Eqns: 2.701e+00, Loss Aux: 1.193e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6563, It: 0, Loss Data: 9.828e-02, Loss Eqns: 2.603e+00, Loss Aux: 6.407e-03, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6564, It: 0, Loss Data: 8.863e-02, Loss Eqns: 2.683e+00, Loss Aux: 6.633e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6565, It: 0, Loss Data: 9.895e-02, Loss Eqns: 2.696e+00, Loss Aux: 1.276e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6566, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.566e+00, Loss Aux: 1.776e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6567, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.603e+00, Loss Aux: 1.621e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6568, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.677e+00, Loss Aux: 1.673e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6569, It: 0, Loss Data: 9.378e-02, Loss Eqns: 2.679e+00, Loss Aux: 1.689e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6570, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.726e+00, Loss Aux: 1.493e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 6571, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.610e+00, Loss Aux: 1.402e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6572, It: 0, Loss Data: 8.453e-02, Loss Eqns: 2.597e+00, Loss Aux: 1.256e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6573, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.668e+00, Loss Aux: 1.067e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6574, It: 0, Loss Data: 9.052e-02, Loss Eqns: 2.674e+00, Loss Aux: 1.120e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6575, It: 0, Loss Data: 1.187e-01, Loss Eqns: 2.715e+00, Loss Aux: 1.129e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6576, It: 0, Loss Data: 8.960e-02, Loss Eqns: 2.719e+00, Loss Aux: 9.798e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6577, It: 0, Loss Data: 8.205e-02, Loss Eqns: 2.691e+00, Loss Aux: 1.125e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6578, It: 0, Loss Data: 8.382e-02, Loss Eqns: 2.688e+00, Loss Aux: 1.132e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6579, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.583e+00, Loss Aux: 1.012e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6580, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.653e+00, Loss Aux: 1.104e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6581, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.503e+00, Loss Aux: 1.625e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6582, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.622e+00, Loss Aux: 1.701e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6583, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.568e+00, Loss Aux: 1.245e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6584, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.659e+00, Loss Aux: 7.774e-03, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6585, It: 0, Loss Data: 9.614e-02, Loss Eqns: 2.562e+00, Loss Aux: 1.033e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6586, It: 0, Loss Data: 9.241e-02, Loss Eqns: 2.571e+00, Loss Aux: 1.993e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6587, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.587e+00, Loss Aux: 2.170e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6588, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.598e+00, Loss Aux: 1.689e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6589, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.704e+00, Loss Aux: 1.068e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6590, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.726e+00, Loss Aux: 8.563e-03, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6591, It: 0, Loss Data: 9.737e-02, Loss Eqns: 2.707e+00, Loss Aux: 1.033e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6592, It: 0, Loss Data: 8.512e-02, Loss Eqns: 2.678e+00, Loss Aux: 1.098e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6593, It: 0, Loss Data: 9.154e-02, Loss Eqns: 2.608e+00, Loss Aux: 9.459e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6594, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.705e+00, Loss Aux: 8.578e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6595, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.550e+00, Loss Aux: 9.253e-03, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 6596, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.618e+00, Loss Aux: 1.323e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6597, It: 0, Loss Data: 9.439e-02, Loss Eqns: 2.637e+00, Loss Aux: 1.382e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6598, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.387e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6599, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.657e+00, Loss Aux: 1.320e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6600, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.721e+00, Loss Aux: 1.432e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6601, It: 0, Loss Data: 9.592e-02, Loss Eqns: 2.600e+00, Loss Aux: 1.199e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6602, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.725e+00, Loss Aux: 1.391e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6603, It: 0, Loss Data: 9.766e-02, Loss Eqns: 2.584e+00, Loss Aux: 1.495e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6604, It: 0, Loss Data: 9.015e-02, Loss Eqns: 2.565e+00, Loss Aux: 1.541e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6605, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.594e+00, Loss Aux: 1.398e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6606, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.107e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6607, It: 0, Loss Data: 8.992e-02, Loss Eqns: 2.659e+00, Loss Aux: 7.869e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6608, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.582e+00, Loss Aux: 9.785e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6609, It: 0, Loss Data: 9.816e-02, Loss Eqns: 2.702e+00, Loss Aux: 1.539e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6610, It: 0, Loss Data: 8.711e-02, Loss Eqns: 2.792e+00, Loss Aux: 1.502e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6611, It: 0, Loss Data: 7.260e-02, Loss Eqns: 2.664e+00, Loss Aux: 1.074e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6612, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.581e+00, Loss Aux: 8.993e-03, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6613, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.632e+00, Loss Aux: 1.348e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6614, It: 0, Loss Data: 9.255e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.188e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6615, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.504e+00, Loss Aux: 2.337e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6616, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.511e+00, Loss Aux: 1.387e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6617, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.569e+00, Loss Aux: 1.153e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6618, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.527e+00, Loss Aux: 1.980e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6619, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.611e+00, Loss Aux: 1.657e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6620, It: 0, Loss Data: 9.214e-02, Loss Eqns: 2.504e+00, Loss Aux: 6.231e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6621, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.684e+00, Loss Aux: 5.025e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6622, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.565e+00, Loss Aux: 1.260e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6623, It: 0, Loss Data: 9.727e-02, Loss Eqns: 2.723e+00, Loss Aux: 1.895e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6624, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.560e+00, Loss Aux: 1.589e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6625, It: 0, Loss Data: 9.929e-02, Loss Eqns: 2.714e+00, Loss Aux: 8.904e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6626, It: 0, Loss Data: 9.836e-02, Loss Eqns: 2.505e+00, Loss Aux: 1.036e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6627, It: 0, Loss Data: 1.196e-01, Loss Eqns: 2.648e+00, Loss Aux: 1.736e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6628, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.706e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6629, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.609e+00, Loss Aux: 9.557e-03, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6630, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.582e+00, Loss Aux: 1.021e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6631, It: 0, Loss Data: 9.213e-02, Loss Eqns: 2.609e+00, Loss Aux: 1.792e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6632, It: 0, Loss Data: 9.587e-02, Loss Eqns: 2.617e+00, Loss Aux: 2.212e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6633, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.568e+00, Loss Aux: 1.317e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6634, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.544e+00, Loss Aux: 1.031e-02, Time: 0.238, Learning Rate: 1.0e-03\n",
      "Epoch: 6635, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.679e+00, Loss Aux: 1.690e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6636, It: 0, Loss Data: 9.771e-02, Loss Eqns: 2.671e+00, Loss Aux: 2.084e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6637, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.614e+00, Loss Aux: 1.065e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6638, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.568e+00, Loss Aux: 5.996e-03, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6639, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.776e+00, Loss Aux: 8.345e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6640, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.562e+00, Loss Aux: 1.031e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6641, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.607e+00, Loss Aux: 9.328e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6642, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.731e+00, Loss Aux: 1.262e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6643, It: 0, Loss Data: 9.641e-02, Loss Eqns: 2.600e+00, Loss Aux: 1.467e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6644, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.685e+00, Loss Aux: 1.831e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6645, It: 0, Loss Data: 9.766e-02, Loss Eqns: 2.606e+00, Loss Aux: 1.772e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6646, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.656e+00, Loss Aux: 1.584e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6647, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.698e+00, Loss Aux: 1.639e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6648, It: 0, Loss Data: 9.635e-02, Loss Eqns: 2.690e+00, Loss Aux: 1.943e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6649, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.666e+00, Loss Aux: 1.723e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6650, It: 0, Loss Data: 8.231e-02, Loss Eqns: 2.698e+00, Loss Aux: 1.502e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6651, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.643e+00, Loss Aux: 1.187e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6652, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.632e+00, Loss Aux: 1.100e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6653, It: 0, Loss Data: 9.504e-02, Loss Eqns: 2.766e+00, Loss Aux: 1.087e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 6654, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.680e+00, Loss Aux: 1.178e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6655, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.729e+00, Loss Aux: 1.129e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6656, It: 0, Loss Data: 9.354e-02, Loss Eqns: 2.770e+00, Loss Aux: 1.151e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 6657, It: 0, Loss Data: 9.943e-02, Loss Eqns: 2.744e+00, Loss Aux: 1.427e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 6658, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.620e+00, Loss Aux: 1.588e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6659, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.587e+00, Loss Aux: 1.357e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6660, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.525e+00, Loss Aux: 1.250e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6661, It: 0, Loss Data: 9.601e-02, Loss Eqns: 2.586e+00, Loss Aux: 1.530e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6662, It: 0, Loss Data: 9.906e-02, Loss Eqns: 2.531e+00, Loss Aux: 1.382e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6663, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.664e+00, Loss Aux: 8.472e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6664, It: 0, Loss Data: 1.379e-01, Loss Eqns: 3.073e+00, Loss Aux: 5.068e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6665, It: 0, Loss Data: 1.369e-01, Loss Eqns: 3.282e+00, Loss Aux: 2.112e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6666, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.838e+00, Loss Aux: 2.848e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6667, It: 0, Loss Data: 1.566e-01, Loss Eqns: 3.076e+00, Loss Aux: 2.072e-02, Time: 0.247, Learning Rate: 1.0e-03\n",
      "Epoch: 6668, It: 0, Loss Data: 1.292e-01, Loss Eqns: 2.828e+00, Loss Aux: 2.065e-03, Time: 0.259, Learning Rate: 1.0e-03\n",
      "Epoch: 6669, It: 0, Loss Data: 1.193e-01, Loss Eqns: 2.752e+00, Loss Aux: 5.524e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6670, It: 0, Loss Data: 1.468e-01, Loss Eqns: 3.039e+00, Loss Aux: 2.918e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6671, It: 0, Loss Data: 1.162e-01, Loss Eqns: 2.579e+00, Loss Aux: 2.575e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6672, It: 0, Loss Data: 1.241e-01, Loss Eqns: 2.601e+00, Loss Aux: 1.722e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6673, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.548e+00, Loss Aux: 1.185e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6674, It: 0, Loss Data: 1.434e-01, Loss Eqns: 2.775e+00, Loss Aux: 1.448e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6675, It: 0, Loss Data: 9.964e-02, Loss Eqns: 2.660e+00, Loss Aux: 1.260e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6676, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.615e+00, Loss Aux: 1.528e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6677, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.703e+00, Loss Aux: 2.137e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6678, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.503e+00, Loss Aux: 1.950e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6679, It: 0, Loss Data: 1.235e-01, Loss Eqns: 2.701e+00, Loss Aux: 8.533e-03, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6680, It: 0, Loss Data: 1.209e-01, Loss Eqns: 2.731e+00, Loss Aux: 4.537e-03, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6681, It: 0, Loss Data: 1.260e-01, Loss Eqns: 2.564e+00, Loss Aux: 7.755e-03, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6682, It: 0, Loss Data: 1.232e-01, Loss Eqns: 2.617e+00, Loss Aux: 1.234e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6683, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.596e+00, Loss Aux: 1.383e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6684, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.491e+00, Loss Aux: 1.919e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 6685, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.835e+00, Loss Aux: 2.199e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 6686, It: 0, Loss Data: 9.867e-02, Loss Eqns: 2.579e+00, Loss Aux: 1.727e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6687, It: 0, Loss Data: 9.684e-02, Loss Eqns: 2.778e+00, Loss Aux: 1.502e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6688, It: 0, Loss Data: 9.650e-02, Loss Eqns: 2.685e+00, Loss Aux: 1.497e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6689, It: 0, Loss Data: 9.005e-02, Loss Eqns: 2.672e+00, Loss Aux: 9.142e-03, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6690, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.612e+00, Loss Aux: 6.063e-03, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6691, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.648e+00, Loss Aux: 9.738e-03, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 6692, It: 0, Loss Data: 7.958e-02, Loss Eqns: 2.594e+00, Loss Aux: 1.566e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6693, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.614e+00, Loss Aux: 1.830e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6694, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.668e+00, Loss Aux: 1.679e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6695, It: 0, Loss Data: 9.444e-02, Loss Eqns: 2.655e+00, Loss Aux: 1.295e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6696, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.622e+00, Loss Aux: 1.203e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6697, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.514e+00, Loss Aux: 1.406e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6698, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.591e+00, Loss Aux: 1.807e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6699, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.583e+00, Loss Aux: 1.574e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6700, It: 0, Loss Data: 9.963e-02, Loss Eqns: 2.516e+00, Loss Aux: 1.086e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6701, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.491e+00, Loss Aux: 8.749e-03, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6702, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.505e+00, Loss Aux: 1.471e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6703, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.524e+00, Loss Aux: 2.042e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6704, It: 0, Loss Data: 1.118e-01, Loss Eqns: 2.581e+00, Loss Aux: 1.400e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6705, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.574e+00, Loss Aux: 6.397e-03, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6706, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.655e+00, Loss Aux: 7.461e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6707, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.607e+00, Loss Aux: 1.772e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6708, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.565e+00, Loss Aux: 2.318e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6709, It: 0, Loss Data: 9.052e-02, Loss Eqns: 2.575e+00, Loss Aux: 2.284e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6710, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.621e+00, Loss Aux: 1.799e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6711, It: 0, Loss Data: 8.312e-02, Loss Eqns: 2.672e+00, Loss Aux: 1.482e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6712, It: 0, Loss Data: 9.233e-02, Loss Eqns: 2.521e+00, Loss Aux: 1.332e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6713, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.552e+00, Loss Aux: 1.010e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6714, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.653e+00, Loss Aux: 8.453e-03, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6715, It: 0, Loss Data: 8.785e-02, Loss Eqns: 2.538e+00, Loss Aux: 1.063e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6716, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.548e+00, Loss Aux: 1.706e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6717, It: 0, Loss Data: 9.796e-02, Loss Eqns: 2.630e+00, Loss Aux: 2.145e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6718, It: 0, Loss Data: 8.984e-02, Loss Eqns: 2.595e+00, Loss Aux: 2.025e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6719, It: 0, Loss Data: 9.723e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.741e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6720, It: 0, Loss Data: 9.364e-02, Loss Eqns: 2.667e+00, Loss Aux: 1.265e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6721, It: 0, Loss Data: 9.521e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.333e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 6722, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.490e+00, Loss Aux: 1.334e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6723, It: 0, Loss Data: 9.927e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.195e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6724, It: 0, Loss Data: 8.543e-02, Loss Eqns: 2.578e+00, Loss Aux: 9.484e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6725, It: 0, Loss Data: 9.362e-02, Loss Eqns: 2.496e+00, Loss Aux: 9.230e-03, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6726, It: 0, Loss Data: 8.640e-02, Loss Eqns: 2.533e+00, Loss Aux: 1.214e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6727, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.574e+00, Loss Aux: 1.444e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6728, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.488e+00, Loss Aux: 1.417e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 6729, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.502e+00, Loss Aux: 1.386e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6730, It: 0, Loss Data: 8.954e-02, Loss Eqns: 2.540e+00, Loss Aux: 1.457e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6731, It: 0, Loss Data: 8.051e-02, Loss Eqns: 2.541e+00, Loss Aux: 1.603e-02, Time: 0.263, Learning Rate: 1.0e-03\n",
      "Epoch: 6732, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.543e+00, Loss Aux: 1.608e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 6733, It: 0, Loss Data: 8.886e-02, Loss Eqns: 2.525e+00, Loss Aux: 1.365e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6734, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.551e+00, Loss Aux: 1.303e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 6735, It: 0, Loss Data: 9.980e-02, Loss Eqns: 2.521e+00, Loss Aux: 1.258e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6736, It: 0, Loss Data: 8.805e-02, Loss Eqns: 2.585e+00, Loss Aux: 1.154e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6737, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.437e+00, Loss Aux: 7.737e-03, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6738, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.523e+00, Loss Aux: 1.003e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6739, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.586e+00, Loss Aux: 1.744e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6740, It: 0, Loss Data: 9.806e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.059e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 6741, It: 0, Loss Data: 8.426e-02, Loss Eqns: 2.569e+00, Loss Aux: 1.727e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6742, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.624e+00, Loss Aux: 1.224e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6743, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.677e+00, Loss Aux: 1.084e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6744, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.616e+00, Loss Aux: 8.685e-03, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6745, It: 0, Loss Data: 1.173e-01, Loss Eqns: 2.456e+00, Loss Aux: 8.559e-03, Time: 0.258, Learning Rate: 1.0e-03\n",
      "Epoch: 6746, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.548e+00, Loss Aux: 9.599e-03, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6747, It: 0, Loss Data: 9.736e-02, Loss Eqns: 2.579e+00, Loss Aux: 1.270e-02, Time: 0.254, Learning Rate: 1.0e-03\n",
      "Epoch: 6748, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.489e+00, Loss Aux: 1.548e-02, Time: 0.256, Learning Rate: 1.0e-03\n",
      "Epoch: 6749, It: 0, Loss Data: 9.234e-02, Loss Eqns: 2.435e+00, Loss Aux: 1.292e-02, Time: 0.261, Learning Rate: 1.0e-03\n",
      "Epoch: 6750, It: 0, Loss Data: 9.706e-02, Loss Eqns: 2.583e+00, Loss Aux: 9.806e-03, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6751, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.601e+00, Loss Aux: 1.117e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6752, It: 0, Loss Data: 9.185e-02, Loss Eqns: 2.628e+00, Loss Aux: 1.331e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 6753, It: 0, Loss Data: 9.372e-02, Loss Eqns: 2.610e+00, Loss Aux: 1.584e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6754, It: 0, Loss Data: 9.097e-02, Loss Eqns: 2.558e+00, Loss Aux: 1.616e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6755, It: 0, Loss Data: 9.520e-02, Loss Eqns: 2.596e+00, Loss Aux: 1.474e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 6756, It: 0, Loss Data: 9.635e-02, Loss Eqns: 2.567e+00, Loss Aux: 1.958e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6757, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.542e+00, Loss Aux: 2.274e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 6758, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.478e+00, Loss Aux: 1.831e-02, Time: 0.251, Learning Rate: 1.0e-03\n",
      "Epoch: 6759, It: 0, Loss Data: 8.949e-02, Loss Eqns: 2.633e+00, Loss Aux: 1.509e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6760, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.609e+00, Loss Aux: 1.274e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6761, It: 0, Loss Data: 8.499e-02, Loss Eqns: 2.581e+00, Loss Aux: 9.480e-03, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6762, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.549e+00, Loss Aux: 8.742e-03, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6763, It: 0, Loss Data: 9.346e-02, Loss Eqns: 2.678e+00, Loss Aux: 1.153e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6764, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.663e+00, Loss Aux: 1.381e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6765, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.549e+00, Loss Aux: 1.771e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6766, It: 0, Loss Data: 8.694e-02, Loss Eqns: 2.607e+00, Loss Aux: 1.691e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6767, It: 0, Loss Data: 1.169e-01, Loss Eqns: 2.513e+00, Loss Aux: 1.120e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 6768, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.609e+00, Loss Aux: 8.306e-03, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6769, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.653e+00, Loss Aux: 1.102e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6770, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.574e+00, Loss Aux: 1.482e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6771, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.593e+00, Loss Aux: 1.696e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6772, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.543e+00, Loss Aux: 1.426e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6773, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.696e+00, Loss Aux: 8.763e-03, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6774, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.612e+00, Loss Aux: 7.747e-03, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6775, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.616e+00, Loss Aux: 1.277e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6776, It: 0, Loss Data: 9.682e-02, Loss Eqns: 2.639e+00, Loss Aux: 1.433e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6777, It: 0, Loss Data: 8.970e-02, Loss Eqns: 2.589e+00, Loss Aux: 7.647e-03, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6778, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.612e+00, Loss Aux: 1.258e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6779, It: 0, Loss Data: 9.859e-02, Loss Eqns: 2.600e+00, Loss Aux: 2.223e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6780, It: 0, Loss Data: 1.422e-01, Loss Eqns: 3.520e+00, Loss Aux: 3.932e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 6781, It: 0, Loss Data: 5.063e-01, Loss Eqns: 4.906e+00, Loss Aux: 3.596e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6782, It: 0, Loss Data: 3.372e-01, Loss Eqns: 4.684e+00, Loss Aux: 5.678e-03, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6783, It: 0, Loss Data: 3.178e-01, Loss Eqns: 4.629e+00, Loss Aux: 4.859e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6784, It: 0, Loss Data: 3.144e-01, Loss Eqns: 5.226e+00, Loss Aux: 4.596e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6785, It: 0, Loss Data: 2.301e-01, Loss Eqns: 3.902e+00, Loss Aux: 1.592e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6786, It: 0, Loss Data: 3.305e-01, Loss Eqns: 4.448e+00, Loss Aux: 1.012e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6787, It: 0, Loss Data: 2.244e-01, Loss Eqns: 4.258e+00, Loss Aux: 7.101e-03, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6788, It: 0, Loss Data: 2.819e-01, Loss Eqns: 4.293e+00, Loss Aux: 3.546e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6789, It: 0, Loss Data: 2.423e-01, Loss Eqns: 4.070e+00, Loss Aux: 3.671e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6790, It: 0, Loss Data: 2.482e-01, Loss Eqns: 3.702e+00, Loss Aux: 3.597e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6791, It: 0, Loss Data: 2.327e-01, Loss Eqns: 3.489e+00, Loss Aux: 3.436e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6792, It: 0, Loss Data: 2.159e-01, Loss Eqns: 3.070e+00, Loss Aux: 3.186e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6793, It: 0, Loss Data: 2.653e-01, Loss Eqns: 3.838e+00, Loss Aux: 4.322e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6794, It: 0, Loss Data: 2.026e-01, Loss Eqns: 3.089e+00, Loss Aux: 2.552e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6795, It: 0, Loss Data: 2.204e-01, Loss Eqns: 3.040e+00, Loss Aux: 1.282e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6796, It: 0, Loss Data: 2.285e-01, Loss Eqns: 3.127e+00, Loss Aux: 6.312e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6797, It: 0, Loss Data: 1.860e-01, Loss Eqns: 2.593e+00, Loss Aux: 1.688e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6798, It: 0, Loss Data: 2.425e-01, Loss Eqns: 2.775e+00, Loss Aux: 3.488e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6799, It: 0, Loss Data: 1.832e-01, Loss Eqns: 2.612e+00, Loss Aux: 3.058e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6800, It: 0, Loss Data: 2.137e-01, Loss Eqns: 2.490e+00, Loss Aux: 2.865e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 6801, It: 0, Loss Data: 1.989e-01, Loss Eqns: 2.708e+00, Loss Aux: 2.490e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6802, It: 0, Loss Data: 1.448e-01, Loss Eqns: 2.946e+00, Loss Aux: 3.293e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 6803, It: 0, Loss Data: 1.821e-01, Loss Eqns: 2.944e+00, Loss Aux: 4.218e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6804, It: 0, Loss Data: 1.537e-01, Loss Eqns: 2.868e+00, Loss Aux: 3.012e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 6805, It: 0, Loss Data: 1.789e-01, Loss Eqns: 2.858e+00, Loss Aux: 2.337e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6806, It: 0, Loss Data: 1.623e-01, Loss Eqns: 3.065e+00, Loss Aux: 2.806e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6807, It: 0, Loss Data: 1.181e-01, Loss Eqns: 3.071e+00, Loss Aux: 3.011e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 6808, It: 0, Loss Data: 1.301e-01, Loss Eqns: 2.989e+00, Loss Aux: 2.431e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6809, It: 0, Loss Data: 1.251e-01, Loss Eqns: 3.033e+00, Loss Aux: 1.831e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6810, It: 0, Loss Data: 1.341e-01, Loss Eqns: 2.998e+00, Loss Aux: 1.940e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6811, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.845e+00, Loss Aux: 3.189e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 6812, It: 0, Loss Data: 1.355e-01, Loss Eqns: 2.992e+00, Loss Aux: 4.272e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6813, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.827e+00, Loss Aux: 3.273e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6814, It: 0, Loss Data: 1.356e-01, Loss Eqns: 2.746e+00, Loss Aux: 1.560e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6815, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.811e+00, Loss Aux: 1.685e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6816, It: 0, Loss Data: 1.221e-01, Loss Eqns: 2.843e+00, Loss Aux: 2.190e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6817, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.834e+00, Loss Aux: 2.354e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6818, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.707e+00, Loss Aux: 3.694e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6819, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.662e+00, Loss Aux: 6.112e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6820, It: 0, Loss Data: 1.271e-01, Loss Eqns: 2.691e+00, Loss Aux: 4.778e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6821, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.683e+00, Loss Aux: 2.630e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6822, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.731e+00, Loss Aux: 1.443e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6823, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.790e+00, Loss Aux: 1.017e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6824, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.710e+00, Loss Aux: 1.378e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6825, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.749e+00, Loss Aux: 2.037e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6826, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.567e+00, Loss Aux: 2.311e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6827, It: 0, Loss Data: 1.262e-01, Loss Eqns: 2.647e+00, Loss Aux: 2.271e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6828, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.640e+00, Loss Aux: 1.792e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6829, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.682e+00, Loss Aux: 1.383e-02, Time: 0.244, Learning Rate: 1.0e-03\n",
      "Epoch: 6830, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.758e+00, Loss Aux: 1.928e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6831, It: 0, Loss Data: 9.986e-02, Loss Eqns: 2.822e+00, Loss Aux: 3.368e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6832, It: 0, Loss Data: 1.200e-01, Loss Eqns: 2.749e+00, Loss Aux: 3.354e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6833, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.621e+00, Loss Aux: 2.518e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6834, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.644e+00, Loss Aux: 2.057e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6835, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.704e+00, Loss Aux: 2.126e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6836, It: 0, Loss Data: 1.148e-01, Loss Eqns: 2.689e+00, Loss Aux: 1.529e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6837, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.712e+00, Loss Aux: 1.051e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6838, It: 0, Loss Data: 8.920e-02, Loss Eqns: 2.685e+00, Loss Aux: 1.329e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6839, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.743e+00, Loss Aux: 2.340e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6840, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.766e+00, Loss Aux: 3.220e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6841, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.725e+00, Loss Aux: 3.068e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6842, It: 0, Loss Data: 9.951e-02, Loss Eqns: 2.706e+00, Loss Aux: 2.401e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6843, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.741e+00, Loss Aux: 1.444e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6844, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.880e+00, Loss Aux: 1.269e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6845, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.780e+00, Loss Aux: 1.452e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6846, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.772e+00, Loss Aux: 2.137e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6847, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.741e+00, Loss Aux: 3.004e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6848, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.674e+00, Loss Aux: 3.217e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6849, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.689e+00, Loss Aux: 2.918e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 6850, It: 0, Loss Data: 8.327e-02, Loss Eqns: 2.654e+00, Loss Aux: 1.893e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6851, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.680e+00, Loss Aux: 1.551e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6852, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.647e+00, Loss Aux: 2.165e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6853, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.610e+00, Loss Aux: 2.624e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6854, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.626e+00, Loss Aux: 2.260e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6855, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.674e+00, Loss Aux: 1.210e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6856, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.668e+00, Loss Aux: 9.534e-03, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 6857, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.754e+00, Loss Aux: 1.587e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6858, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.747e+00, Loss Aux: 2.200e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6859, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.627e+00, Loss Aux: 2.278e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6860, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.686e+00, Loss Aux: 2.590e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6861, It: 0, Loss Data: 9.929e-02, Loss Eqns: 2.748e+00, Loss Aux: 3.493e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 6862, It: 0, Loss Data: 8.483e-02, Loss Eqns: 2.833e+00, Loss Aux: 3.574e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6863, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.768e+00, Loss Aux: 3.035e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6864, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.815e+00, Loss Aux: 2.112e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 6865, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.691e+00, Loss Aux: 1.611e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 6866, It: 0, Loss Data: 9.055e-02, Loss Eqns: 2.639e+00, Loss Aux: 1.235e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6867, It: 0, Loss Data: 9.005e-02, Loss Eqns: 2.641e+00, Loss Aux: 1.042e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6868, It: 0, Loss Data: 9.728e-02, Loss Eqns: 2.635e+00, Loss Aux: 1.464e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 6869, It: 0, Loss Data: 1.159e-01, Loss Eqns: 2.632e+00, Loss Aux: 1.705e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6870, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.651e+00, Loss Aux: 2.583e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6871, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.755e+00, Loss Aux: 2.345e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6872, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.663e+00, Loss Aux: 1.788e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6873, It: 0, Loss Data: 9.925e-02, Loss Eqns: 2.522e+00, Loss Aux: 2.365e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6874, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.579e+00, Loss Aux: 3.936e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6875, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.667e+00, Loss Aux: 3.782e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6876, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.323e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6877, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.658e+00, Loss Aux: 1.234e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6878, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.573e+00, Loss Aux: 1.225e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 6879, It: 0, Loss Data: 9.737e-02, Loss Eqns: 2.594e+00, Loss Aux: 1.606e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 6880, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.620e+00, Loss Aux: 1.566e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6881, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.576e+00, Loss Aux: 1.549e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6882, It: 0, Loss Data: 9.524e-02, Loss Eqns: 2.637e+00, Loss Aux: 2.081e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6883, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.541e+00, Loss Aux: 2.450e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 6884, It: 0, Loss Data: 9.220e-02, Loss Eqns: 2.757e+00, Loss Aux: 2.395e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6885, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.654e+00, Loss Aux: 2.042e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6886, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.895e+00, Loss Aux: 2.345e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 6887, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.639e+00, Loss Aux: 2.309e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 6888, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.735e+00, Loss Aux: 2.501e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6889, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.669e+00, Loss Aux: 2.471e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 6890, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.680e+00, Loss Aux: 2.166e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6891, It: 0, Loss Data: 9.639e-02, Loss Eqns: 2.637e+00, Loss Aux: 2.101e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6892, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.645e+00, Loss Aux: 1.896e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6893, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.758e+00, Loss Aux: 1.563e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6894, It: 0, Loss Data: 8.082e-02, Loss Eqns: 2.794e+00, Loss Aux: 2.139e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6895, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.692e+00, Loss Aux: 2.876e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6896, It: 0, Loss Data: 9.397e-02, Loss Eqns: 2.740e+00, Loss Aux: 2.603e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6897, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.792e+00, Loss Aux: 2.468e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 6898, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.534e+00, Loss Aux: 2.000e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6899, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.709e+00, Loss Aux: 2.373e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 6900, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.662e+00, Loss Aux: 2.165e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6901, It: 0, Loss Data: 9.772e-02, Loss Eqns: 2.722e+00, Loss Aux: 1.741e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 6902, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.769e+00, Loss Aux: 1.529e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6903, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.692e+00, Loss Aux: 2.030e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6904, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.885e+00, Loss Aux: 2.668e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 6905, It: 0, Loss Data: 9.825e-02, Loss Eqns: 2.803e+00, Loss Aux: 2.552e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6906, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.812e+00, Loss Aux: 2.201e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 6907, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.730e+00, Loss Aux: 2.155e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 6908, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.788e+00, Loss Aux: 2.418e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6909, It: 0, Loss Data: 7.569e-02, Loss Eqns: 2.704e+00, Loss Aux: 2.440e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 6910, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.644e+00, Loss Aux: 2.452e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6911, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.444e+00, Loss Aux: 2.457e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6912, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.765e+00, Loss Aux: 2.358e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6913, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.726e+00, Loss Aux: 2.049e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6914, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.654e+00, Loss Aux: 1.411e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 6915, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.508e+00, Loss Aux: 1.855e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6916, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.774e+00, Loss Aux: 2.966e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6917, It: 0, Loss Data: 9.883e-02, Loss Eqns: 2.610e+00, Loss Aux: 3.048e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6918, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.562e+00, Loss Aux: 2.812e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 6919, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.583e+00, Loss Aux: 2.499e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 6920, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.678e+00, Loss Aux: 2.097e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6921, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.669e+00, Loss Aux: 1.212e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6922, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.697e+00, Loss Aux: 8.727e-03, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6923, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.628e+00, Loss Aux: 1.536e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 6924, It: 0, Loss Data: 9.803e-02, Loss Eqns: 2.705e+00, Loss Aux: 2.756e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6925, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.780e+00, Loss Aux: 2.764e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6926, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.750e+00, Loss Aux: 2.504e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6927, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.744e+00, Loss Aux: 2.169e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6928, It: 0, Loss Data: 9.758e-02, Loss Eqns: 2.658e+00, Loss Aux: 1.544e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6929, It: 0, Loss Data: 7.546e-02, Loss Eqns: 2.804e+00, Loss Aux: 1.684e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6930, It: 0, Loss Data: 9.307e-02, Loss Eqns: 2.723e+00, Loss Aux: 1.943e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6931, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.640e+00, Loss Aux: 2.350e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 6932, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.684e+00, Loss Aux: 2.577e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 6933, It: 0, Loss Data: 8.799e-02, Loss Eqns: 2.648e+00, Loss Aux: 2.623e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 6934, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.679e+00, Loss Aux: 2.460e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6935, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.509e+00, Loss Aux: 2.290e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6936, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.574e+00, Loss Aux: 1.967e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6937, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.545e+00, Loss Aux: 1.495e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6938, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.590e+00, Loss Aux: 1.103e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6939, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.698e+00, Loss Aux: 2.016e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 6940, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.640e+00, Loss Aux: 3.381e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 6941, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.651e+00, Loss Aux: 3.495e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6942, It: 0, Loss Data: 9.564e-02, Loss Eqns: 2.667e+00, Loss Aux: 2.683e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 6943, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.670e+00, Loss Aux: 1.817e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6944, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.792e+00, Loss Aux: 1.726e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6945, It: 0, Loss Data: 9.628e-02, Loss Eqns: 2.706e+00, Loss Aux: 2.360e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6946, It: 0, Loss Data: 9.984e-02, Loss Eqns: 2.713e+00, Loss Aux: 2.107e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 6947, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.677e+00, Loss Aux: 1.781e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6948, It: 0, Loss Data: 9.650e-02, Loss Eqns: 2.741e+00, Loss Aux: 1.649e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 6949, It: 0, Loss Data: 9.208e-02, Loss Eqns: 2.738e+00, Loss Aux: 1.920e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 6950, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.724e+00, Loss Aux: 2.199e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 6951, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.688e+00, Loss Aux: 2.047e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6952, It: 0, Loss Data: 9.245e-02, Loss Eqns: 2.722e+00, Loss Aux: 2.295e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6953, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.627e+00, Loss Aux: 2.879e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 6954, It: 0, Loss Data: 9.833e-02, Loss Eqns: 2.768e+00, Loss Aux: 2.793e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6955, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.789e+00, Loss Aux: 1.913e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6956, It: 0, Loss Data: 9.704e-02, Loss Eqns: 2.871e+00, Loss Aux: 1.135e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6957, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.721e+00, Loss Aux: 1.873e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 6958, It: 0, Loss Data: 9.317e-02, Loss Eqns: 2.746e+00, Loss Aux: 3.486e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6959, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.684e+00, Loss Aux: 3.553e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 6960, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.713e+00, Loss Aux: 2.981e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6961, It: 0, Loss Data: 7.759e-02, Loss Eqns: 2.633e+00, Loss Aux: 2.240e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 6962, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.702e+00, Loss Aux: 1.736e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 6963, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.560e+00, Loss Aux: 1.732e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 6964, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.628e+00, Loss Aux: 1.843e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6965, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.527e+00, Loss Aux: 2.225e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 6966, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.551e+00, Loss Aux: 2.204e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 6967, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.576e+00, Loss Aux: 2.005e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6968, It: 0, Loss Data: 9.868e-02, Loss Eqns: 2.766e+00, Loss Aux: 1.924e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 6969, It: 0, Loss Data: 9.964e-02, Loss Eqns: 2.747e+00, Loss Aux: 1.992e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 6970, It: 0, Loss Data: 9.195e-02, Loss Eqns: 2.713e+00, Loss Aux: 2.039e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6971, It: 0, Loss Data: 9.999e-02, Loss Eqns: 2.675e+00, Loss Aux: 2.228e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 6972, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.690e+00, Loss Aux: 2.185e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 6973, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.602e+00, Loss Aux: 2.376e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 6974, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.651e+00, Loss Aux: 2.165e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 6975, It: 0, Loss Data: 9.145e-02, Loss Eqns: 2.712e+00, Loss Aux: 1.745e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 6976, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.625e+00, Loss Aux: 1.686e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 6977, It: 0, Loss Data: 8.858e-02, Loss Eqns: 2.712e+00, Loss Aux: 2.251e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 6978, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.651e+00, Loss Aux: 2.426e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 6979, It: 0, Loss Data: 8.650e-02, Loss Eqns: 2.618e+00, Loss Aux: 2.081e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 6980, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.630e+00, Loss Aux: 1.943e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 6981, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.664e+00, Loss Aux: 1.991e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 6982, It: 0, Loss Data: 9.270e-02, Loss Eqns: 2.704e+00, Loss Aux: 2.112e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6983, It: 0, Loss Data: 9.083e-02, Loss Eqns: 2.732e+00, Loss Aux: 2.086e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 6984, It: 0, Loss Data: 9.089e-02, Loss Eqns: 2.751e+00, Loss Aux: 1.200e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 6985, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.776e+00, Loss Aux: 1.390e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 6986, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.753e+00, Loss Aux: 2.717e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6987, It: 0, Loss Data: 1.388e-01, Loss Eqns: 2.953e+00, Loss Aux: 4.356e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 6988, It: 0, Loss Data: 1.703e-01, Loss Eqns: 3.180e+00, Loss Aux: 1.526e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 6989, It: 0, Loss Data: 1.621e-01, Loss Eqns: 2.937e+00, Loss Aux: 2.457e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 6990, It: 0, Loss Data: 1.381e-01, Loss Eqns: 2.883e+00, Loss Aux: 6.573e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 6991, It: 0, Loss Data: 1.620e-01, Loss Eqns: 2.722e+00, Loss Aux: 5.974e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6992, It: 0, Loss Data: 1.310e-01, Loss Eqns: 2.567e+00, Loss Aux: 2.185e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 6993, It: 0, Loss Data: 1.626e-01, Loss Eqns: 2.733e+00, Loss Aux: 1.105e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 6994, It: 0, Loss Data: 1.270e-01, Loss Eqns: 2.604e+00, Loss Aux: 1.683e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 6995, It: 0, Loss Data: 1.576e-01, Loss Eqns: 2.779e+00, Loss Aux: 2.690e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6996, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.432e+00, Loss Aux: 1.865e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 6997, It: 0, Loss Data: 1.449e-01, Loss Eqns: 2.659e+00, Loss Aux: 1.635e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 6998, It: 0, Loss Data: 1.255e-01, Loss Eqns: 2.381e+00, Loss Aux: 2.228e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 6999, It: 0, Loss Data: 1.270e-01, Loss Eqns: 2.545e+00, Loss Aux: 3.939e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7000, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.507e+00, Loss Aux: 2.979e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7001, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.529e+00, Loss Aux: 2.249e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7002, It: 0, Loss Data: 1.228e-01, Loss Eqns: 2.507e+00, Loss Aux: 2.818e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7003, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.514e+00, Loss Aux: 4.307e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7004, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.563e+00, Loss Aux: 3.500e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7005, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.465e+00, Loss Aux: 1.650e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7006, It: 0, Loss Data: 1.195e-01, Loss Eqns: 2.651e+00, Loss Aux: 7.692e-03, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7007, It: 0, Loss Data: 1.261e-01, Loss Eqns: 2.642e+00, Loss Aux: 1.584e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7008, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.625e+00, Loss Aux: 1.552e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7009, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.546e+00, Loss Aux: 1.763e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7010, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.588e+00, Loss Aux: 2.171e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7011, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.614e+00, Loss Aux: 2.800e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7012, It: 0, Loss Data: 9.743e-02, Loss Eqns: 2.624e+00, Loss Aux: 2.801e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7013, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.788e+00, Loss Aux: 2.008e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7014, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.725e+00, Loss Aux: 2.127e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7015, It: 0, Loss Data: 9.466e-02, Loss Eqns: 2.741e+00, Loss Aux: 3.061e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7016, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.693e+00, Loss Aux: 3.946e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7017, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.701e+00, Loss Aux: 3.385e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7018, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.691e+00, Loss Aux: 2.304e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7019, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.821e+00, Loss Aux: 1.975e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7020, It: 0, Loss Data: 9.119e-02, Loss Eqns: 2.777e+00, Loss Aux: 1.835e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7021, It: 0, Loss Data: 7.898e-02, Loss Eqns: 2.649e+00, Loss Aux: 2.131e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7022, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.673e+00, Loss Aux: 2.162e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7023, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.617e+00, Loss Aux: 1.969e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7024, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.591e+00, Loss Aux: 1.976e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7025, It: 0, Loss Data: 1.167e-01, Loss Eqns: 2.667e+00, Loss Aux: 1.999e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7026, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.586e+00, Loss Aux: 1.976e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7027, It: 0, Loss Data: 8.164e-02, Loss Eqns: 2.674e+00, Loss Aux: 2.300e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7028, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.698e+00, Loss Aux: 2.427e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7029, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.630e+00, Loss Aux: 2.189e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7030, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.587e+00, Loss Aux: 1.864e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7031, It: 0, Loss Data: 9.446e-02, Loss Eqns: 2.631e+00, Loss Aux: 1.771e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7032, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.601e+00, Loss Aux: 1.823e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7033, It: 0, Loss Data: 9.384e-02, Loss Eqns: 2.594e+00, Loss Aux: 1.735e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7034, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.559e+00, Loss Aux: 1.757e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7035, It: 0, Loss Data: 9.606e-02, Loss Eqns: 2.650e+00, Loss Aux: 2.416e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7036, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.522e+00, Loss Aux: 2.951e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7037, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.591e+00, Loss Aux: 2.519e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7038, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.636e+00, Loss Aux: 1.728e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7039, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.568e+00, Loss Aux: 1.746e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7040, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.604e+00, Loss Aux: 2.262e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7041, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.571e+00, Loss Aux: 2.652e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7042, It: 0, Loss Data: 9.573e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.221e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7043, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.562e+00, Loss Aux: 2.190e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7044, It: 0, Loss Data: 9.370e-02, Loss Eqns: 2.644e+00, Loss Aux: 2.688e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7045, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.673e+00, Loss Aux: 2.988e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7046, It: 0, Loss Data: 9.350e-02, Loss Eqns: 2.667e+00, Loss Aux: 2.213e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 7047, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.617e+00, Loss Aux: 1.858e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7048, It: 0, Loss Data: 9.371e-02, Loss Eqns: 2.711e+00, Loss Aux: 1.952e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7049, It: 0, Loss Data: 9.419e-02, Loss Eqns: 2.589e+00, Loss Aux: 2.084e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7050, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.559e+00, Loss Aux: 2.176e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7051, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.653e+00, Loss Aux: 1.900e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 7052, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.597e+00, Loss Aux: 1.774e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7053, It: 0, Loss Data: 9.231e-02, Loss Eqns: 2.667e+00, Loss Aux: 2.105e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7054, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.639e+00, Loss Aux: 2.401e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7055, It: 0, Loss Data: 9.270e-02, Loss Eqns: 2.632e+00, Loss Aux: 2.496e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7056, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.617e+00, Loss Aux: 2.450e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7057, It: 0, Loss Data: 8.526e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.201e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7058, It: 0, Loss Data: 9.882e-02, Loss Eqns: 2.561e+00, Loss Aux: 2.025e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7059, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.501e+00, Loss Aux: 2.072e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7060, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.535e+00, Loss Aux: 2.075e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7061, It: 0, Loss Data: 9.297e-02, Loss Eqns: 2.454e+00, Loss Aux: 1.957e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7062, It: 0, Loss Data: 9.798e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.052e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7063, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.609e+00, Loss Aux: 2.086e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7064, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.633e+00, Loss Aux: 1.997e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7065, It: 0, Loss Data: 9.360e-02, Loss Eqns: 2.723e+00, Loss Aux: 1.842e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7066, It: 0, Loss Data: 9.664e-02, Loss Eqns: 2.670e+00, Loss Aux: 2.282e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7067, It: 0, Loss Data: 9.815e-02, Loss Eqns: 2.545e+00, Loss Aux: 2.683e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7068, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.586e+00, Loss Aux: 2.494e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7069, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.300e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7070, It: 0, Loss Data: 9.450e-02, Loss Eqns: 2.624e+00, Loss Aux: 2.369e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7071, It: 0, Loss Data: 9.484e-02, Loss Eqns: 2.643e+00, Loss Aux: 2.104e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7072, It: 0, Loss Data: 9.820e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.726e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7073, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.629e+00, Loss Aux: 1.529e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7074, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.855e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7075, It: 0, Loss Data: 9.231e-02, Loss Eqns: 2.706e+00, Loss Aux: 1.605e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7076, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.703e+00, Loss Aux: 1.240e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7077, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.656e+00, Loss Aux: 1.775e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7078, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.747e+00, Loss Aux: 2.627e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7079, It: 0, Loss Data: 9.025e-02, Loss Eqns: 2.768e+00, Loss Aux: 3.180e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7080, It: 0, Loss Data: 8.561e-02, Loss Eqns: 2.691e+00, Loss Aux: 2.821e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7081, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.579e+00, Loss Aux: 2.233e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7082, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.605e+00, Loss Aux: 1.977e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7083, It: 0, Loss Data: 1.188e-01, Loss Eqns: 2.748e+00, Loss Aux: 2.187e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7084, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.639e+00, Loss Aux: 2.482e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7085, It: 0, Loss Data: 9.816e-02, Loss Eqns: 2.638e+00, Loss Aux: 2.703e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 7086, It: 0, Loss Data: 9.797e-02, Loss Eqns: 2.671e+00, Loss Aux: 2.117e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7087, It: 0, Loss Data: 7.942e-02, Loss Eqns: 2.661e+00, Loss Aux: 1.968e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7088, It: 0, Loss Data: 8.164e-02, Loss Eqns: 2.744e+00, Loss Aux: 1.911e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7089, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.636e+00, Loss Aux: 2.109e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7090, It: 0, Loss Data: 9.901e-02, Loss Eqns: 2.695e+00, Loss Aux: 2.282e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7091, It: 0, Loss Data: 9.249e-02, Loss Eqns: 2.625e+00, Loss Aux: 2.367e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7092, It: 0, Loss Data: 9.661e-02, Loss Eqns: 2.770e+00, Loss Aux: 2.364e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7093, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.610e+00, Loss Aux: 2.081e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7094, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.566e+00, Loss Aux: 2.369e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7095, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.624e+00, Loss Aux: 2.811e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7096, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.664e+00, Loss Aux: 2.327e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7097, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.657e+00, Loss Aux: 1.487e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7098, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.540e+00, Loss Aux: 1.724e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7099, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.548e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7100, It: 0, Loss Data: 9.428e-02, Loss Eqns: 2.687e+00, Loss Aux: 2.289e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7101, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.760e+00, Loss Aux: 1.264e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7102, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.640e+00, Loss Aux: 1.481e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7103, It: 0, Loss Data: 9.339e-02, Loss Eqns: 2.571e+00, Loss Aux: 2.485e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7104, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.553e+00, Loss Aux: 2.549e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7105, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.671e+00, Loss Aux: 1.804e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7106, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.589e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7107, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.664e+00, Loss Aux: 1.702e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7108, It: 0, Loss Data: 9.200e-02, Loss Eqns: 2.678e+00, Loss Aux: 2.305e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7109, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.751e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7110, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.590e+00, Loss Aux: 3.056e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7111, It: 0, Loss Data: 8.220e-02, Loss Eqns: 2.702e+00, Loss Aux: 3.245e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7112, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.643e+00, Loss Aux: 2.972e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7113, It: 0, Loss Data: 8.856e-02, Loss Eqns: 2.712e+00, Loss Aux: 2.463e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 7114, It: 0, Loss Data: 9.613e-02, Loss Eqns: 2.648e+00, Loss Aux: 1.825e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7115, It: 0, Loss Data: 9.546e-02, Loss Eqns: 2.558e+00, Loss Aux: 1.502e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7116, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.675e+00, Loss Aux: 1.695e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7117, It: 0, Loss Data: 8.825e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.407e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 7118, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.498e+00, Loss Aux: 2.740e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7119, It: 0, Loss Data: 9.238e-02, Loss Eqns: 2.584e+00, Loss Aux: 2.372e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7120, It: 0, Loss Data: 8.630e-02, Loss Eqns: 2.596e+00, Loss Aux: 1.661e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7121, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.560e+00, Loss Aux: 1.371e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7122, It: 0, Loss Data: 9.570e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.760e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7123, It: 0, Loss Data: 8.521e-02, Loss Eqns: 2.581e+00, Loss Aux: 2.429e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 7124, It: 0, Loss Data: 8.867e-02, Loss Eqns: 2.499e+00, Loss Aux: 2.407e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7125, It: 0, Loss Data: 7.929e-02, Loss Eqns: 2.546e+00, Loss Aux: 1.754e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7126, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.638e+00, Loss Aux: 1.429e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7127, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.551e+00, Loss Aux: 2.091e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7128, It: 0, Loss Data: 9.671e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.706e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7129, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.566e+00, Loss Aux: 2.184e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7130, It: 0, Loss Data: 9.530e-02, Loss Eqns: 2.520e+00, Loss Aux: 1.470e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7131, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.445e+00, Loss Aux: 1.651e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7132, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.634e+00, Loss Aux: 1.937e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7133, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.639e+00, Loss Aux: 1.210e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7134, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.616e+00, Loss Aux: 1.460e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7135, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.550e+00, Loss Aux: 2.418e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7136, It: 0, Loss Data: 9.845e-02, Loss Eqns: 2.523e+00, Loss Aux: 3.576e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7137, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.524e+00, Loss Aux: 3.525e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7138, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.549e+00, Loss Aux: 2.405e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7139, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.588e+00, Loss Aux: 1.728e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7140, It: 0, Loss Data: 9.819e-02, Loss Eqns: 2.561e+00, Loss Aux: 1.811e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7141, It: 0, Loss Data: 9.527e-02, Loss Eqns: 2.561e+00, Loss Aux: 2.340e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7142, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.594e+00, Loss Aux: 2.450e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7143, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.562e+00, Loss Aux: 2.236e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 7144, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.590e+00, Loss Aux: 2.048e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7145, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.663e+00, Loss Aux: 1.846e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7146, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.659e+00, Loss Aux: 1.529e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7147, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.677e+00, Loss Aux: 1.705e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7148, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.699e+00, Loss Aux: 2.011e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7149, It: 0, Loss Data: 9.884e-02, Loss Eqns: 2.732e+00, Loss Aux: 2.250e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7150, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.552e+00, Loss Aux: 2.348e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7151, It: 0, Loss Data: 9.773e-02, Loss Eqns: 2.679e+00, Loss Aux: 2.488e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7152, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.737e+00, Loss Aux: 2.313e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7153, It: 0, Loss Data: 9.354e-02, Loss Eqns: 2.657e+00, Loss Aux: 1.619e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7154, It: 0, Loss Data: 9.682e-02, Loss Eqns: 2.764e+00, Loss Aux: 1.705e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7155, It: 0, Loss Data: 9.217e-02, Loss Eqns: 2.622e+00, Loss Aux: 2.123e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7156, It: 0, Loss Data: 9.755e-02, Loss Eqns: 2.614e+00, Loss Aux: 2.038e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7157, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.641e+00, Loss Aux: 1.686e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 7158, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.643e+00, Loss Aux: 1.429e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7159, It: 0, Loss Data: 9.817e-02, Loss Eqns: 2.703e+00, Loss Aux: 1.437e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7160, It: 0, Loss Data: 8.858e-02, Loss Eqns: 2.586e+00, Loss Aux: 1.407e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7161, It: 0, Loss Data: 8.562e-02, Loss Eqns: 2.583e+00, Loss Aux: 1.590e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7162, It: 0, Loss Data: 9.689e-02, Loss Eqns: 2.590e+00, Loss Aux: 2.278e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7163, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.645e+00, Loss Aux: 2.537e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7164, It: 0, Loss Data: 8.639e-02, Loss Eqns: 2.642e+00, Loss Aux: 2.012e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7165, It: 0, Loss Data: 8.841e-02, Loss Eqns: 2.678e+00, Loss Aux: 1.782e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7166, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.582e+00, Loss Aux: 2.257e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7167, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.620e+00, Loss Aux: 2.817e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7168, It: 0, Loss Data: 9.551e-02, Loss Eqns: 2.610e+00, Loss Aux: 2.347e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7169, It: 0, Loss Data: 9.076e-02, Loss Eqns: 2.578e+00, Loss Aux: 2.061e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7170, It: 0, Loss Data: 9.623e-02, Loss Eqns: 2.580e+00, Loss Aux: 1.901e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7171, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.618e+00, Loss Aux: 2.035e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7172, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.577e+00, Loss Aux: 2.133e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7173, It: 0, Loss Data: 8.622e-02, Loss Eqns: 2.663e+00, Loss Aux: 1.782e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7174, It: 0, Loss Data: 9.933e-02, Loss Eqns: 2.603e+00, Loss Aux: 1.261e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7175, It: 0, Loss Data: 9.613e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.475e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7176, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.575e+00, Loss Aux: 1.757e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7177, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.600e+00, Loss Aux: 1.872e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7178, It: 0, Loss Data: 9.902e-02, Loss Eqns: 2.560e+00, Loss Aux: 2.132e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7179, It: 0, Loss Data: 9.658e-02, Loss Eqns: 2.651e+00, Loss Aux: 2.510e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7180, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.743e+00, Loss Aux: 2.314e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7181, It: 0, Loss Data: 9.524e-02, Loss Eqns: 2.688e+00, Loss Aux: 2.069e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7182, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.694e+00, Loss Aux: 2.016e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 7183, It: 0, Loss Data: 9.866e-02, Loss Eqns: 2.580e+00, Loss Aux: 2.261e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7184, It: 0, Loss Data: 9.202e-02, Loss Eqns: 2.613e+00, Loss Aux: 2.183e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7185, It: 0, Loss Data: 8.480e-02, Loss Eqns: 2.682e+00, Loss Aux: 1.827e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7186, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.562e+00, Loss Aux: 1.347e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7187, It: 0, Loss Data: 9.899e-02, Loss Eqns: 2.572e+00, Loss Aux: 9.119e-03, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7188, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.550e+00, Loss Aux: 1.569e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7189, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.587e+00, Loss Aux: 2.560e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7190, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.535e+00, Loss Aux: 2.438e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7191, It: 0, Loss Data: 9.735e-02, Loss Eqns: 2.682e+00, Loss Aux: 2.188e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7192, It: 0, Loss Data: 9.273e-02, Loss Eqns: 2.648e+00, Loss Aux: 1.946e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7193, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.622e+00, Loss Aux: 1.703e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7194, It: 0, Loss Data: 8.860e-02, Loss Eqns: 2.593e+00, Loss Aux: 1.636e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7195, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.605e+00, Loss Aux: 2.026e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7196, It: 0, Loss Data: 8.321e-02, Loss Eqns: 2.691e+00, Loss Aux: 2.306e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7197, It: 0, Loss Data: 9.044e-02, Loss Eqns: 2.621e+00, Loss Aux: 2.091e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7198, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.597e+00, Loss Aux: 1.722e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7199, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.536e+00, Loss Aux: 1.966e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7200, It: 0, Loss Data: 9.702e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.854e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7201, It: 0, Loss Data: 9.586e-02, Loss Eqns: 2.443e+00, Loss Aux: 1.502e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7202, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.511e+00, Loss Aux: 1.398e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7203, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.535e+00, Loss Aux: 1.689e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7204, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.537e+00, Loss Aux: 1.559e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7205, It: 0, Loss Data: 9.251e-02, Loss Eqns: 2.538e+00, Loss Aux: 1.323e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7206, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.586e+00, Loss Aux: 1.480e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7207, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.502e+00, Loss Aux: 1.741e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7208, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.519e+00, Loss Aux: 2.196e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7209, It: 0, Loss Data: 9.181e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.255e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7210, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.548e+00, Loss Aux: 1.668e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7211, It: 0, Loss Data: 9.333e-02, Loss Eqns: 2.578e+00, Loss Aux: 1.702e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7212, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.571e+00, Loss Aux: 2.006e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7213, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.629e+00, Loss Aux: 2.715e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7214, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.704e+00, Loss Aux: 2.764e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7215, It: 0, Loss Data: 8.880e-02, Loss Eqns: 2.606e+00, Loss Aux: 2.327e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7216, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.666e+00, Loss Aux: 2.084e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7217, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.679e+00, Loss Aux: 2.120e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7218, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.650e+00, Loss Aux: 1.271e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7219, It: 0, Loss Data: 8.085e-02, Loss Eqns: 2.659e+00, Loss Aux: 1.016e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7220, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.661e+00, Loss Aux: 1.382e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7221, It: 0, Loss Data: 8.955e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.173e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7222, It: 0, Loss Data: 9.213e-02, Loss Eqns: 2.583e+00, Loss Aux: 2.562e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7223, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.696e+00, Loss Aux: 2.295e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 7224, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.519e+00, Loss Aux: 2.055e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7225, It: 0, Loss Data: 8.937e-02, Loss Eqns: 2.579e+00, Loss Aux: 1.941e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7226, It: 0, Loss Data: 9.651e-02, Loss Eqns: 2.606e+00, Loss Aux: 2.087e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7227, It: 0, Loss Data: 9.236e-02, Loss Eqns: 2.562e+00, Loss Aux: 1.950e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7228, It: 0, Loss Data: 8.639e-02, Loss Eqns: 2.537e+00, Loss Aux: 1.566e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7229, It: 0, Loss Data: 8.911e-02, Loss Eqns: 2.568e+00, Loss Aux: 1.400e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 7230, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.510e+00, Loss Aux: 1.888e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7231, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.521e+00, Loss Aux: 2.586e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7232, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.581e+00, Loss Aux: 1.705e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7233, It: 0, Loss Data: 9.859e-02, Loss Eqns: 2.530e+00, Loss Aux: 1.296e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7234, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.701e+00, Loss Aux: 2.078e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7235, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.524e+00, Loss Aux: 2.730e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7236, It: 0, Loss Data: 9.553e-02, Loss Eqns: 2.574e+00, Loss Aux: 1.973e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7237, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.524e+00, Loss Aux: 1.552e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7238, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.769e+00, Loss Aux: 1.756e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7239, It: 0, Loss Data: 9.632e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.985e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7240, It: 0, Loss Data: 9.624e-02, Loss Eqns: 2.580e+00, Loss Aux: 2.084e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7241, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.563e+00, Loss Aux: 1.808e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7242, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.719e+00, Loss Aux: 1.653e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7243, It: 0, Loss Data: 7.269e-02, Loss Eqns: 2.575e+00, Loss Aux: 1.611e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7244, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.606e+00, Loss Aux: 2.286e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 7245, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.568e+00, Loss Aux: 2.293e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7246, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.696e+00, Loss Aux: 1.602e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7247, It: 0, Loss Data: 9.764e-02, Loss Eqns: 2.520e+00, Loss Aux: 1.448e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7248, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.610e+00, Loss Aux: 1.782e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 7249, It: 0, Loss Data: 9.838e-02, Loss Eqns: 2.551e+00, Loss Aux: 2.567e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7250, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.486e+00, Loss Aux: 2.132e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7251, It: 0, Loss Data: 9.657e-02, Loss Eqns: 2.595e+00, Loss Aux: 2.023e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7252, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.642e+00, Loss Aux: 2.240e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7253, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.394e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 7254, It: 0, Loss Data: 9.175e-02, Loss Eqns: 2.606e+00, Loss Aux: 1.725e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7255, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.645e+00, Loss Aux: 1.298e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7256, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.624e+00, Loss Aux: 1.858e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7257, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.578e+00, Loss Aux: 2.390e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7258, It: 0, Loss Data: 9.674e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.404e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7259, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.624e+00, Loss Aux: 2.437e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7260, It: 0, Loss Data: 9.467e-02, Loss Eqns: 2.599e+00, Loss Aux: 2.132e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7261, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.018e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7262, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.533e+00, Loss Aux: 2.472e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7263, It: 0, Loss Data: 9.138e-02, Loss Eqns: 2.587e+00, Loss Aux: 2.511e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7264, It: 0, Loss Data: 8.048e-02, Loss Eqns: 2.592e+00, Loss Aux: 1.667e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7265, It: 0, Loss Data: 9.560e-02, Loss Eqns: 2.570e+00, Loss Aux: 1.191e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7266, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.555e+00, Loss Aux: 1.474e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7267, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.615e+00, Loss Aux: 1.992e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7268, It: 0, Loss Data: 9.548e-02, Loss Eqns: 2.522e+00, Loss Aux: 1.367e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7269, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.584e+00, Loss Aux: 8.777e-03, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7270, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.572e+00, Loss Aux: 8.461e-03, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7271, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.592e+00, Loss Aux: 1.775e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7272, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.425e+00, Loss Aux: 2.556e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7273, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.533e+00, Loss Aux: 3.051e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7274, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.571e+00, Loss Aux: 3.009e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7275, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.612e+00, Loss Aux: 2.432e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7276, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.658e+00, Loss Aux: 1.939e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7277, It: 0, Loss Data: 8.756e-02, Loss Eqns: 2.596e+00, Loss Aux: 2.232e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7278, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.662e+00, Loss Aux: 2.449e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7279, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.615e+00, Loss Aux: 2.733e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7280, It: 0, Loss Data: 9.814e-02, Loss Eqns: 2.679e+00, Loss Aux: 2.688e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7281, It: 0, Loss Data: 9.699e-02, Loss Eqns: 2.585e+00, Loss Aux: 2.145e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7282, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.508e+00, Loss Aux: 1.308e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7283, It: 0, Loss Data: 9.157e-02, Loss Eqns: 2.703e+00, Loss Aux: 9.222e-03, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 7284, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.648e+00, Loss Aux: 1.298e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7285, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.599e+00, Loss Aux: 1.527e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7286, It: 0, Loss Data: 8.702e-02, Loss Eqns: 2.555e+00, Loss Aux: 1.992e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7287, It: 0, Loss Data: 8.430e-02, Loss Eqns: 2.607e+00, Loss Aux: 2.730e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7288, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.666e+00, Loss Aux: 2.627e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7289, It: 0, Loss Data: 9.581e-02, Loss Eqns: 2.726e+00, Loss Aux: 2.202e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 7290, It: 0, Loss Data: 9.733e-02, Loss Eqns: 2.569e+00, Loss Aux: 2.242e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7291, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.655e+00, Loss Aux: 2.616e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7292, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.636e+00, Loss Aux: 2.319e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7293, It: 0, Loss Data: 8.734e-02, Loss Eqns: 2.595e+00, Loss Aux: 1.418e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7294, It: 0, Loss Data: 9.857e-02, Loss Eqns: 2.488e+00, Loss Aux: 9.532e-03, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7295, It: 0, Loss Data: 8.669e-02, Loss Eqns: 2.427e+00, Loss Aux: 1.253e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7296, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.555e+00, Loss Aux: 1.741e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 7297, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.444e+00, Loss Aux: 1.812e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 7298, It: 0, Loss Data: 9.053e-02, Loss Eqns: 2.546e+00, Loss Aux: 1.999e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7299, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.477e+00, Loss Aux: 1.943e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 7300, It: 0, Loss Data: 7.663e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.980e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7301, It: 0, Loss Data: 9.346e-02, Loss Eqns: 2.559e+00, Loss Aux: 2.317e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7302, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.178e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7303, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.503e+00, Loss Aux: 1.819e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7304, It: 0, Loss Data: 9.444e-02, Loss Eqns: 2.384e+00, Loss Aux: 1.735e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 7305, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.587e+00, Loss Aux: 2.066e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7306, It: 0, Loss Data: 8.346e-02, Loss Eqns: 2.590e+00, Loss Aux: 1.971e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7307, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.522e+00, Loss Aux: 1.550e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7308, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.515e+00, Loss Aux: 1.355e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7309, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.477e+00, Loss Aux: 1.573e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7310, It: 0, Loss Data: 9.980e-02, Loss Eqns: 2.561e+00, Loss Aux: 1.976e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7311, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.598e+00, Loss Aux: 2.455e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7312, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.581e+00, Loss Aux: 2.353e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7313, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.556e+00, Loss Aux: 2.109e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7314, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.532e+00, Loss Aux: 2.304e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7315, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.561e+00, Loss Aux: 2.391e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7316, It: 0, Loss Data: 8.025e-02, Loss Eqns: 2.554e+00, Loss Aux: 2.263e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7317, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.551e+00, Loss Aux: 1.962e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7318, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.576e+00, Loss Aux: 1.715e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7319, It: 0, Loss Data: 9.173e-02, Loss Eqns: 2.562e+00, Loss Aux: 1.484e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7320, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.515e+00, Loss Aux: 1.199e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7321, It: 0, Loss Data: 8.419e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.394e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7322, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.574e+00, Loss Aux: 2.503e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7323, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.612e+00, Loss Aux: 2.669e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7324, It: 0, Loss Data: 8.995e-02, Loss Eqns: 2.619e+00, Loss Aux: 2.155e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 7325, It: 0, Loss Data: 9.201e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.122e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 7326, It: 0, Loss Data: 9.951e-02, Loss Eqns: 2.730e+00, Loss Aux: 1.980e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7327, It: 0, Loss Data: 8.442e-02, Loss Eqns: 2.552e+00, Loss Aux: 1.425e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7328, It: 0, Loss Data: 9.506e-02, Loss Eqns: 2.608e+00, Loss Aux: 1.741e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7329, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.638e+00, Loss Aux: 2.526e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7330, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.590e+00, Loss Aux: 2.851e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7331, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.649e+00, Loss Aux: 2.347e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7332, It: 0, Loss Data: 8.870e-02, Loss Eqns: 2.607e+00, Loss Aux: 1.783e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7333, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.703e+00, Loss Aux: 1.491e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7334, It: 0, Loss Data: 7.949e-02, Loss Eqns: 2.621e+00, Loss Aux: 1.846e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7335, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.678e+00, Loss Aux: 2.025e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7336, It: 0, Loss Data: 9.617e-02, Loss Eqns: 2.720e+00, Loss Aux: 1.905e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7337, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.709e+00, Loss Aux: 1.935e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7338, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.708e+00, Loss Aux: 1.684e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7339, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.687e+00, Loss Aux: 1.306e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 7340, It: 0, Loss Data: 9.304e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.041e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7341, It: 0, Loss Data: 8.907e-02, Loss Eqns: 2.590e+00, Loss Aux: 1.448e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7342, It: 0, Loss Data: 9.049e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.168e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7343, It: 0, Loss Data: 7.556e-02, Loss Eqns: 2.615e+00, Loss Aux: 2.696e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7344, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.588e+00, Loss Aux: 3.039e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 7345, It: 0, Loss Data: 9.830e-02, Loss Eqns: 2.518e+00, Loss Aux: 3.110e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 7346, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.515e+00, Loss Aux: 1.931e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7347, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.565e+00, Loss Aux: 1.378e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7348, It: 0, Loss Data: 8.987e-02, Loss Eqns: 2.616e+00, Loss Aux: 1.185e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7349, It: 0, Loss Data: 8.950e-02, Loss Eqns: 2.592e+00, Loss Aux: 1.343e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7350, It: 0, Loss Data: 9.760e-02, Loss Eqns: 2.484e+00, Loss Aux: 1.347e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7351, It: 0, Loss Data: 9.248e-02, Loss Eqns: 2.530e+00, Loss Aux: 1.873e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7352, It: 0, Loss Data: 9.599e-02, Loss Eqns: 2.646e+00, Loss Aux: 2.095e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7353, It: 0, Loss Data: 8.958e-02, Loss Eqns: 2.571e+00, Loss Aux: 1.853e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7354, It: 0, Loss Data: 8.185e-02, Loss Eqns: 2.520e+00, Loss Aux: 1.890e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7355, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.531e+00, Loss Aux: 1.672e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7356, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.668e+00, Loss Aux: 1.390e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7357, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.474e+00, Loss Aux: 1.579e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7358, It: 0, Loss Data: 1.211e-01, Loss Eqns: 2.579e+00, Loss Aux: 2.213e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7359, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.523e+00, Loss Aux: 2.063e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7360, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.494e+00, Loss Aux: 1.552e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7361, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.715e+00, Loss Aux: 1.537e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7362, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.682e+00, Loss Aux: 1.670e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7363, It: 0, Loss Data: 9.767e-02, Loss Eqns: 2.581e+00, Loss Aux: 2.042e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7364, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.643e+00, Loss Aux: 2.050e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7365, It: 0, Loss Data: 8.994e-02, Loss Eqns: 2.618e+00, Loss Aux: 1.654e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7366, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.686e+00, Loss Aux: 1.442e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7367, It: 0, Loss Data: 8.721e-02, Loss Eqns: 2.578e+00, Loss Aux: 2.051e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 7368, It: 0, Loss Data: 9.851e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.343e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7369, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.564e+00, Loss Aux: 2.328e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7370, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.647e+00, Loss Aux: 2.353e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7371, It: 0, Loss Data: 9.374e-02, Loss Eqns: 2.537e+00, Loss Aux: 2.064e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7372, It: 0, Loss Data: 9.651e-02, Loss Eqns: 2.496e+00, Loss Aux: 1.308e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7373, It: 0, Loss Data: 9.467e-02, Loss Eqns: 2.488e+00, Loss Aux: 1.420e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7374, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.462e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7375, It: 0, Loss Data: 7.681e-02, Loss Eqns: 2.530e+00, Loss Aux: 1.257e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7376, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.442e+00, Loss Aux: 1.568e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 7377, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.594e+00, Loss Aux: 2.424e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7378, It: 0, Loss Data: 8.244e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.574e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7379, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.487e+00, Loss Aux: 1.225e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7380, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.518e+00, Loss Aux: 1.176e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7381, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.510e+00, Loss Aux: 1.775e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7382, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.468e+00, Loss Aux: 1.909e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7383, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.427e+00, Loss Aux: 8.497e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7384, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.509e+00, Loss Aux: 7.561e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7385, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.079e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7386, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.583e+00, Loss Aux: 3.236e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7387, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.531e+00, Loss Aux: 2.925e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7388, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.552e+00, Loss Aux: 2.202e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7389, It: 0, Loss Data: 9.926e-02, Loss Eqns: 2.551e+00, Loss Aux: 1.742e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7390, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.538e+00, Loss Aux: 2.044e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7391, It: 0, Loss Data: 9.363e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.054e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7392, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.462e+00, Loss Aux: 1.561e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7393, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.583e+00, Loss Aux: 1.474e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7394, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.580e+00, Loss Aux: 1.734e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7395, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.634e+00, Loss Aux: 2.009e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7396, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.543e+00, Loss Aux: 2.027e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7397, It: 0, Loss Data: 9.503e-02, Loss Eqns: 2.671e+00, Loss Aux: 2.137e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7398, It: 0, Loss Data: 9.914e-02, Loss Eqns: 2.649e+00, Loss Aux: 2.211e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7399, It: 0, Loss Data: 9.072e-02, Loss Eqns: 2.693e+00, Loss Aux: 2.117e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7400, It: 0, Loss Data: 7.739e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.789e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7401, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.647e+00, Loss Aux: 1.190e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7402, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.619e+00, Loss Aux: 1.101e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7403, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.607e+00, Loss Aux: 1.572e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7404, It: 0, Loss Data: 9.274e-02, Loss Eqns: 2.711e+00, Loss Aux: 1.574e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7405, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.687e+00, Loss Aux: 1.213e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7406, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.563e+00, Loss Aux: 1.471e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7407, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.572e+00, Loss Aux: 2.208e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7408, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.525e+00, Loss Aux: 2.969e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7409, It: 0, Loss Data: 9.562e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.662e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7410, It: 0, Loss Data: 8.589e-02, Loss Eqns: 2.646e+00, Loss Aux: 1.858e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7411, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.581e+00, Loss Aux: 1.641e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7412, It: 0, Loss Data: 8.505e-02, Loss Eqns: 2.618e+00, Loss Aux: 1.616e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7413, It: 0, Loss Data: 9.547e-02, Loss Eqns: 2.585e+00, Loss Aux: 1.343e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7414, It: 0, Loss Data: 1.232e-01, Loss Eqns: 2.515e+00, Loss Aux: 1.358e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7415, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.570e+00, Loss Aux: 1.855e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7416, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.437e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7417, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.532e+00, Loss Aux: 1.630e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7418, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.663e+00, Loss Aux: 1.172e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7419, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.567e+00, Loss Aux: 1.400e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7420, It: 0, Loss Data: 8.174e-02, Loss Eqns: 2.545e+00, Loss Aux: 2.341e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7421, It: 0, Loss Data: 8.952e-02, Loss Eqns: 2.593e+00, Loss Aux: 2.913e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7422, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.554e+00, Loss Aux: 1.400e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7423, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.577e+00, Loss Aux: 1.236e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7424, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.575e+00, Loss Aux: 1.312e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7425, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.543e+00, Loss Aux: 1.720e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7426, It: 0, Loss Data: 9.331e-02, Loss Eqns: 2.529e+00, Loss Aux: 1.535e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7427, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.633e+00, Loss Aux: 1.317e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7428, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.543e+00, Loss Aux: 1.520e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7429, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.498e+00, Loss Aux: 2.110e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7430, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.559e+00, Loss Aux: 2.002e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7431, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.473e+00, Loss Aux: 1.813e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7432, It: 0, Loss Data: 9.943e-02, Loss Eqns: 2.575e+00, Loss Aux: 2.170e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7433, It: 0, Loss Data: 8.328e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.349e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7434, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.410e+00, Loss Aux: 2.032e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7435, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.545e+00, Loss Aux: 1.473e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7436, It: 0, Loss Data: 9.877e-02, Loss Eqns: 2.560e+00, Loss Aux: 1.143e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7437, It: 0, Loss Data: 9.044e-02, Loss Eqns: 2.498e+00, Loss Aux: 1.386e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7438, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.571e+00, Loss Aux: 2.079e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7439, It: 0, Loss Data: 9.525e-02, Loss Eqns: 2.646e+00, Loss Aux: 1.926e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7440, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.665e+00, Loss Aux: 1.466e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7441, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.656e+00, Loss Aux: 1.261e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7442, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.608e+00, Loss Aux: 1.508e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7443, It: 0, Loss Data: 9.581e-02, Loss Eqns: 2.647e+00, Loss Aux: 1.835e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7444, It: 0, Loss Data: 8.305e-02, Loss Eqns: 2.578e+00, Loss Aux: 2.236e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7445, It: 0, Loss Data: 9.206e-02, Loss Eqns: 2.604e+00, Loss Aux: 2.025e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7446, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.551e+00, Loss Aux: 1.847e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7447, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.575e+00, Loss Aux: 1.757e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7448, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.715e+00, Loss Aux: 1.700e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7449, It: 0, Loss Data: 9.436e-02, Loss Eqns: 2.718e+00, Loss Aux: 1.640e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7450, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.882e+00, Loss Aux: 1.029e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7451, It: 0, Loss Data: 8.261e-02, Loss Eqns: 2.645e+00, Loss Aux: 2.529e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7452, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.598e+00, Loss Aux: 3.008e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7453, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.703e+00, Loss Aux: 1.532e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7454, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.544e+00, Loss Aux: 1.020e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7455, It: 0, Loss Data: 9.909e-02, Loss Eqns: 2.826e+00, Loss Aux: 1.120e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7456, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.719e+00, Loss Aux: 1.198e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7457, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.727e+00, Loss Aux: 1.755e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7458, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.857e+00, Loss Aux: 2.149e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7459, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.626e+00, Loss Aux: 1.725e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7460, It: 0, Loss Data: 9.660e-02, Loss Eqns: 2.623e+00, Loss Aux: 1.902e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7461, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.686e+00, Loss Aux: 2.469e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7462, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.629e+00, Loss Aux: 2.276e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7463, It: 0, Loss Data: 9.090e-02, Loss Eqns: 2.602e+00, Loss Aux: 1.644e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7464, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.474e+00, Loss Aux: 2.082e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 7465, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.518e+00, Loss Aux: 2.016e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7466, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.589e+00, Loss Aux: 1.244e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7467, It: 0, Loss Data: 9.085e-02, Loss Eqns: 2.656e+00, Loss Aux: 1.119e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7468, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.629e+00, Loss Aux: 1.893e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7469, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.539e+00, Loss Aux: 2.594e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7470, It: 0, Loss Data: 9.029e-02, Loss Eqns: 2.452e+00, Loss Aux: 1.752e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7471, It: 0, Loss Data: 1.405e-01, Loss Eqns: 2.793e+00, Loss Aux: 1.429e-03, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7472, It: 0, Loss Data: 1.632e-01, Loss Eqns: 3.561e+00, Loss Aux: 4.618e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7473, It: 0, Loss Data: 1.582e-01, Loss Eqns: 3.503e+00, Loss Aux: 4.558e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7474, It: 0, Loss Data: 1.337e-01, Loss Eqns: 3.661e+00, Loss Aux: 4.166e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7475, It: 0, Loss Data: 1.489e-01, Loss Eqns: 3.132e+00, Loss Aux: 3.650e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7476, It: 0, Loss Data: 1.612e-01, Loss Eqns: 3.459e+00, Loss Aux: 2.027e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7477, It: 0, Loss Data: 1.467e-01, Loss Eqns: 3.172e+00, Loss Aux: 1.057e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7478, It: 0, Loss Data: 1.302e-01, Loss Eqns: 2.979e+00, Loss Aux: 1.183e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7479, It: 0, Loss Data: 1.664e-01, Loss Eqns: 3.003e+00, Loss Aux: 2.594e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7480, It: 0, Loss Data: 1.585e-01, Loss Eqns: 3.179e+00, Loss Aux: 3.398e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7481, It: 0, Loss Data: 1.306e-01, Loss Eqns: 2.967e+00, Loss Aux: 3.013e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 7482, It: 0, Loss Data: 1.407e-01, Loss Eqns: 2.864e+00, Loss Aux: 1.986e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 7483, It: 0, Loss Data: 1.552e-01, Loss Eqns: 2.642e+00, Loss Aux: 3.626e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7484, It: 0, Loss Data: 1.370e-01, Loss Eqns: 2.776e+00, Loss Aux: 2.552e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7485, It: 0, Loss Data: 1.712e-01, Loss Eqns: 2.722e+00, Loss Aux: 1.723e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7486, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.729e+00, Loss Aux: 2.897e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7487, It: 0, Loss Data: 1.369e-01, Loss Eqns: 2.659e+00, Loss Aux: 4.467e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7488, It: 0, Loss Data: 1.162e-01, Loss Eqns: 2.725e+00, Loss Aux: 3.177e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7489, It: 0, Loss Data: 1.486e-01, Loss Eqns: 2.557e+00, Loss Aux: 1.622e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7490, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.645e+00, Loss Aux: 1.455e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7491, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.870e+00, Loss Aux: 2.227e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7492, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.747e+00, Loss Aux: 2.364e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7493, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.992e+00, Loss Aux: 1.576e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7494, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.679e+00, Loss Aux: 1.876e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7495, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.770e+00, Loss Aux: 2.939e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7496, It: 0, Loss Data: 9.611e-02, Loss Eqns: 2.794e+00, Loss Aux: 2.731e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7497, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.679e+00, Loss Aux: 2.661e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7498, It: 0, Loss Data: 9.718e-02, Loss Eqns: 2.716e+00, Loss Aux: 2.530e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7499, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.724e+00, Loss Aux: 2.702e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7500, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.578e+00, Loss Aux: 2.736e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7501, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.639e+00, Loss Aux: 3.248e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7502, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.504e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 7503, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.651e+00, Loss Aux: 1.832e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7504, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.670e+00, Loss Aux: 1.451e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7505, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.608e+00, Loss Aux: 1.496e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7506, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.520e+00, Loss Aux: 1.382e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7507, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.575e+00, Loss Aux: 1.553e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7508, It: 0, Loss Data: 8.819e-02, Loss Eqns: 2.506e+00, Loss Aux: 2.307e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7509, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.636e+00, Loss Aux: 3.524e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7510, It: 0, Loss Data: 8.458e-02, Loss Eqns: 2.605e+00, Loss Aux: 3.713e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 7511, It: 0, Loss Data: 9.597e-02, Loss Eqns: 2.599e+00, Loss Aux: 2.625e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7512, It: 0, Loss Data: 9.688e-02, Loss Eqns: 2.677e+00, Loss Aux: 2.065e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7513, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.608e+00, Loss Aux: 2.546e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7514, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.614e+00, Loss Aux: 2.454e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7515, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.691e+00, Loss Aux: 1.871e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 7516, It: 0, Loss Data: 9.573e-02, Loss Eqns: 2.720e+00, Loss Aux: 1.469e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7517, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.611e+00, Loss Aux: 1.475e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7518, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.541e+00, Loss Aux: 2.174e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 7519, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.649e+00, Loss Aux: 2.756e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7520, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.638e+00, Loss Aux: 1.853e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 7521, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.669e+00, Loss Aux: 1.531e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7522, It: 0, Loss Data: 8.283e-02, Loss Eqns: 2.590e+00, Loss Aux: 2.106e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7523, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.910e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7524, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.532e+00, Loss Aux: 2.747e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7525, It: 0, Loss Data: 1.167e-01, Loss Eqns: 2.524e+00, Loss Aux: 2.201e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7526, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.499e+00, Loss Aux: 2.318e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7527, It: 0, Loss Data: 1.146e-01, Loss Eqns: 2.482e+00, Loss Aux: 2.632e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 7528, It: 0, Loss Data: 9.130e-02, Loss Eqns: 2.554e+00, Loss Aux: 1.947e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7529, It: 0, Loss Data: 9.876e-02, Loss Eqns: 2.507e+00, Loss Aux: 1.525e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7530, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.529e+00, Loss Aux: 1.452e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7531, It: 0, Loss Data: 9.998e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.819e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7532, It: 0, Loss Data: 9.086e-02, Loss Eqns: 2.581e+00, Loss Aux: 2.227e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7533, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.548e+00, Loss Aux: 2.140e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7534, It: 0, Loss Data: 1.213e-01, Loss Eqns: 2.603e+00, Loss Aux: 1.866e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7535, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.675e+00, Loss Aux: 2.501e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7536, It: 0, Loss Data: 9.423e-02, Loss Eqns: 2.643e+00, Loss Aux: 2.826e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7537, It: 0, Loss Data: 7.835e-02, Loss Eqns: 2.674e+00, Loss Aux: 2.327e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7538, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.695e+00, Loss Aux: 1.958e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7539, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.656e+00, Loss Aux: 1.861e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7540, It: 0, Loss Data: 9.200e-02, Loss Eqns: 2.658e+00, Loss Aux: 2.248e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7541, It: 0, Loss Data: 8.209e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.461e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7542, It: 0, Loss Data: 7.924e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.537e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7543, It: 0, Loss Data: 8.278e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.409e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 7544, It: 0, Loss Data: 8.581e-02, Loss Eqns: 2.536e+00, Loss Aux: 2.380e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7545, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.492e+00, Loss Aux: 2.368e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7546, It: 0, Loss Data: 9.732e-02, Loss Eqns: 2.589e+00, Loss Aux: 2.599e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7547, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.507e+00, Loss Aux: 2.362e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 7548, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.480e+00, Loss Aux: 2.030e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7549, It: 0, Loss Data: 8.772e-02, Loss Eqns: 2.692e+00, Loss Aux: 1.724e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7550, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.650e+00, Loss Aux: 1.378e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7551, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.521e+00, Loss Aux: 1.420e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7552, It: 0, Loss Data: 9.107e-02, Loss Eqns: 2.557e+00, Loss Aux: 2.137e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7553, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.491e+00, Loss Aux: 2.969e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7554, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.576e+00, Loss Aux: 2.580e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7555, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.598e+00, Loss Aux: 2.132e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7556, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.659e+00, Loss Aux: 2.210e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7557, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.613e+00, Loss Aux: 2.247e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7558, It: 0, Loss Data: 8.351e-02, Loss Eqns: 2.663e+00, Loss Aux: 1.670e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7559, It: 0, Loss Data: 8.677e-02, Loss Eqns: 2.551e+00, Loss Aux: 1.168e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 7560, It: 0, Loss Data: 9.049e-02, Loss Eqns: 2.570e+00, Loss Aux: 2.433e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7561, It: 0, Loss Data: 1.136e-01, Loss Eqns: 2.478e+00, Loss Aux: 3.644e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7562, It: 0, Loss Data: 9.869e-02, Loss Eqns: 2.537e+00, Loss Aux: 2.991e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 7563, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.563e+00, Loss Aux: 1.899e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7564, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.550e+00, Loss Aux: 1.633e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7565, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.629e+00, Loss Aux: 1.889e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7566, It: 0, Loss Data: 9.581e-02, Loss Eqns: 2.629e+00, Loss Aux: 1.769e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7567, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.505e+00, Loss Aux: 1.785e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7568, It: 0, Loss Data: 9.307e-02, Loss Eqns: 2.626e+00, Loss Aux: 2.153e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7569, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.549e+00, Loss Aux: 2.488e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7570, It: 0, Loss Data: 9.350e-02, Loss Eqns: 2.605e+00, Loss Aux: 2.085e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7571, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.283e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7572, It: 0, Loss Data: 9.101e-02, Loss Eqns: 2.519e+00, Loss Aux: 2.967e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7573, It: 0, Loss Data: 9.495e-02, Loss Eqns: 2.651e+00, Loss Aux: 2.503e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7574, It: 0, Loss Data: 9.351e-02, Loss Eqns: 2.573e+00, Loss Aux: 1.958e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7575, It: 0, Loss Data: 8.473e-02, Loss Eqns: 2.539e+00, Loss Aux: 1.247e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7576, It: 0, Loss Data: 8.196e-02, Loss Eqns: 2.516e+00, Loss Aux: 1.143e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 7577, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.445e+00, Loss Aux: 2.107e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7578, It: 0, Loss Data: 9.328e-02, Loss Eqns: 2.475e+00, Loss Aux: 2.455e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7579, It: 0, Loss Data: 9.937e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.330e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7580, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.543e+00, Loss Aux: 2.436e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7581, It: 0, Loss Data: 9.191e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.001e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7582, It: 0, Loss Data: 9.445e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.489e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7583, It: 0, Loss Data: 9.750e-02, Loss Eqns: 2.486e+00, Loss Aux: 3.090e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7584, It: 0, Loss Data: 9.160e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.293e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 7585, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.462e+00, Loss Aux: 1.547e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7586, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.676e+00, Loss Aux: 1.464e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7587, It: 0, Loss Data: 9.884e-02, Loss Eqns: 2.570e+00, Loss Aux: 1.745e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7588, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.569e+00, Loss Aux: 1.789e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7589, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.626e+00, Loss Aux: 2.084e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 7590, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.523e+00, Loss Aux: 3.112e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7591, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.523e+00, Loss Aux: 3.824e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7592, It: 0, Loss Data: 9.579e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.402e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7593, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.483e+00, Loss Aux: 2.261e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 7594, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.571e+00, Loss Aux: 1.880e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7595, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.613e+00, Loss Aux: 2.372e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7596, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.506e+00, Loss Aux: 2.406e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7597, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.514e+00, Loss Aux: 1.555e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7598, It: 0, Loss Data: 8.640e-02, Loss Eqns: 2.591e+00, Loss Aux: 1.616e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 7599, It: 0, Loss Data: 8.516e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.167e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7600, It: 0, Loss Data: 9.249e-02, Loss Eqns: 2.576e+00, Loss Aux: 2.743e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7601, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.494e+00, Loss Aux: 2.449e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 7602, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.519e+00, Loss Aux: 2.524e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7603, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.510e+00, Loss Aux: 2.289e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7604, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.566e+00, Loss Aux: 1.967e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7605, It: 0, Loss Data: 8.957e-02, Loss Eqns: 2.539e+00, Loss Aux: 1.579e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7606, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.636e+00, Loss Aux: 1.913e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7607, It: 0, Loss Data: 9.301e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.665e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7608, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.566e+00, Loss Aux: 3.045e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7609, It: 0, Loss Data: 8.634e-02, Loss Eqns: 2.541e+00, Loss Aux: 2.652e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7610, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.533e+00, Loss Aux: 2.386e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7611, It: 0, Loss Data: 9.929e-02, Loss Eqns: 2.519e+00, Loss Aux: 2.493e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7612, It: 0, Loss Data: 8.081e-02, Loss Eqns: 2.530e+00, Loss Aux: 2.768e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7613, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.531e+00, Loss Aux: 2.618e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7614, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.546e+00, Loss Aux: 2.332e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7615, It: 0, Loss Data: 9.792e-02, Loss Eqns: 2.473e+00, Loss Aux: 1.933e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7616, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.469e+00, Loss Aux: 2.146e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 7617, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.475e+00, Loss Aux: 2.233e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7618, It: 0, Loss Data: 8.822e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.152e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7619, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.522e+00, Loss Aux: 2.287e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7620, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.453e+00, Loss Aux: 2.079e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7621, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.542e+00, Loss Aux: 2.136e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7622, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.544e+00, Loss Aux: 2.393e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7623, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.417e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7624, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.256e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7625, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.576e+00, Loss Aux: 2.239e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7626, It: 0, Loss Data: 9.408e-02, Loss Eqns: 2.563e+00, Loss Aux: 1.924e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7627, It: 0, Loss Data: 9.587e-02, Loss Eqns: 2.606e+00, Loss Aux: 2.014e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7628, It: 0, Loss Data: 8.126e-02, Loss Eqns: 2.671e+00, Loss Aux: 1.745e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7629, It: 0, Loss Data: 8.778e-02, Loss Eqns: 2.697e+00, Loss Aux: 2.118e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7630, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.578e+00, Loss Aux: 2.697e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7631, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.696e+00, Loss Aux: 2.133e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7632, It: 0, Loss Data: 9.445e-02, Loss Eqns: 2.755e+00, Loss Aux: 1.680e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7633, It: 0, Loss Data: 7.770e-02, Loss Eqns: 2.620e+00, Loss Aux: 1.939e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7634, It: 0, Loss Data: 9.444e-02, Loss Eqns: 2.569e+00, Loss Aux: 3.157e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7635, It: 0, Loss Data: 8.665e-02, Loss Eqns: 2.622e+00, Loss Aux: 3.880e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7636, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.560e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7637, It: 0, Loss Data: 9.976e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.782e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7638, It: 0, Loss Data: 9.471e-02, Loss Eqns: 2.546e+00, Loss Aux: 2.451e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7639, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.525e+00, Loss Aux: 2.307e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7640, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.575e+00, Loss Aux: 2.313e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7641, It: 0, Loss Data: 9.876e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.184e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7642, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.463e+00, Loss Aux: 1.741e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7643, It: 0, Loss Data: 8.156e-02, Loss Eqns: 2.611e+00, Loss Aux: 1.650e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7644, It: 0, Loss Data: 9.938e-02, Loss Eqns: 2.587e+00, Loss Aux: 1.729e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7645, It: 0, Loss Data: 8.786e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.917e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7646, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.576e+00, Loss Aux: 3.631e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7647, It: 0, Loss Data: 8.981e-02, Loss Eqns: 2.606e+00, Loss Aux: 3.421e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7648, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.132e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7649, It: 0, Loss Data: 7.565e-02, Loss Eqns: 2.531e+00, Loss Aux: 1.804e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7650, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.184e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7651, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.575e+00, Loss Aux: 2.526e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7652, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.511e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7653, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.444e+00, Loss Aux: 2.148e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7654, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.266e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7655, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.487e+00, Loss Aux: 2.920e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7656, It: 0, Loss Data: 8.974e-02, Loss Eqns: 2.597e+00, Loss Aux: 2.742e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7657, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.528e+00, Loss Aux: 2.049e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7658, It: 0, Loss Data: 9.289e-02, Loss Eqns: 2.495e+00, Loss Aux: 2.085e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 7659, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.468e+00, Loss Aux: 2.874e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7660, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.476e+00, Loss Aux: 2.851e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7661, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.540e+00, Loss Aux: 1.779e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7662, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.517e+00, Loss Aux: 2.088e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7663, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.643e+00, Loss Aux: 2.355e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7664, It: 0, Loss Data: 8.941e-02, Loss Eqns: 2.619e+00, Loss Aux: 2.031e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7665, It: 0, Loss Data: 8.793e-02, Loss Eqns: 2.715e+00, Loss Aux: 1.603e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7666, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.619e+00, Loss Aux: 2.055e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7667, It: 0, Loss Data: 9.114e-02, Loss Eqns: 2.564e+00, Loss Aux: 3.121e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 7668, It: 0, Loss Data: 8.150e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.955e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7669, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.479e+00, Loss Aux: 1.992e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7670, It: 0, Loss Data: 9.525e-02, Loss Eqns: 2.481e+00, Loss Aux: 1.733e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 7671, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.451e+00, Loss Aux: 1.943e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 7672, It: 0, Loss Data: 9.513e-02, Loss Eqns: 2.512e+00, Loss Aux: 2.511e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 7673, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.383e+00, Loss Aux: 2.428e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7674, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.588e+00, Loss Aux: 2.471e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7675, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.558e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7676, It: 0, Loss Data: 9.970e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.837e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7677, It: 0, Loss Data: 8.307e-02, Loss Eqns: 2.579e+00, Loss Aux: 2.058e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7678, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.258e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7679, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.641e+00, Loss Aux: 1.708e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7680, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.499e+00, Loss Aux: 2.343e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7681, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.597e+00, Loss Aux: 2.554e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7682, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.659e+00, Loss Aux: 2.131e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7683, It: 0, Loss Data: 8.642e-02, Loss Eqns: 2.557e+00, Loss Aux: 1.805e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7684, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.491e+00, Loss Aux: 1.693e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7685, It: 0, Loss Data: 8.682e-02, Loss Eqns: 2.557e+00, Loss Aux: 1.375e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7686, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.542e+00, Loss Aux: 1.097e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7687, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.497e+00, Loss Aux: 1.945e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 7688, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.553e+00, Loss Aux: 3.097e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 7689, It: 0, Loss Data: 8.909e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.551e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7690, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.580e+00, Loss Aux: 3.297e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7691, It: 0, Loss Data: 7.728e-02, Loss Eqns: 2.629e+00, Loss Aux: 2.854e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7692, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.401e+00, Loss Aux: 2.529e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7693, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.466e+00, Loss Aux: 2.337e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7694, It: 0, Loss Data: 9.662e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.047e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7695, It: 0, Loss Data: 9.093e-02, Loss Eqns: 2.480e+00, Loss Aux: 1.714e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7696, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.467e+00, Loss Aux: 1.769e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7697, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.600e+00, Loss Aux: 1.977e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7698, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.537e+00, Loss Aux: 1.954e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7699, It: 0, Loss Data: 9.617e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.137e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 7700, It: 0, Loss Data: 9.675e-02, Loss Eqns: 2.571e+00, Loss Aux: 2.704e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7701, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.552e+00, Loss Aux: 1.900e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 7702, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.554e+00, Loss Aux: 1.331e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7703, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.581e+00, Loss Aux: 1.843e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7704, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.558e+00, Loss Aux: 2.193e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7705, It: 0, Loss Data: 9.385e-02, Loss Eqns: 2.602e+00, Loss Aux: 1.806e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7706, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.371e+00, Loss Aux: 2.309e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7707, It: 0, Loss Data: 9.588e-02, Loss Eqns: 2.579e+00, Loss Aux: 2.601e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7708, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.509e+00, Loss Aux: 1.928e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7709, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.525e+00, Loss Aux: 1.493e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7710, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.695e+00, Loss Aux: 1.941e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7711, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.601e+00, Loss Aux: 2.298e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 7712, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.620e+00, Loss Aux: 2.319e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7713, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.432e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7714, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.549e+00, Loss Aux: 2.133e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7715, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.439e+00, Loss Aux: 1.364e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7716, It: 0, Loss Data: 9.798e-02, Loss Eqns: 2.515e+00, Loss Aux: 1.467e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7717, It: 0, Loss Data: 9.613e-02, Loss Eqns: 2.581e+00, Loss Aux: 2.375e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7718, It: 0, Loss Data: 9.500e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.843e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7719, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.541e+00, Loss Aux: 2.845e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7720, It: 0, Loss Data: 9.618e-02, Loss Eqns: 2.664e+00, Loss Aux: 2.352e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7721, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.629e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7722, It: 0, Loss Data: 9.983e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.501e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7723, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.871e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7724, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.516e+00, Loss Aux: 2.386e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7725, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.608e+00, Loss Aux: 2.768e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7726, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.567e+00, Loss Aux: 2.732e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7727, It: 0, Loss Data: 8.310e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.518e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7728, It: 0, Loss Data: 9.029e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.284e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 7729, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.552e+00, Loss Aux: 2.552e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7730, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.497e+00, Loss Aux: 2.756e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7731, It: 0, Loss Data: 8.898e-02, Loss Eqns: 2.533e+00, Loss Aux: 2.287e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 7732, It: 0, Loss Data: 9.185e-02, Loss Eqns: 2.407e+00, Loss Aux: 1.444e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7733, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.548e+00, Loss Aux: 1.133e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7734, It: 0, Loss Data: 9.676e-02, Loss Eqns: 2.513e+00, Loss Aux: 1.782e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7735, It: 0, Loss Data: 9.915e-02, Loss Eqns: 2.503e+00, Loss Aux: 2.976e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7736, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.545e+00, Loss Aux: 3.323e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7737, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.554e+00, Loss Aux: 3.038e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7738, It: 0, Loss Data: 9.175e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.677e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7739, It: 0, Loss Data: 9.841e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.582e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7740, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.621e+00, Loss Aux: 2.139e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7741, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.084e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7742, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.559e+00, Loss Aux: 1.178e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7743, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.484e+00, Loss Aux: 2.040e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7744, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.508e+00, Loss Aux: 3.899e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7745, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.630e+00, Loss Aux: 4.120e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7746, It: 0, Loss Data: 9.146e-02, Loss Eqns: 2.552e+00, Loss Aux: 2.831e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7747, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.662e+00, Loss Aux: 1.822e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7748, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.518e+00, Loss Aux: 1.675e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7749, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.450e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7750, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.599e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7751, It: 0, Loss Data: 9.389e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.529e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7752, It: 0, Loss Data: 9.887e-02, Loss Eqns: 2.477e+00, Loss Aux: 3.072e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7753, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.523e+00, Loss Aux: 2.303e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7754, It: 0, Loss Data: 9.403e-02, Loss Eqns: 2.587e+00, Loss Aux: 1.452e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7755, It: 0, Loss Data: 9.693e-02, Loss Eqns: 2.508e+00, Loss Aux: 1.773e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7756, It: 0, Loss Data: 9.988e-02, Loss Eqns: 2.529e+00, Loss Aux: 3.566e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7757, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.357e+00, Loss Aux: 3.867e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7758, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.561e+00, Loss Aux: 2.050e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7759, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.531e+00, Loss Aux: 1.252e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7760, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.564e+00, Loss Aux: 1.972e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7761, It: 0, Loss Data: 1.201e-01, Loss Eqns: 2.611e+00, Loss Aux: 2.829e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7762, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.590e+00, Loss Aux: 2.429e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7763, It: 0, Loss Data: 9.721e-02, Loss Eqns: 2.585e+00, Loss Aux: 1.811e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 7764, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.578e+00, Loss Aux: 2.274e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7765, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.681e+00, Loss Aux: 2.779e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7766, It: 0, Loss Data: 9.301e-02, Loss Eqns: 2.527e+00, Loss Aux: 1.856e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7767, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.713e+00, Loss Aux: 1.376e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7768, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.615e+00, Loss Aux: 1.933e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7769, It: 0, Loss Data: 8.363e-02, Loss Eqns: 2.515e+00, Loss Aux: 3.159e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7770, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.481e+00, Loss Aux: 3.075e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7771, It: 0, Loss Data: 9.944e-02, Loss Eqns: 2.553e+00, Loss Aux: 1.705e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7772, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.561e+00, Loss Aux: 1.143e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7773, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.520e+00, Loss Aux: 2.412e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7774, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.856e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7775, It: 0, Loss Data: 9.202e-02, Loss Eqns: 2.587e+00, Loss Aux: 1.840e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 7776, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.441e+00, Loss Aux: 1.747e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7777, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.830e+00, Loss Aux: 2.651e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7778, It: 0, Loss Data: 1.834e-01, Loss Eqns: 3.441e+00, Loss Aux: 1.517e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7779, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.955e+00, Loss Aux: 1.675e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7780, It: 0, Loss Data: 1.671e-01, Loss Eqns: 3.714e+00, Loss Aux: 2.045e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7781, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.655e+00, Loss Aux: 1.120e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7782, It: 0, Loss Data: 1.634e-01, Loss Eqns: 3.061e+00, Loss Aux: 8.347e-03, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7783, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.647e+00, Loss Aux: 2.262e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7784, It: 0, Loss Data: 1.517e-01, Loss Eqns: 3.210e+00, Loss Aux: 3.559e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7785, It: 0, Loss Data: 1.275e-01, Loss Eqns: 2.480e+00, Loss Aux: 2.837e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7786, It: 0, Loss Data: 1.273e-01, Loss Eqns: 2.820e+00, Loss Aux: 2.915e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7787, It: 0, Loss Data: 1.401e-01, Loss Eqns: 2.482e+00, Loss Aux: 3.468e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7788, It: 0, Loss Data: 1.212e-01, Loss Eqns: 2.757e+00, Loss Aux: 2.550e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7789, It: 0, Loss Data: 1.557e-01, Loss Eqns: 2.672e+00, Loss Aux: 1.491e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7790, It: 0, Loss Data: 1.210e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.488e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7791, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.622e+00, Loss Aux: 4.235e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7792, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.649e+00, Loss Aux: 2.547e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7793, It: 0, Loss Data: 1.426e-01, Loss Eqns: 2.607e+00, Loss Aux: 1.257e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 7794, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.482e+00, Loss Aux: 1.852e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7795, It: 0, Loss Data: 1.262e-01, Loss Eqns: 2.569e+00, Loss Aux: 2.907e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 7796, It: 0, Loss Data: 9.577e-02, Loss Eqns: 2.572e+00, Loss Aux: 1.898e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7797, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.598e+00, Loss Aux: 1.600e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7798, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.446e+00, Loss Aux: 2.608e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7799, It: 0, Loss Data: 1.210e-01, Loss Eqns: 2.407e+00, Loss Aux: 4.072e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7800, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.015e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7801, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.462e+00, Loss Aux: 1.371e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7802, It: 0, Loss Data: 9.375e-02, Loss Eqns: 2.475e+00, Loss Aux: 1.439e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7803, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.479e+00, Loss Aux: 2.722e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7804, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.452e+00, Loss Aux: 3.118e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7805, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.537e+00, Loss Aux: 2.678e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7806, It: 0, Loss Data: 9.513e-02, Loss Eqns: 2.540e+00, Loss Aux: 2.955e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7807, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.613e+00, Loss Aux: 3.072e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7808, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.474e+00, Loss Aux: 2.587e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7809, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.478e+00, Loss Aux: 2.482e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 7810, It: 0, Loss Data: 9.895e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.570e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 7811, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.098e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7812, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.499e+00, Loss Aux: 1.711e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7813, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.532e+00, Loss Aux: 1.635e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7814, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.530e+00, Loss Aux: 1.831e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7815, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.449e+00, Loss Aux: 1.830e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7816, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.509e+00, Loss Aux: 1.569e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7817, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.694e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7818, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.542e+00, Loss Aux: 3.741e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7819, It: 0, Loss Data: 8.855e-02, Loss Eqns: 2.575e+00, Loss Aux: 3.329e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7820, It: 0, Loss Data: 9.264e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.405e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7821, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.584e+00, Loss Aux: 2.079e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7822, It: 0, Loss Data: 9.122e-02, Loss Eqns: 2.571e+00, Loss Aux: 2.120e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7823, It: 0, Loss Data: 8.274e-02, Loss Eqns: 2.544e+00, Loss Aux: 2.344e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7824, It: 0, Loss Data: 9.718e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.733e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 7825, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.448e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7826, It: 0, Loss Data: 9.438e-02, Loss Eqns: 2.505e+00, Loss Aux: 1.847e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7827, It: 0, Loss Data: 9.052e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.171e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7828, It: 0, Loss Data: 9.833e-02, Loss Eqns: 2.393e+00, Loss Aux: 2.553e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7829, It: 0, Loss Data: 9.071e-02, Loss Eqns: 2.386e+00, Loss Aux: 2.022e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7830, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.465e+00, Loss Aux: 1.379e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7831, It: 0, Loss Data: 9.320e-02, Loss Eqns: 2.470e+00, Loss Aux: 1.738e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7832, It: 0, Loss Data: 9.343e-02, Loss Eqns: 2.308e+00, Loss Aux: 2.896e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7833, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.499e+00, Loss Aux: 3.350e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7834, It: 0, Loss Data: 9.526e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.224e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7835, It: 0, Loss Data: 9.394e-02, Loss Eqns: 2.472e+00, Loss Aux: 1.317e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7836, It: 0, Loss Data: 9.980e-02, Loss Eqns: 2.413e+00, Loss Aux: 1.615e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7837, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.408e+00, Loss Aux: 2.258e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 7838, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.443e+00, Loss Aux: 2.139e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7839, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.489e+00, Loss Aux: 1.876e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7840, It: 0, Loss Data: 9.538e-02, Loss Eqns: 2.524e+00, Loss Aux: 2.042e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7841, It: 0, Loss Data: 9.048e-02, Loss Eqns: 2.557e+00, Loss Aux: 2.342e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7842, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.451e+00, Loss Aux: 2.195e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7843, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.473e+00, Loss Aux: 1.878e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 7844, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.481e+00, Loss Aux: 2.139e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7845, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.495e+00, Loss Aux: 2.659e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7846, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.604e+00, Loss Aux: 2.678e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 7847, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.525e+00, Loss Aux: 2.454e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7848, It: 0, Loss Data: 8.437e-02, Loss Eqns: 2.516e+00, Loss Aux: 2.228e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 7849, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.528e+00, Loss Aux: 2.130e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7850, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.511e+00, Loss Aux: 2.180e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 7851, It: 0, Loss Data: 8.022e-02, Loss Eqns: 2.540e+00, Loss Aux: 2.157e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7852, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.528e+00, Loss Aux: 1.934e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7853, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.490e+00, Loss Aux: 1.520e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7854, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.541e+00, Loss Aux: 1.746e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 7855, It: 0, Loss Data: 9.047e-02, Loss Eqns: 2.642e+00, Loss Aux: 2.212e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7856, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.568e+00, Loss Aux: 2.332e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7857, It: 0, Loss Data: 9.280e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.293e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7858, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.963e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7859, It: 0, Loss Data: 8.058e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.688e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7860, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.395e+00, Loss Aux: 1.991e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 7861, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.558e+00, Loss Aux: 2.090e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7862, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.504e+00, Loss Aux: 2.025e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 7863, It: 0, Loss Data: 9.905e-02, Loss Eqns: 2.519e+00, Loss Aux: 1.582e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 7864, It: 0, Loss Data: 9.528e-02, Loss Eqns: 2.520e+00, Loss Aux: 1.431e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 7865, It: 0, Loss Data: 8.218e-02, Loss Eqns: 2.547e+00, Loss Aux: 1.777e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 7866, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.392e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7867, It: 0, Loss Data: 9.223e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.752e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7868, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.455e+00, Loss Aux: 2.785e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7869, It: 0, Loss Data: 9.227e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.166e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7870, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.441e+00, Loss Aux: 1.827e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7871, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.523e+00, Loss Aux: 1.923e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7872, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.474e+00, Loss Aux: 1.849e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7873, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.518e+00, Loss Aux: 1.731e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7874, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.408e+00, Loss Aux: 1.695e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7875, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.476e+00, Loss Aux: 2.277e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7876, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.528e+00, Loss Aux: 2.840e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7877, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.427e+00, Loss Aux: 2.774e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7878, It: 0, Loss Data: 9.371e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.347e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7879, It: 0, Loss Data: 8.988e-02, Loss Eqns: 2.532e+00, Loss Aux: 2.503e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 7880, It: 0, Loss Data: 8.694e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.546e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7881, It: 0, Loss Data: 9.847e-02, Loss Eqns: 2.465e+00, Loss Aux: 1.904e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7882, It: 0, Loss Data: 9.871e-02, Loss Eqns: 2.524e+00, Loss Aux: 1.748e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7883, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.630e+00, Loss Aux: 2.267e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7884, It: 0, Loss Data: 9.079e-02, Loss Eqns: 2.522e+00, Loss Aux: 2.515e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7885, It: 0, Loss Data: 8.668e-02, Loss Eqns: 2.590e+00, Loss Aux: 2.638e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7886, It: 0, Loss Data: 8.758e-02, Loss Eqns: 2.607e+00, Loss Aux: 2.517e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7887, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.458e+00, Loss Aux: 1.967e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7888, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.539e+00, Loss Aux: 1.612e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7889, It: 0, Loss Data: 9.365e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.468e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7890, It: 0, Loss Data: 9.722e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.485e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7891, It: 0, Loss Data: 8.743e-02, Loss Eqns: 2.463e+00, Loss Aux: 1.600e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7892, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.431e+00, Loss Aux: 1.554e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7893, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.562e+00, Loss Aux: 2.227e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7894, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.432e+00, Loss Aux: 2.103e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7895, It: 0, Loss Data: 9.732e-02, Loss Eqns: 2.565e+00, Loss Aux: 1.546e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 7896, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.672e+00, Loss Aux: 2.079e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 7897, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.027e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7898, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.600e+00, Loss Aux: 2.168e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7899, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.578e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7900, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.594e+00, Loss Aux: 2.363e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 7901, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.613e+00, Loss Aux: 1.417e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7902, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.577e+00, Loss Aux: 1.289e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7903, It: 0, Loss Data: 9.499e-02, Loss Eqns: 2.667e+00, Loss Aux: 1.677e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7904, It: 0, Loss Data: 8.157e-02, Loss Eqns: 2.614e+00, Loss Aux: 1.709e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 7905, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.661e+00, Loss Aux: 1.998e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 7906, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.605e+00, Loss Aux: 3.132e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 7907, It: 0, Loss Data: 9.403e-02, Loss Eqns: 2.708e+00, Loss Aux: 3.653e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7908, It: 0, Loss Data: 9.591e-02, Loss Eqns: 2.541e+00, Loss Aux: 2.509e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7909, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.485e+00, Loss Aux: 1.688e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7910, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.708e+00, Loss Aux: 1.901e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7911, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.549e+00, Loss Aux: 1.755e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7912, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.549e+00, Loss Aux: 1.609e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 7913, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.568e+00, Loss Aux: 1.791e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7914, It: 0, Loss Data: 9.463e-02, Loss Eqns: 2.560e+00, Loss Aux: 1.946e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 7915, It: 0, Loss Data: 9.327e-02, Loss Eqns: 2.655e+00, Loss Aux: 2.351e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7916, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.635e+00, Loss Aux: 2.656e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 7917, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.602e+00, Loss Aux: 1.783e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7918, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.550e+00, Loss Aux: 1.521e-02, Time: 0.242, Learning Rate: 1.0e-03\n",
      "Epoch: 7919, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.613e+00, Loss Aux: 3.048e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7920, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.519e+00, Loss Aux: 3.792e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7921, It: 0, Loss Data: 9.272e-02, Loss Eqns: 2.519e+00, Loss Aux: 2.653e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7922, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.608e+00, Loss Aux: 1.676e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7923, It: 0, Loss Data: 9.595e-02, Loss Eqns: 2.576e+00, Loss Aux: 1.542e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7924, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.542e+00, Loss Aux: 1.635e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7925, It: 0, Loss Data: 8.566e-02, Loss Eqns: 2.476e+00, Loss Aux: 1.878e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7926, It: 0, Loss Data: 8.814e-02, Loss Eqns: 2.499e+00, Loss Aux: 2.167e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7927, It: 0, Loss Data: 8.879e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.435e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7928, It: 0, Loss Data: 9.191e-02, Loss Eqns: 2.620e+00, Loss Aux: 2.913e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7929, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.305e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 7930, It: 0, Loss Data: 9.116e-02, Loss Eqns: 2.480e+00, Loss Aux: 1.826e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7931, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.529e+00, Loss Aux: 1.755e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7932, It: 0, Loss Data: 9.588e-02, Loss Eqns: 2.467e+00, Loss Aux: 2.309e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7933, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.600e+00, Loss Aux: 2.365e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 7934, It: 0, Loss Data: 9.648e-02, Loss Eqns: 2.475e+00, Loss Aux: 2.047e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 7935, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.605e+00, Loss Aux: 1.930e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 7936, It: 0, Loss Data: 8.267e-02, Loss Eqns: 2.520e+00, Loss Aux: 2.238e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 7937, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.586e+00, Loss Aux: 2.762e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7938, It: 0, Loss Data: 8.036e-02, Loss Eqns: 2.595e+00, Loss Aux: 2.748e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7939, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.015e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7940, It: 0, Loss Data: 7.795e-02, Loss Eqns: 2.489e+00, Loss Aux: 1.656e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 7941, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.589e+00, Loss Aux: 1.760e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7942, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.493e+00, Loss Aux: 1.740e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 7943, It: 0, Loss Data: 9.697e-02, Loss Eqns: 2.546e+00, Loss Aux: 1.980e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 7944, It: 0, Loss Data: 1.188e-01, Loss Eqns: 2.490e+00, Loss Aux: 2.274e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7945, It: 0, Loss Data: 8.854e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.456e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7946, It: 0, Loss Data: 9.954e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.635e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7947, It: 0, Loss Data: 9.291e-02, Loss Eqns: 2.515e+00, Loss Aux: 2.197e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7948, It: 0, Loss Data: 9.923e-02, Loss Eqns: 2.471e+00, Loss Aux: 1.679e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7949, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.537e+00, Loss Aux: 1.629e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 7950, It: 0, Loss Data: 9.759e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.790e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7951, It: 0, Loss Data: 7.878e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.875e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7952, It: 0, Loss Data: 9.390e-02, Loss Eqns: 2.611e+00, Loss Aux: 2.843e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 7953, It: 0, Loss Data: 8.343e-02, Loss Eqns: 2.518e+00, Loss Aux: 2.601e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7954, It: 0, Loss Data: 8.528e-02, Loss Eqns: 2.531e+00, Loss Aux: 2.102e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 7955, It: 0, Loss Data: 9.123e-02, Loss Eqns: 2.549e+00, Loss Aux: 1.527e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7956, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.545e+00, Loss Aux: 1.364e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 7957, It: 0, Loss Data: 9.372e-02, Loss Eqns: 2.463e+00, Loss Aux: 1.618e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 7958, It: 0, Loss Data: 7.971e-02, Loss Eqns: 2.583e+00, Loss Aux: 1.876e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 7959, It: 0, Loss Data: 9.445e-02, Loss Eqns: 2.588e+00, Loss Aux: 1.918e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 7960, It: 0, Loss Data: 9.115e-02, Loss Eqns: 2.531e+00, Loss Aux: 1.659e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 7961, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.496e+00, Loss Aux: 1.610e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 7962, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.018e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 7963, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.495e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 7964, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.441e+00, Loss Aux: 2.434e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 7965, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.419e+00, Loss Aux: 1.841e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7966, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.442e+00, Loss Aux: 1.589e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7967, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.462e+00, Loss Aux: 1.771e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7968, It: 0, Loss Data: 8.355e-02, Loss Eqns: 2.494e+00, Loss Aux: 1.943e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7969, It: 0, Loss Data: 9.174e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.044e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7970, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.871e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7971, It: 0, Loss Data: 9.716e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.109e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 7972, It: 0, Loss Data: 9.897e-02, Loss Eqns: 2.498e+00, Loss Aux: 2.328e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7973, It: 0, Loss Data: 9.670e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.123e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 7974, It: 0, Loss Data: 9.770e-02, Loss Eqns: 2.474e+00, Loss Aux: 1.877e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7975, It: 0, Loss Data: 7.954e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.090e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 7976, It: 0, Loss Data: 9.691e-02, Loss Eqns: 2.482e+00, Loss Aux: 2.262e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 7977, It: 0, Loss Data: 8.874e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.431e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 7978, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.556e+00, Loss Aux: 2.159e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7979, It: 0, Loss Data: 9.093e-02, Loss Eqns: 2.337e+00, Loss Aux: 1.863e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7980, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.465e+00, Loss Aux: 2.103e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 7981, It: 0, Loss Data: 9.487e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.049e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7982, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.538e+00, Loss Aux: 1.721e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 7983, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.567e+00, Loss Aux: 1.677e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 7984, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.528e+00, Loss Aux: 1.424e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 7985, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.416e+00, Loss Aux: 1.499e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 7986, It: 0, Loss Data: 9.812e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.338e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7987, It: 0, Loss Data: 9.395e-02, Loss Eqns: 2.592e+00, Loss Aux: 2.792e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 7988, It: 0, Loss Data: 8.310e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.340e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 7989, It: 0, Loss Data: 8.993e-02, Loss Eqns: 2.655e+00, Loss Aux: 1.701e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 7990, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.568e+00, Loss Aux: 1.841e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 7991, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.556e+00, Loss Aux: 2.080e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 7992, It: 0, Loss Data: 8.592e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.571e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 7993, It: 0, Loss Data: 8.913e-02, Loss Eqns: 2.522e+00, Loss Aux: 2.136e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 7994, It: 0, Loss Data: 1.145e-01, Loss Eqns: 2.555e+00, Loss Aux: 1.297e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 7995, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.419e+00, Loss Aux: 1.433e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 7996, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.524e+00, Loss Aux: 2.063e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 7997, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.468e+00, Loss Aux: 1.761e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 7998, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.493e+00, Loss Aux: 1.734e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 7999, It: 0, Loss Data: 1.379e-01, Loss Eqns: 2.616e+00, Loss Aux: 1.330e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8000, It: 0, Loss Data: 1.860e-01, Loss Eqns: 4.295e+00, Loss Aux: 3.770e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8001, It: 0, Loss Data: 1.703e-01, Loss Eqns: 4.146e+00, Loss Aux: 2.026e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8002, It: 0, Loss Data: 2.211e-01, Loss Eqns: 4.692e+00, Loss Aux: 1.964e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 8003, It: 0, Loss Data: 1.293e-01, Loss Eqns: 3.976e+00, Loss Aux: 3.562e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8004, It: 0, Loss Data: 2.165e-01, Loss Eqns: 4.295e+00, Loss Aux: 3.434e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8005, It: 0, Loss Data: 1.715e-01, Loss Eqns: 3.428e+00, Loss Aux: 1.207e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8006, It: 0, Loss Data: 1.952e-01, Loss Eqns: 3.727e+00, Loss Aux: 1.090e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8007, It: 0, Loss Data: 1.514e-01, Loss Eqns: 3.359e+00, Loss Aux: 3.089e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8008, It: 0, Loss Data: 1.787e-01, Loss Eqns: 3.634e+00, Loss Aux: 4.234e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 8009, It: 0, Loss Data: 1.526e-01, Loss Eqns: 3.319e+00, Loss Aux: 2.989e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8010, It: 0, Loss Data: 1.771e-01, Loss Eqns: 3.108e+00, Loss Aux: 1.485e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8011, It: 0, Loss Data: 1.801e-01, Loss Eqns: 3.000e+00, Loss Aux: 3.046e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8012, It: 0, Loss Data: 1.933e-01, Loss Eqns: 2.917e+00, Loss Aux: 4.446e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8013, It: 0, Loss Data: 2.021e-01, Loss Eqns: 3.744e+00, Loss Aux: 4.435e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8014, It: 0, Loss Data: 3.333e-01, Loss Eqns: 3.141e+00, Loss Aux: 3.509e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8015, It: 0, Loss Data: 2.032e-01, Loss Eqns: 3.144e+00, Loss Aux: 4.042e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8016, It: 0, Loss Data: 2.551e-01, Loss Eqns: 2.808e+00, Loss Aux: 7.008e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8017, It: 0, Loss Data: 1.995e-01, Loss Eqns: 2.836e+00, Loss Aux: 3.407e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8018, It: 0, Loss Data: 2.115e-01, Loss Eqns: 2.607e+00, Loss Aux: 1.991e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8019, It: 0, Loss Data: 2.349e-01, Loss Eqns: 2.725e+00, Loss Aux: 1.114e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8020, It: 0, Loss Data: 1.598e-01, Loss Eqns: 2.604e+00, Loss Aux: 2.543e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8021, It: 0, Loss Data: 2.380e-01, Loss Eqns: 2.698e+00, Loss Aux: 7.098e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8022, It: 0, Loss Data: 1.339e-01, Loss Eqns: 2.473e+00, Loss Aux: 5.311e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8023, It: 0, Loss Data: 2.085e-01, Loss Eqns: 2.510e+00, Loss Aux: 4.121e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8024, It: 0, Loss Data: 1.910e-01, Loss Eqns: 2.537e+00, Loss Aux: 3.341e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8025, It: 0, Loss Data: 1.249e-01, Loss Eqns: 2.578e+00, Loss Aux: 4.719e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8026, It: 0, Loss Data: 1.760e-01, Loss Eqns: 2.684e+00, Loss Aux: 6.607e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8027, It: 0, Loss Data: 1.455e-01, Loss Eqns: 2.494e+00, Loss Aux: 5.230e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8028, It: 0, Loss Data: 1.488e-01, Loss Eqns: 2.510e+00, Loss Aux: 2.835e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8029, It: 0, Loss Data: 1.534e-01, Loss Eqns: 2.697e+00, Loss Aux: 1.613e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8030, It: 0, Loss Data: 1.289e-01, Loss Eqns: 2.613e+00, Loss Aux: 2.301e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8031, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.698e+00, Loss Aux: 3.815e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8032, It: 0, Loss Data: 1.449e-01, Loss Eqns: 2.592e+00, Loss Aux: 4.567e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8033, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.568e+00, Loss Aux: 3.341e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8034, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.745e+00, Loss Aux: 1.953e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8035, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.494e+00, Loss Aux: 2.290e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8036, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.480e+00, Loss Aux: 4.100e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8037, It: 0, Loss Data: 1.242e-01, Loss Eqns: 2.528e+00, Loss Aux: 6.158e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8038, It: 0, Loss Data: 1.207e-01, Loss Eqns: 2.448e+00, Loss Aux: 5.456e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 8039, It: 0, Loss Data: 1.193e-01, Loss Eqns: 2.484e+00, Loss Aux: 2.624e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8040, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.549e+00, Loss Aux: 1.192e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8041, It: 0, Loss Data: 1.334e-01, Loss Eqns: 2.541e+00, Loss Aux: 1.599e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8042, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.408e+00, Loss Aux: 3.062e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8043, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.463e+00, Loss Aux: 4.445e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8044, It: 0, Loss Data: 1.105e-01, Loss Eqns: 2.560e+00, Loss Aux: 3.765e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8045, It: 0, Loss Data: 1.217e-01, Loss Eqns: 2.621e+00, Loss Aux: 2.472e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8046, It: 0, Loss Data: 9.666e-02, Loss Eqns: 2.655e+00, Loss Aux: 1.858e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8047, It: 0, Loss Data: 9.812e-02, Loss Eqns: 2.597e+00, Loss Aux: 2.205e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8048, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.605e+00, Loss Aux: 2.731e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8049, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.617e+00, Loss Aux: 3.194e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8050, It: 0, Loss Data: 8.450e-02, Loss Eqns: 2.513e+00, Loss Aux: 3.849e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8051, It: 0, Loss Data: 1.207e-01, Loss Eqns: 2.595e+00, Loss Aux: 3.821e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 8052, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.473e+00, Loss Aux: 2.861e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8053, It: 0, Loss Data: 1.208e-01, Loss Eqns: 2.582e+00, Loss Aux: 1.990e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8054, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.542e+00, Loss Aux: 1.820e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8055, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.657e+00, Loss Aux: 2.553e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8056, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.566e+00, Loss Aux: 3.777e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8057, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.669e+00, Loss Aux: 4.431e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8058, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.634e+00, Loss Aux: 4.238e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8059, It: 0, Loss Data: 8.748e-02, Loss Eqns: 2.587e+00, Loss Aux: 3.416e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8060, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.621e+00, Loss Aux: 2.684e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8061, It: 0, Loss Data: 9.838e-02, Loss Eqns: 2.619e+00, Loss Aux: 2.537e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8062, It: 0, Loss Data: 8.259e-02, Loss Eqns: 2.775e+00, Loss Aux: 3.105e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8063, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.555e+00, Loss Aux: 4.167e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8064, It: 0, Loss Data: 9.528e-02, Loss Eqns: 2.553e+00, Loss Aux: 3.796e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8065, It: 0, Loss Data: 9.096e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.588e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 8066, It: 0, Loss Data: 9.704e-02, Loss Eqns: 2.578e+00, Loss Aux: 2.030e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8067, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.497e+00, Loss Aux: 1.830e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8068, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.574e+00, Loss Aux: 2.158e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8069, It: 0, Loss Data: 8.689e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.972e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8070, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.505e+00, Loss Aux: 3.589e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8071, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.893e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8072, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.434e+00, Loss Aux: 3.445e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8073, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.564e+00, Loss Aux: 2.923e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8074, It: 0, Loss Data: 9.819e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.765e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8075, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.569e+00, Loss Aux: 2.970e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8076, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.464e+00, Loss Aux: 2.908e-02, Time: 0.241, Learning Rate: 1.0e-03\n",
      "Epoch: 8077, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.589e+00, Loss Aux: 3.142e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8078, It: 0, Loss Data: 8.532e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.939e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 8079, It: 0, Loss Data: 8.823e-02, Loss Eqns: 2.552e+00, Loss Aux: 2.637e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8080, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.609e+00, Loss Aux: 2.607e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8081, It: 0, Loss Data: 9.162e-02, Loss Eqns: 2.508e+00, Loss Aux: 3.192e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8082, It: 0, Loss Data: 9.876e-02, Loss Eqns: 2.518e+00, Loss Aux: 3.143e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8083, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.571e+00, Loss Aux: 3.354e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8084, It: 0, Loss Data: 9.826e-02, Loss Eqns: 2.468e+00, Loss Aux: 3.526e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8085, It: 0, Loss Data: 9.692e-02, Loss Eqns: 2.579e+00, Loss Aux: 3.308e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8086, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.508e+00, Loss Aux: 3.101e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8087, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.527e+00, Loss Aux: 2.658e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8088, It: 0, Loss Data: 8.698e-02, Loss Eqns: 2.547e+00, Loss Aux: 2.595e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8089, It: 0, Loss Data: 8.825e-02, Loss Eqns: 2.553e+00, Loss Aux: 3.324e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8090, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.692e+00, Loss Aux: 3.826e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 8091, It: 0, Loss Data: 9.475e-02, Loss Eqns: 2.596e+00, Loss Aux: 3.742e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8092, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.310e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8093, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.538e+00, Loss Aux: 3.127e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8094, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.512e+00, Loss Aux: 2.729e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8095, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.561e+00, Loss Aux: 2.653e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8096, It: 0, Loss Data: 9.647e-02, Loss Eqns: 2.514e+00, Loss Aux: 2.848e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8097, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.615e+00, Loss Aux: 2.334e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8098, It: 0, Loss Data: 9.961e-02, Loss Eqns: 2.673e+00, Loss Aux: 2.375e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8099, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.664e+00, Loss Aux: 3.691e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8100, It: 0, Loss Data: 9.863e-02, Loss Eqns: 2.698e+00, Loss Aux: 4.283e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8101, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.580e+00, Loss Aux: 3.804e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8102, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.606e+00, Loss Aux: 3.244e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8103, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.607e+00, Loss Aux: 3.094e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8104, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.559e+00, Loss Aux: 2.590e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8105, It: 0, Loss Data: 9.690e-02, Loss Eqns: 2.610e+00, Loss Aux: 2.439e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8106, It: 0, Loss Data: 9.859e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.876e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8107, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.574e+00, Loss Aux: 3.183e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8108, It: 0, Loss Data: 8.124e-02, Loss Eqns: 2.519e+00, Loss Aux: 3.149e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8109, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.525e+00, Loss Aux: 3.390e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8110, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.477e+00, Loss Aux: 3.925e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8111, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.557e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8112, It: 0, Loss Data: 9.616e-02, Loss Eqns: 2.659e+00, Loss Aux: 2.920e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8113, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.492e+00, Loss Aux: 2.821e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8114, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.556e+00, Loss Aux: 3.701e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8115, It: 0, Loss Data: 9.331e-02, Loss Eqns: 2.590e+00, Loss Aux: 3.553e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8116, It: 0, Loss Data: 8.599e-02, Loss Eqns: 2.604e+00, Loss Aux: 2.600e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8117, It: 0, Loss Data: 8.035e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.185e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8118, It: 0, Loss Data: 9.719e-02, Loss Eqns: 2.587e+00, Loss Aux: 2.836e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8119, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.522e+00, Loss Aux: 3.436e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8120, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.505e+00, Loss Aux: 3.146e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8121, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.451e+00, Loss Aux: 2.656e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8122, It: 0, Loss Data: 9.767e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.077e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8123, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.980e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 8124, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.586e+00, Loss Aux: 2.376e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 8125, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.611e+00, Loss Aux: 2.223e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8126, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.564e+00, Loss Aux: 2.562e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8127, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.558e+00, Loss Aux: 3.137e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8128, It: 0, Loss Data: 7.999e-02, Loss Eqns: 2.588e+00, Loss Aux: 3.265e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8129, It: 0, Loss Data: 9.495e-02, Loss Eqns: 2.559e+00, Loss Aux: 3.077e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8130, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.514e+00, Loss Aux: 3.333e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8131, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.485e+00, Loss Aux: 3.801e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8132, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.684e+00, Loss Aux: 3.637e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8133, It: 0, Loss Data: 8.941e-02, Loss Eqns: 2.596e+00, Loss Aux: 3.078e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8134, It: 0, Loss Data: 9.765e-02, Loss Eqns: 2.620e+00, Loss Aux: 2.891e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8135, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.623e+00, Loss Aux: 2.803e-02, Time: 0.243, Learning Rate: 1.0e-03\n",
      "Epoch: 8136, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.561e+00, Loss Aux: 2.671e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8137, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.534e+00, Loss Aux: 2.795e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8138, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.641e+00, Loss Aux: 2.281e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8139, It: 0, Loss Data: 8.019e-02, Loss Eqns: 2.635e+00, Loss Aux: 2.723e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8140, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.580e+00, Loss Aux: 3.676e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8141, It: 0, Loss Data: 9.375e-02, Loss Eqns: 2.523e+00, Loss Aux: 4.590e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8142, It: 0, Loss Data: 9.401e-02, Loss Eqns: 2.472e+00, Loss Aux: 4.286e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8143, It: 0, Loss Data: 9.702e-02, Loss Eqns: 2.449e+00, Loss Aux: 3.417e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8144, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.530e+00, Loss Aux: 2.524e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8145, It: 0, Loss Data: 9.137e-02, Loss Eqns: 2.549e+00, Loss Aux: 1.961e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8146, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.566e+00, Loss Aux: 1.699e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8147, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.508e+00, Loss Aux: 1.749e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8148, It: 0, Loss Data: 9.748e-02, Loss Eqns: 2.566e+00, Loss Aux: 2.346e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8149, It: 0, Loss Data: 9.018e-02, Loss Eqns: 2.675e+00, Loss Aux: 2.982e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 8150, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.508e+00, Loss Aux: 3.719e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8151, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.544e+00, Loss Aux: 4.089e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8152, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.634e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8153, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.664e+00, Loss Aux: 2.831e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8154, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.539e+00, Loss Aux: 2.556e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8155, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.551e+00, Loss Aux: 3.081e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8156, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.611e+00, Loss Aux: 3.147e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8157, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.545e+00, Loss Aux: 2.750e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8158, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.564e+00, Loss Aux: 2.456e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8159, It: 0, Loss Data: 9.722e-02, Loss Eqns: 2.630e+00, Loss Aux: 2.299e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8160, It: 0, Loss Data: 9.842e-02, Loss Eqns: 2.607e+00, Loss Aux: 2.714e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8161, It: 0, Loss Data: 7.852e-02, Loss Eqns: 2.618e+00, Loss Aux: 2.942e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8162, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.482e+00, Loss Aux: 3.052e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 8163, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.506e+00, Loss Aux: 3.394e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8164, It: 0, Loss Data: 9.962e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.330e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8165, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.450e+00, Loss Aux: 2.860e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8166, It: 0, Loss Data: 9.849e-02, Loss Eqns: 2.675e+00, Loss Aux: 2.688e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8167, It: 0, Loss Data: 8.372e-02, Loss Eqns: 2.611e+00, Loss Aux: 2.730e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8168, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.874e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8169, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.908e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8170, It: 0, Loss Data: 9.526e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.900e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8171, It: 0, Loss Data: 9.747e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.491e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8172, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.500e+00, Loss Aux: 1.920e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8173, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.514e+00, Loss Aux: 1.669e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8174, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.474e+00, Loss Aux: 2.176e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8175, It: 0, Loss Data: 9.294e-02, Loss Eqns: 2.521e+00, Loss Aux: 3.139e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8176, It: 0, Loss Data: 9.650e-02, Loss Eqns: 2.573e+00, Loss Aux: 3.292e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8177, It: 0, Loss Data: 9.906e-02, Loss Eqns: 2.541e+00, Loss Aux: 3.768e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8178, It: 0, Loss Data: 9.097e-02, Loss Eqns: 2.558e+00, Loss Aux: 3.962e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8179, It: 0, Loss Data: 9.365e-02, Loss Eqns: 2.532e+00, Loss Aux: 2.868e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8180, It: 0, Loss Data: 9.686e-02, Loss Eqns: 2.548e+00, Loss Aux: 2.056e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8181, It: 0, Loss Data: 7.501e-02, Loss Eqns: 2.612e+00, Loss Aux: 3.211e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8182, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.537e+00, Loss Aux: 4.561e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8183, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.535e+00, Loss Aux: 3.603e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8184, It: 0, Loss Data: 9.510e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.574e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8185, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.499e+00, Loss Aux: 2.248e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8186, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.535e+00, Loss Aux: 3.007e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8187, It: 0, Loss Data: 9.936e-02, Loss Eqns: 2.506e+00, Loss Aux: 3.935e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8188, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.402e+00, Loss Aux: 3.356e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8189, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.445e+00, Loss Aux: 3.076e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8190, It: 0, Loss Data: 8.744e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.782e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8191, It: 0, Loss Data: 8.595e-02, Loss Eqns: 2.595e+00, Loss Aux: 2.137e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8192, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.463e+00, Loss Aux: 1.792e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8193, It: 0, Loss Data: 9.527e-02, Loss Eqns: 2.532e+00, Loss Aux: 2.695e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8194, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.570e+00, Loss Aux: 3.194e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8195, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.173e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8196, It: 0, Loss Data: 9.967e-02, Loss Eqns: 2.551e+00, Loss Aux: 3.302e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8197, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.558e+00, Loss Aux: 4.415e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8198, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.539e+00, Loss Aux: 4.078e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8199, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.668e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8200, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.587e+00, Loss Aux: 2.327e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 8201, It: 0, Loss Data: 1.129e-01, Loss Eqns: 2.513e+00, Loss Aux: 4.142e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8202, It: 0, Loss Data: 9.414e-02, Loss Eqns: 2.534e+00, Loss Aux: 4.739e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8203, It: 0, Loss Data: 9.420e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.456e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8204, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.573e+00, Loss Aux: 2.009e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8205, It: 0, Loss Data: 9.590e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.172e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8206, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.940e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8207, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.501e+00, Loss Aux: 4.874e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8208, It: 0, Loss Data: 9.904e-02, Loss Eqns: 2.471e+00, Loss Aux: 4.018e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8209, It: 0, Loss Data: 9.895e-02, Loss Eqns: 2.559e+00, Loss Aux: 2.489e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8210, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.622e+00, Loss Aux: 1.813e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8211, It: 0, Loss Data: 9.568e-02, Loss Eqns: 2.582e+00, Loss Aux: 2.113e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8212, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.592e+00, Loss Aux: 2.601e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8213, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.445e+00, Loss Aux: 2.999e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 8214, It: 0, Loss Data: 9.996e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.284e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8215, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.481e+00, Loss Aux: 3.459e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 8216, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.439e+00, Loss Aux: 3.867e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8217, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.857e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8218, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.528e+00, Loss Aux: 3.241e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8219, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.551e+00, Loss Aux: 2.635e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8220, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.913e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8221, It: 0, Loss Data: 9.065e-02, Loss Eqns: 2.524e+00, Loss Aux: 3.685e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 8222, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.607e+00, Loss Aux: 4.043e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8223, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.494e+00, Loss Aux: 3.104e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 8224, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.552e+00, Loss Aux: 2.405e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8225, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.615e+00, Loss Aux: 2.441e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8226, It: 0, Loss Data: 8.723e-02, Loss Eqns: 2.645e+00, Loss Aux: 2.698e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8227, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.500e+00, Loss Aux: 2.788e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8228, It: 0, Loss Data: 9.338e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.128e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8229, It: 0, Loss Data: 8.995e-02, Loss Eqns: 2.544e+00, Loss Aux: 3.532e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8230, It: 0, Loss Data: 7.923e-02, Loss Eqns: 2.522e+00, Loss Aux: 3.381e-02, Time: 0.237, Learning Rate: 1.0e-03\n",
      "Epoch: 8231, It: 0, Loss Data: 9.407e-02, Loss Eqns: 2.478e+00, Loss Aux: 3.534e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8232, It: 0, Loss Data: 7.494e-02, Loss Eqns: 2.555e+00, Loss Aux: 3.929e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8233, It: 0, Loss Data: 9.001e-02, Loss Eqns: 2.601e+00, Loss Aux: 3.679e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8234, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.537e+00, Loss Aux: 3.480e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8235, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.532e+00, Loss Aux: 3.030e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8236, It: 0, Loss Data: 8.856e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.787e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8237, It: 0, Loss Data: 8.373e-02, Loss Eqns: 2.570e+00, Loss Aux: 2.433e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8238, It: 0, Loss Data: 9.006e-02, Loss Eqns: 2.531e+00, Loss Aux: 2.053e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8239, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.467e+00, Loss Aux: 1.906e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8240, It: 0, Loss Data: 8.930e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.826e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8241, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.394e+00, Loss Aux: 4.315e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8242, It: 0, Loss Data: 9.509e-02, Loss Eqns: 2.514e+00, Loss Aux: 4.259e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8243, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.461e+00, Loss Aux: 3.527e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8244, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.453e+00, Loss Aux: 4.115e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8245, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.414e+00, Loss Aux: 3.904e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8246, It: 0, Loss Data: 8.413e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.233e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8247, It: 0, Loss Data: 9.576e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.842e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8248, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.320e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8249, It: 0, Loss Data: 9.736e-02, Loss Eqns: 2.520e+00, Loss Aux: 2.038e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8250, It: 0, Loss Data: 9.830e-02, Loss Eqns: 2.518e+00, Loss Aux: 2.104e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8251, It: 0, Loss Data: 9.801e-02, Loss Eqns: 2.507e+00, Loss Aux: 2.517e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8252, It: 0, Loss Data: 9.739e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.867e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8253, It: 0, Loss Data: 9.837e-02, Loss Eqns: 2.500e+00, Loss Aux: 3.480e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8254, It: 0, Loss Data: 8.008e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.123e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8255, It: 0, Loss Data: 9.977e-02, Loss Eqns: 2.517e+00, Loss Aux: 4.088e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8256, It: 0, Loss Data: 9.576e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.307e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8257, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.495e+00, Loss Aux: 2.787e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 8258, It: 0, Loss Data: 8.534e-02, Loss Eqns: 2.522e+00, Loss Aux: 3.016e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8259, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.603e+00, Loss Aux: 3.107e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8260, It: 0, Loss Data: 9.759e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.741e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8261, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.496e+00, Loss Aux: 2.603e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8262, It: 0, Loss Data: 9.248e-02, Loss Eqns: 2.583e+00, Loss Aux: 3.131e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 8263, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.716e+00, Loss Aux: 2.957e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 8264, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.387e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8265, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.633e+00, Loss Aux: 2.841e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8266, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.622e+00, Loss Aux: 3.707e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8267, It: 0, Loss Data: 9.067e-02, Loss Eqns: 2.632e+00, Loss Aux: 3.945e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8268, It: 0, Loss Data: 8.428e-02, Loss Eqns: 2.645e+00, Loss Aux: 3.409e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8269, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.580e+00, Loss Aux: 2.608e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8270, It: 0, Loss Data: 8.382e-02, Loss Eqns: 2.670e+00, Loss Aux: 2.699e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8271, It: 0, Loss Data: 7.701e-02, Loss Eqns: 2.527e+00, Loss Aux: 3.095e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8272, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.512e+00, Loss Aux: 3.186e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8273, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.527e+00, Loss Aux: 3.068e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8274, It: 0, Loss Data: 9.145e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.574e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8275, It: 0, Loss Data: 9.273e-02, Loss Eqns: 2.554e+00, Loss Aux: 2.506e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8276, It: 0, Loss Data: 8.659e-02, Loss Eqns: 2.549e+00, Loss Aux: 2.508e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8277, It: 0, Loss Data: 9.351e-02, Loss Eqns: 2.507e+00, Loss Aux: 2.846e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8278, It: 0, Loss Data: 9.151e-02, Loss Eqns: 2.517e+00, Loss Aux: 3.094e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8279, It: 0, Loss Data: 9.333e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.774e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8280, It: 0, Loss Data: 9.038e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.205e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8281, It: 0, Loss Data: 9.928e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.285e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8282, It: 0, Loss Data: 9.853e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.126e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8283, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.460e+00, Loss Aux: 3.035e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8284, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.328e+00, Loss Aux: 2.261e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8285, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.513e+00, Loss Aux: 2.117e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8286, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.373e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8287, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.502e+00, Loss Aux: 2.724e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8288, It: 0, Loss Data: 9.624e-02, Loss Eqns: 2.469e+00, Loss Aux: 2.868e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8289, It: 0, Loss Data: 9.384e-02, Loss Eqns: 2.505e+00, Loss Aux: 3.162e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8290, It: 0, Loss Data: 8.371e-02, Loss Eqns: 2.570e+00, Loss Aux: 3.100e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8291, It: 0, Loss Data: 8.855e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.879e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8292, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.588e+00, Loss Aux: 3.051e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8293, It: 0, Loss Data: 9.068e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.010e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8294, It: 0, Loss Data: 9.484e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.558e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8295, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.567e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8296, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.528e+00, Loss Aux: 2.791e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8297, It: 0, Loss Data: 9.220e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.727e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 8298, It: 0, Loss Data: 8.086e-02, Loss Eqns: 2.494e+00, Loss Aux: 2.161e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8299, It: 0, Loss Data: 9.205e-02, Loss Eqns: 2.487e+00, Loss Aux: 2.044e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8300, It: 0, Loss Data: 9.379e-02, Loss Eqns: 2.540e+00, Loss Aux: 2.457e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8301, It: 0, Loss Data: 9.990e-02, Loss Eqns: 2.579e+00, Loss Aux: 3.025e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8302, It: 0, Loss Data: 9.775e-02, Loss Eqns: 2.481e+00, Loss Aux: 3.386e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8303, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.548e+00, Loss Aux: 3.397e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8304, It: 0, Loss Data: 9.402e-02, Loss Eqns: 2.636e+00, Loss Aux: 3.325e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8305, It: 0, Loss Data: 9.620e-02, Loss Eqns: 2.570e+00, Loss Aux: 2.901e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8306, It: 0, Loss Data: 8.052e-02, Loss Eqns: 2.601e+00, Loss Aux: 2.186e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8307, It: 0, Loss Data: 8.825e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.233e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8308, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.562e+00, Loss Aux: 3.042e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8309, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.545e+00, Loss Aux: 3.539e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8310, It: 0, Loss Data: 9.178e-02, Loss Eqns: 2.674e+00, Loss Aux: 3.259e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8311, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.531e+00, Loss Aux: 2.819e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8312, It: 0, Loss Data: 8.816e-02, Loss Eqns: 2.528e+00, Loss Aux: 2.812e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8313, It: 0, Loss Data: 9.056e-02, Loss Eqns: 2.556e+00, Loss Aux: 2.626e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8314, It: 0, Loss Data: 9.214e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.715e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8315, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.791e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8316, It: 0, Loss Data: 9.470e-02, Loss Eqns: 2.471e+00, Loss Aux: 2.880e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8317, It: 0, Loss Data: 8.488e-02, Loss Eqns: 2.353e+00, Loss Aux: 2.759e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8318, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.853e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8319, It: 0, Loss Data: 8.957e-02, Loss Eqns: 2.425e+00, Loss Aux: 3.237e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8320, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.524e+00, Loss Aux: 2.706e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8321, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.137e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8322, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.499e+00, Loss Aux: 2.201e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8323, It: 0, Loss Data: 9.757e-02, Loss Eqns: 2.518e+00, Loss Aux: 2.271e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8324, It: 0, Loss Data: 9.975e-02, Loss Eqns: 2.442e+00, Loss Aux: 2.853e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8325, It: 0, Loss Data: 8.589e-02, Loss Eqns: 2.517e+00, Loss Aux: 3.748e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8326, It: 0, Loss Data: 8.296e-02, Loss Eqns: 2.493e+00, Loss Aux: 3.270e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8327, It: 0, Loss Data: 8.370e-02, Loss Eqns: 2.575e+00, Loss Aux: 2.493e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8328, It: 0, Loss Data: 1.174e-01, Loss Eqns: 2.606e+00, Loss Aux: 3.205e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8329, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.544e+00, Loss Aux: 2.810e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8330, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.594e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8331, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.537e+00, Loss Aux: 2.864e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8332, It: 0, Loss Data: 9.735e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.605e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8333, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.455e+00, Loss Aux: 1.979e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8334, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.545e+00, Loss Aux: 1.685e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8335, It: 0, Loss Data: 9.420e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.919e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8336, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.581e+00, Loss Aux: 3.848e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8337, It: 0, Loss Data: 9.716e-02, Loss Eqns: 2.591e+00, Loss Aux: 3.956e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8338, It: 0, Loss Data: 9.129e-02, Loss Eqns: 2.576e+00, Loss Aux: 3.074e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8339, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.587e+00, Loss Aux: 2.701e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8340, It: 0, Loss Data: 9.002e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.898e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 8341, It: 0, Loss Data: 7.633e-02, Loss Eqns: 2.507e+00, Loss Aux: 3.155e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8342, It: 0, Loss Data: 9.273e-02, Loss Eqns: 2.541e+00, Loss Aux: 2.761e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8343, It: 0, Loss Data: 8.548e-02, Loss Eqns: 2.531e+00, Loss Aux: 2.198e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8344, It: 0, Loss Data: 8.811e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.456e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8345, It: 0, Loss Data: 9.906e-02, Loss Eqns: 2.512e+00, Loss Aux: 3.592e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8346, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.559e+00, Loss Aux: 3.935e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8347, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.864e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8348, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.443e+00, Loss Aux: 1.859e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8349, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.507e+00, Loss Aux: 1.774e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8350, It: 0, Loss Data: 9.137e-02, Loss Eqns: 2.498e+00, Loss Aux: 2.579e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8351, It: 0, Loss Data: 1.140e-01, Loss Eqns: 2.381e+00, Loss Aux: 3.179e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8352, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.494e+00, Loss Aux: 2.820e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8353, It: 0, Loss Data: 9.949e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.741e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8354, It: 0, Loss Data: 9.228e-02, Loss Eqns: 2.557e+00, Loss Aux: 2.878e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8355, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.505e+00, Loss Aux: 3.131e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8356, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.537e+00, Loss Aux: 2.750e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8357, It: 0, Loss Data: 1.168e-01, Loss Eqns: 2.572e+00, Loss Aux: 2.815e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 8358, It: 0, Loss Data: 9.690e-02, Loss Eqns: 2.514e+00, Loss Aux: 2.433e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8359, It: 0, Loss Data: 9.502e-02, Loss Eqns: 2.544e+00, Loss Aux: 1.969e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8360, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.569e+00, Loss Aux: 2.512e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8361, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.599e+00, Loss Aux: 3.439e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8362, It: 0, Loss Data: 8.795e-02, Loss Eqns: 2.557e+00, Loss Aux: 3.381e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 8363, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.545e+00, Loss Aux: 2.694e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8364, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.583e+00, Loss Aux: 3.581e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8365, It: 0, Loss Data: 9.981e-02, Loss Eqns: 2.556e+00, Loss Aux: 3.753e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8366, It: 0, Loss Data: 9.962e-02, Loss Eqns: 2.595e+00, Loss Aux: 2.621e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8367, It: 0, Loss Data: 9.610e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.338e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8368, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.439e+00, Loss Aux: 2.779e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8369, It: 0, Loss Data: 9.966e-02, Loss Eqns: 2.472e+00, Loss Aux: 2.852e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8370, It: 0, Loss Data: 9.590e-02, Loss Eqns: 2.594e+00, Loss Aux: 2.534e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 8371, It: 0, Loss Data: 9.993e-02, Loss Eqns: 2.591e+00, Loss Aux: 2.808e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8372, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.630e+00, Loss Aux: 3.126e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8373, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.261e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8374, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.499e+00, Loss Aux: 2.425e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8375, It: 0, Loss Data: 8.486e-02, Loss Eqns: 2.579e+00, Loss Aux: 3.130e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8376, It: 0, Loss Data: 9.214e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.532e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8377, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.527e+00, Loss Aux: 2.181e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8378, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.519e+00, Loss Aux: 2.464e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 8379, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.679e+00, Loss Aux: 2.705e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8380, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.546e+00, Loss Aux: 1.836e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8381, It: 0, Loss Data: 9.258e-02, Loss Eqns: 2.615e+00, Loss Aux: 2.090e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8382, It: 0, Loss Data: 8.950e-02, Loss Eqns: 2.555e+00, Loss Aux: 3.451e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8383, It: 0, Loss Data: 9.127e-02, Loss Eqns: 2.565e+00, Loss Aux: 4.122e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8384, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.516e+00, Loss Aux: 3.186e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8385, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.856e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8386, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.580e+00, Loss Aux: 3.484e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8387, It: 0, Loss Data: 7.359e-02, Loss Eqns: 2.555e+00, Loss Aux: 3.704e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8388, It: 0, Loss Data: 8.213e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.907e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8389, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.448e+00, Loss Aux: 2.618e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8390, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.457e+00, Loss Aux: 2.727e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8391, It: 0, Loss Data: 9.824e-02, Loss Eqns: 2.520e+00, Loss Aux: 2.848e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8392, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.107e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8393, It: 0, Loss Data: 9.874e-02, Loss Eqns: 2.466e+00, Loss Aux: 2.293e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8394, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.609e+00, Loss Aux: 2.656e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8395, It: 0, Loss Data: 9.477e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.567e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8396, It: 0, Loss Data: 8.076e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.305e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8397, It: 0, Loss Data: 9.948e-02, Loss Eqns: 2.481e+00, Loss Aux: 2.651e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8398, It: 0, Loss Data: 9.750e-02, Loss Eqns: 2.599e+00, Loss Aux: 3.361e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8399, It: 0, Loss Data: 9.406e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.569e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8400, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.543e+00, Loss Aux: 2.705e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8401, It: 0, Loss Data: 8.949e-02, Loss Eqns: 2.587e+00, Loss Aux: 3.431e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8402, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.535e+00, Loss Aux: 3.455e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8403, It: 0, Loss Data: 8.508e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.555e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8404, It: 0, Loss Data: 9.835e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.635e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8405, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.502e+00, Loss Aux: 3.309e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8406, It: 0, Loss Data: 9.815e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.594e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8407, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.431e+00, Loss Aux: 2.069e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8408, It: 0, Loss Data: 9.047e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.702e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8409, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.431e+00, Loss Aux: 3.345e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8410, It: 0, Loss Data: 9.594e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.795e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8411, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.353e+00, Loss Aux: 2.283e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8412, It: 0, Loss Data: 8.874e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.139e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8413, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.575e+00, Loss Aux: 3.559e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 8414, It: 0, Loss Data: 9.798e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.103e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8415, It: 0, Loss Data: 9.181e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.641e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8416, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.475e+00, Loss Aux: 2.470e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8417, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.473e+00, Loss Aux: 2.655e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8418, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.481e+00, Loss Aux: 2.857e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8419, It: 0, Loss Data: 8.223e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.462e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8420, It: 0, Loss Data: 9.234e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.012e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8421, It: 0, Loss Data: 8.352e-02, Loss Eqns: 2.475e+00, Loss Aux: 2.117e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8422, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.458e+00, Loss Aux: 2.755e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8423, It: 0, Loss Data: 9.300e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.485e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8424, It: 0, Loss Data: 8.172e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.393e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8425, It: 0, Loss Data: 9.566e-02, Loss Eqns: 2.583e+00, Loss Aux: 3.245e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8426, It: 0, Loss Data: 9.959e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.993e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8427, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.527e+00, Loss Aux: 3.285e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8428, It: 0, Loss Data: 9.195e-02, Loss Eqns: 2.461e+00, Loss Aux: 3.120e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8429, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.437e+00, Loss Aux: 2.517e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8430, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.276e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8431, It: 0, Loss Data: 7.753e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.293e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 8432, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.462e+00, Loss Aux: 2.511e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8433, It: 0, Loss Data: 8.440e-02, Loss Eqns: 2.541e+00, Loss Aux: 2.299e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8434, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.430e+00, Loss Aux: 2.237e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8435, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.549e+00, Loss Aux: 2.520e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8436, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.493e+00, Loss Aux: 3.249e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8437, It: 0, Loss Data: 8.834e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.309e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8438, It: 0, Loss Data: 8.488e-02, Loss Eqns: 2.533e+00, Loss Aux: 2.815e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8439, It: 0, Loss Data: 9.928e-02, Loss Eqns: 2.576e+00, Loss Aux: 2.260e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8440, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.447e+00, Loss Aux: 2.357e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8441, It: 0, Loss Data: 8.978e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.882e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8442, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.554e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8443, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.508e+00, Loss Aux: 2.134e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8444, It: 0, Loss Data: 9.639e-02, Loss Eqns: 2.715e+00, Loss Aux: 1.982e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8445, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.432e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8446, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.501e+00, Loss Aux: 2.716e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8447, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.580e+00, Loss Aux: 3.198e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8448, It: 0, Loss Data: 8.098e-02, Loss Eqns: 2.455e+00, Loss Aux: 2.944e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8449, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.495e+00, Loss Aux: 2.517e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8450, It: 0, Loss Data: 9.129e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.580e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8451, It: 0, Loss Data: 9.684e-02, Loss Eqns: 2.512e+00, Loss Aux: 2.454e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8452, It: 0, Loss Data: 9.660e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.158e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8453, It: 0, Loss Data: 8.195e-02, Loss Eqns: 2.547e+00, Loss Aux: 2.406e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8454, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.499e+00, Loss Aux: 2.671e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8455, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.460e+00, Loss Aux: 2.418e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8456, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.438e+00, Loss Aux: 2.521e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8457, It: 0, Loss Data: 8.376e-02, Loss Eqns: 2.488e+00, Loss Aux: 3.042e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8458, It: 0, Loss Data: 9.849e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.644e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8459, It: 0, Loss Data: 9.214e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.145e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8460, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.402e+00, Loss Aux: 2.919e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8461, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.903e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8462, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.459e+00, Loss Aux: 3.102e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8463, It: 0, Loss Data: 8.691e-02, Loss Eqns: 2.477e+00, Loss Aux: 3.009e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 8464, It: 0, Loss Data: 7.965e-02, Loss Eqns: 2.491e+00, Loss Aux: 3.097e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8465, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.491e+00, Loss Aux: 3.383e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8466, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.495e+00, Loss Aux: 3.015e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8467, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.116e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8468, It: 0, Loss Data: 9.396e-02, Loss Eqns: 2.440e+00, Loss Aux: 1.518e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8469, It: 0, Loss Data: 9.011e-02, Loss Eqns: 2.543e+00, Loss Aux: 1.850e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8470, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.044e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8471, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.481e+00, Loss Aux: 3.297e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8472, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.499e+00, Loss Aux: 2.389e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8473, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.497e+00, Loss Aux: 2.285e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8474, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.488e+00, Loss Aux: 3.325e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8475, It: 0, Loss Data: 9.928e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.829e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8476, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.528e+00, Loss Aux: 2.755e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 8477, It: 0, Loss Data: 9.281e-02, Loss Eqns: 2.454e+00, Loss Aux: 1.962e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8478, It: 0, Loss Data: 8.603e-02, Loss Eqns: 2.476e+00, Loss Aux: 2.522e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8479, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.524e+00, Loss Aux: 3.612e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8480, It: 0, Loss Data: 9.191e-02, Loss Eqns: 2.478e+00, Loss Aux: 3.069e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8481, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.608e+00, Loss Aux: 2.373e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8482, It: 0, Loss Data: 9.611e-02, Loss Eqns: 2.566e+00, Loss Aux: 2.359e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8483, It: 0, Loss Data: 7.914e-02, Loss Eqns: 2.621e+00, Loss Aux: 2.325e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8484, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.581e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8485, It: 0, Loss Data: 9.964e-02, Loss Eqns: 2.574e+00, Loss Aux: 2.840e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8486, It: 0, Loss Data: 9.440e-02, Loss Eqns: 2.462e+00, Loss Aux: 3.039e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8487, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.551e+00, Loss Aux: 3.153e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8488, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.464e+00, Loss Aux: 3.186e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8489, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.698e+00, Loss Aux: 2.740e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8490, It: 0, Loss Data: 8.306e-02, Loss Eqns: 2.621e+00, Loss Aux: 2.430e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8491, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.565e+00, Loss Aux: 2.406e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8492, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.652e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8493, It: 0, Loss Data: 9.379e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.694e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8494, It: 0, Loss Data: 9.020e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.728e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8495, It: 0, Loss Data: 9.715e-02, Loss Eqns: 2.527e+00, Loss Aux: 3.073e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8496, It: 0, Loss Data: 8.822e-02, Loss Eqns: 2.531e+00, Loss Aux: 3.022e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8497, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.579e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8498, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.397e+00, Loss Aux: 2.222e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8499, It: 0, Loss Data: 9.604e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.718e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8500, It: 0, Loss Data: 8.088e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.646e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8501, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.368e+00, Loss Aux: 2.298e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8502, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.396e+00, Loss Aux: 2.527e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8503, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.480e+00, Loss Aux: 2.682e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8504, It: 0, Loss Data: 9.799e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.314e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8505, It: 0, Loss Data: 9.110e-02, Loss Eqns: 2.568e+00, Loss Aux: 1.800e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8506, It: 0, Loss Data: 9.287e-02, Loss Eqns: 2.398e+00, Loss Aux: 1.621e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8507, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.542e+00, Loss Aux: 2.847e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8508, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.531e+00, Loss Aux: 4.148e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8509, It: 0, Loss Data: 8.870e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.458e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8510, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.470e+00, Loss Aux: 2.658e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8511, It: 0, Loss Data: 9.508e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.713e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8512, It: 0, Loss Data: 9.719e-02, Loss Eqns: 2.500e+00, Loss Aux: 3.204e-02, Time: 0.245, Learning Rate: 1.0e-03\n",
      "Epoch: 8513, It: 0, Loss Data: 8.302e-02, Loss Eqns: 2.506e+00, Loss Aux: 2.985e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8514, It: 0, Loss Data: 8.509e-02, Loss Eqns: 2.574e+00, Loss Aux: 2.647e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8515, It: 0, Loss Data: 8.533e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.372e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8516, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.599e+00, Loss Aux: 2.326e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 8517, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.526e+00, Loss Aux: 2.200e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8518, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.527e+00, Loss Aux: 2.722e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8519, It: 0, Loss Data: 9.544e-02, Loss Eqns: 2.569e+00, Loss Aux: 2.944e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8520, It: 0, Loss Data: 8.215e-02, Loss Eqns: 2.593e+00, Loss Aux: 2.927e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8521, It: 0, Loss Data: 9.876e-02, Loss Eqns: 2.530e+00, Loss Aux: 3.231e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8522, It: 0, Loss Data: 9.487e-02, Loss Eqns: 2.539e+00, Loss Aux: 3.021e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8523, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.588e+00, Loss Aux: 2.385e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8524, It: 0, Loss Data: 8.643e-02, Loss Eqns: 2.451e+00, Loss Aux: 1.786e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8525, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.416e+00, Loss Aux: 1.867e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8526, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.317e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8527, It: 0, Loss Data: 9.456e-02, Loss Eqns: 2.536e+00, Loss Aux: 2.857e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8528, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.499e+00, Loss Aux: 2.651e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8529, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.503e+00, Loss Aux: 2.283e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8530, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.518e+00, Loss Aux: 1.852e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8531, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.469e+00, Loss Aux: 1.828e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8532, It: 0, Loss Data: 8.330e-02, Loss Eqns: 2.476e+00, Loss Aux: 2.612e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8533, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.592e+00, Loss Aux: 3.545e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8534, It: 0, Loss Data: 8.992e-02, Loss Eqns: 2.512e+00, Loss Aux: 3.463e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8535, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.842e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8536, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.617e+00, Loss Aux: 2.744e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8537, It: 0, Loss Data: 9.574e-02, Loss Eqns: 2.545e+00, Loss Aux: 2.142e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8538, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.702e+00, Loss Aux: 2.416e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8539, It: 0, Loss Data: 8.799e-02, Loss Eqns: 2.533e+00, Loss Aux: 3.022e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8540, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.620e+00, Loss Aux: 3.097e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8541, It: 0, Loss Data: 8.369e-02, Loss Eqns: 2.611e+00, Loss Aux: 2.511e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8542, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.563e+00, Loss Aux: 2.207e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8543, It: 0, Loss Data: 8.801e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.629e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 8544, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.576e+00, Loss Aux: 3.562e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8545, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.599e+00, Loss Aux: 2.985e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8546, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.568e+00, Loss Aux: 2.233e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8547, It: 0, Loss Data: 8.828e-02, Loss Eqns: 2.651e+00, Loss Aux: 1.929e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8548, It: 0, Loss Data: 8.622e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.565e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8549, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.341e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8550, It: 0, Loss Data: 8.618e-02, Loss Eqns: 2.505e+00, Loss Aux: 1.890e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8551, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.455e+00, Loss Aux: 2.240e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8552, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.424e+00, Loss Aux: 3.474e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8553, It: 0, Loss Data: 9.348e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.723e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8554, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.548e+00, Loss Aux: 2.647e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8555, It: 0, Loss Data: 9.095e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.121e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8556, It: 0, Loss Data: 9.333e-02, Loss Eqns: 2.429e+00, Loss Aux: 1.905e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8557, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.500e+00, Loss Aux: 1.830e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8558, It: 0, Loss Data: 7.981e-02, Loss Eqns: 2.466e+00, Loss Aux: 2.149e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8559, It: 0, Loss Data: 9.516e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.226e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8560, It: 0, Loss Data: 9.811e-02, Loss Eqns: 2.554e+00, Loss Aux: 3.409e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 8561, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.469e+00, Loss Aux: 3.364e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8562, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.525e+00, Loss Aux: 3.194e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 8563, It: 0, Loss Data: 9.625e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.712e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8564, It: 0, Loss Data: 9.200e-02, Loss Eqns: 2.447e+00, Loss Aux: 2.370e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8565, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.581e+00, Loss Aux: 2.182e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8566, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.995e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8567, It: 0, Loss Data: 8.729e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.269e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8568, It: 0, Loss Data: 8.328e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.868e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8569, It: 0, Loss Data: 9.074e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.945e-02, Time: 0.143, Learning Rate: 1.0e-03\n",
      "Epoch: 8570, It: 0, Loss Data: 9.378e-02, Loss Eqns: 2.527e+00, Loss Aux: 2.768e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8571, It: 0, Loss Data: 9.168e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.596e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8572, It: 0, Loss Data: 9.573e-02, Loss Eqns: 2.472e+00, Loss Aux: 2.136e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8573, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.582e+00, Loss Aux: 2.219e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8574, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.431e+00, Loss Aux: 2.731e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8575, It: 0, Loss Data: 9.965e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.783e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8576, It: 0, Loss Data: 9.907e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.090e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8577, It: 0, Loss Data: 9.973e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.305e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8578, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.523e+00, Loss Aux: 2.764e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 8579, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.601e+00, Loss Aux: 3.168e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8580, It: 0, Loss Data: 8.016e-02, Loss Eqns: 2.596e+00, Loss Aux: 2.787e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8581, It: 0, Loss Data: 7.716e-02, Loss Eqns: 2.546e+00, Loss Aux: 2.318e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8582, It: 0, Loss Data: 8.626e-02, Loss Eqns: 2.626e+00, Loss Aux: 2.592e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8583, It: 0, Loss Data: 8.954e-02, Loss Eqns: 2.586e+00, Loss Aux: 3.282e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8584, It: 0, Loss Data: 8.913e-02, Loss Eqns: 2.600e+00, Loss Aux: 2.988e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8585, It: 0, Loss Data: 8.812e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.661e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8586, It: 0, Loss Data: 9.367e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.686e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8587, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.557e+00, Loss Aux: 2.123e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8588, It: 0, Loss Data: 8.370e-02, Loss Eqns: 2.286e+00, Loss Aux: 2.022e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 8589, It: 0, Loss Data: 8.611e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.202e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8590, It: 0, Loss Data: 9.545e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.316e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8591, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.374e+00, Loss Aux: 2.463e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8592, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.457e+00, Loss Aux: 2.657e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8593, It: 0, Loss Data: 9.747e-02, Loss Eqns: 2.449e+00, Loss Aux: 3.008e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 8594, It: 0, Loss Data: 9.201e-02, Loss Eqns: 2.361e+00, Loss Aux: 2.682e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8595, It: 0, Loss Data: 9.327e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.505e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8596, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.382e+00, Loss Aux: 2.300e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8597, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.152e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8598, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.435e+00, Loss Aux: 2.282e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 8599, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.433e+00, Loss Aux: 3.127e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8600, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.425e+00, Loss Aux: 3.469e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 8601, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.335e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8602, It: 0, Loss Data: 8.964e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.002e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8603, It: 0, Loss Data: 9.690e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.655e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8604, It: 0, Loss Data: 9.955e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.411e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8605, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.441e+00, Loss Aux: 2.209e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8606, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.441e+00, Loss Aux: 2.534e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8607, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.439e+00, Loss Aux: 2.237e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8608, It: 0, Loss Data: 8.741e-02, Loss Eqns: 2.484e+00, Loss Aux: 1.998e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8609, It: 0, Loss Data: 9.641e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.180e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8610, It: 0, Loss Data: 8.770e-02, Loss Eqns: 2.521e+00, Loss Aux: 3.187e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8611, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.444e+00, Loss Aux: 3.338e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8612, It: 0, Loss Data: 9.192e-02, Loss Eqns: 2.516e+00, Loss Aux: 3.682e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8613, It: 0, Loss Data: 9.504e-02, Loss Eqns: 2.500e+00, Loss Aux: 3.309e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8614, It: 0, Loss Data: 7.885e-02, Loss Eqns: 2.580e+00, Loss Aux: 2.603e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8615, It: 0, Loss Data: 9.595e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.511e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8616, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.483e+00, Loss Aux: 2.344e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8617, It: 0, Loss Data: 9.272e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.409e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 8618, It: 0, Loss Data: 8.620e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.177e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8619, It: 0, Loss Data: 9.809e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.129e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8620, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.569e+00, Loss Aux: 2.527e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8621, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.466e+00, Loss Aux: 2.482e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8622, It: 0, Loss Data: 8.746e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.482e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8623, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.527e+00, Loss Aux: 2.504e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8624, It: 0, Loss Data: 9.937e-02, Loss Eqns: 2.577e+00, Loss Aux: 2.102e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8625, It: 0, Loss Data: 9.691e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.055e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8626, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.544e+00, Loss Aux: 2.389e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8627, It: 0, Loss Data: 9.674e-02, Loss Eqns: 2.594e+00, Loss Aux: 2.169e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8628, It: 0, Loss Data: 8.553e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.338e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8629, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.527e+00, Loss Aux: 2.637e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8630, It: 0, Loss Data: 9.887e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.799e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 8631, It: 0, Loss Data: 7.981e-02, Loss Eqns: 2.548e+00, Loss Aux: 3.197e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8632, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.571e+00, Loss Aux: 3.028e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8633, It: 0, Loss Data: 9.467e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.576e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8634, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.455e+00, Loss Aux: 1.948e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8635, It: 0, Loss Data: 9.887e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.768e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 8636, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.449e+00, Loss Aux: 1.533e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8637, It: 0, Loss Data: 9.971e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.030e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8638, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.181e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8639, It: 0, Loss Data: 9.683e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.260e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8640, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.437e+00, Loss Aux: 2.855e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8641, It: 0, Loss Data: 7.274e-02, Loss Eqns: 2.464e+00, Loss Aux: 2.883e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8642, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.484e+00, Loss Aux: 2.873e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8643, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.519e+00, Loss Aux: 2.919e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8644, It: 0, Loss Data: 8.376e-02, Loss Eqns: 2.540e+00, Loss Aux: 2.927e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8645, It: 0, Loss Data: 9.008e-02, Loss Eqns: 2.504e+00, Loss Aux: 3.124e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8646, It: 0, Loss Data: 9.423e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.125e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8647, It: 0, Loss Data: 8.403e-02, Loss Eqns: 2.534e+00, Loss Aux: 1.543e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8648, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.573e+00, Loss Aux: 1.702e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 8649, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.482e+00, Loss Aux: 1.920e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8650, It: 0, Loss Data: 9.866e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.661e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8651, It: 0, Loss Data: 8.359e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.067e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8652, It: 0, Loss Data: 9.334e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.553e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8653, It: 0, Loss Data: 9.378e-02, Loss Eqns: 2.471e+00, Loss Aux: 2.199e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8654, It: 0, Loss Data: 6.921e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.908e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8655, It: 0, Loss Data: 9.391e-02, Loss Eqns: 2.519e+00, Loss Aux: 3.252e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8656, It: 0, Loss Data: 8.990e-02, Loss Eqns: 2.598e+00, Loss Aux: 2.768e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8657, It: 0, Loss Data: 8.121e-02, Loss Eqns: 2.501e+00, Loss Aux: 2.579e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8658, It: 0, Loss Data: 7.648e-02, Loss Eqns: 2.390e+00, Loss Aux: 2.786e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8659, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.420e+00, Loss Aux: 2.751e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8660, It: 0, Loss Data: 9.739e-02, Loss Eqns: 2.469e+00, Loss Aux: 1.834e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8661, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.435e+00, Loss Aux: 1.704e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8662, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.341e+00, Loss Aux: 1.906e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8663, It: 0, Loss Data: 9.547e-02, Loss Eqns: 2.363e+00, Loss Aux: 2.542e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8664, It: 0, Loss Data: 9.492e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.009e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8665, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.395e+00, Loss Aux: 2.771e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8666, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.435e+00, Loss Aux: 2.582e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8667, It: 0, Loss Data: 8.435e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.493e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8668, It: 0, Loss Data: 9.439e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.234e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8669, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.507e+00, Loss Aux: 2.540e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8670, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.498e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8671, It: 0, Loss Data: 9.465e-02, Loss Eqns: 2.554e+00, Loss Aux: 1.913e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8672, It: 0, Loss Data: 9.838e-02, Loss Eqns: 2.453e+00, Loss Aux: 1.944e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8673, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.613e+00, Loss Aux: 2.154e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8674, It: 0, Loss Data: 8.659e-02, Loss Eqns: 2.606e+00, Loss Aux: 2.405e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8675, It: 0, Loss Data: 9.286e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.889e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8676, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.541e+00, Loss Aux: 3.137e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8677, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.493e+00, Loss Aux: 3.056e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8678, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.631e+00, Loss Aux: 2.207e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8679, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.706e+00, Loss Aux: 2.436e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8680, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.514e+00, Loss Aux: 2.782e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8681, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.824e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8682, It: 0, Loss Data: 9.552e-02, Loss Eqns: 2.517e+00, Loss Aux: 2.417e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8683, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.558e+00, Loss Aux: 1.764e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 8684, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.550e+00, Loss Aux: 1.572e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 8685, It: 0, Loss Data: 8.664e-02, Loss Eqns: 2.542e+00, Loss Aux: 2.154e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8686, It: 0, Loss Data: 8.194e-02, Loss Eqns: 2.577e+00, Loss Aux: 2.860e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8687, It: 0, Loss Data: 8.390e-02, Loss Eqns: 2.513e+00, Loss Aux: 3.412e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8688, It: 0, Loss Data: 9.905e-02, Loss Eqns: 2.471e+00, Loss Aux: 3.703e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8689, It: 0, Loss Data: 9.566e-02, Loss Eqns: 2.499e+00, Loss Aux: 3.827e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8690, It: 0, Loss Data: 7.574e-02, Loss Eqns: 2.548e+00, Loss Aux: 3.104e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 8691, It: 0, Loss Data: 9.178e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.183e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8692, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.562e+00, Loss Aux: 2.119e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8693, It: 0, Loss Data: 8.653e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.589e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8694, It: 0, Loss Data: 9.208e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.288e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8695, It: 0, Loss Data: 9.312e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.112e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8696, It: 0, Loss Data: 8.280e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.742e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8697, It: 0, Loss Data: 8.204e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.590e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8698, It: 0, Loss Data: 9.163e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.035e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8699, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.433e+00, Loss Aux: 2.237e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8700, It: 0, Loss Data: 9.417e-02, Loss Eqns: 2.469e+00, Loss Aux: 2.071e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8701, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.595e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 8702, It: 0, Loss Data: 9.977e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.372e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8703, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.418e+00, Loss Aux: 2.962e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8704, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.022e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8705, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.463e+00, Loss Aux: 1.764e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8706, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.513e+00, Loss Aux: 1.603e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8707, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.425e+00, Loss Aux: 1.663e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 8708, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.680e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 8709, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.512e+00, Loss Aux: 3.946e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8710, It: 0, Loss Data: 8.392e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.811e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8711, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.371e+00, Loss Aux: 3.201e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8712, It: 0, Loss Data: 8.514e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.443e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8713, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.201e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8714, It: 0, Loss Data: 9.817e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.787e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8715, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.376e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8716, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.507e+00, Loss Aux: 1.513e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8717, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.533e+00, Loss Aux: 1.581e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8718, It: 0, Loss Data: 9.330e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.915e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8719, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.448e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8720, It: 0, Loss Data: 9.857e-02, Loss Eqns: 2.484e+00, Loss Aux: 2.777e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8721, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.084e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 8722, It: 0, Loss Data: 7.883e-02, Loss Eqns: 2.498e+00, Loss Aux: 1.922e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8723, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.502e+00, Loss Aux: 3.296e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8724, It: 0, Loss Data: 8.637e-02, Loss Eqns: 2.484e+00, Loss Aux: 3.548e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8725, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.572e+00, Loss Aux: 2.931e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8726, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.585e+00, Loss Aux: 3.392e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8727, It: 0, Loss Data: 9.330e-02, Loss Eqns: 2.456e+00, Loss Aux: 3.366e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8728, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.248e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 8729, It: 0, Loss Data: 9.280e-02, Loss Eqns: 2.554e+00, Loss Aux: 1.795e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8730, It: 0, Loss Data: 1.275e-01, Loss Eqns: 2.769e+00, Loss Aux: 2.883e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8731, It: 0, Loss Data: 2.191e-01, Loss Eqns: 4.072e+00, Loss Aux: 1.411e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8732, It: 0, Loss Data: 1.612e-01, Loss Eqns: 3.231e+00, Loss Aux: 3.477e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8733, It: 0, Loss Data: 1.948e-01, Loss Eqns: 3.939e+00, Loss Aux: 5.279e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8734, It: 0, Loss Data: 1.242e-01, Loss Eqns: 2.812e+00, Loss Aux: 2.023e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8735, It: 0, Loss Data: 1.476e-01, Loss Eqns: 3.325e+00, Loss Aux: 1.494e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8736, It: 0, Loss Data: 1.176e-01, Loss Eqns: 2.802e+00, Loss Aux: 3.348e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8737, It: 0, Loss Data: 1.467e-01, Loss Eqns: 2.851e+00, Loss Aux: 5.775e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8738, It: 0, Loss Data: 1.238e-01, Loss Eqns: 2.831e+00, Loss Aux: 4.171e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 8739, It: 0, Loss Data: 1.337e-01, Loss Eqns: 2.493e+00, Loss Aux: 3.298e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8740, It: 0, Loss Data: 1.256e-01, Loss Eqns: 2.728e+00, Loss Aux: 3.677e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8741, It: 0, Loss Data: 1.196e-01, Loss Eqns: 2.510e+00, Loss Aux: 3.201e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8742, It: 0, Loss Data: 1.622e-01, Loss Eqns: 2.540e+00, Loss Aux: 2.437e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8743, It: 0, Loss Data: 1.101e-01, Loss Eqns: 2.520e+00, Loss Aux: 3.285e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8744, It: 0, Loss Data: 1.188e-01, Loss Eqns: 2.828e+00, Loss Aux: 4.105e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8745, It: 0, Loss Data: 1.418e-01, Loss Eqns: 2.390e+00, Loss Aux: 4.480e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8746, It: 0, Loss Data: 1.685e-01, Loss Eqns: 3.235e+00, Loss Aux: 2.296e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8747, It: 0, Loss Data: 1.218e-01, Loss Eqns: 2.529e+00, Loss Aux: 2.351e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8748, It: 0, Loss Data: 1.620e-01, Loss Eqns: 3.244e+00, Loss Aux: 2.846e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8749, It: 0, Loss Data: 1.199e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.923e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8750, It: 0, Loss Data: 1.642e-01, Loss Eqns: 2.815e+00, Loss Aux: 2.569e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8751, It: 0, Loss Data: 1.302e-01, Loss Eqns: 2.426e+00, Loss Aux: 2.597e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8752, It: 0, Loss Data: 1.540e-01, Loss Eqns: 3.036e+00, Loss Aux: 3.180e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8753, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.570e+00, Loss Aux: 3.041e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8754, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.916e+00, Loss Aux: 3.018e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8755, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.474e+00, Loss Aux: 3.970e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8756, It: 0, Loss Data: 1.457e-01, Loss Eqns: 2.770e+00, Loss Aux: 4.138e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8757, It: 0, Loss Data: 1.269e-01, Loss Eqns: 2.430e+00, Loss Aux: 2.168e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8758, It: 0, Loss Data: 1.301e-01, Loss Eqns: 2.640e+00, Loss Aux: 1.915e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8759, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.414e+00, Loss Aux: 4.598e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 8760, It: 0, Loss Data: 1.392e-01, Loss Eqns: 2.489e+00, Loss Aux: 4.473e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8761, It: 0, Loss Data: 1.658e-01, Loss Eqns: 2.549e+00, Loss Aux: 1.640e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8762, It: 0, Loss Data: 9.660e-02, Loss Eqns: 2.464e+00, Loss Aux: 3.303e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8763, It: 0, Loss Data: 1.457e-01, Loss Eqns: 2.619e+00, Loss Aux: 5.808e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8764, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.106e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8765, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.445e+00, Loss Aux: 2.276e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8766, It: 0, Loss Data: 8.926e-02, Loss Eqns: 2.261e+00, Loss Aux: 2.177e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8767, It: 0, Loss Data: 1.360e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.596e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8768, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.471e+00, Loss Aux: 1.608e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8769, It: 0, Loss Data: 1.259e-01, Loss Eqns: 2.534e+00, Loss Aux: 1.710e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8770, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.326e+00, Loss Aux: 3.406e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8771, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.524e+00, Loss Aux: 4.244e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8772, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.389e+00, Loss Aux: 2.711e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8773, It: 0, Loss Data: 1.354e-01, Loss Eqns: 2.466e+00, Loss Aux: 2.539e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8774, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.413e+00, Loss Aux: 4.229e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 8775, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.369e+00, Loss Aux: 4.684e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8776, It: 0, Loss Data: 1.113e-01, Loss Eqns: 2.450e+00, Loss Aux: 3.109e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8777, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.371e+00, Loss Aux: 2.832e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8778, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.587e+00, Loss Aux: 3.859e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8779, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.379e+00, Loss Aux: 3.786e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8780, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.384e+00, Loss Aux: 2.354e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8781, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.242e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8782, It: 0, Loss Data: 9.412e-02, Loss Eqns: 2.538e+00, Loss Aux: 3.107e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8783, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.519e+00, Loss Aux: 4.106e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8784, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.523e+00, Loss Aux: 3.805e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 8785, It: 0, Loss Data: 9.180e-02, Loss Eqns: 2.457e+00, Loss Aux: 2.747e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8786, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.584e+00, Loss Aux: 2.018e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8787, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.076e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8788, It: 0, Loss Data: 8.235e-02, Loss Eqns: 2.517e+00, Loss Aux: 2.717e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8789, It: 0, Loss Data: 9.315e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.898e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8790, It: 0, Loss Data: 1.148e-01, Loss Eqns: 2.365e+00, Loss Aux: 4.078e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8791, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.523e+00, Loss Aux: 3.795e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 8792, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.425e+00, Loss Aux: 3.299e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8793, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.941e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8794, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.406e+00, Loss Aux: 4.133e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8795, It: 0, Loss Data: 9.717e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.602e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8796, It: 0, Loss Data: 8.304e-02, Loss Eqns: 2.408e+00, Loss Aux: 2.419e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8797, It: 0, Loss Data: 7.600e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.918e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8798, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.428e+00, Loss Aux: 3.236e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8799, It: 0, Loss Data: 9.294e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.944e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8800, It: 0, Loss Data: 9.414e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.591e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8801, It: 0, Loss Data: 9.210e-02, Loss Eqns: 2.464e+00, Loss Aux: 3.113e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8802, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.389e+00, Loss Aux: 3.493e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8803, It: 0, Loss Data: 8.707e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.907e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8804, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.413e+00, Loss Aux: 2.475e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8805, It: 0, Loss Data: 9.175e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.191e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8806, It: 0, Loss Data: 9.412e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.730e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8807, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.364e+00, Loss Aux: 3.113e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8808, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.684e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8809, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.462e+00, Loss Aux: 3.196e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8810, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.172e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8811, It: 0, Loss Data: 9.000e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.876e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8812, It: 0, Loss Data: 9.484e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.844e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8813, It: 0, Loss Data: 8.590e-02, Loss Eqns: 2.505e+00, Loss Aux: 3.291e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8814, It: 0, Loss Data: 8.989e-02, Loss Eqns: 2.460e+00, Loss Aux: 3.258e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8815, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.390e+00, Loss Aux: 2.596e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8816, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.487e+00, Loss Aux: 2.597e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8817, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.714e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8818, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.478e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8819, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.481e+00, Loss Aux: 2.218e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 8820, It: 0, Loss Data: 8.226e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.618e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8821, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.527e+00, Loss Aux: 3.132e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8822, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.385e+00, Loss Aux: 3.125e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8823, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.918e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 8824, It: 0, Loss Data: 8.589e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.943e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 8825, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.050e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8826, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.344e+00, Loss Aux: 2.747e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8827, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.302e+00, Loss Aux: 2.231e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8828, It: 0, Loss Data: 9.811e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.280e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8829, It: 0, Loss Data: 9.676e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.938e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8830, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.442e+00, Loss Aux: 3.119e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8831, It: 0, Loss Data: 9.995e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.994e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8832, It: 0, Loss Data: 7.712e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.095e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8833, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.393e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8834, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.495e+00, Loss Aux: 3.231e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8835, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.463e+00, Loss Aux: 2.461e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 8836, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.418e+00, Loss Aux: 2.305e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8837, It: 0, Loss Data: 8.368e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.980e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8838, It: 0, Loss Data: 8.541e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.202e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8839, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.494e+00, Loss Aux: 3.147e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8840, It: 0, Loss Data: 7.935e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.907e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 8841, It: 0, Loss Data: 9.941e-02, Loss Eqns: 2.497e+00, Loss Aux: 2.517e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8842, It: 0, Loss Data: 8.085e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.870e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8843, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.422e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8844, It: 0, Loss Data: 9.138e-02, Loss Eqns: 2.520e+00, Loss Aux: 2.947e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 8845, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.402e+00, Loss Aux: 2.396e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8846, It: 0, Loss Data: 8.342e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.390e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8847, It: 0, Loss Data: 9.384e-02, Loss Eqns: 2.368e+00, Loss Aux: 2.330e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 8848, It: 0, Loss Data: 8.906e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.193e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 8849, It: 0, Loss Data: 8.824e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.152e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8850, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.410e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8851, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.403e+00, Loss Aux: 2.689e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 8852, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.425e+00, Loss Aux: 2.737e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8853, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.224e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8854, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.492e+00, Loss Aux: 3.333e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8855, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.528e+00, Loss Aux: 2.679e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 8856, It: 0, Loss Data: 9.717e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.686e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8857, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.613e+00, Loss Aux: 4.029e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8858, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.767e+00, Loss Aux: 2.553e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8859, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.648e+00, Loss Aux: 2.058e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8860, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.757e+00, Loss Aux: 2.355e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8861, It: 0, Loss Data: 9.100e-02, Loss Eqns: 2.477e+00, Loss Aux: 1.878e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8862, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.587e+00, Loss Aux: 1.741e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8863, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.421e+00, Loss Aux: 3.300e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8864, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.733e+00, Loss Aux: 4.191e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8865, It: 0, Loss Data: 9.604e-02, Loss Eqns: 2.607e+00, Loss Aux: 2.717e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 8866, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.689e+00, Loss Aux: 2.017e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8867, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.597e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8868, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.547e+00, Loss Aux: 3.178e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 8869, It: 0, Loss Data: 9.664e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.089e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8870, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.449e+00, Loss Aux: 3.617e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8871, It: 0, Loss Data: 8.992e-02, Loss Eqns: 2.543e+00, Loss Aux: 4.281e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8872, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.518e+00, Loss Aux: 3.486e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8873, It: 0, Loss Data: 1.133e-01, Loss Eqns: 2.500e+00, Loss Aux: 2.221e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 8874, It: 0, Loss Data: 9.171e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.149e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8875, It: 0, Loss Data: 8.399e-02, Loss Eqns: 2.584e+00, Loss Aux: 2.175e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8876, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.398e+00, Loss Aux: 2.069e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8877, It: 0, Loss Data: 9.070e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.271e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 8878, It: 0, Loss Data: 9.248e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.236e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 8879, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.427e+00, Loss Aux: 3.859e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 8880, It: 0, Loss Data: 9.157e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.167e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8881, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.418e+00, Loss Aux: 2.518e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 8882, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.540e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 8883, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.482e+00, Loss Aux: 2.357e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8884, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.490e+00, Loss Aux: 1.968e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8885, It: 0, Loss Data: 9.098e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.177e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 8886, It: 0, Loss Data: 9.116e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.828e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8887, It: 0, Loss Data: 9.406e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.977e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8888, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.484e+00, Loss Aux: 2.726e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8889, It: 0, Loss Data: 1.176e-01, Loss Eqns: 2.344e+00, Loss Aux: 1.555e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8890, It: 0, Loss Data: 9.716e-02, Loss Eqns: 2.428e+00, Loss Aux: 1.830e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8891, It: 0, Loss Data: 9.760e-02, Loss Eqns: 2.558e+00, Loss Aux: 3.569e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8892, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.533e+00, Loss Aux: 4.806e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8893, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.522e+00, Loss Aux: 3.894e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8894, It: 0, Loss Data: 9.614e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.788e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8895, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.588e+00, Loss Aux: 2.299e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8896, It: 0, Loss Data: 9.311e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.131e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8897, It: 0, Loss Data: 9.625e-02, Loss Eqns: 2.510e+00, Loss Aux: 1.758e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8898, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.036e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8899, It: 0, Loss Data: 8.548e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.838e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8900, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.551e+00, Loss Aux: 3.064e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8901, It: 0, Loss Data: 7.952e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.742e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8902, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.435e+00, Loss Aux: 2.220e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8903, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.438e+00, Loss Aux: 2.045e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8904, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.386e+00, Loss Aux: 2.927e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8905, It: 0, Loss Data: 9.471e-02, Loss Eqns: 2.421e+00, Loss Aux: 4.491e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 8906, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.551e+00, Loss Aux: 3.342e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8907, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.012e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8908, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.512e+00, Loss Aux: 1.875e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 8909, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.536e+00, Loss Aux: 2.827e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8910, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.528e+00, Loss Aux: 3.080e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8911, It: 0, Loss Data: 9.149e-02, Loss Eqns: 2.472e+00, Loss Aux: 2.771e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8912, It: 0, Loss Data: 9.796e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.805e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8913, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.581e+00, Loss Aux: 3.173e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8914, It: 0, Loss Data: 9.633e-02, Loss Eqns: 2.490e+00, Loss Aux: 3.171e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8915, It: 0, Loss Data: 9.777e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.703e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8916, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.496e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 8917, It: 0, Loss Data: 8.719e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.563e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8918, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.853e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 8919, It: 0, Loss Data: 8.662e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.267e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8920, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.376e+00, Loss Aux: 3.221e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8921, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.372e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8922, It: 0, Loss Data: 8.032e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.106e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8923, It: 0, Loss Data: 9.442e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.642e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8924, It: 0, Loss Data: 9.813e-02, Loss Eqns: 2.447e+00, Loss Aux: 3.312e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8925, It: 0, Loss Data: 9.969e-02, Loss Eqns: 2.423e+00, Loss Aux: 3.067e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8926, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.097e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 8927, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.515e+00, Loss Aux: 3.247e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8928, It: 0, Loss Data: 9.275e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.188e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8929, It: 0, Loss Data: 8.709e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.899e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 8930, It: 0, Loss Data: 8.931e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.581e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 8931, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.542e+00, Loss Aux: 2.592e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8932, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.414e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8933, It: 0, Loss Data: 9.551e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.158e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8934, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.181e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8935, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.256e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 8936, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.426e+00, Loss Aux: 2.128e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8937, It: 0, Loss Data: 1.194e-01, Loss Eqns: 2.516e+00, Loss Aux: 2.586e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8938, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.486e+00, Loss Aux: 3.154e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8939, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.039e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 8940, It: 0, Loss Data: 9.045e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.797e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8941, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.471e+00, Loss Aux: 2.939e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8942, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.499e+00, Loss Aux: 3.088e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8943, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.543e+00, Loss Aux: 2.534e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8944, It: 0, Loss Data: 8.174e-02, Loss Eqns: 2.429e+00, Loss Aux: 2.173e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 8945, It: 0, Loss Data: 9.518e-02, Loss Eqns: 2.508e+00, Loss Aux: 2.341e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 8946, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.463e+00, Loss Aux: 2.801e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8947, It: 0, Loss Data: 9.063e-02, Loss Eqns: 2.427e+00, Loss Aux: 2.344e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 8948, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.492e+00, Loss Aux: 2.054e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8949, It: 0, Loss Data: 8.381e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.487e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8950, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.841e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 8951, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.808e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8952, It: 0, Loss Data: 7.958e-02, Loss Eqns: 2.516e+00, Loss Aux: 3.013e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8953, It: 0, Loss Data: 8.319e-02, Loss Eqns: 2.461e+00, Loss Aux: 3.274e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8954, It: 0, Loss Data: 7.943e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.021e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8955, It: 0, Loss Data: 9.653e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.170e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8956, It: 0, Loss Data: 9.382e-02, Loss Eqns: 2.469e+00, Loss Aux: 3.491e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8957, It: 0, Loss Data: 8.956e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.024e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8958, It: 0, Loss Data: 9.040e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.391e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8959, It: 0, Loss Data: 9.897e-02, Loss Eqns: 2.505e+00, Loss Aux: 2.390e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8960, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.399e+00, Loss Aux: 2.515e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8961, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.495e+00, Loss Aux: 2.331e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 8962, It: 0, Loss Data: 7.907e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.613e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 8963, It: 0, Loss Data: 9.240e-02, Loss Eqns: 2.569e+00, Loss Aux: 3.152e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8964, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.470e+00, Loss Aux: 3.281e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 8965, It: 0, Loss Data: 8.335e-02, Loss Eqns: 2.474e+00, Loss Aux: 3.285e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8966, It: 0, Loss Data: 7.957e-02, Loss Eqns: 2.444e+00, Loss Aux: 3.516e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 8967, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.196e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 8968, It: 0, Loss Data: 9.756e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.049e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8969, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.265e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8970, It: 0, Loss Data: 8.688e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.813e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 8971, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.405e+00, Loss Aux: 2.329e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 8972, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.531e+00, Loss Aux: 2.374e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 8973, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.496e+00, Loss Aux: 2.652e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8974, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.523e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8975, It: 0, Loss Data: 8.953e-02, Loss Eqns: 2.424e+00, Loss Aux: 2.889e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 8976, It: 0, Loss Data: 9.573e-02, Loss Eqns: 2.522e+00, Loss Aux: 3.575e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 8977, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.609e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 8978, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.490e+00, Loss Aux: 3.033e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 8979, It: 0, Loss Data: 8.017e-02, Loss Eqns: 2.532e+00, Loss Aux: 2.252e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 8980, It: 0, Loss Data: 9.558e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.365e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8981, It: 0, Loss Data: 9.884e-02, Loss Eqns: 2.495e+00, Loss Aux: 2.608e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 8982, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.245e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 8983, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.504e+00, Loss Aux: 2.009e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8984, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.524e+00, Loss Aux: 2.053e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 8985, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.484e+00, Loss Aux: 2.698e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 8986, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.570e+00, Loss Aux: 3.481e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 8987, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.384e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 8988, It: 0, Loss Data: 7.662e-02, Loss Eqns: 2.527e+00, Loss Aux: 3.062e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8989, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.101e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8990, It: 0, Loss Data: 8.641e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.977e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 8991, It: 0, Loss Data: 7.447e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.289e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 8992, It: 0, Loss Data: 8.671e-02, Loss Eqns: 2.535e+00, Loss Aux: 1.899e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 8993, It: 0, Loss Data: 8.061e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.108e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 8994, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.445e+00, Loss Aux: 2.667e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8995, It: 0, Loss Data: 9.368e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.305e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 8996, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.348e+00, Loss Aux: 3.313e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 8997, It: 0, Loss Data: 9.407e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.596e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 8998, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.277e+00, Loss Aux: 2.380e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 8999, It: 0, Loss Data: 9.477e-02, Loss Eqns: 2.350e+00, Loss Aux: 2.652e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9000, It: 0, Loss Data: 8.600e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.370e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9001, It: 0, Loss Data: 9.188e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.235e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9002, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.283e+00, Loss Aux: 2.779e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9003, It: 0, Loss Data: 7.569e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.693e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9004, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.348e+00, Loss Aux: 2.772e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9005, It: 0, Loss Data: 9.833e-02, Loss Eqns: 2.312e+00, Loss Aux: 2.827e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9006, It: 0, Loss Data: 9.894e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.417e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9007, It: 0, Loss Data: 8.854e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.421e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9008, It: 0, Loss Data: 9.195e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.547e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9009, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.799e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9010, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.618e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 9011, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.727e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9012, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.492e+00, Loss Aux: 3.113e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9013, It: 0, Loss Data: 8.605e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.321e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9014, It: 0, Loss Data: 9.361e-02, Loss Eqns: 2.415e+00, Loss Aux: 3.187e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9015, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.370e+00, Loss Aux: 2.527e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9016, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.269e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9017, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.374e+00, Loss Aux: 2.087e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9018, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.369e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 9019, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.514e+00, Loss Aux: 2.956e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9020, It: 0, Loss Data: 9.450e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.101e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9021, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.367e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9022, It: 0, Loss Data: 8.444e-02, Loss Eqns: 2.564e+00, Loss Aux: 2.008e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 9023, It: 0, Loss Data: 9.941e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.237e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9024, It: 0, Loss Data: 8.906e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.763e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9025, It: 0, Loss Data: 8.984e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.284e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9026, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.549e+00, Loss Aux: 3.031e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9027, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.519e+00, Loss Aux: 2.509e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9028, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.494e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9029, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.579e+00, Loss Aux: 2.476e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9030, It: 0, Loss Data: 9.706e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.261e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9031, It: 0, Loss Data: 9.548e-02, Loss Eqns: 2.573e+00, Loss Aux: 2.033e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9032, It: 0, Loss Data: 8.094e-02, Loss Eqns: 2.482e+00, Loss Aux: 1.868e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9033, It: 0, Loss Data: 8.762e-02, Loss Eqns: 2.455e+00, Loss Aux: 2.062e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9034, It: 0, Loss Data: 8.419e-02, Loss Eqns: 2.518e+00, Loss Aux: 2.343e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9035, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.462e+00, Loss Aux: 3.201e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9036, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.625e+00, Loss Aux: 3.820e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9037, It: 0, Loss Data: 7.369e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.661e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9038, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.470e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9039, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.430e+00, Loss Aux: 1.894e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9040, It: 0, Loss Data: 8.559e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.255e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9041, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.354e+00, Loss Aux: 2.865e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 9042, It: 0, Loss Data: 9.814e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.500e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9043, It: 0, Loss Data: 9.287e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.195e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9044, It: 0, Loss Data: 8.180e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.505e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9045, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.977e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9046, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.477e+00, Loss Aux: 3.357e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9047, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.453e+00, Loss Aux: 3.545e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9048, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.657e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9049, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.466e+00, Loss Aux: 3.122e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9050, It: 0, Loss Data: 7.817e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.507e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9051, It: 0, Loss Data: 9.706e-02, Loss Eqns: 2.269e+00, Loss Aux: 2.106e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9052, It: 0, Loss Data: 7.169e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.055e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9053, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.235e+00, Loss Aux: 2.055e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9054, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.319e+00, Loss Aux: 1.733e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9055, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.331e+00, Loss Aux: 1.860e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9056, It: 0, Loss Data: 8.649e-02, Loss Eqns: 2.329e+00, Loss Aux: 2.348e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9057, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.301e+00, Loss Aux: 3.103e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9058, It: 0, Loss Data: 1.180e-01, Loss Eqns: 2.263e+00, Loss Aux: 3.203e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9059, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.340e+00, Loss Aux: 2.760e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9060, It: 0, Loss Data: 9.137e-02, Loss Eqns: 2.386e+00, Loss Aux: 2.165e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9061, It: 0, Loss Data: 9.130e-02, Loss Eqns: 2.361e+00, Loss Aux: 2.227e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9062, It: 0, Loss Data: 9.700e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.139e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9063, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.448e+00, Loss Aux: 3.176e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9064, It: 0, Loss Data: 9.363e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.781e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9065, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.519e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9066, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.441e+00, Loss Aux: 2.696e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9067, It: 0, Loss Data: 9.233e-02, Loss Eqns: 2.477e+00, Loss Aux: 2.833e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9068, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.791e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9069, It: 0, Loss Data: 9.134e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.413e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9070, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.489e+00, Loss Aux: 2.409e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9071, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.435e+00, Loss Aux: 2.619e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9072, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.572e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9073, It: 0, Loss Data: 9.211e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.332e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9074, It: 0, Loss Data: 8.102e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.214e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9075, It: 0, Loss Data: 8.617e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.585e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9076, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.488e+00, Loss Aux: 3.362e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9077, It: 0, Loss Data: 8.130e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.670e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9078, It: 0, Loss Data: 8.251e-02, Loss Eqns: 2.524e+00, Loss Aux: 3.189e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9079, It: 0, Loss Data: 9.924e-02, Loss Eqns: 2.467e+00, Loss Aux: 2.136e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9080, It: 0, Loss Data: 8.195e-02, Loss Eqns: 2.472e+00, Loss Aux: 1.636e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9081, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.819e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9082, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.556e+00, Loss Aux: 1.788e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9083, It: 0, Loss Data: 8.691e-02, Loss Eqns: 2.396e+00, Loss Aux: 1.829e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9084, It: 0, Loss Data: 8.716e-02, Loss Eqns: 2.515e+00, Loss Aux: 2.879e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9085, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.469e+00, Loss Aux: 3.278e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9086, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.090e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9087, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.668e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9088, It: 0, Loss Data: 8.955e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.109e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9089, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.545e+00, Loss Aux: 2.750e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9090, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.644e+00, Loss Aux: 3.269e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9091, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.410e+00, Loss Aux: 2.241e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9092, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.407e+00, Loss Aux: 1.873e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9093, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.013e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9094, It: 0, Loss Data: 8.816e-02, Loss Eqns: 2.481e+00, Loss Aux: 1.794e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9095, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.504e+00, Loss Aux: 1.723e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9096, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.529e+00, Loss Aux: 2.141e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9097, It: 0, Loss Data: 9.356e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.565e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9098, It: 0, Loss Data: 8.100e-02, Loss Eqns: 2.508e+00, Loss Aux: 2.870e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9099, It: 0, Loss Data: 8.763e-02, Loss Eqns: 2.616e+00, Loss Aux: 2.980e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9100, It: 0, Loss Data: 9.964e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.482e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9101, It: 0, Loss Data: 9.697e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.090e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9102, It: 0, Loss Data: 9.200e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.159e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9103, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.543e+00, Loss Aux: 2.272e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9104, It: 0, Loss Data: 8.648e-02, Loss Eqns: 2.498e+00, Loss Aux: 2.491e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 9105, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.534e+00, Loss Aux: 2.874e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9106, It: 0, Loss Data: 7.406e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.869e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9107, It: 0, Loss Data: 9.741e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.706e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9108, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.384e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9109, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.593e+00, Loss Aux: 1.491e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9110, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.809e+00, Loss Aux: 2.679e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9111, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.559e+00, Loss Aux: 1.971e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9112, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.420e+00, Loss Aux: 3.639e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9113, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.875e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9114, It: 0, Loss Data: 1.159e-01, Loss Eqns: 2.472e+00, Loss Aux: 2.288e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9115, It: 0, Loss Data: 8.996e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.432e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9116, It: 0, Loss Data: 9.800e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.725e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9117, It: 0, Loss Data: 9.785e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.398e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9118, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.396e+00, Loss Aux: 2.378e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9119, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.523e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9120, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.511e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9121, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.427e+00, Loss Aux: 2.386e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9122, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.431e+00, Loss Aux: 2.186e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9123, It: 0, Loss Data: 9.402e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.117e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9124, It: 0, Loss Data: 8.118e-02, Loss Eqns: 2.464e+00, Loss Aux: 2.897e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9125, It: 0, Loss Data: 9.721e-02, Loss Eqns: 2.494e+00, Loss Aux: 3.630e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9126, It: 0, Loss Data: 8.614e-02, Loss Eqns: 2.461e+00, Loss Aux: 2.087e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9127, It: 0, Loss Data: 9.547e-02, Loss Eqns: 2.468e+00, Loss Aux: 1.514e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9128, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.419e+00, Loss Aux: 2.578e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9129, It: 0, Loss Data: 9.936e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.098e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9130, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.455e+00, Loss Aux: 2.650e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9131, It: 0, Loss Data: 7.877e-02, Loss Eqns: 2.457e+00, Loss Aux: 2.215e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9132, It: 0, Loss Data: 8.460e-02, Loss Eqns: 2.544e+00, Loss Aux: 2.104e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9133, It: 0, Loss Data: 7.568e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.410e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9134, It: 0, Loss Data: 9.539e-02, Loss Eqns: 2.451e+00, Loss Aux: 3.027e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9135, It: 0, Loss Data: 8.403e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.851e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9136, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.494e+00, Loss Aux: 2.305e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9137, It: 0, Loss Data: 9.502e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.438e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9138, It: 0, Loss Data: 9.637e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.574e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9139, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.616e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9140, It: 0, Loss Data: 9.729e-02, Loss Eqns: 2.434e+00, Loss Aux: 2.193e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9141, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.116e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9142, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.877e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 9143, It: 0, Loss Data: 7.695e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.057e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9144, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.471e+00, Loss Aux: 2.476e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9145, It: 0, Loss Data: 8.162e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.328e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 9146, It: 0, Loss Data: 8.929e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.540e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9147, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.463e+00, Loss Aux: 2.826e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9148, It: 0, Loss Data: 9.130e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.403e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9149, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.597e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9150, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.706e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 9151, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.670e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9152, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.692e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9153, It: 0, Loss Data: 9.167e-02, Loss Eqns: 2.604e+00, Loss Aux: 1.943e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9154, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.520e+00, Loss Aux: 1.389e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9155, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.411e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9156, It: 0, Loss Data: 9.726e-02, Loss Eqns: 2.583e+00, Loss Aux: 3.336e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 9157, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.602e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9158, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.187e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9159, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.759e+00, Loss Aux: 2.744e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9160, It: 0, Loss Data: 9.266e-02, Loss Eqns: 2.434e+00, Loss Aux: 2.599e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9161, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.551e+00, Loss Aux: 2.253e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9162, It: 0, Loss Data: 9.757e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.867e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9163, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.420e+00, Loss Aux: 2.366e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9164, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.502e+00, Loss Aux: 1.869e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9165, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.528e+00, Loss Aux: 2.445e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9166, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.516e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9167, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.164e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9168, It: 0, Loss Data: 8.076e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.196e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 9169, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.492e+00, Loss Aux: 2.415e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9170, It: 0, Loss Data: 8.147e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.077e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9171, It: 0, Loss Data: 9.387e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.197e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 9172, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.664e+00, Loss Aux: 2.781e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9173, It: 0, Loss Data: 9.902e-02, Loss Eqns: 2.554e+00, Loss Aux: 2.793e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9174, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.583e+00, Loss Aux: 2.869e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9175, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.443e+00, Loss Aux: 2.926e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9176, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.454e+00, Loss Aux: 1.647e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9177, It: 0, Loss Data: 9.627e-02, Loss Eqns: 2.375e+00, Loss Aux: 1.617e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9178, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.882e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9179, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.367e+00, Loss Aux: 3.339e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9180, It: 0, Loss Data: 9.328e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.723e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9181, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.352e+00, Loss Aux: 2.038e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9182, It: 0, Loss Data: 8.888e-02, Loss Eqns: 2.418e+00, Loss Aux: 1.790e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9183, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.483e+00, Loss Aux: 2.431e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9184, It: 0, Loss Data: 9.253e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.719e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9185, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.510e+00, Loss Aux: 3.816e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9186, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.828e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9187, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.449e+00, Loss Aux: 2.473e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9188, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.388e+00, Loss Aux: 2.256e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9189, It: 0, Loss Data: 9.868e-02, Loss Eqns: 2.474e+00, Loss Aux: 1.636e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9190, It: 0, Loss Data: 9.302e-02, Loss Eqns: 2.354e+00, Loss Aux: 1.552e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9191, It: 0, Loss Data: 9.813e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.198e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 9192, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.445e+00, Loss Aux: 3.190e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9193, It: 0, Loss Data: 8.966e-02, Loss Eqns: 2.438e+00, Loss Aux: 3.410e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9194, It: 0, Loss Data: 9.652e-02, Loss Eqns: 2.516e+00, Loss Aux: 3.108e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9195, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.960e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9196, It: 0, Loss Data: 9.277e-02, Loss Eqns: 2.457e+00, Loss Aux: 3.131e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9197, It: 0, Loss Data: 9.042e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.483e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9198, It: 0, Loss Data: 9.157e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.810e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9199, It: 0, Loss Data: 9.173e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.116e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 9200, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.519e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9201, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.003e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9202, It: 0, Loss Data: 9.121e-02, Loss Eqns: 2.413e+00, Loss Aux: 1.941e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9203, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.015e+00, Loss Aux: 3.349e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9204, It: 0, Loss Data: 1.737e-01, Loss Eqns: 3.509e+00, Loss Aux: 1.983e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9205, It: 0, Loss Data: 1.142e-01, Loss Eqns: 3.424e+00, Loss Aux: 3.074e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9206, It: 0, Loss Data: 1.712e-01, Loss Eqns: 4.036e+00, Loss Aux: 3.891e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9207, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.966e+00, Loss Aux: 1.427e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 9208, It: 0, Loss Data: 1.503e-01, Loss Eqns: 3.166e+00, Loss Aux: 7.559e-03, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9209, It: 0, Loss Data: 1.261e-01, Loss Eqns: 2.624e+00, Loss Aux: 4.339e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9210, It: 0, Loss Data: 1.488e-01, Loss Eqns: 2.871e+00, Loss Aux: 7.386e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9211, It: 0, Loss Data: 1.383e-01, Loss Eqns: 2.646e+00, Loss Aux: 4.520e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9212, It: 0, Loss Data: 1.450e-01, Loss Eqns: 2.555e+00, Loss Aux: 2.342e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 9213, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.467e+00, Loss Aux: 2.745e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9214, It: 0, Loss Data: 1.388e-01, Loss Eqns: 2.816e+00, Loss Aux: 3.140e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9215, It: 0, Loss Data: 1.335e-01, Loss Eqns: 2.562e+00, Loss Aux: 1.735e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9216, It: 0, Loss Data: 1.449e-01, Loss Eqns: 2.623e+00, Loss Aux: 2.818e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9217, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.551e+00, Loss Aux: 3.887e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 9218, It: 0, Loss Data: 1.220e-01, Loss Eqns: 2.520e+00, Loss Aux: 4.225e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9219, It: 0, Loss Data: 1.301e-01, Loss Eqns: 2.463e+00, Loss Aux: 2.848e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9220, It: 0, Loss Data: 1.293e-01, Loss Eqns: 2.424e+00, Loss Aux: 2.901e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9221, It: 0, Loss Data: 1.872e-01, Loss Eqns: 2.531e+00, Loss Aux: 2.451e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9222, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.568e+00, Loss Aux: 4.026e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9223, It: 0, Loss Data: 1.506e-01, Loss Eqns: 2.620e+00, Loss Aux: 7.052e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9224, It: 0, Loss Data: 1.339e-01, Loss Eqns: 2.484e+00, Loss Aux: 6.265e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9225, It: 0, Loss Data: 1.890e-01, Loss Eqns: 2.871e+00, Loss Aux: 3.888e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9226, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.393e+00, Loss Aux: 3.914e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9227, It: 0, Loss Data: 1.559e-01, Loss Eqns: 3.216e+00, Loss Aux: 5.076e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9228, It: 0, Loss Data: 9.778e-02, Loss Eqns: 2.527e+00, Loss Aux: 4.273e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9229, It: 0, Loss Data: 1.400e-01, Loss Eqns: 2.975e+00, Loss Aux: 2.510e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9230, It: 0, Loss Data: 1.215e-01, Loss Eqns: 2.420e+00, Loss Aux: 2.290e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9231, It: 0, Loss Data: 1.305e-01, Loss Eqns: 2.780e+00, Loss Aux: 3.332e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9232, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.359e+00, Loss Aux: 2.712e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9233, It: 0, Loss Data: 1.095e-01, Loss Eqns: 2.690e+00, Loss Aux: 2.133e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9234, It: 0, Loss Data: 1.194e-01, Loss Eqns: 2.421e+00, Loss Aux: 3.312e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9235, It: 0, Loss Data: 1.272e-01, Loss Eqns: 2.624e+00, Loss Aux: 4.986e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9236, It: 0, Loss Data: 1.225e-01, Loss Eqns: 2.368e+00, Loss Aux: 4.563e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9237, It: 0, Loss Data: 1.206e-01, Loss Eqns: 2.418e+00, Loss Aux: 3.448e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9238, It: 0, Loss Data: 1.244e-01, Loss Eqns: 2.449e+00, Loss Aux: 3.036e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9239, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.498e+00, Loss Aux: 2.501e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9240, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.540e+00, Loss Aux: 1.410e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9241, It: 0, Loss Data: 1.254e-01, Loss Eqns: 2.531e+00, Loss Aux: 1.995e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9242, It: 0, Loss Data: 9.250e-02, Loss Eqns: 2.464e+00, Loss Aux: 4.200e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9243, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.492e+00, Loss Aux: 5.086e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9244, It: 0, Loss Data: 9.480e-02, Loss Eqns: 2.570e+00, Loss Aux: 3.433e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9245, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.527e+00, Loss Aux: 2.036e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9246, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.514e+00, Loss Aux: 1.882e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9247, It: 0, Loss Data: 1.129e-01, Loss Eqns: 2.488e+00, Loss Aux: 3.052e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9248, It: 0, Loss Data: 9.986e-02, Loss Eqns: 2.482e+00, Loss Aux: 3.360e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9249, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.374e+00, Loss Aux: 3.140e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9250, It: 0, Loss Data: 9.940e-02, Loss Eqns: 2.479e+00, Loss Aux: 3.752e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9251, It: 0, Loss Data: 8.494e-02, Loss Eqns: 2.572e+00, Loss Aux: 4.636e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9252, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.392e+00, Loss Aux: 4.417e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9253, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.435e+00, Loss Aux: 3.236e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9254, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.490e+00, Loss Aux: 2.738e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9255, It: 0, Loss Data: 1.484e-01, Loss Eqns: 2.962e+00, Loss Aux: 3.576e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9256, It: 0, Loss Data: 2.208e-01, Loss Eqns: 3.503e+00, Loss Aux: 1.579e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9257, It: 0, Loss Data: 1.911e-01, Loss Eqns: 3.471e+00, Loss Aux: 2.252e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9258, It: 0, Loss Data: 1.260e-01, Loss Eqns: 2.916e+00, Loss Aux: 4.216e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9259, It: 0, Loss Data: 1.873e-01, Loss Eqns: 3.521e+00, Loss Aux: 3.452e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9260, It: 0, Loss Data: 1.390e-01, Loss Eqns: 2.528e+00, Loss Aux: 1.504e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9261, It: 0, Loss Data: 1.718e-01, Loss Eqns: 3.027e+00, Loss Aux: 1.580e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9262, It: 0, Loss Data: 1.497e-01, Loss Eqns: 2.691e+00, Loss Aux: 4.731e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9263, It: 0, Loss Data: 1.516e-01, Loss Eqns: 2.728e+00, Loss Aux: 7.189e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9264, It: 0, Loss Data: 1.305e-01, Loss Eqns: 2.695e+00, Loss Aux: 5.783e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9265, It: 0, Loss Data: 1.539e-01, Loss Eqns: 2.472e+00, Loss Aux: 3.796e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9266, It: 0, Loss Data: 1.217e-01, Loss Eqns: 2.397e+00, Loss Aux: 2.033e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9267, It: 0, Loss Data: 2.360e-01, Loss Eqns: 2.723e+00, Loss Aux: 5.939e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9268, It: 0, Loss Data: 1.406e-01, Loss Eqns: 2.226e+00, Loss Aux: 3.682e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9269, It: 0, Loss Data: 2.086e-01, Loss Eqns: 2.478e+00, Loss Aux: 2.574e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9270, It: 0, Loss Data: 1.513e-01, Loss Eqns: 2.338e+00, Loss Aux: 4.093e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9271, It: 0, Loss Data: 1.438e-01, Loss Eqns: 2.527e+00, Loss Aux: 6.010e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 9272, It: 0, Loss Data: 1.557e-01, Loss Eqns: 2.411e+00, Loss Aux: 5.171e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9273, It: 0, Loss Data: 1.293e-01, Loss Eqns: 2.427e+00, Loss Aux: 3.075e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9274, It: 0, Loss Data: 1.341e-01, Loss Eqns: 2.457e+00, Loss Aux: 2.414e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 9275, It: 0, Loss Data: 1.228e-01, Loss Eqns: 2.389e+00, Loss Aux: 2.627e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9276, It: 0, Loss Data: 2.066e-01, Loss Eqns: 3.163e+00, Loss Aux: 4.611e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9277, It: 0, Loss Data: 1.313e-01, Loss Eqns: 2.600e+00, Loss Aux: 3.493e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9278, It: 0, Loss Data: 1.741e-01, Loss Eqns: 2.693e+00, Loss Aux: 2.600e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9279, It: 0, Loss Data: 1.571e-01, Loss Eqns: 2.616e+00, Loss Aux: 3.377e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9280, It: 0, Loss Data: 1.355e-01, Loss Eqns: 2.462e+00, Loss Aux: 5.033e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9281, It: 0, Loss Data: 1.214e-01, Loss Eqns: 2.683e+00, Loss Aux: 4.581e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9282, It: 0, Loss Data: 1.280e-01, Loss Eqns: 2.431e+00, Loss Aux: 2.705e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9283, It: 0, Loss Data: 1.514e-01, Loss Eqns: 2.455e+00, Loss Aux: 2.823e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9284, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.411e+00, Loss Aux: 4.758e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9285, It: 0, Loss Data: 1.452e-01, Loss Eqns: 2.524e+00, Loss Aux: 5.991e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9286, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.462e+00, Loss Aux: 4.292e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9287, It: 0, Loss Data: 1.434e-01, Loss Eqns: 2.371e+00, Loss Aux: 2.236e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9288, It: 0, Loss Data: 1.330e-01, Loss Eqns: 2.507e+00, Loss Aux: 2.045e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9289, It: 0, Loss Data: 1.205e-01, Loss Eqns: 2.551e+00, Loss Aux: 3.007e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9290, It: 0, Loss Data: 1.491e-01, Loss Eqns: 2.707e+00, Loss Aux: 4.868e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9291, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.503e+00, Loss Aux: 4.117e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9292, It: 0, Loss Data: 1.249e-01, Loss Eqns: 2.371e+00, Loss Aux: 3.035e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9293, It: 0, Loss Data: 1.230e-01, Loss Eqns: 2.378e+00, Loss Aux: 3.322e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9294, It: 0, Loss Data: 1.207e-01, Loss Eqns: 2.430e+00, Loss Aux: 5.512e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9295, It: 0, Loss Data: 1.398e-01, Loss Eqns: 2.499e+00, Loss Aux: 6.425e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9296, It: 0, Loss Data: 9.577e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.412e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9297, It: 0, Loss Data: 1.325e-01, Loss Eqns: 2.440e+00, Loss Aux: 2.677e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9298, It: 0, Loss Data: 9.330e-02, Loss Eqns: 2.403e+00, Loss Aux: 1.916e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9299, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.523e+00, Loss Aux: 2.549e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9300, It: 0, Loss Data: 8.311e-02, Loss Eqns: 2.551e+00, Loss Aux: 2.875e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9301, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.523e+00, Loss Aux: 2.827e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9302, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.481e+00, Loss Aux: 3.818e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9303, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.480e+00, Loss Aux: 4.635e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9304, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.502e+00, Loss Aux: 4.011e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9305, It: 0, Loss Data: 9.879e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.879e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 9306, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.914e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9307, It: 0, Loss Data: 8.430e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.642e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9308, It: 0, Loss Data: 9.545e-02, Loss Eqns: 2.487e+00, Loss Aux: 4.337e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9309, It: 0, Loss Data: 8.986e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.710e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9310, It: 0, Loss Data: 8.366e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.871e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9311, It: 0, Loss Data: 9.757e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.462e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9312, It: 0, Loss Data: 9.927e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.468e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9313, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.394e+00, Loss Aux: 2.760e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9314, It: 0, Loss Data: 9.971e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.864e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9315, It: 0, Loss Data: 1.175e-01, Loss Eqns: 2.436e+00, Loss Aux: 3.345e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9316, It: 0, Loss Data: 9.750e-02, Loss Eqns: 2.400e+00, Loss Aux: 4.030e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9317, It: 0, Loss Data: 9.243e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.142e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9318, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.624e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9319, It: 0, Loss Data: 9.223e-02, Loss Eqns: 2.443e+00, Loss Aux: 3.032e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 9320, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.215e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9321, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.480e+00, Loss Aux: 3.509e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9322, It: 0, Loss Data: 9.731e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.026e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9323, It: 0, Loss Data: 9.797e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.516e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9324, It: 0, Loss Data: 9.631e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.617e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9325, It: 0, Loss Data: 9.998e-02, Loss Eqns: 2.525e+00, Loss Aux: 2.579e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9326, It: 0, Loss Data: 9.436e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.705e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9327, It: 0, Loss Data: 8.325e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.133e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9328, It: 0, Loss Data: 9.981e-02, Loss Eqns: 2.493e+00, Loss Aux: 3.595e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9329, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.430e+00, Loss Aux: 4.081e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9330, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.471e+00, Loss Aux: 3.952e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9331, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.202e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9332, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.558e+00, Loss Aux: 2.705e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9333, It: 0, Loss Data: 9.276e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.757e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9334, It: 0, Loss Data: 9.184e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.936e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9335, It: 0, Loss Data: 8.602e-02, Loss Eqns: 2.455e+00, Loss Aux: 3.338e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9336, It: 0, Loss Data: 9.250e-02, Loss Eqns: 2.511e+00, Loss Aux: 3.610e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9337, It: 0, Loss Data: 9.678e-02, Loss Eqns: 2.518e+00, Loss Aux: 3.242e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9338, It: 0, Loss Data: 9.389e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.830e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9339, It: 0, Loss Data: 8.978e-02, Loss Eqns: 2.420e+00, Loss Aux: 2.994e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9340, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.481e+00, Loss Aux: 3.259e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9341, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.060e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9342, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.771e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9343, It: 0, Loss Data: 7.778e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.704e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9344, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.481e+00, Loss Aux: 2.649e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9345, It: 0, Loss Data: 9.883e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.576e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 9346, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.497e+00, Loss Aux: 2.863e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 9347, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.681e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9348, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.265e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9349, It: 0, Loss Data: 8.363e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.973e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 9350, It: 0, Loss Data: 8.869e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.312e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9351, It: 0, Loss Data: 9.025e-02, Loss Eqns: 2.446e+00, Loss Aux: 3.034e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9352, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.168e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9353, It: 0, Loss Data: 9.076e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.681e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9354, It: 0, Loss Data: 7.959e-02, Loss Eqns: 2.350e+00, Loss Aux: 2.488e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9355, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.880e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9356, It: 0, Loss Data: 8.824e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.606e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9357, It: 0, Loss Data: 9.553e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.527e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 9358, It: 0, Loss Data: 8.213e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.781e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9359, It: 0, Loss Data: 8.345e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.475e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9360, It: 0, Loss Data: 9.466e-02, Loss Eqns: 2.454e+00, Loss Aux: 3.264e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9361, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.425e+00, Loss Aux: 3.587e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9362, It: 0, Loss Data: 9.409e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.158e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9363, It: 0, Loss Data: 9.765e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.025e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9364, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.375e+00, Loss Aux: 3.213e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 9365, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.680e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9366, It: 0, Loss Data: 9.087e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.319e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9367, It: 0, Loss Data: 8.412e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.431e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9368, It: 0, Loss Data: 8.664e-02, Loss Eqns: 2.449e+00, Loss Aux: 3.035e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9369, It: 0, Loss Data: 8.800e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.388e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9370, It: 0, Loss Data: 7.986e-02, Loss Eqns: 2.479e+00, Loss Aux: 3.387e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9371, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.520e+00, Loss Aux: 3.408e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9372, It: 0, Loss Data: 9.471e-02, Loss Eqns: 2.645e+00, Loss Aux: 3.023e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9373, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.380e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9374, It: 0, Loss Data: 7.848e-02, Loss Eqns: 2.449e+00, Loss Aux: 2.421e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9375, It: 0, Loss Data: 9.881e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.278e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9376, It: 0, Loss Data: 8.052e-02, Loss Eqns: 2.453e+00, Loss Aux: 4.268e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9377, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.997e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9378, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.799e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9379, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.340e+00, Loss Aux: 2.140e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9380, It: 0, Loss Data: 7.620e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.391e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9381, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.439e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9382, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.406e+00, Loss Aux: 2.491e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 9383, It: 0, Loss Data: 9.401e-02, Loss Eqns: 2.466e+00, Loss Aux: 2.887e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9384, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.383e+00, Loss Aux: 3.229e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9385, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.394e+00, Loss Aux: 3.394e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9386, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.382e+00, Loss Aux: 2.548e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9387, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.238e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9388, It: 0, Loss Data: 8.152e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.592e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9389, It: 0, Loss Data: 9.777e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.086e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 9390, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.582e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9391, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.555e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9392, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.347e+00, Loss Aux: 3.150e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 9393, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.700e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9394, It: 0, Loss Data: 9.167e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.612e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9395, It: 0, Loss Data: 9.439e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.092e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9396, It: 0, Loss Data: 7.852e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.506e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9397, It: 0, Loss Data: 9.702e-02, Loss Eqns: 2.503e+00, Loss Aux: 3.492e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9398, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.546e+00, Loss Aux: 2.932e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9399, It: 0, Loss Data: 9.208e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.781e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9400, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.574e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9401, It: 0, Loss Data: 9.151e-02, Loss Eqns: 2.553e+00, Loss Aux: 2.214e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9402, It: 0, Loss Data: 8.968e-02, Loss Eqns: 2.578e+00, Loss Aux: 1.831e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9403, It: 0, Loss Data: 9.397e-02, Loss Eqns: 2.542e+00, Loss Aux: 1.814e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9404, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.591e+00, Loss Aux: 2.684e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9405, It: 0, Loss Data: 8.549e-02, Loss Eqns: 2.559e+00, Loss Aux: 3.848e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9406, It: 0, Loss Data: 9.548e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.320e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9407, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.559e+00, Loss Aux: 4.108e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9408, It: 0, Loss Data: 7.750e-02, Loss Eqns: 2.598e+00, Loss Aux: 3.960e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9409, It: 0, Loss Data: 9.461e-02, Loss Eqns: 2.424e+00, Loss Aux: 4.050e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9410, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.467e+00, Loss Aux: 3.709e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9411, It: 0, Loss Data: 7.507e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.669e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9412, It: 0, Loss Data: 8.064e-02, Loss Eqns: 2.507e+00, Loss Aux: 1.939e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9413, It: 0, Loss Data: 8.963e-02, Loss Eqns: 2.422e+00, Loss Aux: 1.850e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9414, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.456e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9415, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.287e+00, Loss Aux: 3.062e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9416, It: 0, Loss Data: 9.641e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.215e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9417, It: 0, Loss Data: 8.795e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.814e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9418, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.637e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 9419, It: 0, Loss Data: 8.378e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.928e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9420, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.618e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9421, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.475e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9422, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.355e+00, Loss Aux: 2.378e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9423, It: 0, Loss Data: 8.956e-02, Loss Eqns: 2.364e+00, Loss Aux: 1.956e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9424, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.382e+00, Loss Aux: 2.176e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9425, It: 0, Loss Data: 8.942e-02, Loss Eqns: 2.382e+00, Loss Aux: 2.806e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9426, It: 0, Loss Data: 9.416e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.887e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9427, It: 0, Loss Data: 9.884e-02, Loss Eqns: 2.292e+00, Loss Aux: 2.708e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9428, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.356e+00, Loss Aux: 3.082e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9429, It: 0, Loss Data: 8.427e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.388e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9430, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.212e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9431, It: 0, Loss Data: 8.432e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.176e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9432, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.428e+00, Loss Aux: 1.624e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9433, It: 0, Loss Data: 7.620e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.004e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9434, It: 0, Loss Data: 9.782e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.338e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9435, It: 0, Loss Data: 9.501e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.653e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9436, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.946e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9437, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.368e+00, Loss Aux: 2.429e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9438, It: 0, Loss Data: 8.364e-02, Loss Eqns: 2.517e+00, Loss Aux: 2.373e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9439, It: 0, Loss Data: 9.054e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.004e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9440, It: 0, Loss Data: 9.503e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.261e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9441, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.757e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9442, It: 0, Loss Data: 9.684e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.541e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9443, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.318e+00, Loss Aux: 2.876e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9444, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.120e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9445, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.374e+00, Loss Aux: 2.457e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9446, It: 0, Loss Data: 7.856e-02, Loss Eqns: 2.400e+00, Loss Aux: 1.822e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9447, It: 0, Loss Data: 8.626e-02, Loss Eqns: 2.539e+00, Loss Aux: 1.972e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9448, It: 0, Loss Data: 9.294e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.911e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9449, It: 0, Loss Data: 9.066e-02, Loss Eqns: 2.432e+00, Loss Aux: 3.756e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 9450, It: 0, Loss Data: 9.316e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.523e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9451, It: 0, Loss Data: 7.263e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.871e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9452, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.530e+00, Loss Aux: 2.400e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9453, It: 0, Loss Data: 8.339e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.288e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9454, It: 0, Loss Data: 8.996e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.430e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9455, It: 0, Loss Data: 8.178e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.411e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9456, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.747e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9457, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.432e+00, Loss Aux: 3.142e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9458, It: 0, Loss Data: 9.382e-02, Loss Eqns: 2.480e+00, Loss Aux: 3.572e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9459, It: 0, Loss Data: 9.635e-02, Loss Eqns: 2.474e+00, Loss Aux: 3.468e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9460, It: 0, Loss Data: 7.904e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.448e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9461, It: 0, Loss Data: 8.668e-02, Loss Eqns: 2.457e+00, Loss Aux: 1.765e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9462, It: 0, Loss Data: 9.410e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.242e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9463, It: 0, Loss Data: 8.024e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.177e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9464, It: 0, Loss Data: 9.950e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.128e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9465, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.271e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9466, It: 0, Loss Data: 8.164e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.069e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9467, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.442e+00, Loss Aux: 2.515e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 9468, It: 0, Loss Data: 8.923e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.961e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9469, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.396e+00, Loss Aux: 2.750e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9470, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.442e+00, Loss Aux: 2.339e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9471, It: 0, Loss Data: 9.069e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.473e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9472, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.673e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9473, It: 0, Loss Data: 8.626e-02, Loss Eqns: 2.314e+00, Loss Aux: 2.856e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9474, It: 0, Loss Data: 8.013e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.506e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9475, It: 0, Loss Data: 8.908e-02, Loss Eqns: 2.440e+00, Loss Aux: 1.998e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9476, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.416e+00, Loss Aux: 1.945e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9477, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.369e+00, Loss Aux: 2.462e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9478, It: 0, Loss Data: 9.874e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.475e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9479, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.320e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 9480, It: 0, Loss Data: 9.531e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.433e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9481, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.045e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9482, It: 0, Loss Data: 8.468e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.485e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9483, It: 0, Loss Data: 8.149e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.957e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9484, It: 0, Loss Data: 8.961e-02, Loss Eqns: 2.393e+00, Loss Aux: 2.603e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9485, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.331e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9486, It: 0, Loss Data: 8.905e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.406e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9487, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.355e+00, Loss Aux: 2.530e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9488, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.336e+00, Loss Aux: 1.901e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9489, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.346e+00, Loss Aux: 1.694e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9490, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.052e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9491, It: 0, Loss Data: 9.313e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.765e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9492, It: 0, Loss Data: 9.920e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.058e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9493, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.460e+00, Loss Aux: 3.204e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9494, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.428e+00, Loss Aux: 3.136e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9495, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.703e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9496, It: 0, Loss Data: 8.977e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.383e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9497, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.385e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9498, It: 0, Loss Data: 8.297e-02, Loss Eqns: 2.536e+00, Loss Aux: 2.525e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9499, It: 0, Loss Data: 8.566e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.408e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9500, It: 0, Loss Data: 9.030e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.125e-02, Time: 0.235, Learning Rate: 1.0e-03\n",
      "Epoch: 9501, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.334e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9502, It: 0, Loss Data: 9.846e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.719e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9503, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.563e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9504, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.507e+00, Loss Aux: 2.719e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9505, It: 0, Loss Data: 9.799e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.307e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9506, It: 0, Loss Data: 7.612e-02, Loss Eqns: 2.428e+00, Loss Aux: 1.992e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 9507, It: 0, Loss Data: 8.748e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.250e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9508, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.423e+00, Loss Aux: 2.963e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9509, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.389e+00, Loss Aux: 3.277e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9510, It: 0, Loss Data: 8.813e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.907e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9511, It: 0, Loss Data: 9.135e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.427e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9512, It: 0, Loss Data: 8.704e-02, Loss Eqns: 2.464e+00, Loss Aux: 2.066e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9513, It: 0, Loss Data: 9.764e-02, Loss Eqns: 2.484e+00, Loss Aux: 2.282e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9514, It: 0, Loss Data: 7.934e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.830e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9515, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.468e+00, Loss Aux: 2.841e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9516, It: 0, Loss Data: 8.828e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.369e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 9517, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.284e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9518, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.422e+00, Loss Aux: 2.605e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9519, It: 0, Loss Data: 9.747e-02, Loss Eqns: 2.396e+00, Loss Aux: 2.652e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9520, It: 0, Loss Data: 8.911e-02, Loss Eqns: 2.344e+00, Loss Aux: 2.230e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9521, It: 0, Loss Data: 9.059e-02, Loss Eqns: 2.293e+00, Loss Aux: 2.190e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9522, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.946e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9523, It: 0, Loss Data: 9.412e-02, Loss Eqns: 2.544e+00, Loss Aux: 3.391e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9524, It: 0, Loss Data: 9.221e-02, Loss Eqns: 2.439e+00, Loss Aux: 3.058e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9525, It: 0, Loss Data: 9.564e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.270e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9526, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.516e+00, Loss Aux: 1.938e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9527, It: 0, Loss Data: 9.649e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.058e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9528, It: 0, Loss Data: 7.664e-02, Loss Eqns: 2.468e+00, Loss Aux: 3.096e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9529, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.390e+00, Loss Aux: 3.850e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9530, It: 0, Loss Data: 8.021e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.099e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9531, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.386e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9532, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.324e+00, Loss Aux: 1.939e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9533, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.123e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9534, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.425e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9535, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.392e+00, Loss Aux: 2.205e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9536, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.458e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9537, It: 0, Loss Data: 9.618e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.142e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9538, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.449e+00, Loss Aux: 3.404e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9539, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.643e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9540, It: 0, Loss Data: 9.904e-02, Loss Eqns: 2.589e+00, Loss Aux: 1.763e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9541, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.350e+00, Loss Aux: 1.739e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9542, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.455e+00, Loss Aux: 3.054e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9543, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.486e+00, Loss Aux: 3.720e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9544, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.869e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9545, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.424e+00, Loss Aux: 1.927e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9546, It: 0, Loss Data: 8.829e-02, Loss Eqns: 2.442e+00, Loss Aux: 2.506e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9547, It: 0, Loss Data: 8.204e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.209e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9548, It: 0, Loss Data: 9.116e-02, Loss Eqns: 2.453e+00, Loss Aux: 3.225e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9549, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.612e+00, Loss Aux: 2.920e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9550, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.819e+00, Loss Aux: 1.933e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9551, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.609e+00, Loss Aux: 2.227e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9552, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.680e+00, Loss Aux: 2.806e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9553, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.473e+00, Loss Aux: 1.809e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9554, It: 0, Loss Data: 1.175e-01, Loss Eqns: 2.574e+00, Loss Aux: 1.400e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9555, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.438e+00, Loss Aux: 2.833e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9556, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.812e+00, Loss Aux: 5.070e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9557, It: 0, Loss Data: 9.830e-02, Loss Eqns: 2.866e+00, Loss Aux: 4.653e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9558, It: 0, Loss Data: 9.678e-02, Loss Eqns: 2.850e+00, Loss Aux: 3.184e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9559, It: 0, Loss Data: 8.330e-02, Loss Eqns: 2.632e+00, Loss Aux: 2.224e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9560, It: 0, Loss Data: 1.222e-01, Loss Eqns: 2.978e+00, Loss Aux: 1.888e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9561, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.639e+00, Loss Aux: 1.496e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9562, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.642e+00, Loss Aux: 1.890e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9563, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.516e+00, Loss Aux: 3.097e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9564, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.663e+00, Loss Aux: 4.150e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9565, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.535e+00, Loss Aux: 4.011e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9566, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.580e+00, Loss Aux: 3.482e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9567, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.456e+00, Loss Aux: 3.337e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9568, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.575e+00, Loss Aux: 3.047e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 9569, It: 0, Loss Data: 9.307e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.436e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9570, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.490e+00, Loss Aux: 3.006e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9571, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.449e+00, Loss Aux: 4.171e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9572, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.387e+00, Loss Aux: 3.342e-02, Time: 0.141, Learning Rate: 1.0e-03\n",
      "Epoch: 9573, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.389e+00, Loss Aux: 1.630e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9574, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.422e+00, Loss Aux: 1.321e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9575, It: 0, Loss Data: 9.227e-02, Loss Eqns: 2.504e+00, Loss Aux: 2.610e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9576, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.999e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9577, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.434e+00, Loss Aux: 3.901e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9578, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.380e+00, Loss Aux: 3.337e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9579, It: 0, Loss Data: 9.520e-02, Loss Eqns: 2.536e+00, Loss Aux: 3.211e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9580, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.356e+00, Loss Aux: 2.889e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9581, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.539e+00, Loss Aux: 2.370e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9582, It: 0, Loss Data: 9.179e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.469e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9583, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.565e+00, Loss Aux: 2.593e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9584, It: 0, Loss Data: 8.639e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.440e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9585, It: 0, Loss Data: 8.917e-02, Loss Eqns: 2.512e+00, Loss Aux: 2.625e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9586, It: 0, Loss Data: 9.095e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.818e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9587, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.601e+00, Loss Aux: 2.676e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9588, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.426e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9589, It: 0, Loss Data: 9.421e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.287e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9590, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.492e+00, Loss Aux: 3.691e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9591, It: 0, Loss Data: 8.135e-02, Loss Eqns: 2.487e+00, Loss Aux: 2.328e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9592, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.427e+00, Loss Aux: 1.642e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9593, It: 0, Loss Data: 8.214e-02, Loss Eqns: 2.424e+00, Loss Aux: 2.036e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9594, It: 0, Loss Data: 9.335e-02, Loss Eqns: 2.510e+00, Loss Aux: 3.081e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9595, It: 0, Loss Data: 9.512e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.204e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9596, It: 0, Loss Data: 9.366e-02, Loss Eqns: 2.507e+00, Loss Aux: 2.515e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9597, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.743e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9598, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.571e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9599, It: 0, Loss Data: 9.530e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.948e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9600, It: 0, Loss Data: 9.556e-02, Loss Eqns: 2.441e+00, Loss Aux: 3.215e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 9601, It: 0, Loss Data: 8.287e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.068e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9602, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.446e+00, Loss Aux: 1.853e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9603, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.300e+00, Loss Aux: 2.466e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9604, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.459e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9605, It: 0, Loss Data: 8.405e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.035e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9606, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.309e+00, Loss Aux: 2.216e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9607, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.360e+00, Loss Aux: 2.056e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9608, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.303e+00, Loss Aux: 2.601e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9609, It: 0, Loss Data: 8.763e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.467e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9610, It: 0, Loss Data: 8.142e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.231e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9611, It: 0, Loss Data: 9.285e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.670e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9612, It: 0, Loss Data: 8.486e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.782e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9613, It: 0, Loss Data: 9.362e-02, Loss Eqns: 2.320e+00, Loss Aux: 2.612e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9614, It: 0, Loss Data: 9.328e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.716e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9615, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.806e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9616, It: 0, Loss Data: 9.410e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.185e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9617, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.396e+00, Loss Aux: 1.928e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9618, It: 0, Loss Data: 7.995e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.258e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9619, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.763e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9620, It: 0, Loss Data: 9.635e-02, Loss Eqns: 2.462e+00, Loss Aux: 2.781e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9621, It: 0, Loss Data: 8.316e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.370e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9622, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.646e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9623, It: 0, Loss Data: 8.518e-02, Loss Eqns: 2.425e+00, Loss Aux: 3.501e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9624, It: 0, Loss Data: 8.071e-02, Loss Eqns: 2.476e+00, Loss Aux: 3.762e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9625, It: 0, Loss Data: 7.767e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.075e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9626, It: 0, Loss Data: 8.518e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.409e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9627, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.361e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9628, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.275e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9629, It: 0, Loss Data: 8.977e-02, Loss Eqns: 2.327e+00, Loss Aux: 2.352e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9630, It: 0, Loss Data: 8.094e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.600e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9631, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.341e+00, Loss Aux: 2.775e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9632, It: 0, Loss Data: 9.517e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.704e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9633, It: 0, Loss Data: 9.607e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.728e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9634, It: 0, Loss Data: 9.333e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.767e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9635, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.047e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9636, It: 0, Loss Data: 8.937e-02, Loss Eqns: 2.409e+00, Loss Aux: 3.576e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9637, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.392e+00, Loss Aux: 3.598e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9638, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.344e+00, Loss Aux: 2.900e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9639, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.498e+00, Loss Aux: 2.513e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9640, It: 0, Loss Data: 8.130e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.653e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9641, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.456e+00, Loss Aux: 3.371e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9642, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.522e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9643, It: 0, Loss Data: 8.886e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.902e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9644, It: 0, Loss Data: 8.857e-02, Loss Eqns: 2.367e+00, Loss Aux: 2.348e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9645, It: 0, Loss Data: 8.574e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.343e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9646, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.271e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9647, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.232e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9648, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.455e+00, Loss Aux: 2.352e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9649, It: 0, Loss Data: 8.719e-02, Loss Eqns: 2.408e+00, Loss Aux: 2.388e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9650, It: 0, Loss Data: 8.361e-02, Loss Eqns: 2.413e+00, Loss Aux: 2.395e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9651, It: 0, Loss Data: 8.778e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.047e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9652, It: 0, Loss Data: 8.942e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.929e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9653, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.318e+00, Loss Aux: 2.849e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9654, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.383e+00, Loss Aux: 2.707e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9655, It: 0, Loss Data: 8.864e-02, Loss Eqns: 2.300e+00, Loss Aux: 2.544e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9656, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.276e+00, Loss Aux: 2.504e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9657, It: 0, Loss Data: 9.259e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.489e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9658, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.269e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9659, It: 0, Loss Data: 8.589e-02, Loss Eqns: 2.363e+00, Loss Aux: 2.276e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9660, It: 0, Loss Data: 9.006e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.745e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9661, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.391e+00, Loss Aux: 3.311e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9662, It: 0, Loss Data: 9.272e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.650e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9663, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.144e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9664, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.354e+00, Loss Aux: 2.857e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 9665, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.590e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9666, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.468e+00, Loss Aux: 2.212e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9667, It: 0, Loss Data: 8.541e-02, Loss Eqns: 2.412e+00, Loss Aux: 1.824e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9668, It: 0, Loss Data: 9.797e-02, Loss Eqns: 2.533e+00, Loss Aux: 1.964e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9669, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.457e+00, Loss Aux: 2.031e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9670, It: 0, Loss Data: 8.000e-02, Loss Eqns: 2.463e+00, Loss Aux: 1.863e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9671, It: 0, Loss Data: 8.653e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.251e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9672, It: 0, Loss Data: 9.493e-02, Loss Eqns: 2.479e+00, Loss Aux: 3.470e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 9673, It: 0, Loss Data: 9.330e-02, Loss Eqns: 2.418e+00, Loss Aux: 4.158e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9674, It: 0, Loss Data: 9.350e-02, Loss Eqns: 2.375e+00, Loss Aux: 4.114e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9675, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.414e+00, Loss Aux: 3.693e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9676, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.967e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9677, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.314e+00, Loss Aux: 2.200e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9678, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.399e+00, Loss Aux: 1.751e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9679, It: 0, Loss Data: 9.142e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.053e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9680, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.541e+00, Loss Aux: 2.057e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9681, It: 0, Loss Data: 9.102e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.174e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9682, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.502e+00, Loss Aux: 3.132e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9683, It: 0, Loss Data: 7.530e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.243e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9684, It: 0, Loss Data: 9.718e-02, Loss Eqns: 2.385e+00, Loss Aux: 4.182e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9685, It: 0, Loss Data: 8.976e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.735e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9686, It: 0, Loss Data: 8.650e-02, Loss Eqns: 2.486e+00, Loss Aux: 3.021e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9687, It: 0, Loss Data: 8.246e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.320e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9688, It: 0, Loss Data: 8.461e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.108e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 9689, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.193e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9690, It: 0, Loss Data: 9.380e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.023e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9691, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.413e+00, Loss Aux: 1.546e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9692, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.357e+00, Loss Aux: 1.552e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9693, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.079e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9694, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.253e+00, Loss Aux: 2.838e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9695, It: 0, Loss Data: 9.054e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.881e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9696, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.428e+00, Loss Aux: 4.165e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9697, It: 0, Loss Data: 8.396e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.434e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9698, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.399e+00, Loss Aux: 2.677e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9699, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.311e+00, Loss Aux: 2.859e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9700, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.315e+00, Loss Aux: 3.189e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9701, It: 0, Loss Data: 8.489e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.136e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9702, It: 0, Loss Data: 7.880e-02, Loss Eqns: 2.387e+00, Loss Aux: 1.784e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9703, It: 0, Loss Data: 7.693e-02, Loss Eqns: 2.380e+00, Loss Aux: 1.971e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9704, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.453e+00, Loss Aux: 2.288e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9705, It: 0, Loss Data: 9.652e-02, Loss Eqns: 2.378e+00, Loss Aux: 2.573e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9706, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.345e+00, Loss Aux: 2.705e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 9707, It: 0, Loss Data: 9.969e-02, Loss Eqns: 2.386e+00, Loss Aux: 2.934e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9708, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.182e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9709, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.434e+00, Loss Aux: 3.075e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9710, It: 0, Loss Data: 7.910e-02, Loss Eqns: 2.427e+00, Loss Aux: 2.229e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9711, It: 0, Loss Data: 7.788e-02, Loss Eqns: 2.421e+00, Loss Aux: 1.578e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9712, It: 0, Loss Data: 9.272e-02, Loss Eqns: 2.439e+00, Loss Aux: 1.939e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9713, It: 0, Loss Data: 8.916e-02, Loss Eqns: 2.471e+00, Loss Aux: 2.794e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9714, It: 0, Loss Data: 9.138e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.621e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9715, It: 0, Loss Data: 8.851e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.855e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9716, It: 0, Loss Data: 9.385e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.369e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9717, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.938e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9718, It: 0, Loss Data: 9.463e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.528e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 9719, It: 0, Loss Data: 8.109e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.142e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9720, It: 0, Loss Data: 7.782e-02, Loss Eqns: 2.325e+00, Loss Aux: 2.336e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9721, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.414e+00, Loss Aux: 2.527e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9722, It: 0, Loss Data: 9.070e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.930e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9723, It: 0, Loss Data: 8.506e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.341e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9724, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.346e+00, Loss Aux: 2.893e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9725, It: 0, Loss Data: 7.838e-02, Loss Eqns: 2.362e+00, Loss Aux: 2.347e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9726, It: 0, Loss Data: 9.238e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.282e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9727, It: 0, Loss Data: 9.712e-02, Loss Eqns: 2.369e+00, Loss Aux: 2.990e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9728, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.212e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9729, It: 0, Loss Data: 8.908e-02, Loss Eqns: 2.420e+00, Loss Aux: 2.765e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9730, It: 0, Loss Data: 8.271e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.043e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9731, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.464e+00, Loss Aux: 1.617e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9732, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.440e+00, Loss Aux: 2.154e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9733, It: 0, Loss Data: 9.406e-02, Loss Eqns: 2.491e+00, Loss Aux: 3.090e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9734, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.851e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9735, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.299e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9736, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.525e+00, Loss Aux: 2.453e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 9737, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.509e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9738, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.503e+00, Loss Aux: 2.569e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 9739, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.508e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 9740, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.953e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9741, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.446e+00, Loss Aux: 3.329e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9742, It: 0, Loss Data: 8.678e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.162e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9743, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.520e+00, Loss Aux: 2.151e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9744, It: 0, Loss Data: 9.343e-02, Loss Eqns: 2.479e+00, Loss Aux: 1.784e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9745, It: 0, Loss Data: 9.829e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.564e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9746, It: 0, Loss Data: 9.759e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.785e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9747, It: 0, Loss Data: 9.113e-02, Loss Eqns: 2.546e+00, Loss Aux: 3.558e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9748, It: 0, Loss Data: 7.965e-02, Loss Eqns: 2.447e+00, Loss Aux: 2.867e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9749, It: 0, Loss Data: 9.496e-02, Loss Eqns: 2.710e+00, Loss Aux: 2.590e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9750, It: 0, Loss Data: 8.414e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.766e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9751, It: 0, Loss Data: 7.767e-02, Loss Eqns: 2.488e+00, Loss Aux: 2.845e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9752, It: 0, Loss Data: 9.782e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.789e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9753, It: 0, Loss Data: 1.132e-01, Loss Eqns: 2.332e+00, Loss Aux: 2.466e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9754, It: 0, Loss Data: 8.486e-02, Loss Eqns: 2.280e+00, Loss Aux: 2.429e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9755, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.360e+00, Loss Aux: 2.955e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9756, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.233e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9757, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.403e+00, Loss Aux: 1.510e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9758, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.389e+00, Loss Aux: 1.794e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9759, It: 0, Loss Data: 9.745e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.348e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9760, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.449e+00, Loss Aux: 4.088e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9761, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.497e+00, Loss Aux: 2.869e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9762, It: 0, Loss Data: 9.928e-02, Loss Eqns: 2.522e+00, Loss Aux: 1.946e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9763, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.536e+00, Loss Aux: 1.763e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9764, It: 0, Loss Data: 8.210e-02, Loss Eqns: 2.527e+00, Loss Aux: 2.400e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9765, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.559e+00, Loss Aux: 2.465e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9766, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.712e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 9767, It: 0, Loss Data: 9.178e-02, Loss Eqns: 2.482e+00, Loss Aux: 3.565e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9768, It: 0, Loss Data: 9.353e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.210e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9769, It: 0, Loss Data: 7.639e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.583e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9770, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.306e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9771, It: 0, Loss Data: 7.643e-02, Loss Eqns: 2.460e+00, Loss Aux: 1.640e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 9772, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.444e+00, Loss Aux: 1.843e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9773, It: 0, Loss Data: 9.834e-02, Loss Eqns: 2.378e+00, Loss Aux: 2.393e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9774, It: 0, Loss Data: 8.125e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.574e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9775, It: 0, Loss Data: 8.864e-02, Loss Eqns: 2.308e+00, Loss Aux: 2.678e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9776, It: 0, Loss Data: 8.879e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.640e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9777, It: 0, Loss Data: 8.345e-02, Loss Eqns: 2.353e+00, Loss Aux: 2.719e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9778, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.349e+00, Loss Aux: 2.662e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9779, It: 0, Loss Data: 9.407e-02, Loss Eqns: 2.315e+00, Loss Aux: 2.604e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9780, It: 0, Loss Data: 9.863e-02, Loss Eqns: 2.354e+00, Loss Aux: 2.764e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9781, It: 0, Loss Data: 8.100e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.058e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9782, It: 0, Loss Data: 8.243e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.740e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9783, It: 0, Loss Data: 7.758e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.205e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9784, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.299e+00, Loss Aux: 1.992e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9785, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.423e+00, Loss Aux: 2.203e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 9786, It: 0, Loss Data: 9.285e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.659e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9787, It: 0, Loss Data: 9.858e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.629e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9788, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.325e+00, Loss Aux: 2.649e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9789, It: 0, Loss Data: 8.677e-02, Loss Eqns: 2.293e+00, Loss Aux: 2.735e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9790, It: 0, Loss Data: 9.860e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.609e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9791, It: 0, Loss Data: 7.692e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.299e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9792, It: 0, Loss Data: 8.720e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.062e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9793, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.375e+00, Loss Aux: 2.269e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9794, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.061e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9795, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.445e+00, Loss Aux: 3.707e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9796, It: 0, Loss Data: 9.465e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.424e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9797, It: 0, Loss Data: 7.629e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.325e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9798, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.515e+00, Loss Aux: 1.930e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9799, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.490e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9800, It: 0, Loss Data: 8.798e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.593e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9801, It: 0, Loss Data: 9.239e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.342e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9802, It: 0, Loss Data: 7.457e-02, Loss Eqns: 2.408e+00, Loss Aux: 2.387e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9803, It: 0, Loss Data: 9.373e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.535e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9804, It: 0, Loss Data: 7.207e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.685e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9805, It: 0, Loss Data: 8.029e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.617e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 9806, It: 0, Loss Data: 8.865e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.609e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9807, It: 0, Loss Data: 9.149e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.647e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9808, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.763e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9809, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.423e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9810, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.181e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9811, It: 0, Loss Data: 8.638e-02, Loss Eqns: 2.445e+00, Loss Aux: 1.933e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9812, It: 0, Loss Data: 8.983e-02, Loss Eqns: 2.348e+00, Loss Aux: 1.569e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9813, It: 0, Loss Data: 7.843e-02, Loss Eqns: 2.300e+00, Loss Aux: 2.140e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9814, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.201e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9815, It: 0, Loss Data: 9.429e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.329e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9816, It: 0, Loss Data: 8.614e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.067e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9817, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.348e+00, Loss Aux: 2.615e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9818, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.335e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9819, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.421e+00, Loss Aux: 1.946e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 9820, It: 0, Loss Data: 9.611e-02, Loss Eqns: 2.398e+00, Loss Aux: 1.884e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9821, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.410e+00, Loss Aux: 1.953e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9822, It: 0, Loss Data: 8.191e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.393e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9823, It: 0, Loss Data: 7.826e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.454e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9824, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.194e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 9825, It: 0, Loss Data: 9.542e-02, Loss Eqns: 2.461e+00, Loss Aux: 2.330e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 9826, It: 0, Loss Data: 9.093e-02, Loss Eqns: 2.447e+00, Loss Aux: 2.715e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9827, It: 0, Loss Data: 8.371e-02, Loss Eqns: 2.468e+00, Loss Aux: 3.576e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9828, It: 0, Loss Data: 7.837e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.588e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9829, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.571e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9830, It: 0, Loss Data: 9.405e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.133e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 9831, It: 0, Loss Data: 7.522e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.384e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9832, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.513e+00, Loss Aux: 2.419e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9833, It: 0, Loss Data: 9.239e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.160e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9834, It: 0, Loss Data: 9.335e-02, Loss Eqns: 2.449e+00, Loss Aux: 2.310e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9835, It: 0, Loss Data: 8.259e-02, Loss Eqns: 2.475e+00, Loss Aux: 2.398e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9836, It: 0, Loss Data: 8.116e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.761e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9837, It: 0, Loss Data: 8.519e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.617e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 9838, It: 0, Loss Data: 9.216e-02, Loss Eqns: 2.333e+00, Loss Aux: 2.357e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9839, It: 0, Loss Data: 8.800e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.466e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9840, It: 0, Loss Data: 8.110e-02, Loss Eqns: 2.328e+00, Loss Aux: 2.517e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9841, It: 0, Loss Data: 9.934e-02, Loss Eqns: 2.294e+00, Loss Aux: 2.809e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9842, It: 0, Loss Data: 8.435e-02, Loss Eqns: 2.315e+00, Loss Aux: 2.837e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9843, It: 0, Loss Data: 8.810e-02, Loss Eqns: 2.340e+00, Loss Aux: 2.395e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9844, It: 0, Loss Data: 9.616e-02, Loss Eqns: 2.273e+00, Loss Aux: 2.025e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9845, It: 0, Loss Data: 9.097e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.039e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9846, It: 0, Loss Data: 9.201e-02, Loss Eqns: 2.374e+00, Loss Aux: 1.814e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 9847, It: 0, Loss Data: 8.919e-02, Loss Eqns: 2.340e+00, Loss Aux: 2.052e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9848, It: 0, Loss Data: 9.838e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.023e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9849, It: 0, Loss Data: 8.395e-02, Loss Eqns: 2.512e+00, Loss Aux: 3.744e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9850, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.366e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9851, It: 0, Loss Data: 9.555e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.133e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9852, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.399e+00, Loss Aux: 1.809e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9853, It: 0, Loss Data: 9.004e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.252e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9854, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.395e+00, Loss Aux: 2.540e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9855, It: 0, Loss Data: 9.241e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.166e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9856, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.225e+00, Loss Aux: 1.735e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9857, It: 0, Loss Data: 9.894e-02, Loss Eqns: 2.410e+00, Loss Aux: 1.698e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 9858, It: 0, Loss Data: 9.017e-02, Loss Eqns: 2.532e+00, Loss Aux: 1.878e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9859, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.403e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9860, It: 0, Loss Data: 8.209e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.480e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9861, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.537e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 9862, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.434e+00, Loss Aux: 3.779e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9863, It: 0, Loss Data: 9.032e-02, Loss Eqns: 2.477e+00, Loss Aux: 4.912e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9864, It: 0, Loss Data: 9.084e-02, Loss Eqns: 2.464e+00, Loss Aux: 4.008e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9865, It: 0, Loss Data: 9.039e-02, Loss Eqns: 2.363e+00, Loss Aux: 2.720e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9866, It: 0, Loss Data: 8.349e-02, Loss Eqns: 2.490e+00, Loss Aux: 1.977e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9867, It: 0, Loss Data: 9.087e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.008e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 9868, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.307e+00, Loss Aux: 2.598e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9869, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.368e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9870, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.427e+00, Loss Aux: 2.025e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9871, It: 0, Loss Data: 7.257e-02, Loss Eqns: 2.453e+00, Loss Aux: 1.805e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9872, It: 0, Loss Data: 7.113e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.240e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9873, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.518e+00, Loss Aux: 2.739e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9874, It: 0, Loss Data: 9.656e-02, Loss Eqns: 2.403e+00, Loss Aux: 2.870e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9875, It: 0, Loss Data: 9.713e-02, Loss Eqns: 2.514e+00, Loss Aux: 2.587e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 9876, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.665e+00, Loss Aux: 2.150e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9877, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.022e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9878, It: 0, Loss Data: 9.745e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.130e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9879, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.723e+00, Loss Aux: 1.987e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9880, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.462e+00, Loss Aux: 1.835e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9881, It: 0, Loss Data: 1.053e-01, Loss Eqns: 3.521e+00, Loss Aux: 2.227e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9882, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.992e+00, Loss Aux: 2.058e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9883, It: 0, Loss Data: 1.010e-01, Loss Eqns: 3.042e+00, Loss Aux: 2.583e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9884, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.839e+00, Loss Aux: 2.827e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9885, It: 0, Loss Data: 8.915e-02, Loss Eqns: 2.600e+00, Loss Aux: 2.146e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9886, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.624e+00, Loss Aux: 2.044e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9887, It: 0, Loss Data: 9.767e-02, Loss Eqns: 2.641e+00, Loss Aux: 3.324e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 9888, It: 0, Loss Data: 9.592e-02, Loss Eqns: 2.536e+00, Loss Aux: 4.226e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9889, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.543e+00, Loss Aux: 3.827e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 9890, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.463e+00, Loss Aux: 3.231e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9891, It: 0, Loss Data: 1.123e-01, Loss Eqns: 2.502e+00, Loss Aux: 2.618e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9892, It: 0, Loss Data: 9.546e-02, Loss Eqns: 2.442e+00, Loss Aux: 2.234e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9893, It: 0, Loss Data: 9.772e-02, Loss Eqns: 2.390e+00, Loss Aux: 2.050e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9894, It: 0, Loss Data: 9.376e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.401e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9895, It: 0, Loss Data: 9.946e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.117e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9896, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.492e+00, Loss Aux: 3.343e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9897, It: 0, Loss Data: 9.463e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.178e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9898, It: 0, Loss Data: 9.042e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.398e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9899, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.518e+00, Loss Aux: 1.955e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9900, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.490e+00, Loss Aux: 2.293e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9901, It: 0, Loss Data: 8.490e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.844e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 9902, It: 0, Loss Data: 9.920e-02, Loss Eqns: 2.542e+00, Loss Aux: 3.246e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9903, It: 0, Loss Data: 9.087e-02, Loss Eqns: 2.479e+00, Loss Aux: 3.013e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9904, It: 0, Loss Data: 8.671e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.365e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9905, It: 0, Loss Data: 7.751e-02, Loss Eqns: 2.555e+00, Loss Aux: 1.599e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9906, It: 0, Loss Data: 8.538e-02, Loss Eqns: 2.530e+00, Loss Aux: 2.168e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9907, It: 0, Loss Data: 8.334e-02, Loss Eqns: 2.523e+00, Loss Aux: 3.656e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9908, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.467e+00, Loss Aux: 4.170e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 9909, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.441e+00, Loss Aux: 3.492e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9910, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.498e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9911, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.398e+00, Loss Aux: 1.852e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9912, It: 0, Loss Data: 9.665e-02, Loss Eqns: 2.329e+00, Loss Aux: 1.460e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9913, It: 0, Loss Data: 9.699e-02, Loss Eqns: 2.340e+00, Loss Aux: 1.746e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 9914, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.511e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9915, It: 0, Loss Data: 8.167e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.598e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9916, It: 0, Loss Data: 8.585e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.238e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 9917, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.967e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9918, It: 0, Loss Data: 9.655e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.712e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9919, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.362e+00, Loss Aux: 2.302e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9920, It: 0, Loss Data: 9.409e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.347e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9921, It: 0, Loss Data: 9.510e-02, Loss Eqns: 2.414e+00, Loss Aux: 2.463e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9922, It: 0, Loss Data: 8.314e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.172e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9923, It: 0, Loss Data: 8.061e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.854e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 9924, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.537e+00, Loss Aux: 1.849e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9925, It: 0, Loss Data: 8.694e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.724e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9926, It: 0, Loss Data: 9.410e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.962e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9927, It: 0, Loss Data: 9.001e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.142e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9928, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.502e+00, Loss Aux: 2.043e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9929, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.503e+00, Loss Aux: 3.039e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9930, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.539e+00, Loss Aux: 3.723e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9931, It: 0, Loss Data: 8.711e-02, Loss Eqns: 2.474e+00, Loss Aux: 3.033e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 9932, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.152e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9933, It: 0, Loss Data: 9.532e-02, Loss Eqns: 2.480e+00, Loss Aux: 1.708e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9934, It: 0, Loss Data: 9.363e-02, Loss Eqns: 2.425e+00, Loss Aux: 1.962e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9935, It: 0, Loss Data: 9.195e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.015e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9936, It: 0, Loss Data: 8.923e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.336e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9937, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.356e+00, Loss Aux: 2.540e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9938, It: 0, Loss Data: 9.774e-02, Loss Eqns: 2.352e+00, Loss Aux: 1.990e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9939, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.366e+00, Loss Aux: 1.568e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9940, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.450e+00, Loss Aux: 1.417e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 9941, It: 0, Loss Data: 9.170e-02, Loss Eqns: 2.443e+00, Loss Aux: 1.818e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 9942, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.380e+00, Loss Aux: 2.627e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9943, It: 0, Loss Data: 8.740e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.233e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 9944, It: 0, Loss Data: 1.130e-01, Loss Eqns: 2.584e+00, Loss Aux: 3.258e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 9945, It: 0, Loss Data: 1.053e-01, Loss Eqns: 3.173e+00, Loss Aux: 5.041e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9946, It: 0, Loss Data: 1.081e-01, Loss Eqns: 2.758e+00, Loss Aux: 4.027e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9947, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.814e+00, Loss Aux: 2.607e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 9948, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.576e+00, Loss Aux: 3.014e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9949, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.691e+00, Loss Aux: 2.679e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9950, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.955e+00, Loss Aux: 1.708e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9951, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.553e+00, Loss Aux: 1.983e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9952, It: 0, Loss Data: 1.172e-01, Loss Eqns: 3.074e+00, Loss Aux: 3.017e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 9953, It: 0, Loss Data: 1.016e-01, Loss Eqns: 3.382e+00, Loss Aux: 2.610e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9954, It: 0, Loss Data: 1.254e-01, Loss Eqns: 3.377e+00, Loss Aux: 2.506e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 9955, It: 0, Loss Data: 1.090e-01, Loss Eqns: 3.220e+00, Loss Aux: 3.119e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9956, It: 0, Loss Data: 1.015e-01, Loss Eqns: 3.361e+00, Loss Aux: 2.323e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 9957, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.714e+00, Loss Aux: 1.579e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9958, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.950e+00, Loss Aux: 2.466e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9959, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.706e+00, Loss Aux: 4.511e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 9960, It: 0, Loss Data: 1.185e-01, Loss Eqns: 2.613e+00, Loss Aux: 3.652e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9961, It: 0, Loss Data: 1.300e-01, Loss Eqns: 2.650e+00, Loss Aux: 2.213e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9962, It: 0, Loss Data: 1.195e-01, Loss Eqns: 2.398e+00, Loss Aux: 2.257e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9963, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.500e+00, Loss Aux: 3.243e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 9964, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.546e+00, Loss Aux: 2.343e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9965, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.508e+00, Loss Aux: 1.067e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 9966, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.383e+00, Loss Aux: 2.149e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 9967, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.573e+00, Loss Aux: 4.850e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 9968, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.467e+00, Loss Aux: 5.279e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 9969, It: 0, Loss Data: 9.432e-02, Loss Eqns: 2.496e+00, Loss Aux: 3.645e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9970, It: 0, Loss Data: 9.256e-02, Loss Eqns: 2.408e+00, Loss Aux: 2.818e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 9971, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.487e+00, Loss Aux: 2.557e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 9972, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.454e+00, Loss Aux: 2.232e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 9973, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.466e+00, Loss Aux: 2.233e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 9974, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.420e+00, Loss Aux: 2.842e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 9975, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.503e+00, Loss Aux: 3.373e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9976, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.420e+00, Loss Aux: 3.188e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9977, It: 0, Loss Data: 9.816e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.542e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 9978, It: 0, Loss Data: 8.699e-02, Loss Eqns: 2.461e+00, Loss Aux: 2.676e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 9979, It: 0, Loss Data: 8.603e-02, Loss Eqns: 2.496e+00, Loss Aux: 2.739e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 9980, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.387e+00, Loss Aux: 2.914e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 9981, It: 0, Loss Data: 9.926e-02, Loss Eqns: 2.494e+00, Loss Aux: 3.397e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 9982, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.536e+00, Loss Aux: 4.037e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 9983, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.539e+00, Loss Aux: 3.866e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 9984, It: 0, Loss Data: 9.432e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.883e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 9985, It: 0, Loss Data: 8.201e-02, Loss Eqns: 2.483e+00, Loss Aux: 2.549e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 9986, It: 0, Loss Data: 8.966e-02, Loss Eqns: 2.455e+00, Loss Aux: 3.171e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9987, It: 0, Loss Data: 9.659e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.327e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 9988, It: 0, Loss Data: 8.278e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.408e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 9989, It: 0, Loss Data: 8.988e-02, Loss Eqns: 2.320e+00, Loss Aux: 2.163e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 9990, It: 0, Loss Data: 9.616e-02, Loss Eqns: 2.356e+00, Loss Aux: 2.544e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 9991, It: 0, Loss Data: 8.746e-02, Loss Eqns: 2.274e+00, Loss Aux: 2.853e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 9992, It: 0, Loss Data: 8.538e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.993e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 9993, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.417e+00, Loss Aux: 2.901e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 9994, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.910e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 9995, It: 0, Loss Data: 8.785e-02, Loss Eqns: 2.425e+00, Loss Aux: 3.165e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 9996, It: 0, Loss Data: 9.910e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.400e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9997, It: 0, Loss Data: 9.707e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.408e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 9998, It: 0, Loss Data: 7.849e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.794e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 9999, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.667e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10000, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.876e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10001, It: 0, Loss Data: 9.478e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.561e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10002, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.390e+00, Loss Aux: 2.591e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10003, It: 0, Loss Data: 8.391e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.641e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10004, It: 0, Loss Data: 7.660e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.611e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10005, It: 0, Loss Data: 9.177e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.156e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10006, It: 0, Loss Data: 8.750e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.121e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10007, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.474e+00, Loss Aux: 2.451e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10008, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.075e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10009, It: 0, Loss Data: 9.109e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.462e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10010, It: 0, Loss Data: 8.510e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.021e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10011, It: 0, Loss Data: 8.983e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.680e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10012, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.991e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10013, It: 0, Loss Data: 9.037e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.470e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10014, It: 0, Loss Data: 9.079e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.928e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10015, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.420e+00, Loss Aux: 2.859e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10016, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.022e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10017, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.205e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10018, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.441e+00, Loss Aux: 3.505e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10019, It: 0, Loss Data: 9.343e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.227e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10020, It: 0, Loss Data: 9.033e-02, Loss Eqns: 2.507e+00, Loss Aux: 2.235e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10021, It: 0, Loss Data: 8.058e-02, Loss Eqns: 2.450e+00, Loss Aux: 1.800e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10022, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.394e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10023, It: 0, Loss Data: 9.553e-02, Loss Eqns: 2.461e+00, Loss Aux: 2.923e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10024, It: 0, Loss Data: 8.603e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.123e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10025, It: 0, Loss Data: 9.132e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.143e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10026, It: 0, Loss Data: 9.237e-02, Loss Eqns: 2.490e+00, Loss Aux: 3.063e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10027, It: 0, Loss Data: 8.573e-02, Loss Eqns: 2.481e+00, Loss Aux: 2.876e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10028, It: 0, Loss Data: 9.084e-02, Loss Eqns: 2.396e+00, Loss Aux: 2.285e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10029, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.206e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10030, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.440e+00, Loss Aux: 2.557e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10031, It: 0, Loss Data: 8.607e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.777e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10032, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.002e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10033, It: 0, Loss Data: 8.098e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.085e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10034, It: 0, Loss Data: 9.818e-02, Loss Eqns: 2.312e+00, Loss Aux: 2.786e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10035, It: 0, Loss Data: 9.689e-02, Loss Eqns: 2.286e+00, Loss Aux: 2.744e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10036, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.064e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10037, It: 0, Loss Data: 8.533e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.168e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10038, It: 0, Loss Data: 8.065e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.220e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10039, It: 0, Loss Data: 8.980e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.746e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10040, It: 0, Loss Data: 9.626e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.522e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10041, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.314e+00, Loss Aux: 2.669e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10042, It: 0, Loss Data: 9.615e-02, Loss Eqns: 2.289e+00, Loss Aux: 2.592e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10043, It: 0, Loss Data: 9.991e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.685e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10044, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.484e+00, Loss Aux: 2.339e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10045, It: 0, Loss Data: 8.736e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.120e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10046, It: 0, Loss Data: 9.935e-02, Loss Eqns: 2.369e+00, Loss Aux: 2.432e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10047, It: 0, Loss Data: 8.915e-02, Loss Eqns: 2.466e+00, Loss Aux: 3.201e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10048, It: 0, Loss Data: 8.884e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.180e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10049, It: 0, Loss Data: 9.040e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.414e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10050, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.991e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10051, It: 0, Loss Data: 7.318e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.636e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10052, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.415e+00, Loss Aux: 3.149e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10053, It: 0, Loss Data: 9.090e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.716e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10054, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.472e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10055, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.245e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10056, It: 0, Loss Data: 9.569e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.002e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10057, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.462e+00, Loss Aux: 2.437e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 10058, It: 0, Loss Data: 8.517e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.153e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 10059, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.461e+00, Loss Aux: 3.086e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10060, It: 0, Loss Data: 8.895e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.081e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10061, It: 0, Loss Data: 9.034e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.648e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 10062, It: 0, Loss Data: 8.228e-02, Loss Eqns: 2.529e+00, Loss Aux: 2.757e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10063, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.449e+00, Loss Aux: 3.222e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10064, It: 0, Loss Data: 8.193e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.787e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10065, It: 0, Loss Data: 8.414e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.373e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10066, It: 0, Loss Data: 8.355e-02, Loss Eqns: 2.363e+00, Loss Aux: 2.457e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10067, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.109e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10068, It: 0, Loss Data: 9.012e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.227e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10069, It: 0, Loss Data: 8.499e-02, Loss Eqns: 2.297e+00, Loss Aux: 2.128e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10070, It: 0, Loss Data: 8.694e-02, Loss Eqns: 2.683e+00, Loss Aux: 2.757e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10071, It: 0, Loss Data: 1.197e-01, Loss Eqns: 2.755e+00, Loss Aux: 2.217e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 10072, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.614e+00, Loss Aux: 2.519e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10073, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.782e+00, Loss Aux: 3.741e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10074, It: 0, Loss Data: 9.417e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.812e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10075, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.675e+00, Loss Aux: 1.800e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10076, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.946e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10077, It: 0, Loss Data: 1.233e-01, Loss Eqns: 2.726e+00, Loss Aux: 4.382e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 10078, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.518e+00, Loss Aux: 3.340e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10079, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.716e+00, Loss Aux: 2.300e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10080, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.369e+00, Loss Aux: 1.925e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10081, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.616e+00, Loss Aux: 1.715e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10082, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.429e+00, Loss Aux: 1.916e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10083, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.410e+00, Loss Aux: 2.826e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10084, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.443e+00, Loss Aux: 4.566e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10085, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.427e+00, Loss Aux: 3.992e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10086, It: 0, Loss Data: 9.939e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.968e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10087, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.375e+00, Loss Aux: 2.907e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10088, It: 0, Loss Data: 1.171e-01, Loss Eqns: 2.348e+00, Loss Aux: 3.715e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10089, It: 0, Loss Data: 8.273e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.997e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10090, It: 0, Loss Data: 8.332e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.340e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10091, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.297e+00, Loss Aux: 2.809e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10092, It: 0, Loss Data: 1.159e-01, Loss Eqns: 2.355e+00, Loss Aux: 3.790e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10093, It: 0, Loss Data: 9.271e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.630e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10094, It: 0, Loss Data: 9.922e-02, Loss Eqns: 2.495e+00, Loss Aux: 2.521e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10095, It: 0, Loss Data: 9.197e-02, Loss Eqns: 2.466e+00, Loss Aux: 1.904e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10096, It: 0, Loss Data: 9.249e-02, Loss Eqns: 2.435e+00, Loss Aux: 1.864e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10097, It: 0, Loss Data: 9.376e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.130e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10098, It: 0, Loss Data: 9.777e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.278e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10099, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.526e+00, Loss Aux: 2.435e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10100, It: 0, Loss Data: 9.668e-02, Loss Eqns: 2.521e+00, Loss Aux: 2.562e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10101, It: 0, Loss Data: 8.958e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.977e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10102, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.514e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10103, It: 0, Loss Data: 8.319e-02, Loss Eqns: 2.512e+00, Loss Aux: 3.741e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10104, It: 0, Loss Data: 8.770e-02, Loss Eqns: 2.549e+00, Loss Aux: 2.866e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10105, It: 0, Loss Data: 9.631e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.493e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10106, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.506e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10107, It: 0, Loss Data: 8.428e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.742e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10108, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.355e+00, Loss Aux: 2.962e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10109, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.519e+00, Loss Aux: 2.083e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10110, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.497e+00, Loss Aux: 1.912e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10111, It: 0, Loss Data: 8.417e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.075e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10112, It: 0, Loss Data: 9.256e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.542e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 10113, It: 0, Loss Data: 8.520e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.258e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10114, It: 0, Loss Data: 8.482e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.997e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10115, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.398e+00, Loss Aux: 3.851e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10116, It: 0, Loss Data: 9.287e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.902e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10117, It: 0, Loss Data: 9.833e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.664e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10118, It: 0, Loss Data: 8.953e-02, Loss Eqns: 2.383e+00, Loss Aux: 2.392e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10119, It: 0, Loss Data: 9.213e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.454e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10120, It: 0, Loss Data: 9.675e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.755e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10121, It: 0, Loss Data: 8.835e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.147e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10122, It: 0, Loss Data: 8.909e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.541e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10123, It: 0, Loss Data: 9.550e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.041e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10124, It: 0, Loss Data: 8.921e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.319e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10125, It: 0, Loss Data: 7.252e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.100e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10126, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.455e+00, Loss Aux: 2.609e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10127, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.218e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10128, It: 0, Loss Data: 9.959e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.700e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10129, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.942e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10130, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.456e+00, Loss Aux: 2.051e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 10131, It: 0, Loss Data: 7.665e-02, Loss Eqns: 2.338e+00, Loss Aux: 2.313e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10132, It: 0, Loss Data: 9.038e-02, Loss Eqns: 2.462e+00, Loss Aux: 2.842e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10133, It: 0, Loss Data: 9.641e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.883e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10134, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.378e+00, Loss Aux: 2.633e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10135, It: 0, Loss Data: 9.752e-02, Loss Eqns: 2.494e+00, Loss Aux: 2.936e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10136, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.324e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10137, It: 0, Loss Data: 9.927e-02, Loss Eqns: 2.617e+00, Loss Aux: 4.289e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10138, It: 0, Loss Data: 9.481e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.010e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10139, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.538e+00, Loss Aux: 2.153e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10140, It: 0, Loss Data: 9.215e-02, Loss Eqns: 2.477e+00, Loss Aux: 2.091e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10141, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.247e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10142, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.302e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10143, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.557e+00, Loss Aux: 2.435e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10144, It: 0, Loss Data: 9.499e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.708e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10145, It: 0, Loss Data: 8.314e-02, Loss Eqns: 2.548e+00, Loss Aux: 3.309e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10146, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.419e+00, Loss Aux: 3.656e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10147, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.497e+00, Loss Aux: 3.083e-02, Time: 0.144, Learning Rate: 1.0e-03\n",
      "Epoch: 10148, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.461e+00, Loss Aux: 2.332e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 10149, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.380e+00, Loss Aux: 2.230e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10150, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.608e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10151, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.102e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10152, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.416e+00, Loss Aux: 2.694e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10153, It: 0, Loss Data: 7.921e-02, Loss Eqns: 2.318e+00, Loss Aux: 2.226e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10154, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.329e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 10155, It: 0, Loss Data: 9.824e-02, Loss Eqns: 2.448e+00, Loss Aux: 3.090e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10156, It: 0, Loss Data: 8.498e-02, Loss Eqns: 2.466e+00, Loss Aux: 4.081e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10157, It: 0, Loss Data: 8.960e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.298e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 10158, It: 0, Loss Data: 8.673e-02, Loss Eqns: 2.414e+00, Loss Aux: 3.530e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10159, It: 0, Loss Data: 7.027e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.537e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10160, It: 0, Loss Data: 7.763e-02, Loss Eqns: 2.426e+00, Loss Aux: 2.211e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10161, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.674e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10162, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.318e+00, Loss Aux: 2.680e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10163, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.337e+00, Loss Aux: 2.063e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10164, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.371e+00, Loss Aux: 1.976e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10165, It: 0, Loss Data: 8.464e-02, Loss Eqns: 2.371e+00, Loss Aux: 2.507e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10166, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.106e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10167, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.362e+00, Loss Aux: 3.200e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10168, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.948e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10169, It: 0, Loss Data: 9.233e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.947e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10170, It: 0, Loss Data: 8.410e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.035e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10171, It: 0, Loss Data: 1.067e-01, Loss Eqns: 2.239e+00, Loss Aux: 2.622e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10172, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.675e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10173, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.332e+00, Loss Aux: 2.686e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10174, It: 0, Loss Data: 8.935e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.652e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10175, It: 0, Loss Data: 9.142e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.466e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10176, It: 0, Loss Data: 9.217e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.287e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10177, It: 0, Loss Data: 8.515e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.095e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10178, It: 0, Loss Data: 7.978e-02, Loss Eqns: 2.413e+00, Loss Aux: 2.368e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10179, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.395e+00, Loss Aux: 2.954e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10180, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.111e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10181, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.528e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10182, It: 0, Loss Data: 9.815e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.229e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 10183, It: 0, Loss Data: 8.201e-02, Loss Eqns: 2.497e+00, Loss Aux: 2.044e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10184, It: 0, Loss Data: 9.925e-02, Loss Eqns: 2.244e+00, Loss Aux: 2.487e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10185, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.467e+00, Loss Aux: 2.808e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10186, It: 0, Loss Data: 8.170e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.236e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10187, It: 0, Loss Data: 9.049e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.028e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10188, It: 0, Loss Data: 9.638e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.618e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10189, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.312e+00, Loss Aux: 2.576e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10190, It: 0, Loss Data: 9.109e-02, Loss Eqns: 2.413e+00, Loss Aux: 2.536e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10191, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.456e+00, Loss Aux: 2.354e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 10192, It: 0, Loss Data: 9.481e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.556e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10193, It: 0, Loss Data: 9.826e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.160e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 10194, It: 0, Loss Data: 8.190e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.024e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10195, It: 0, Loss Data: 9.508e-02, Loss Eqns: 2.743e+00, Loss Aux: 3.344e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10196, It: 0, Loss Data: 2.278e-01, Loss Eqns: 3.564e+00, Loss Aux: 1.068e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10197, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.875e+00, Loss Aux: 3.363e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10198, It: 0, Loss Data: 1.755e-01, Loss Eqns: 3.613e+00, Loss Aux: 5.695e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10199, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.680e+00, Loss Aux: 2.634e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 10200, It: 0, Loss Data: 1.604e-01, Loss Eqns: 3.274e+00, Loss Aux: 1.429e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10201, It: 0, Loss Data: 9.957e-02, Loss Eqns: 2.631e+00, Loss Aux: 2.451e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10202, It: 0, Loss Data: 1.473e-01, Loss Eqns: 3.395e+00, Loss Aux: 5.347e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10203, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.202e+00, Loss Aux: 4.910e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 10204, It: 0, Loss Data: 1.637e-01, Loss Eqns: 3.389e+00, Loss Aux: 3.350e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10205, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.697e+00, Loss Aux: 2.778e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10206, It: 0, Loss Data: 1.736e-01, Loss Eqns: 3.669e+00, Loss Aux: 2.354e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10207, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.499e+00, Loss Aux: 1.934e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10208, It: 0, Loss Data: 1.472e-01, Loss Eqns: 3.133e+00, Loss Aux: 2.359e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10209, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.522e+00, Loss Aux: 4.037e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10210, It: 0, Loss Data: 1.377e-01, Loss Eqns: 2.695e+00, Loss Aux: 5.839e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10211, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.416e+00, Loss Aux: 4.596e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10212, It: 0, Loss Data: 1.313e-01, Loss Eqns: 2.405e+00, Loss Aux: 2.919e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10213, It: 0, Loss Data: 1.761e-01, Loss Eqns: 2.747e+00, Loss Aux: 2.190e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10214, It: 0, Loss Data: 1.591e-01, Loss Eqns: 2.515e+00, Loss Aux: 4.253e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10215, It: 0, Loss Data: 1.612e-01, Loss Eqns: 2.804e+00, Loss Aux: 3.818e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10216, It: 0, Loss Data: 1.504e-01, Loss Eqns: 2.432e+00, Loss Aux: 2.129e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10217, It: 0, Loss Data: 1.606e-01, Loss Eqns: 2.602e+00, Loss Aux: 2.686e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10218, It: 0, Loss Data: 1.198e-01, Loss Eqns: 2.386e+00, Loss Aux: 4.371e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10219, It: 0, Loss Data: 1.430e-01, Loss Eqns: 2.625e+00, Loss Aux: 4.930e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10220, It: 0, Loss Data: 1.205e-01, Loss Eqns: 2.459e+00, Loss Aux: 3.382e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10221, It: 0, Loss Data: 1.388e-01, Loss Eqns: 2.518e+00, Loss Aux: 2.389e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10222, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.383e+00, Loss Aux: 2.443e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10223, It: 0, Loss Data: 1.254e-01, Loss Eqns: 2.427e+00, Loss Aux: 4.345e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 10224, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.442e+00, Loss Aux: 4.034e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10225, It: 0, Loss Data: 1.267e-01, Loss Eqns: 2.369e+00, Loss Aux: 2.962e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10226, It: 0, Loss Data: 1.185e-01, Loss Eqns: 2.313e+00, Loss Aux: 3.245e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10227, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.406e+00, Loss Aux: 3.251e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10228, It: 0, Loss Data: 1.762e-01, Loss Eqns: 2.674e+00, Loss Aux: 5.576e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10229, It: 0, Loss Data: 1.223e-01, Loss Eqns: 2.380e+00, Loss Aux: 4.386e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10230, It: 0, Loss Data: 1.394e-01, Loss Eqns: 2.417e+00, Loss Aux: 2.304e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 10231, It: 0, Loss Data: 1.300e-01, Loss Eqns: 2.448e+00, Loss Aux: 2.420e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10232, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.510e+00, Loss Aux: 3.745e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10233, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.470e+00, Loss Aux: 3.761e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10234, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.462e+00, Loss Aux: 2.463e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10235, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.548e+00, Loss Aux: 3.637e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10236, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.414e+00, Loss Aux: 2.891e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10237, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.491e+00, Loss Aux: 3.120e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10238, It: 0, Loss Data: 8.644e-02, Loss Eqns: 2.493e+00, Loss Aux: 4.336e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10239, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.683e+00, Loss Aux: 4.272e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10240, It: 0, Loss Data: 9.947e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.039e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10241, It: 0, Loss Data: 9.540e-02, Loss Eqns: 2.485e+00, Loss Aux: 2.478e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10242, It: 0, Loss Data: 8.055e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.752e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10243, It: 0, Loss Data: 9.312e-02, Loss Eqns: 2.451e+00, Loss Aux: 3.250e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10244, It: 0, Loss Data: 9.738e-02, Loss Eqns: 2.444e+00, Loss Aux: 3.568e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10245, It: 0, Loss Data: 9.543e-02, Loss Eqns: 2.513e+00, Loss Aux: 3.277e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10246, It: 0, Loss Data: 9.873e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.040e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10247, It: 0, Loss Data: 9.604e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.931e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10248, It: 0, Loss Data: 8.677e-02, Loss Eqns: 2.289e+00, Loss Aux: 2.871e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10249, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.243e+00, Loss Aux: 2.999e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10250, It: 0, Loss Data: 9.850e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.240e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10251, It: 0, Loss Data: 9.285e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.460e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10252, It: 0, Loss Data: 9.307e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.290e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10253, It: 0, Loss Data: 9.499e-02, Loss Eqns: 2.288e+00, Loss Aux: 2.762e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10254, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.307e+00, Loss Aux: 2.548e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10255, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.355e+00, Loss Aux: 2.984e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 10256, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.110e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10257, It: 0, Loss Data: 8.623e-02, Loss Eqns: 2.332e+00, Loss Aux: 2.481e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10258, It: 0, Loss Data: 8.283e-02, Loss Eqns: 2.442e+00, Loss Aux: 2.294e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10259, It: 0, Loss Data: 7.747e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.609e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10260, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.972e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10261, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.381e+00, Loss Aux: 3.459e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10262, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.110e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10263, It: 0, Loss Data: 8.948e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.776e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10264, It: 0, Loss Data: 8.217e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.854e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10265, It: 0, Loss Data: 8.964e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.381e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10266, It: 0, Loss Data: 8.478e-02, Loss Eqns: 2.466e+00, Loss Aux: 2.738e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10267, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.528e+00, Loss Aux: 3.387e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 10268, It: 0, Loss Data: 8.092e-02, Loss Eqns: 2.485e+00, Loss Aux: 3.943e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10269, It: 0, Loss Data: 8.803e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.416e-02, Time: 0.227, Learning Rate: 1.0e-03\n",
      "Epoch: 10270, It: 0, Loss Data: 9.650e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.454e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10271, It: 0, Loss Data: 7.737e-02, Loss Eqns: 2.434e+00, Loss Aux: 1.926e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10272, It: 0, Loss Data: 9.361e-02, Loss Eqns: 2.492e+00, Loss Aux: 2.534e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10273, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.894e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 10274, It: 0, Loss Data: 9.491e-02, Loss Eqns: 2.408e+00, Loss Aux: 4.337e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10275, It: 0, Loss Data: 7.394e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.575e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10276, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.438e+00, Loss Aux: 2.442e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10277, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.354e+00, Loss Aux: 2.083e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10278, It: 0, Loss Data: 8.489e-02, Loss Eqns: 2.295e+00, Loss Aux: 2.146e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10279, It: 0, Loss Data: 8.465e-02, Loss Eqns: 2.366e+00, Loss Aux: 2.292e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10280, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.837e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10281, It: 0, Loss Data: 9.997e-02, Loss Eqns: 2.448e+00, Loss Aux: 3.281e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10282, It: 0, Loss Data: 8.146e-02, Loss Eqns: 2.518e+00, Loss Aux: 3.773e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10283, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.434e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10284, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.271e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10285, It: 0, Loss Data: 9.346e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.119e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10286, It: 0, Loss Data: 9.531e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.200e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10287, It: 0, Loss Data: 8.818e-02, Loss Eqns: 2.410e+00, Loss Aux: 4.283e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 10288, It: 0, Loss Data: 9.494e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.218e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 10289, It: 0, Loss Data: 9.029e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.748e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10290, It: 0, Loss Data: 7.965e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.192e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10291, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.338e+00, Loss Aux: 2.272e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10292, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.402e+00, Loss Aux: 3.469e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10293, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.421e+00, Loss Aux: 3.933e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10294, It: 0, Loss Data: 8.746e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.152e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10295, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.422e+00, Loss Aux: 3.047e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10296, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.443e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10297, It: 0, Loss Data: 9.375e-02, Loss Eqns: 2.446e+00, Loss Aux: 4.062e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10298, It: 0, Loss Data: 8.449e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.490e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10299, It: 0, Loss Data: 8.611e-02, Loss Eqns: 2.491e+00, Loss Aux: 2.821e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10300, It: 0, Loss Data: 8.986e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.893e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10301, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.311e+00, Loss Aux: 2.945e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10302, It: 0, Loss Data: 8.324e-02, Loss Eqns: 2.491e+00, Loss Aux: 3.040e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10303, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.368e+00, Loss Aux: 2.992e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10304, It: 0, Loss Data: 9.879e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.542e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10305, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.429e+00, Loss Aux: 2.327e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10306, It: 0, Loss Data: 7.932e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.390e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10307, It: 0, Loss Data: 9.188e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.546e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10308, It: 0, Loss Data: 8.518e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.644e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 10309, It: 0, Loss Data: 9.834e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.121e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10310, It: 0, Loss Data: 9.861e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.374e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10311, It: 0, Loss Data: 9.231e-02, Loss Eqns: 2.437e+00, Loss Aux: 3.998e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10312, It: 0, Loss Data: 7.920e-02, Loss Eqns: 2.461e+00, Loss Aux: 4.031e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10313, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.191e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10314, It: 0, Loss Data: 9.004e-02, Loss Eqns: 2.401e+00, Loss Aux: 2.268e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10315, It: 0, Loss Data: 9.136e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.049e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 10316, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.752e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10317, It: 0, Loss Data: 8.263e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.803e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10318, It: 0, Loss Data: 7.346e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.623e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10319, It: 0, Loss Data: 8.629e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.852e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10320, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.330e+00, Loss Aux: 2.646e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10321, It: 0, Loss Data: 8.203e-02, Loss Eqns: 2.316e+00, Loss Aux: 2.631e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10322, It: 0, Loss Data: 9.529e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.326e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10323, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.334e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10324, It: 0, Loss Data: 9.754e-02, Loss Eqns: 2.267e+00, Loss Aux: 2.413e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10325, It: 0, Loss Data: 1.131e-01, Loss Eqns: 2.352e+00, Loss Aux: 1.983e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10326, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.371e+00, Loss Aux: 2.373e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 10327, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.986e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10328, It: 0, Loss Data: 8.521e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.120e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10329, It: 0, Loss Data: 8.347e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.857e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10330, It: 0, Loss Data: 8.033e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.711e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10331, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.474e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10332, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.741e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10333, It: 0, Loss Data: 6.794e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.034e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10334, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.266e+00, Loss Aux: 2.493e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10335, It: 0, Loss Data: 9.642e-02, Loss Eqns: 2.386e+00, Loss Aux: 2.364e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10336, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.325e+00, Loss Aux: 2.679e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10337, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.336e+00, Loss Aux: 2.982e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10338, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.243e+00, Loss Aux: 2.915e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10339, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.326e+00, Loss Aux: 2.443e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10340, It: 0, Loss Data: 9.205e-02, Loss Eqns: 2.277e+00, Loss Aux: 2.477e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10341, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.073e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10342, It: 0, Loss Data: 9.387e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.688e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10343, It: 0, Loss Data: 9.046e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.490e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10344, It: 0, Loss Data: 8.576e-02, Loss Eqns: 2.451e+00, Loss Aux: 3.074e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10345, It: 0, Loss Data: 8.411e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.641e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10346, It: 0, Loss Data: 9.936e-02, Loss Eqns: 2.318e+00, Loss Aux: 2.718e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10347, It: 0, Loss Data: 9.331e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.049e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10348, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.833e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 10349, It: 0, Loss Data: 8.862e-02, Loss Eqns: 2.395e+00, Loss Aux: 2.467e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10350, It: 0, Loss Data: 7.548e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.711e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10351, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.337e+00, Loss Aux: 2.853e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10352, It: 0, Loss Data: 8.613e-02, Loss Eqns: 2.513e+00, Loss Aux: 2.794e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10353, It: 0, Loss Data: 9.338e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.404e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10354, It: 0, Loss Data: 9.836e-02, Loss Eqns: 2.502e+00, Loss Aux: 2.125e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10355, It: 0, Loss Data: 7.635e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.323e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10356, It: 0, Loss Data: 9.074e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.366e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 10357, It: 0, Loss Data: 8.671e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.824e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10358, It: 0, Loss Data: 8.698e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.565e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10359, It: 0, Loss Data: 9.311e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.353e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10360, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.324e+00, Loss Aux: 3.152e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10361, It: 0, Loss Data: 7.789e-02, Loss Eqns: 2.341e+00, Loss Aux: 2.812e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10362, It: 0, Loss Data: 8.914e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.202e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10363, It: 0, Loss Data: 7.407e-02, Loss Eqns: 2.356e+00, Loss Aux: 1.765e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10364, It: 0, Loss Data: 8.050e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.030e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10365, It: 0, Loss Data: 8.630e-02, Loss Eqns: 2.335e+00, Loss Aux: 2.922e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10366, It: 0, Loss Data: 9.618e-02, Loss Eqns: 2.225e+00, Loss Aux: 3.555e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10367, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.325e+00, Loss Aux: 3.113e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10368, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.373e+00, Loss Aux: 2.472e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10369, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.272e+00, Loss Aux: 2.995e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10370, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.336e+00, Loss Aux: 3.876e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 10371, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.959e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10372, It: 0, Loss Data: 8.400e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.207e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10373, It: 0, Loss Data: 8.523e-02, Loss Eqns: 2.390e+00, Loss Aux: 2.564e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10374, It: 0, Loss Data: 8.479e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.792e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10375, It: 0, Loss Data: 9.807e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.310e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10376, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.637e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10377, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.052e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10378, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.389e+00, Loss Aux: 1.966e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10379, It: 0, Loss Data: 9.583e-02, Loss Eqns: 2.467e+00, Loss Aux: 2.501e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10380, It: 0, Loss Data: 7.060e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.064e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10381, It: 0, Loss Data: 8.073e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.054e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10382, It: 0, Loss Data: 7.489e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.514e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10383, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.422e+00, Loss Aux: 4.245e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10384, It: 0, Loss Data: 9.873e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.082e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10385, It: 0, Loss Data: 8.175e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.030e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10386, It: 0, Loss Data: 6.479e-02, Loss Eqns: 2.435e+00, Loss Aux: 2.294e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10387, It: 0, Loss Data: 8.268e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.446e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10388, It: 0, Loss Data: 8.571e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.725e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10389, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.380e+00, Loss Aux: 2.646e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10390, It: 0, Loss Data: 9.659e-02, Loss Eqns: 2.367e+00, Loss Aux: 2.426e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10391, It: 0, Loss Data: 9.437e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.430e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10392, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.350e+00, Loss Aux: 2.335e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10393, It: 0, Loss Data: 8.745e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.756e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10394, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.429e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10395, It: 0, Loss Data: 8.405e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.023e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10396, It: 0, Loss Data: 9.816e-02, Loss Eqns: 2.395e+00, Loss Aux: 2.547e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10397, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.979e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10398, It: 0, Loss Data: 8.065e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.831e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10399, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.574e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10400, It: 0, Loss Data: 9.467e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.621e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10401, It: 0, Loss Data: 8.928e-02, Loss Eqns: 2.353e+00, Loss Aux: 2.042e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10402, It: 0, Loss Data: 9.403e-02, Loss Eqns: 2.305e+00, Loss Aux: 2.100e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10403, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.341e+00, Loss Aux: 2.792e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10404, It: 0, Loss Data: 8.142e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.125e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10405, It: 0, Loss Data: 7.810e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.064e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10406, It: 0, Loss Data: 9.440e-02, Loss Eqns: 2.320e+00, Loss Aux: 2.746e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10407, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.316e+00, Loss Aux: 2.496e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10408, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.348e+00, Loss Aux: 2.372e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10409, It: 0, Loss Data: 9.450e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.338e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10410, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.346e+00, Loss Aux: 2.545e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10411, It: 0, Loss Data: 8.358e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.115e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10412, It: 0, Loss Data: 9.004e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.420e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10413, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.439e+00, Loss Aux: 3.046e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10414, It: 0, Loss Data: 7.344e-02, Loss Eqns: 2.494e+00, Loss Aux: 2.761e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10415, It: 0, Loss Data: 9.210e-02, Loss Eqns: 2.460e+00, Loss Aux: 2.651e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10416, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.469e+00, Loss Aux: 2.436e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 10417, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.354e+00, Loss Aux: 2.263e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10418, It: 0, Loss Data: 8.150e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.285e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10419, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.563e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10420, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.221e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10421, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.268e+00, Loss Aux: 2.781e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10422, It: 0, Loss Data: 9.618e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.205e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10423, It: 0, Loss Data: 9.760e-02, Loss Eqns: 2.468e+00, Loss Aux: 1.607e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10424, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.390e+00, Loss Aux: 1.976e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10425, It: 0, Loss Data: 9.287e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.045e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10426, It: 0, Loss Data: 7.119e-02, Loss Eqns: 2.484e+00, Loss Aux: 4.017e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10427, It: 0, Loss Data: 8.266e-02, Loss Eqns: 2.463e+00, Loss Aux: 3.686e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 10428, It: 0, Loss Data: 8.559e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.587e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10429, It: 0, Loss Data: 9.544e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.338e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10430, It: 0, Loss Data: 9.953e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.750e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10431, It: 0, Loss Data: 8.012e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.496e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10432, It: 0, Loss Data: 8.986e-02, Loss Eqns: 2.528e+00, Loss Aux: 2.432e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10433, It: 0, Loss Data: 9.893e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.555e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10434, It: 0, Loss Data: 7.633e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.364e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10435, It: 0, Loss Data: 8.225e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.294e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10436, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.511e+00, Loss Aux: 2.404e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10437, It: 0, Loss Data: 8.217e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.552e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10438, It: 0, Loss Data: 8.410e-02, Loss Eqns: 2.409e+00, Loss Aux: 3.171e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10439, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.523e+00, Loss Aux: 4.138e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10440, It: 0, Loss Data: 8.544e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.608e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10441, It: 0, Loss Data: 9.859e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.699e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10442, It: 0, Loss Data: 8.839e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.335e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10443, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.488e+00, Loss Aux: 2.031e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10444, It: 0, Loss Data: 9.981e-02, Loss Eqns: 2.349e+00, Loss Aux: 1.799e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10445, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.360e+00, Loss Aux: 1.727e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10446, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.480e+00, Loss Aux: 2.197e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10447, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.846e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10448, It: 0, Loss Data: 8.632e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.182e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10449, It: 0, Loss Data: 8.495e-02, Loss Eqns: 2.490e+00, Loss Aux: 3.044e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10450, It: 0, Loss Data: 9.661e-02, Loss Eqns: 2.540e+00, Loss Aux: 2.361e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10451, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.262e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10452, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.205e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10453, It: 0, Loss Data: 9.312e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.687e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10454, It: 0, Loss Data: 9.366e-02, Loss Eqns: 2.403e+00, Loss Aux: 2.992e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10455, It: 0, Loss Data: 9.674e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.177e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10456, It: 0, Loss Data: 8.516e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.134e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10457, It: 0, Loss Data: 7.761e-02, Loss Eqns: 2.479e+00, Loss Aux: 2.508e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10458, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.900e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10459, It: 0, Loss Data: 8.135e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.756e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10460, It: 0, Loss Data: 9.550e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.472e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10461, It: 0, Loss Data: 1.169e-01, Loss Eqns: 2.356e+00, Loss Aux: 2.392e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 10462, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.894e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10463, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.363e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10464, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.388e+00, Loss Aux: 3.016e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10465, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.704e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10466, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.515e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10467, It: 0, Loss Data: 9.144e-02, Loss Eqns: 2.321e+00, Loss Aux: 2.442e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 10468, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.155e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10469, It: 0, Loss Data: 8.613e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.214e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10470, It: 0, Loss Data: 7.952e-02, Loss Eqns: 2.396e+00, Loss Aux: 2.221e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10471, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.640e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10472, It: 0, Loss Data: 7.677e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.036e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10473, It: 0, Loss Data: 8.536e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.927e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10474, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.310e+00, Loss Aux: 2.575e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 10475, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.316e+00, Loss Aux: 2.786e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10476, It: 0, Loss Data: 9.481e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.527e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10477, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.341e+00, Loss Aux: 3.268e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10478, It: 0, Loss Data: 8.499e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.578e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10479, It: 0, Loss Data: 8.500e-02, Loss Eqns: 2.265e+00, Loss Aux: 2.205e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10480, It: 0, Loss Data: 7.906e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.532e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10481, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.445e+00, Loss Aux: 3.011e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10482, It: 0, Loss Data: 9.370e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.764e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10483, It: 0, Loss Data: 7.661e-02, Loss Eqns: 2.495e+00, Loss Aux: 2.802e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10484, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.763e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10485, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.786e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 10486, It: 0, Loss Data: 7.570e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.881e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10487, It: 0, Loss Data: 9.009e-02, Loss Eqns: 2.467e+00, Loss Aux: 2.038e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10488, It: 0, Loss Data: 7.928e-02, Loss Eqns: 2.375e+00, Loss Aux: 1.885e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10489, It: 0, Loss Data: 8.348e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.148e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10490, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.946e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10491, It: 0, Loss Data: 7.730e-02, Loss Eqns: 2.488e+00, Loss Aux: 3.232e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10492, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.773e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10493, It: 0, Loss Data: 8.524e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.007e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10494, It: 0, Loss Data: 8.017e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.462e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10495, It: 0, Loss Data: 9.144e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.148e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10496, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.305e+00, Loss Aux: 2.355e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10497, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.367e+00, Loss Aux: 2.296e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10498, It: 0, Loss Data: 8.548e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.643e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10499, It: 0, Loss Data: 9.360e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.286e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 10500, It: 0, Loss Data: 7.929e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.879e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10501, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.413e+00, Loss Aux: 1.919e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10502, It: 0, Loss Data: 8.112e-02, Loss Eqns: 2.402e+00, Loss Aux: 1.782e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10503, It: 0, Loss Data: 7.826e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.709e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10504, It: 0, Loss Data: 9.334e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.690e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10505, It: 0, Loss Data: 8.935e-02, Loss Eqns: 2.205e+00, Loss Aux: 3.111e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10506, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.296e+00, Loss Aux: 2.275e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 10507, It: 0, Loss Data: 8.940e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.008e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10508, It: 0, Loss Data: 8.723e-02, Loss Eqns: 2.278e+00, Loss Aux: 2.782e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10509, It: 0, Loss Data: 9.550e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.329e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10510, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.236e+00, Loss Aux: 2.524e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10511, It: 0, Loss Data: 8.746e-02, Loss Eqns: 2.258e+00, Loss Aux: 1.923e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10512, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.298e+00, Loss Aux: 2.404e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10513, It: 0, Loss Data: 9.960e-02, Loss Eqns: 2.212e+00, Loss Aux: 3.190e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10514, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.019e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10515, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.274e+00, Loss Aux: 2.912e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10516, It: 0, Loss Data: 9.281e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.057e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 10517, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.222e+00, Loss Aux: 3.024e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 10518, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.932e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10519, It: 0, Loss Data: 8.760e-02, Loss Eqns: 2.248e+00, Loss Aux: 2.568e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10520, It: 0, Loss Data: 8.507e-02, Loss Eqns: 2.261e+00, Loss Aux: 1.816e-02, Time: 0.144, Learning Rate: 1.0e-03\n",
      "Epoch: 10521, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.359e+00, Loss Aux: 1.507e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10522, It: 0, Loss Data: 9.374e-02, Loss Eqns: 2.312e+00, Loss Aux: 1.661e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10523, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.366e+00, Loss Aux: 2.567e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10524, It: 0, Loss Data: 8.835e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.811e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10525, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.559e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10526, It: 0, Loss Data: 9.633e-02, Loss Eqns: 2.486e+00, Loss Aux: 2.661e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10527, It: 0, Loss Data: 8.654e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.140e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10528, It: 0, Loss Data: 8.532e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.512e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10529, It: 0, Loss Data: 8.058e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.428e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10530, It: 0, Loss Data: 9.541e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.672e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10531, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.297e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10532, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.368e+00, Loss Aux: 2.266e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10533, It: 0, Loss Data: 8.274e-02, Loss Eqns: 2.431e+00, Loss Aux: 1.922e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10534, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.354e+00, Loss Aux: 1.487e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10535, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.391e+00, Loss Aux: 1.752e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 10536, It: 0, Loss Data: 9.154e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.968e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10537, It: 0, Loss Data: 7.998e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.431e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10538, It: 0, Loss Data: 8.453e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.042e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 10539, It: 0, Loss Data: 7.987e-02, Loss Eqns: 2.470e+00, Loss Aux: 2.512e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10540, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.236e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10541, It: 0, Loss Data: 7.989e-02, Loss Eqns: 2.421e+00, Loss Aux: 2.490e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10542, It: 0, Loss Data: 8.869e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.703e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10543, It: 0, Loss Data: 8.874e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.454e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10544, It: 0, Loss Data: 8.578e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.284e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 10545, It: 0, Loss Data: 7.796e-02, Loss Eqns: 2.343e+00, Loss Aux: 2.491e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10546, It: 0, Loss Data: 8.607e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.525e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10547, It: 0, Loss Data: 7.392e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.696e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 10548, It: 0, Loss Data: 8.362e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.547e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10549, It: 0, Loss Data: 7.855e-02, Loss Eqns: 2.286e+00, Loss Aux: 2.414e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10550, It: 0, Loss Data: 9.784e-02, Loss Eqns: 2.228e+00, Loss Aux: 2.787e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10551, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.281e+00, Loss Aux: 2.983e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10552, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.808e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10553, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.363e+00, Loss Aux: 2.260e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10554, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.147e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10555, It: 0, Loss Data: 8.165e-02, Loss Eqns: 2.300e+00, Loss Aux: 2.076e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10556, It: 0, Loss Data: 9.177e-02, Loss Eqns: 2.284e+00, Loss Aux: 2.638e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10557, It: 0, Loss Data: 9.973e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.862e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10558, It: 0, Loss Data: 9.117e-02, Loss Eqns: 2.307e+00, Loss Aux: 2.537e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10559, It: 0, Loss Data: 8.159e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.336e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10560, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.793e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 10561, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.446e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10562, It: 0, Loss Data: 9.061e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.392e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10563, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.552e+00, Loss Aux: 2.608e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10564, It: 0, Loss Data: 7.636e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.636e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10565, It: 0, Loss Data: 9.316e-02, Loss Eqns: 2.353e+00, Loss Aux: 2.930e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10566, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.309e+00, Loss Aux: 2.807e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10567, It: 0, Loss Data: 9.484e-02, Loss Eqns: 2.309e+00, Loss Aux: 2.280e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10568, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.301e+00, Loss Aux: 2.065e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10569, It: 0, Loss Data: 8.221e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.509e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10570, It: 0, Loss Data: 7.436e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.090e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10571, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.360e+00, Loss Aux: 3.254e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10572, It: 0, Loss Data: 7.741e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.835e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10573, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.340e+00, Loss Aux: 2.376e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10574, It: 0, Loss Data: 8.742e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.244e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 10575, It: 0, Loss Data: 8.989e-02, Loss Eqns: 2.301e+00, Loss Aux: 2.409e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10576, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.336e+00, Loss Aux: 2.268e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10577, It: 0, Loss Data: 9.465e-02, Loss Eqns: 2.340e+00, Loss Aux: 2.257e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10578, It: 0, Loss Data: 8.809e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.431e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10579, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.840e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10580, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.824e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10581, It: 0, Loss Data: 8.529e-02, Loss Eqns: 2.361e+00, Loss Aux: 2.520e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10582, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.449e+00, Loss Aux: 2.454e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10583, It: 0, Loss Data: 9.636e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.251e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10584, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.233e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10585, It: 0, Loss Data: 7.109e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.556e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10586, It: 0, Loss Data: 7.968e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.146e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10587, It: 0, Loss Data: 9.421e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.721e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 10588, It: 0, Loss Data: 7.652e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.481e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10589, It: 0, Loss Data: 7.764e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.547e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10590, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.322e+00, Loss Aux: 2.463e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10591, It: 0, Loss Data: 9.008e-02, Loss Eqns: 2.329e+00, Loss Aux: 1.546e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10592, It: 0, Loss Data: 8.411e-02, Loss Eqns: 2.366e+00, Loss Aux: 1.773e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10593, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.261e+00, Loss Aux: 2.254e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10594, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.253e+00, Loss Aux: 2.087e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10595, It: 0, Loss Data: 9.718e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.547e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10596, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.955e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10597, It: 0, Loss Data: 8.851e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.306e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10598, It: 0, Loss Data: 9.289e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.229e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10599, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.030e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10600, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.341e+00, Loss Aux: 2.773e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10601, It: 0, Loss Data: 7.926e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.195e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10602, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.959e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10603, It: 0, Loss Data: 7.312e-02, Loss Eqns: 2.364e+00, Loss Aux: 2.428e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10604, It: 0, Loss Data: 8.032e-02, Loss Eqns: 2.348e+00, Loss Aux: 1.989e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10605, It: 0, Loss Data: 9.203e-02, Loss Eqns: 2.450e+00, Loss Aux: 1.714e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10606, It: 0, Loss Data: 8.374e-02, Loss Eqns: 2.371e+00, Loss Aux: 2.268e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10607, It: 0, Loss Data: 7.798e-02, Loss Eqns: 2.488e+00, Loss Aux: 3.173e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10608, It: 0, Loss Data: 9.934e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.775e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10609, It: 0, Loss Data: 9.375e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.725e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10610, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.549e+00, Loss Aux: 3.061e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10611, It: 0, Loss Data: 9.276e-02, Loss Eqns: 2.369e+00, Loss Aux: 2.984e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10612, It: 0, Loss Data: 8.643e-02, Loss Eqns: 2.366e+00, Loss Aux: 2.667e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10613, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.785e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10614, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.307e+00, Loss Aux: 2.537e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10615, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.249e+00, Loss Aux: 2.761e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10616, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.399e+00, Loss Aux: 2.694e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10617, It: 0, Loss Data: 8.849e-02, Loss Eqns: 2.300e+00, Loss Aux: 2.499e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10618, It: 0, Loss Data: 7.897e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.624e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10619, It: 0, Loss Data: 9.361e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.652e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10620, It: 0, Loss Data: 9.925e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.249e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10621, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.421e+00, Loss Aux: 2.297e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10622, It: 0, Loss Data: 9.313e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.438e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10623, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.340e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10624, It: 0, Loss Data: 8.900e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.741e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10625, It: 0, Loss Data: 7.962e-02, Loss Eqns: 2.476e+00, Loss Aux: 2.819e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10626, It: 0, Loss Data: 8.935e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.880e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10627, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.048e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10628, It: 0, Loss Data: 8.309e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.644e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10629, It: 0, Loss Data: 9.680e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.152e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10630, It: 0, Loss Data: 9.573e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.256e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10631, It: 0, Loss Data: 8.074e-02, Loss Eqns: 2.369e+00, Loss Aux: 2.453e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10632, It: 0, Loss Data: 8.069e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.518e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10633, It: 0, Loss Data: 8.757e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.680e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 10634, It: 0, Loss Data: 7.780e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.059e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 10635, It: 0, Loss Data: 8.632e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.139e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10636, It: 0, Loss Data: 9.483e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.945e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10637, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.501e+00, Loss Aux: 2.428e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10638, It: 0, Loss Data: 8.367e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.084e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10639, It: 0, Loss Data: 7.764e-02, Loss Eqns: 2.366e+00, Loss Aux: 2.615e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10640, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.328e+00, Loss Aux: 2.752e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10641, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.268e+00, Loss Aux: 2.425e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10642, It: 0, Loss Data: 9.219e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.207e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10643, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.388e+00, Loss Aux: 2.742e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 10644, It: 0, Loss Data: 8.207e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.579e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10645, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.493e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10646, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.669e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10647, It: 0, Loss Data: 9.068e-02, Loss Eqns: 2.382e+00, Loss Aux: 2.886e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10648, It: 0, Loss Data: 9.986e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.898e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10649, It: 0, Loss Data: 9.210e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.270e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10650, It: 0, Loss Data: 7.823e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.166e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10651, It: 0, Loss Data: 9.983e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.660e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10652, It: 0, Loss Data: 9.683e-02, Loss Eqns: 2.459e+00, Loss Aux: 2.696e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10653, It: 0, Loss Data: 8.080e-02, Loss Eqns: 2.479e+00, Loss Aux: 1.681e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10654, It: 0, Loss Data: 8.303e-02, Loss Eqns: 2.445e+00, Loss Aux: 1.524e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 10655, It: 0, Loss Data: 9.775e-02, Loss Eqns: 2.397e+00, Loss Aux: 2.764e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 10656, It: 0, Loss Data: 9.376e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.087e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 10657, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.332e+00, Loss Aux: 2.581e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10658, It: 0, Loss Data: 8.717e-02, Loss Eqns: 2.392e+00, Loss Aux: 2.132e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10659, It: 0, Loss Data: 9.517e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.329e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10660, It: 0, Loss Data: 8.825e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.552e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10661, It: 0, Loss Data: 8.258e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.420e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10662, It: 0, Loss Data: 9.507e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.734e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10663, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.772e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10664, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.339e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10665, It: 0, Loss Data: 9.142e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.195e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10666, It: 0, Loss Data: 8.661e-02, Loss Eqns: 2.353e+00, Loss Aux: 2.232e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10667, It: 0, Loss Data: 9.917e-02, Loss Eqns: 2.415e+00, Loss Aux: 2.105e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10668, It: 0, Loss Data: 8.010e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.583e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10669, It: 0, Loss Data: 8.975e-02, Loss Eqns: 2.307e+00, Loss Aux: 2.813e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10670, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.359e+00, Loss Aux: 2.198e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10671, It: 0, Loss Data: 8.112e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.203e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10672, It: 0, Loss Data: 8.485e-02, Loss Eqns: 2.413e+00, Loss Aux: 2.671e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10673, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.385e+00, Loss Aux: 2.916e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10674, It: 0, Loss Data: 9.691e-02, Loss Eqns: 2.407e+00, Loss Aux: 2.739e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10675, It: 0, Loss Data: 8.000e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.472e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10676, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.403e+00, Loss Aux: 2.827e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10677, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.212e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10678, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.865e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10679, It: 0, Loss Data: 8.890e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.174e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10680, It: 0, Loss Data: 8.564e-02, Loss Eqns: 2.480e+00, Loss Aux: 1.844e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10681, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.340e+00, Loss Aux: 2.015e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10682, It: 0, Loss Data: 8.268e-02, Loss Eqns: 2.469e+00, Loss Aux: 2.352e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10683, It: 0, Loss Data: 1.091e-01, Loss Eqns: 2.406e+00, Loss Aux: 2.240e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10684, It: 0, Loss Data: 8.930e-02, Loss Eqns: 2.329e+00, Loss Aux: 1.993e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 10685, It: 0, Loss Data: 8.820e-02, Loss Eqns: 2.367e+00, Loss Aux: 2.455e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10686, It: 0, Loss Data: 8.863e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.778e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10687, It: 0, Loss Data: 9.607e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.055e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10688, It: 0, Loss Data: 8.425e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.146e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10689, It: 0, Loss Data: 8.241e-02, Loss Eqns: 2.350e+00, Loss Aux: 2.838e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10690, It: 0, Loss Data: 8.265e-02, Loss Eqns: 2.329e+00, Loss Aux: 2.862e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10691, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.685e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10692, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.201e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10693, It: 0, Loss Data: 9.717e-02, Loss Eqns: 2.437e+00, Loss Aux: 2.115e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10694, It: 0, Loss Data: 9.625e-02, Loss Eqns: 2.417e+00, Loss Aux: 1.998e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10695, It: 0, Loss Data: 7.715e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.106e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10696, It: 0, Loss Data: 9.028e-02, Loss Eqns: 2.535e+00, Loss Aux: 2.130e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10697, It: 0, Loss Data: 8.321e-02, Loss Eqns: 2.607e+00, Loss Aux: 1.879e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10698, It: 0, Loss Data: 8.637e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.116e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10699, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.069e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10700, It: 0, Loss Data: 9.532e-02, Loss Eqns: 2.824e+00, Loss Aux: 2.989e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10701, It: 0, Loss Data: 8.233e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.161e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10702, It: 0, Loss Data: 1.065e-01, Loss Eqns: 3.490e+00, Loss Aux: 3.420e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10703, It: 0, Loss Data: 1.259e-01, Loss Eqns: 3.215e+00, Loss Aux: 2.146e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10704, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.944e+00, Loss Aux: 2.087e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10705, It: 0, Loss Data: 1.575e-01, Loss Eqns: 3.074e+00, Loss Aux: 2.929e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10706, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.412e+00, Loss Aux: 1.783e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10707, It: 0, Loss Data: 1.461e-01, Loss Eqns: 3.001e+00, Loss Aux: 1.701e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10708, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.428e+00, Loss Aux: 2.766e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10709, It: 0, Loss Data: 1.269e-01, Loss Eqns: 3.835e+00, Loss Aux: 4.933e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10710, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.364e+00, Loss Aux: 4.941e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10711, It: 0, Loss Data: 1.249e-01, Loss Eqns: 3.611e+00, Loss Aux: 4.075e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10712, It: 0, Loss Data: 1.069e-01, Loss Eqns: 3.263e+00, Loss Aux: 4.313e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10713, It: 0, Loss Data: 1.294e-01, Loss Eqns: 3.462e+00, Loss Aux: 3.023e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10714, It: 0, Loss Data: 1.311e-01, Loss Eqns: 2.940e+00, Loss Aux: 1.857e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10715, It: 0, Loss Data: 1.454e-01, Loss Eqns: 2.954e+00, Loss Aux: 2.032e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10716, It: 0, Loss Data: 1.231e-01, Loss Eqns: 2.823e+00, Loss Aux: 3.061e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 10717, It: 0, Loss Data: 1.345e-01, Loss Eqns: 2.776e+00, Loss Aux: 3.451e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10718, It: 0, Loss Data: 1.266e-01, Loss Eqns: 2.668e+00, Loss Aux: 2.655e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10719, It: 0, Loss Data: 1.172e-01, Loss Eqns: 2.723e+00, Loss Aux: 2.587e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10720, It: 0, Loss Data: 9.929e-02, Loss Eqns: 2.722e+00, Loss Aux: 3.618e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10721, It: 0, Loss Data: 1.249e-01, Loss Eqns: 2.765e+00, Loss Aux: 3.394e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10722, It: 0, Loss Data: 1.226e-01, Loss Eqns: 2.483e+00, Loss Aux: 2.648e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10723, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.546e+00, Loss Aux: 3.083e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10724, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.554e+00, Loss Aux: 4.560e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10725, It: 0, Loss Data: 1.141e-01, Loss Eqns: 2.550e+00, Loss Aux: 4.597e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10726, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.438e+00, Loss Aux: 2.925e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10727, It: 0, Loss Data: 1.222e-01, Loss Eqns: 2.542e+00, Loss Aux: 1.767e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10728, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.661e+00, Loss Aux: 1.702e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10729, It: 0, Loss Data: 9.596e-02, Loss Eqns: 2.550e+00, Loss Aux: 2.573e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10730, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.579e+00, Loss Aux: 3.028e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10731, It: 0, Loss Data: 9.659e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.838e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10732, It: 0, Loss Data: 9.683e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.576e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10733, It: 0, Loss Data: 8.508e-02, Loss Eqns: 2.413e+00, Loss Aux: 4.188e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10734, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.400e+00, Loss Aux: 2.802e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10735, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.542e+00, Loss Aux: 2.314e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10736, It: 0, Loss Data: 8.522e-02, Loss Eqns: 2.466e+00, Loss Aux: 2.550e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 10737, It: 0, Loss Data: 9.222e-02, Loss Eqns: 2.530e+00, Loss Aux: 2.908e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10738, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.995e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10739, It: 0, Loss Data: 8.860e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.421e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10740, It: 0, Loss Data: 9.283e-02, Loss Eqns: 2.531e+00, Loss Aux: 3.591e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10741, It: 0, Loss Data: 9.227e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.521e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10742, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.378e+00, Loss Aux: 1.880e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10743, It: 0, Loss Data: 9.604e-02, Loss Eqns: 2.341e+00, Loss Aux: 2.321e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10744, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.230e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10745, It: 0, Loss Data: 8.129e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.932e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10746, It: 0, Loss Data: 9.395e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.901e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10747, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.338e+00, Loss Aux: 3.647e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10748, It: 0, Loss Data: 9.919e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.947e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10749, It: 0, Loss Data: 8.324e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.610e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10750, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.413e+00, Loss Aux: 2.755e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10751, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.360e+00, Loss Aux: 2.606e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10752, It: 0, Loss Data: 9.315e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.927e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10753, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.244e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10754, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.922e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10755, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.425e+00, Loss Aux: 2.409e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10756, It: 0, Loss Data: 8.219e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.542e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10757, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.130e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10758, It: 0, Loss Data: 8.917e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.566e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 10759, It: 0, Loss Data: 1.224e-01, Loss Eqns: 2.505e+00, Loss Aux: 2.940e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 10760, It: 0, Loss Data: 1.250e-01, Loss Eqns: 2.708e+00, Loss Aux: 3.305e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10761, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.446e+00, Loss Aux: 3.442e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10762, It: 0, Loss Data: 9.367e-02, Loss Eqns: 2.536e+00, Loss Aux: 2.536e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10763, It: 0, Loss Data: 1.113e-01, Loss Eqns: 2.565e+00, Loss Aux: 2.952e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10764, It: 0, Loss Data: 9.462e-02, Loss Eqns: 2.518e+00, Loss Aux: 4.107e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10765, It: 0, Loss Data: 9.281e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.522e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10766, It: 0, Loss Data: 1.164e-01, Loss Eqns: 2.531e+00, Loss Aux: 2.067e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 10767, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.449e+00, Loss Aux: 2.242e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 10768, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.375e+00, Loss Aux: 4.709e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10769, It: 0, Loss Data: 1.157e-01, Loss Eqns: 2.498e+00, Loss Aux: 4.620e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10770, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.220e+00, Loss Aux: 2.666e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10771, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.350e+00, Loss Aux: 2.284e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 10772, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.099e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10773, It: 0, Loss Data: 1.326e-01, Loss Eqns: 2.357e+00, Loss Aux: 4.097e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10774, It: 0, Loss Data: 8.972e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.071e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10775, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.482e+00, Loss Aux: 2.633e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10776, It: 0, Loss Data: 8.668e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.071e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10777, It: 0, Loss Data: 9.162e-02, Loss Eqns: 2.483e+00, Loss Aux: 4.132e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10778, It: 0, Loss Data: 8.852e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.872e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10779, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.485e+00, Loss Aux: 3.154e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10780, It: 0, Loss Data: 9.237e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.106e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10781, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.515e+00, Loss Aux: 3.109e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10782, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.382e+00, Loss Aux: 2.361e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10783, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.454e+00, Loss Aux: 2.151e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10784, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.440e+00, Loss Aux: 2.605e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10785, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.567e+00, Loss Aux: 2.467e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10786, It: 0, Loss Data: 9.534e-02, Loss Eqns: 2.419e+00, Loss Aux: 1.875e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10787, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.462e+00, Loss Aux: 2.619e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10788, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.261e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10789, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.545e+00, Loss Aux: 4.656e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10790, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.374e+00, Loss Aux: 4.085e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10791, It: 0, Loss Data: 8.864e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.415e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 10792, It: 0, Loss Data: 9.855e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.563e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10793, It: 0, Loss Data: 9.842e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.932e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10794, It: 0, Loss Data: 8.302e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.123e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10795, It: 0, Loss Data: 1.054e-01, Loss Eqns: 2.420e+00, Loss Aux: 2.335e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10796, It: 0, Loss Data: 9.232e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.714e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10797, It: 0, Loss Data: 9.785e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.782e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10798, It: 0, Loss Data: 8.316e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.749e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10799, It: 0, Loss Data: 9.240e-02, Loss Eqns: 2.357e+00, Loss Aux: 3.256e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10800, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.369e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10801, It: 0, Loss Data: 8.986e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.380e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10802, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.361e+00, Loss Aux: 2.809e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10803, It: 0, Loss Data: 9.542e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.676e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10804, It: 0, Loss Data: 8.241e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.101e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10805, It: 0, Loss Data: 9.149e-02, Loss Eqns: 2.461e+00, Loss Aux: 3.170e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10806, It: 0, Loss Data: 9.081e-02, Loss Eqns: 2.549e+00, Loss Aux: 2.522e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10807, It: 0, Loss Data: 8.358e-02, Loss Eqns: 2.480e+00, Loss Aux: 2.344e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10808, It: 0, Loss Data: 8.249e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.778e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10809, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.630e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10810, It: 0, Loss Data: 9.800e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.319e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10811, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.456e+00, Loss Aux: 2.903e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10812, It: 0, Loss Data: 8.481e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.497e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10813, It: 0, Loss Data: 8.605e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.555e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10814, It: 0, Loss Data: 9.683e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.160e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10815, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.182e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10816, It: 0, Loss Data: 9.312e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.100e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10817, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.388e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10818, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.337e+00, Loss Aux: 3.305e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10819, It: 0, Loss Data: 9.403e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.353e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10820, It: 0, Loss Data: 8.278e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.144e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10821, It: 0, Loss Data: 9.418e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.389e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10822, It: 0, Loss Data: 8.783e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.701e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10823, It: 0, Loss Data: 7.830e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.331e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10824, It: 0, Loss Data: 9.064e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.455e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 10825, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.316e+00, Loss Aux: 3.264e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10826, It: 0, Loss Data: 9.451e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.179e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10827, It: 0, Loss Data: 9.747e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.414e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10828, It: 0, Loss Data: 8.448e-02, Loss Eqns: 2.468e+00, Loss Aux: 3.487e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10829, It: 0, Loss Data: 8.234e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.359e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10830, It: 0, Loss Data: 8.839e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.174e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10831, It: 0, Loss Data: 8.989e-02, Loss Eqns: 2.441e+00, Loss Aux: 3.181e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10832, It: 0, Loss Data: 7.715e-02, Loss Eqns: 2.440e+00, Loss Aux: 3.326e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10833, It: 0, Loss Data: 7.617e-02, Loss Eqns: 2.454e+00, Loss Aux: 3.135e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10834, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.896e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10835, It: 0, Loss Data: 7.977e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.995e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10836, It: 0, Loss Data: 8.147e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.119e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10837, It: 0, Loss Data: 9.501e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.154e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10838, It: 0, Loss Data: 9.423e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.024e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10839, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.149e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10840, It: 0, Loss Data: 8.662e-02, Loss Eqns: 2.400e+00, Loss Aux: 2.918e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10841, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.066e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10842, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.489e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10843, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.388e+00, Loss Aux: 3.624e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 10844, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.166e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10845, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.469e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10846, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.339e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10847, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.318e+00, Loss Aux: 2.498e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10848, It: 0, Loss Data: 7.718e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.376e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10849, It: 0, Loss Data: 8.929e-02, Loss Eqns: 2.335e+00, Loss Aux: 2.378e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10850, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.935e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10851, It: 0, Loss Data: 8.602e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.591e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10852, It: 0, Loss Data: 7.721e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.627e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10853, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.207e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10854, It: 0, Loss Data: 9.045e-02, Loss Eqns: 2.277e+00, Loss Aux: 2.844e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10855, It: 0, Loss Data: 8.023e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.826e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10856, It: 0, Loss Data: 9.032e-02, Loss Eqns: 2.367e+00, Loss Aux: 2.951e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10857, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.861e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10858, It: 0, Loss Data: 9.981e-02, Loss Eqns: 2.315e+00, Loss Aux: 2.398e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10859, It: 0, Loss Data: 8.158e-02, Loss Eqns: 2.272e+00, Loss Aux: 2.304e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10860, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.294e+00, Loss Aux: 2.395e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10861, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.436e+00, Loss Aux: 3.225e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10862, It: 0, Loss Data: 8.326e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.198e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 10863, It: 0, Loss Data: 9.276e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.123e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10864, It: 0, Loss Data: 8.201e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.398e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 10865, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.516e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10866, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.760e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10867, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.371e+00, Loss Aux: 2.498e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10868, It: 0, Loss Data: 8.751e-02, Loss Eqns: 2.510e+00, Loss Aux: 2.789e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10869, It: 0, Loss Data: 9.184e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.043e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10870, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.342e+00, Loss Aux: 2.975e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10871, It: 0, Loss Data: 8.913e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.279e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10872, It: 0, Loss Data: 7.855e-02, Loss Eqns: 2.548e+00, Loss Aux: 3.366e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10873, It: 0, Loss Data: 8.276e-02, Loss Eqns: 2.539e+00, Loss Aux: 2.679e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10874, It: 0, Loss Data: 9.379e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.703e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10875, It: 0, Loss Data: 7.775e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.069e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10876, It: 0, Loss Data: 9.042e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.371e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 10877, It: 0, Loss Data: 8.681e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.294e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10878, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.393e+00, Loss Aux: 2.942e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 10879, It: 0, Loss Data: 7.776e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.640e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10880, It: 0, Loss Data: 8.336e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.204e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10881, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.351e+00, Loss Aux: 2.432e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 10882, It: 0, Loss Data: 9.298e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.823e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 10883, It: 0, Loss Data: 9.482e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.997e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10884, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.682e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10885, It: 0, Loss Data: 7.855e-02, Loss Eqns: 2.395e+00, Loss Aux: 2.634e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10886, It: 0, Loss Data: 8.063e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.028e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 10887, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.040e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10888, It: 0, Loss Data: 9.968e-02, Loss Eqns: 2.393e+00, Loss Aux: 2.495e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 10889, It: 0, Loss Data: 8.171e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.822e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10890, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.458e+00, Loss Aux: 3.259e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10891, It: 0, Loss Data: 7.564e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.118e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10892, It: 0, Loss Data: 7.433e-02, Loss Eqns: 2.285e+00, Loss Aux: 2.568e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 10893, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.377e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10894, It: 0, Loss Data: 7.897e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.856e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10895, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.151e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 10896, It: 0, Loss Data: 8.646e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.985e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10897, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.376e+00, Loss Aux: 2.812e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10898, It: 0, Loss Data: 7.189e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.871e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10899, It: 0, Loss Data: 8.140e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.278e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 10900, It: 0, Loss Data: 8.960e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.607e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10901, It: 0, Loss Data: 8.267e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.162e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10902, It: 0, Loss Data: 7.960e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.865e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10903, It: 0, Loss Data: 9.796e-02, Loss Eqns: 2.304e+00, Loss Aux: 2.908e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10904, It: 0, Loss Data: 9.716e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.011e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10905, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.326e+00, Loss Aux: 3.067e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10906, It: 0, Loss Data: 9.706e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.266e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10907, It: 0, Loss Data: 9.374e-02, Loss Eqns: 2.338e+00, Loss Aux: 2.737e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10908, It: 0, Loss Data: 9.236e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.378e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10909, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.315e+00, Loss Aux: 2.668e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10910, It: 0, Loss Data: 7.372e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.438e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10911, It: 0, Loss Data: 9.446e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.688e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10912, It: 0, Loss Data: 8.090e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.084e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10913, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.192e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10914, It: 0, Loss Data: 8.815e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.351e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10915, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.328e+00, Loss Aux: 2.853e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10916, It: 0, Loss Data: 8.485e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.066e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 10917, It: 0, Loss Data: 8.834e-02, Loss Eqns: 2.303e+00, Loss Aux: 2.143e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10918, It: 0, Loss Data: 8.244e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.391e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10919, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.736e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10920, It: 0, Loss Data: 9.297e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.747e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 10921, It: 0, Loss Data: 8.906e-02, Loss Eqns: 2.324e+00, Loss Aux: 2.537e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 10922, It: 0, Loss Data: 9.353e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.768e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10923, It: 0, Loss Data: 8.737e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.234e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10924, It: 0, Loss Data: 8.819e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.286e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 10925, It: 0, Loss Data: 8.520e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.938e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 10926, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.434e+00, Loss Aux: 2.500e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10927, It: 0, Loss Data: 8.909e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.872e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10928, It: 0, Loss Data: 9.858e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.424e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10929, It: 0, Loss Data: 9.129e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.722e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10930, It: 0, Loss Data: 9.093e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.282e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 10931, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.425e+00, Loss Aux: 2.611e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 10932, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.438e+00, Loss Aux: 2.669e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10933, It: 0, Loss Data: 8.346e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.695e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10934, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.325e+00, Loss Aux: 2.892e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10935, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.358e+00, Loss Aux: 2.660e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 10936, It: 0, Loss Data: 8.860e-02, Loss Eqns: 2.242e+00, Loss Aux: 2.279e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10937, It: 0, Loss Data: 8.020e-02, Loss Eqns: 2.273e+00, Loss Aux: 2.718e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10938, It: 0, Loss Data: 9.391e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.144e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10939, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.307e+00, Loss Aux: 2.669e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10940, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.306e+00, Loss Aux: 2.355e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10941, It: 0, Loss Data: 9.563e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.794e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10942, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.483e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10943, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.300e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 10944, It: 0, Loss Data: 1.244e-01, Loss Eqns: 2.312e+00, Loss Aux: 2.847e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 10945, It: 0, Loss Data: 8.225e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.652e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 10946, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.306e+00, Loss Aux: 2.501e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 10947, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.439e+00, Loss Aux: 2.415e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10948, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.294e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10949, It: 0, Loss Data: 8.884e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.540e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10950, It: 0, Loss Data: 8.398e-02, Loss Eqns: 2.447e+00, Loss Aux: 3.040e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 10951, It: 0, Loss Data: 8.630e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.649e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10952, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.520e+00, Loss Aux: 3.535e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10953, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.500e+00, Loss Aux: 2.704e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 10954, It: 0, Loss Data: 9.733e-02, Loss Eqns: 2.464e+00, Loss Aux: 2.549e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10955, It: 0, Loss Data: 9.237e-02, Loss Eqns: 2.427e+00, Loss Aux: 2.892e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 10956, It: 0, Loss Data: 7.205e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.971e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 10957, It: 0, Loss Data: 7.930e-02, Loss Eqns: 2.380e+00, Loss Aux: 2.391e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 10958, It: 0, Loss Data: 9.862e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.475e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 10959, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.367e+00, Loss Aux: 3.283e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10960, It: 0, Loss Data: 9.875e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.085e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10961, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.175e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10962, It: 0, Loss Data: 1.211e-01, Loss Eqns: 2.407e+00, Loss Aux: 1.914e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 10963, It: 0, Loss Data: 9.914e-02, Loss Eqns: 2.350e+00, Loss Aux: 1.835e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10964, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.991e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 10965, It: 0, Loss Data: 8.689e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.844e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 10966, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.330e+00, Loss Aux: 3.030e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 10967, It: 0, Loss Data: 9.638e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.442e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10968, It: 0, Loss Data: 8.684e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.372e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10969, It: 0, Loss Data: 8.524e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.725e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10970, It: 0, Loss Data: 8.040e-02, Loss Eqns: 2.448e+00, Loss Aux: 2.701e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10971, It: 0, Loss Data: 8.855e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.880e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 10972, It: 0, Loss Data: 7.250e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.050e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 10973, It: 0, Loss Data: 9.469e-02, Loss Eqns: 2.310e+00, Loss Aux: 2.917e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10974, It: 0, Loss Data: 8.073e-02, Loss Eqns: 2.441e+00, Loss Aux: 2.457e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10975, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.119e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 10976, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.280e+00, Loss Aux: 2.015e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 10977, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.414e+00, Loss Aux: 3.062e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 10978, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.466e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 10979, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.300e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 10980, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.337e+00, Loss Aux: 3.766e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 10981, It: 0, Loss Data: 8.623e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.405e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 10982, It: 0, Loss Data: 8.207e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.326e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10983, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.309e+00, Loss Aux: 3.270e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 10984, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.310e+00, Loss Aux: 2.706e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 10985, It: 0, Loss Data: 8.757e-02, Loss Eqns: 2.296e+00, Loss Aux: 2.149e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 10986, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.431e+00, Loss Aux: 2.285e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 10987, It: 0, Loss Data: 9.496e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.737e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10988, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.912e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 10989, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.456e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 10990, It: 0, Loss Data: 7.372e-02, Loss Eqns: 2.310e+00, Loss Aux: 2.348e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 10991, It: 0, Loss Data: 8.045e-02, Loss Eqns: 2.414e+00, Loss Aux: 2.872e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 10992, It: 0, Loss Data: 8.113e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.211e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 10993, It: 0, Loss Data: 9.563e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.133e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10994, It: 0, Loss Data: 9.675e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.493e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 10995, It: 0, Loss Data: 7.983e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.457e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 10996, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.729e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 10997, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.383e+00, Loss Aux: 2.747e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 10998, It: 0, Loss Data: 8.715e-02, Loss Eqns: 2.378e+00, Loss Aux: 2.724e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 10999, It: 0, Loss Data: 9.380e-02, Loss Eqns: 2.312e+00, Loss Aux: 2.627e-02, Time: 0.236, Learning Rate: 1.0e-03\n",
      "Epoch: 11000, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.551e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11001, It: 0, Loss Data: 7.385e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.613e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11002, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.405e+00, Loss Aux: 2.389e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11003, It: 0, Loss Data: 8.314e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.745e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11004, It: 0, Loss Data: 9.854e-02, Loss Eqns: 2.384e+00, Loss Aux: 2.763e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11005, It: 0, Loss Data: 7.297e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.464e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11006, It: 0, Loss Data: 6.832e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.313e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11007, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.353e+00, Loss Aux: 2.687e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11008, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.909e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11009, It: 0, Loss Data: 8.028e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.733e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11010, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.814e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11011, It: 0, Loss Data: 9.660e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.848e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11012, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.022e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11013, It: 0, Loss Data: 9.384e-02, Loss Eqns: 2.440e+00, Loss Aux: 2.966e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11014, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.429e+00, Loss Aux: 2.407e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11015, It: 0, Loss Data: 9.420e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.441e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11016, It: 0, Loss Data: 9.542e-02, Loss Eqns: 2.498e+00, Loss Aux: 3.063e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11017, It: 0, Loss Data: 9.637e-02, Loss Eqns: 2.596e+00, Loss Aux: 3.010e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11018, It: 0, Loss Data: 9.783e-02, Loss Eqns: 2.514e+00, Loss Aux: 3.325e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11019, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.531e+00, Loss Aux: 3.024e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11020, It: 0, Loss Data: 9.103e-02, Loss Eqns: 2.279e+00, Loss Aux: 2.609e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11021, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.458e+00, Loss Aux: 2.254e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11022, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.458e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11023, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.563e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11024, It: 0, Loss Data: 8.897e-02, Loss Eqns: 2.403e+00, Loss Aux: 2.524e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11025, It: 0, Loss Data: 8.632e-02, Loss Eqns: 2.467e+00, Loss Aux: 2.580e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11026, It: 0, Loss Data: 8.847e-02, Loss Eqns: 2.423e+00, Loss Aux: 2.575e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11027, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.452e+00, Loss Aux: 2.446e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11028, It: 0, Loss Data: 8.116e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.643e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11029, It: 0, Loss Data: 9.234e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.387e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11030, It: 0, Loss Data: 8.124e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.074e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11031, It: 0, Loss Data: 9.016e-02, Loss Eqns: 2.418e+00, Loss Aux: 4.073e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11032, It: 0, Loss Data: 9.953e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.296e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11033, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.367e+00, Loss Aux: 2.007e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11034, It: 0, Loss Data: 9.639e-02, Loss Eqns: 2.430e+00, Loss Aux: 1.553e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11035, It: 0, Loss Data: 9.498e-02, Loss Eqns: 2.429e+00, Loss Aux: 2.321e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11036, It: 0, Loss Data: 8.654e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.769e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11037, It: 0, Loss Data: 8.451e-02, Loss Eqns: 2.283e+00, Loss Aux: 2.893e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 11038, It: 0, Loss Data: 9.361e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.059e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11039, It: 0, Loss Data: 8.930e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.056e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11040, It: 0, Loss Data: 9.661e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.601e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11041, It: 0, Loss Data: 8.843e-02, Loss Eqns: 2.443e+00, Loss Aux: 2.448e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11042, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.102e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11043, It: 0, Loss Data: 8.715e-02, Loss Eqns: 2.449e+00, Loss Aux: 3.709e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11044, It: 0, Loss Data: 9.405e-02, Loss Eqns: 2.474e+00, Loss Aux: 2.910e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11045, It: 0, Loss Data: 9.028e-02, Loss Eqns: 2.489e+00, Loss Aux: 2.085e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11046, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.429e+00, Loss Aux: 1.607e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11047, It: 0, Loss Data: 9.104e-02, Loss Eqns: 2.465e+00, Loss Aux: 2.049e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11048, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.488e+00, Loss Aux: 3.050e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11049, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.369e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11050, It: 0, Loss Data: 8.192e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.555e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11051, It: 0, Loss Data: 8.800e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.705e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11052, It: 0, Loss Data: 8.734e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.432e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11053, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.112e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11054, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.299e+00, Loss Aux: 3.190e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11055, It: 0, Loss Data: 9.241e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.054e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11056, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.366e+00, Loss Aux: 2.696e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11057, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.366e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11058, It: 0, Loss Data: 8.911e-02, Loss Eqns: 2.321e+00, Loss Aux: 1.969e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11059, It: 0, Loss Data: 9.358e-02, Loss Eqns: 2.295e+00, Loss Aux: 2.055e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11060, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.288e+00, Loss Aux: 2.792e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11061, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.270e+00, Loss Aux: 3.597e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11062, It: 0, Loss Data: 9.186e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.857e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 11063, It: 0, Loss Data: 9.508e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.261e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11064, It: 0, Loss Data: 8.826e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.709e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11065, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.315e+00, Loss Aux: 2.332e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11066, It: 0, Loss Data: 8.329e-02, Loss Eqns: 2.335e+00, Loss Aux: 2.036e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11067, It: 0, Loss Data: 7.599e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.102e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11068, It: 0, Loss Data: 8.857e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.167e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11069, It: 0, Loss Data: 8.511e-02, Loss Eqns: 2.303e+00, Loss Aux: 2.444e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11070, It: 0, Loss Data: 7.544e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.077e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11071, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.108e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11072, It: 0, Loss Data: 8.133e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.143e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11073, It: 0, Loss Data: 8.386e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.059e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11074, It: 0, Loss Data: 7.157e-02, Loss Eqns: 2.373e+00, Loss Aux: 2.795e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11075, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.237e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11076, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.070e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11077, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.330e+00, Loss Aux: 2.075e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11078, It: 0, Loss Data: 7.530e-02, Loss Eqns: 2.335e+00, Loss Aux: 2.722e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11079, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.276e+00, Loss Aux: 3.786e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11080, It: 0, Loss Data: 8.872e-02, Loss Eqns: 2.250e+00, Loss Aux: 3.250e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11081, It: 0, Loss Data: 7.873e-02, Loss Eqns: 2.257e+00, Loss Aux: 2.588e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11082, It: 0, Loss Data: 9.997e-02, Loss Eqns: 2.312e+00, Loss Aux: 2.622e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11083, It: 0, Loss Data: 9.373e-02, Loss Eqns: 2.236e+00, Loss Aux: 3.000e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11084, It: 0, Loss Data: 9.041e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.828e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11085, It: 0, Loss Data: 8.861e-02, Loss Eqns: 2.288e+00, Loss Aux: 2.523e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11086, It: 0, Loss Data: 9.723e-02, Loss Eqns: 2.350e+00, Loss Aux: 2.569e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11087, It: 0, Loss Data: 7.595e-02, Loss Eqns: 2.404e+00, Loss Aux: 2.861e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11088, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.313e+00, Loss Aux: 2.482e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11089, It: 0, Loss Data: 9.334e-02, Loss Eqns: 2.262e+00, Loss Aux: 1.986e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11090, It: 0, Loss Data: 8.097e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.140e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11091, It: 0, Loss Data: 9.979e-02, Loss Eqns: 2.312e+00, Loss Aux: 2.434e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11092, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.368e+00, Loss Aux: 2.380e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11093, It: 0, Loss Data: 8.246e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.324e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 11094, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.523e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11095, It: 0, Loss Data: 9.829e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.515e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11096, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.276e+00, Loss Aux: 3.899e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11097, It: 0, Loss Data: 8.650e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.906e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11098, It: 0, Loss Data: 8.666e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.204e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11099, It: 0, Loss Data: 8.965e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.337e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11100, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.545e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11101, It: 0, Loss Data: 9.221e-02, Loss Eqns: 2.332e+00, Loss Aux: 2.790e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11102, It: 0, Loss Data: 9.357e-02, Loss Eqns: 2.316e+00, Loss Aux: 2.343e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11103, It: 0, Loss Data: 8.360e-02, Loss Eqns: 2.451e+00, Loss Aux: 2.439e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11104, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.652e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11105, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.510e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11106, It: 0, Loss Data: 7.901e-02, Loss Eqns: 2.354e+00, Loss Aux: 2.230e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11107, It: 0, Loss Data: 8.766e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.091e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11108, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.435e+00, Loss Aux: 2.313e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11109, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.156e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11110, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.407e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11111, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.417e+00, Loss Aux: 2.565e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11112, It: 0, Loss Data: 9.957e-02, Loss Eqns: 2.381e+00, Loss Aux: 2.519e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11113, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.473e+00, Loss Aux: 2.928e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11114, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.428e+00, Loss Aux: 2.932e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11115, It: 0, Loss Data: 8.682e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.902e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11116, It: 0, Loss Data: 8.380e-02, Loss Eqns: 2.607e+00, Loss Aux: 2.985e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11117, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.579e+00, Loss Aux: 2.027e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11118, It: 0, Loss Data: 8.987e-02, Loss Eqns: 2.464e+00, Loss Aux: 1.863e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11119, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.893e+00, Loss Aux: 2.058e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11120, It: 0, Loss Data: 8.793e-02, Loss Eqns: 2.559e+00, Loss Aux: 1.837e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11121, It: 0, Loss Data: 8.532e-02, Loss Eqns: 2.478e+00, Loss Aux: 2.959e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11122, It: 0, Loss Data: 9.856e-02, Loss Eqns: 2.551e+00, Loss Aux: 4.586e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11123, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.002e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11124, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.426e+00, Loss Aux: 2.814e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11125, It: 0, Loss Data: 9.430e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.444e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11126, It: 0, Loss Data: 9.386e-02, Loss Eqns: 2.338e+00, Loss Aux: 1.938e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11127, It: 0, Loss Data: 8.381e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.003e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11128, It: 0, Loss Data: 8.352e-02, Loss Eqns: 2.410e+00, Loss Aux: 2.818e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11129, It: 0, Loss Data: 8.800e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.903e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11130, It: 0, Loss Data: 9.772e-02, Loss Eqns: 2.285e+00, Loss Aux: 2.282e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11131, It: 0, Loss Data: 8.498e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.077e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11132, It: 0, Loss Data: 8.931e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.461e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11133, It: 0, Loss Data: 7.374e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.144e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11134, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.650e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11135, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.306e+00, Loss Aux: 4.107e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11136, It: 0, Loss Data: 9.882e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.170e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11137, It: 0, Loss Data: 9.199e-02, Loss Eqns: 2.268e+00, Loss Aux: 2.135e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 11138, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.400e+00, Loss Aux: 1.580e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11139, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.929e+00, Loss Aux: 3.700e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11140, It: 0, Loss Data: 1.287e-01, Loss Eqns: 4.073e+00, Loss Aux: 4.138e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11141, It: 0, Loss Data: 1.483e-01, Loss Eqns: 4.432e+00, Loss Aux: 3.872e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11142, It: 0, Loss Data: 1.079e-01, Loss Eqns: 4.063e+00, Loss Aux: 4.247e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11143, It: 0, Loss Data: 1.306e-01, Loss Eqns: 4.203e+00, Loss Aux: 2.940e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11144, It: 0, Loss Data: 1.025e-01, Loss Eqns: 3.458e+00, Loss Aux: 1.709e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11145, It: 0, Loss Data: 1.521e-01, Loss Eqns: 3.425e+00, Loss Aux: 1.819e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11146, It: 0, Loss Data: 1.118e-01, Loss Eqns: 3.132e+00, Loss Aux: 3.300e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11147, It: 0, Loss Data: 1.280e-01, Loss Eqns: 3.050e+00, Loss Aux: 3.847e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11148, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.197e+00, Loss Aux: 3.331e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11149, It: 0, Loss Data: 1.277e-01, Loss Eqns: 2.924e+00, Loss Aux: 2.864e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11150, It: 0, Loss Data: 1.258e-01, Loss Eqns: 2.993e+00, Loss Aux: 2.748e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11151, It: 0, Loss Data: 1.185e-01, Loss Eqns: 2.944e+00, Loss Aux: 2.180e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11152, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.768e+00, Loss Aux: 2.537e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11153, It: 0, Loss Data: 1.193e-01, Loss Eqns: 2.804e+00, Loss Aux: 4.077e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11154, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.809e+00, Loss Aux: 6.072e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11155, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.717e+00, Loss Aux: 5.609e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 11156, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.637e+00, Loss Aux: 3.409e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11157, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.697e+00, Loss Aux: 2.179e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11158, It: 0, Loss Data: 8.564e-02, Loss Eqns: 2.548e+00, Loss Aux: 2.520e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11159, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.590e+00, Loss Aux: 2.782e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11160, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.599e+00, Loss Aux: 2.482e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11161, It: 0, Loss Data: 9.849e-02, Loss Eqns: 2.555e+00, Loss Aux: 2.949e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11162, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.522e+00, Loss Aux: 4.312e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11163, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.540e+00, Loss Aux: 5.132e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11164, It: 0, Loss Data: 9.139e-02, Loss Eqns: 2.501e+00, Loss Aux: 4.393e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11165, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.667e+00, Loss Aux: 3.468e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11166, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.486e+00, Loss Aux: 3.489e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11167, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.450e+00, Loss Aux: 3.671e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11168, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.997e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11169, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.500e+00, Loss Aux: 2.638e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11170, It: 0, Loss Data: 8.926e-02, Loss Eqns: 2.409e+00, Loss Aux: 2.830e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11171, It: 0, Loss Data: 9.675e-02, Loss Eqns: 2.515e+00, Loss Aux: 2.983e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 11172, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.542e+00, Loss Aux: 2.913e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11173, It: 0, Loss Data: 9.725e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.001e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11174, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.401e+00, Loss Aux: 5.566e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11175, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.465e+00, Loss Aux: 5.045e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11176, It: 0, Loss Data: 1.122e-01, Loss Eqns: 2.480e+00, Loss Aux: 3.532e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11177, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.461e+00, Loss Aux: 3.314e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11178, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.485e+00, Loss Aux: 3.536e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11179, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.446e+00, Loss Aux: 2.751e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11180, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.535e+00, Loss Aux: 2.187e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11181, It: 0, Loss Data: 9.532e-02, Loss Eqns: 2.603e+00, Loss Aux: 2.193e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11182, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.526e+00, Loss Aux: 2.938e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11183, It: 0, Loss Data: 1.235e-01, Loss Eqns: 2.778e+00, Loss Aux: 6.292e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11184, It: 0, Loss Data: 1.218e-01, Loss Eqns: 2.724e+00, Loss Aux: 4.509e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11185, It: 0, Loss Data: 1.426e-01, Loss Eqns: 2.874e+00, Loss Aux: 3.896e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11186, It: 0, Loss Data: 1.119e-01, Loss Eqns: 2.582e+00, Loss Aux: 4.312e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11187, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.793e+00, Loss Aux: 4.516e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11188, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.480e+00, Loss Aux: 2.560e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11189, It: 0, Loss Data: 1.390e-01, Loss Eqns: 2.744e+00, Loss Aux: 3.128e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11190, It: 0, Loss Data: 8.781e-02, Loss Eqns: 2.414e+00, Loss Aux: 5.747e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 11191, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.638e+00, Loss Aux: 5.790e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11192, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.490e+00, Loss Aux: 2.944e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 11193, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.510e+00, Loss Aux: 2.030e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11194, It: 0, Loss Data: 1.194e-01, Loss Eqns: 2.316e+00, Loss Aux: 3.588e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11195, It: 0, Loss Data: 1.179e-01, Loss Eqns: 2.311e+00, Loss Aux: 6.150e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11196, It: 0, Loss Data: 1.154e-01, Loss Eqns: 2.301e+00, Loss Aux: 5.895e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11197, It: 0, Loss Data: 1.252e-01, Loss Eqns: 2.355e+00, Loss Aux: 5.008e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11198, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.250e+00, Loss Aux: 4.188e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11199, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.356e+00, Loss Aux: 4.018e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11200, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.338e+00, Loss Aux: 3.706e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11201, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.319e+00, Loss Aux: 2.203e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11202, It: 0, Loss Data: 1.148e-01, Loss Eqns: 2.494e+00, Loss Aux: 2.853e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11203, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.382e+00, Loss Aux: 5.429e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11204, It: 0, Loss Data: 1.165e-01, Loss Eqns: 2.466e+00, Loss Aux: 7.289e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11205, It: 0, Loss Data: 9.477e-02, Loss Eqns: 2.438e+00, Loss Aux: 5.087e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11206, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.489e+00, Loss Aux: 3.133e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11207, It: 0, Loss Data: 8.911e-02, Loss Eqns: 2.446e+00, Loss Aux: 2.447e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11208, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.581e+00, Loss Aux: 3.767e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11209, It: 0, Loss Data: 9.858e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.535e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11210, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.790e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11211, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.391e+00, Loss Aux: 3.309e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 11212, It: 0, Loss Data: 9.533e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.893e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11213, It: 0, Loss Data: 9.606e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.440e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11214, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.404e+00, Loss Aux: 4.069e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11215, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.395e+00, Loss Aux: 3.555e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11216, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.395e+00, Loss Aux: 3.855e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11217, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.506e+00, Loss Aux: 4.635e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 11218, It: 0, Loss Data: 9.391e-02, Loss Eqns: 2.457e+00, Loss Aux: 4.717e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11219, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.459e+00, Loss Aux: 4.413e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11220, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.423e+00, Loss Aux: 3.971e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11221, It: 0, Loss Data: 7.724e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.632e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11222, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.468e+00, Loss Aux: 3.145e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 11223, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.453e+00, Loss Aux: 2.466e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11224, It: 0, Loss Data: 8.860e-02, Loss Eqns: 2.434e+00, Loss Aux: 2.955e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11225, It: 0, Loss Data: 8.110e-02, Loss Eqns: 2.427e+00, Loss Aux: 4.036e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11226, It: 0, Loss Data: 8.233e-02, Loss Eqns: 2.414e+00, Loss Aux: 4.606e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11227, It: 0, Loss Data: 8.476e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.668e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 11228, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.392e+00, Loss Aux: 3.425e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11229, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.837e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11230, It: 0, Loss Data: 9.394e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.753e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11231, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.433e+00, Loss Aux: 2.528e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11232, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.408e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11233, It: 0, Loss Data: 8.498e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.189e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11234, It: 0, Loss Data: 8.127e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.468e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11235, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.219e+00, Loss Aux: 5.300e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11236, It: 0, Loss Data: 9.277e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.235e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11237, It: 0, Loss Data: 9.534e-02, Loss Eqns: 2.440e+00, Loss Aux: 3.655e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11238, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.367e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11239, It: 0, Loss Data: 9.563e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.616e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11240, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.282e+00, Loss Aux: 3.566e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11241, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.665e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11242, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.906e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11243, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.382e+00, Loss Aux: 3.633e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11244, It: 0, Loss Data: 9.276e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.000e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11245, It: 0, Loss Data: 9.790e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.738e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11246, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.769e+00, Loss Aux: 4.939e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 11247, It: 0, Loss Data: 1.804e-01, Loss Eqns: 2.877e+00, Loss Aux: 2.642e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11248, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.521e+00, Loss Aux: 4.775e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11249, It: 0, Loss Data: 1.419e-01, Loss Eqns: 2.736e+00, Loss Aux: 7.731e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11250, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.688e+00, Loss Aux: 4.586e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11251, It: 0, Loss Data: 1.334e-01, Loss Eqns: 2.473e+00, Loss Aux: 2.403e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11252, It: 0, Loss Data: 1.262e-01, Loss Eqns: 2.537e+00, Loss Aux: 2.757e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11253, It: 0, Loss Data: 1.182e-01, Loss Eqns: 2.439e+00, Loss Aux: 6.394e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11254, It: 0, Loss Data: 1.274e-01, Loss Eqns: 2.516e+00, Loss Aux: 7.166e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11255, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.363e+00, Loss Aux: 5.072e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11256, It: 0, Loss Data: 1.272e-01, Loss Eqns: 2.478e+00, Loss Aux: 3.580e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11257, It: 0, Loss Data: 9.830e-02, Loss Eqns: 2.442e+00, Loss Aux: 4.022e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11258, It: 0, Loss Data: 1.288e-01, Loss Eqns: 2.445e+00, Loss Aux: 4.671e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11259, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.384e+00, Loss Aux: 3.569e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11260, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.434e+00, Loss Aux: 2.936e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11261, It: 0, Loss Data: 9.262e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.699e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11262, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.736e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11263, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.465e+00, Loss Aux: 4.088e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11264, It: 0, Loss Data: 8.989e-02, Loss Eqns: 2.474e+00, Loss Aux: 3.382e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11265, It: 0, Loss Data: 8.921e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.479e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11266, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.445e+00, Loss Aux: 4.572e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11267, It: 0, Loss Data: 1.176e-01, Loss Eqns: 2.389e+00, Loss Aux: 4.677e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11268, It: 0, Loss Data: 9.944e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.789e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11269, It: 0, Loss Data: 9.614e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.227e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11270, It: 0, Loss Data: 9.465e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.477e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11271, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.420e+00, Loss Aux: 3.708e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11272, It: 0, Loss Data: 8.300e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.579e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11273, It: 0, Loss Data: 9.651e-02, Loss Eqns: 2.390e+00, Loss Aux: 3.503e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11274, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.385e+00, Loss Aux: 3.918e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11275, It: 0, Loss Data: 9.650e-02, Loss Eqns: 2.467e+00, Loss Aux: 4.310e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11276, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.493e+00, Loss Aux: 4.665e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11277, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.187e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11278, It: 0, Loss Data: 9.464e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.897e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11279, It: 0, Loss Data: 8.762e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.683e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11280, It: 0, Loss Data: 9.868e-02, Loss Eqns: 2.419e+00, Loss Aux: 2.426e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 11281, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.380e+00, Loss Aux: 3.917e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11282, It: 0, Loss Data: 1.543e-01, Loss Eqns: 3.036e+00, Loss Aux: 6.056e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11283, It: 0, Loss Data: 1.387e-01, Loss Eqns: 2.744e+00, Loss Aux: 2.994e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11284, It: 0, Loss Data: 1.959e-01, Loss Eqns: 2.966e+00, Loss Aux: 3.127e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11285, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.450e+00, Loss Aux: 5.774e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11286, It: 0, Loss Data: 1.577e-01, Loss Eqns: 3.020e+00, Loss Aux: 6.903e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11287, It: 0, Loss Data: 9.707e-02, Loss Eqns: 2.427e+00, Loss Aux: 2.762e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11288, It: 0, Loss Data: 1.782e-01, Loss Eqns: 2.621e+00, Loss Aux: 1.776e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11289, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.478e+00, Loss Aux: 4.586e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11290, It: 0, Loss Data: 1.478e-01, Loss Eqns: 2.236e+00, Loss Aux: 9.105e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11291, It: 0, Loss Data: 1.255e-01, Loss Eqns: 2.353e+00, Loss Aux: 7.888e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11292, It: 0, Loss Data: 1.379e-01, Loss Eqns: 2.233e+00, Loss Aux: 4.665e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11293, It: 0, Loss Data: 1.439e-01, Loss Eqns: 2.359e+00, Loss Aux: 3.167e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11294, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.457e+00, Loss Aux: 3.507e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11295, It: 0, Loss Data: 1.196e-01, Loss Eqns: 2.407e+00, Loss Aux: 4.641e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11296, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.579e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11297, It: 0, Loss Data: 1.310e-01, Loss Eqns: 2.317e+00, Loss Aux: 3.663e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11298, It: 0, Loss Data: 1.225e-01, Loss Eqns: 2.287e+00, Loss Aux: 4.037e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11299, It: 0, Loss Data: 9.843e-02, Loss Eqns: 2.429e+00, Loss Aux: 5.368e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11300, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.346e+00, Loss Aux: 5.806e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11301, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.236e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11302, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.359e+00, Loss Aux: 3.173e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11303, It: 0, Loss Data: 9.846e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.491e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11304, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.326e+00, Loss Aux: 5.159e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11305, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.278e+00, Loss Aux: 6.085e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11306, It: 0, Loss Data: 1.125e-01, Loss Eqns: 2.318e+00, Loss Aux: 4.144e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11307, It: 0, Loss Data: 1.148e-01, Loss Eqns: 2.252e+00, Loss Aux: 2.548e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11308, It: 0, Loss Data: 8.852e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.380e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11309, It: 0, Loss Data: 8.662e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.787e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11310, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.267e+00, Loss Aux: 4.955e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11311, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.235e+00, Loss Aux: 5.307e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11312, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.369e+00, Loss Aux: 5.011e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11313, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.394e+00, Loss Aux: 4.809e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11314, It: 0, Loss Data: 9.766e-02, Loss Eqns: 2.400e+00, Loss Aux: 4.289e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11315, It: 0, Loss Data: 9.783e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.739e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11316, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.151e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11317, It: 0, Loss Data: 9.361e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.095e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11318, It: 0, Loss Data: 7.335e-02, Loss Eqns: 2.497e+00, Loss Aux: 3.824e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11319, It: 0, Loss Data: 9.911e-02, Loss Eqns: 2.370e+00, Loss Aux: 5.012e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11320, It: 0, Loss Data: 9.030e-02, Loss Eqns: 2.410e+00, Loss Aux: 5.650e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11321, It: 0, Loss Data: 7.723e-02, Loss Eqns: 2.464e+00, Loss Aux: 5.126e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11322, It: 0, Loss Data: 8.585e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.249e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11323, It: 0, Loss Data: 9.294e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.271e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11324, It: 0, Loss Data: 8.778e-02, Loss Eqns: 2.333e+00, Loss Aux: 2.638e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11325, It: 0, Loss Data: 8.862e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.729e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11326, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.676e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11327, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.635e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11328, It: 0, Loss Data: 9.856e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.532e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11329, It: 0, Loss Data: 9.655e-02, Loss Eqns: 2.456e+00, Loss Aux: 3.992e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11330, It: 0, Loss Data: 8.108e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.649e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11331, It: 0, Loss Data: 7.751e-02, Loss Eqns: 2.390e+00, Loss Aux: 3.674e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11332, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.351e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11333, It: 0, Loss Data: 9.149e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.257e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11334, It: 0, Loss Data: 8.968e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.989e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11335, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.261e+00, Loss Aux: 3.650e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11336, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.512e+00, Loss Aux: 4.778e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11337, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.341e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11338, It: 0, Loss Data: 1.167e-01, Loss Eqns: 2.485e+00, Loss Aux: 2.811e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11339, It: 0, Loss Data: 1.155e-01, Loss Eqns: 2.277e+00, Loss Aux: 3.438e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11340, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.502e+00, Loss Aux: 4.018e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11341, It: 0, Loss Data: 1.098e-01, Loss Eqns: 2.465e+00, Loss Aux: 3.332e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11342, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.390e+00, Loss Aux: 2.953e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11343, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.430e+00, Loss Aux: 3.471e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11344, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.391e+00, Loss Aux: 4.947e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11345, It: 0, Loss Data: 8.187e-02, Loss Eqns: 2.604e+00, Loss Aux: 5.129e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11346, It: 0, Loss Data: 8.111e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.887e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11347, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.476e+00, Loss Aux: 3.054e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 11348, It: 0, Loss Data: 9.484e-02, Loss Eqns: 2.499e+00, Loss Aux: 3.475e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11349, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.531e+00, Loss Aux: 4.383e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11350, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.762e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11351, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.209e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11352, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.548e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11353, It: 0, Loss Data: 8.212e-02, Loss Eqns: 2.420e+00, Loss Aux: 5.015e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11354, It: 0, Loss Data: 8.674e-02, Loss Eqns: 2.347e+00, Loss Aux: 5.196e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11355, It: 0, Loss Data: 8.490e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.879e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11356, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.276e+00, Loss Aux: 2.929e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11357, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.325e+00, Loss Aux: 3.026e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11358, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.266e+00, Loss Aux: 3.902e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11359, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.250e+00, Loss Aux: 4.022e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11360, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.912e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11361, It: 0, Loss Data: 9.170e-02, Loss Eqns: 2.304e+00, Loss Aux: 2.724e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11362, It: 0, Loss Data: 7.919e-02, Loss Eqns: 2.454e+00, Loss Aux: 3.756e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11363, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.312e+00, Loss Aux: 5.257e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11364, It: 0, Loss Data: 8.026e-02, Loss Eqns: 2.322e+00, Loss Aux: 5.525e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11365, It: 0, Loss Data: 7.939e-02, Loss Eqns: 2.437e+00, Loss Aux: 4.430e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11366, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.343e+00, Loss Aux: 3.733e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11367, It: 0, Loss Data: 9.546e-02, Loss Eqns: 2.436e+00, Loss Aux: 4.065e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11368, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.025e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11369, It: 0, Loss Data: 8.745e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.149e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11370, It: 0, Loss Data: 7.850e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.444e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11371, It: 0, Loss Data: 9.556e-02, Loss Eqns: 2.417e+00, Loss Aux: 2.677e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11372, It: 0, Loss Data: 7.627e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.864e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11373, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.502e+00, Loss Aux: 4.646e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11374, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.351e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11375, It: 0, Loss Data: 9.543e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.348e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11376, It: 0, Loss Data: 8.963e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.335e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11377, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.129e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11378, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.410e+00, Loss Aux: 3.865e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11379, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.415e+00, Loss Aux: 3.586e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11380, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.363e+00, Loss Aux: 3.475e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11381, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.308e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11382, It: 0, Loss Data: 9.096e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.958e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 11383, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.063e-02, Time: 0.232, Learning Rate: 1.0e-03\n",
      "Epoch: 11384, It: 0, Loss Data: 9.284e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.417e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11385, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.121e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11386, It: 0, Loss Data: 1.213e-01, Loss Eqns: 2.460e+00, Loss Aux: 4.687e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11387, It: 0, Loss Data: 9.992e-02, Loss Eqns: 2.488e+00, Loss Aux: 3.199e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11388, It: 0, Loss Data: 1.195e-01, Loss Eqns: 2.476e+00, Loss Aux: 3.260e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11389, It: 0, Loss Data: 8.198e-02, Loss Eqns: 2.521e+00, Loss Aux: 5.280e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11390, It: 0, Loss Data: 1.233e-01, Loss Eqns: 2.548e+00, Loss Aux: 6.955e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11391, It: 0, Loss Data: 8.407e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.823e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11392, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.459e+00, Loss Aux: 2.680e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11393, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.357e+00, Loss Aux: 2.649e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11394, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.416e+00, Loss Aux: 4.246e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11395, It: 0, Loss Data: 1.150e-01, Loss Eqns: 2.367e+00, Loss Aux: 4.983e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11396, It: 0, Loss Data: 9.173e-02, Loss Eqns: 2.347e+00, Loss Aux: 2.958e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11397, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.228e+00, Loss Aux: 2.232e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11398, It: 0, Loss Data: 9.855e-02, Loss Eqns: 2.402e+00, Loss Aux: 2.796e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11399, It: 0, Loss Data: 1.138e-01, Loss Eqns: 2.440e+00, Loss Aux: 4.153e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11400, It: 0, Loss Data: 9.871e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.628e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11401, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.363e+00, Loss Aux: 4.683e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11402, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.717e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11403, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.432e+00, Loss Aux: 5.099e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 11404, It: 0, Loss Data: 8.933e-02, Loss Eqns: 2.445e+00, Loss Aux: 4.941e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11405, It: 0, Loss Data: 7.623e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.923e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11406, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.340e+00, Loss Aux: 3.525e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 11407, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.415e+00, Loss Aux: 3.636e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11408, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.485e+00, Loss Aux: 3.768e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11409, It: 0, Loss Data: 9.614e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.570e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11410, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.403e+00, Loss Aux: 3.354e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11411, It: 0, Loss Data: 7.782e-02, Loss Eqns: 2.462e+00, Loss Aux: 3.451e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11412, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.852e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11413, It: 0, Loss Data: 8.818e-02, Loss Eqns: 2.472e+00, Loss Aux: 4.189e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11414, It: 0, Loss Data: 9.645e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.328e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11415, It: 0, Loss Data: 8.353e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.463e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11416, It: 0, Loss Data: 9.165e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.518e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11417, It: 0, Loss Data: 7.631e-02, Loss Eqns: 2.419e+00, Loss Aux: 4.420e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11418, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.410e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11419, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.363e+00, Loss Aux: 4.129e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11420, It: 0, Loss Data: 8.705e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.944e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11421, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.349e+00, Loss Aux: 4.371e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11422, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.320e+00, Loss Aux: 3.944e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11423, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.365e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11424, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.350e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11425, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.515e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11426, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.692e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11427, It: 0, Loss Data: 8.916e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.352e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11428, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.404e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11429, It: 0, Loss Data: 8.925e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.704e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11430, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.498e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11431, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.824e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11432, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.158e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 11433, It: 0, Loss Data: 9.287e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.401e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11434, It: 0, Loss Data: 9.931e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.403e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11435, It: 0, Loss Data: 8.906e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.658e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11436, It: 0, Loss Data: 9.027e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.145e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11437, It: 0, Loss Data: 9.085e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.869e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11438, It: 0, Loss Data: 8.458e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.190e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11439, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.782e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11440, It: 0, Loss Data: 9.980e-02, Loss Eqns: 2.388e+00, Loss Aux: 4.330e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11441, It: 0, Loss Data: 9.010e-02, Loss Eqns: 2.304e+00, Loss Aux: 5.018e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11442, It: 0, Loss Data: 8.664e-02, Loss Eqns: 2.443e+00, Loss Aux: 4.968e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11443, It: 0, Loss Data: 8.442e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.977e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11444, It: 0, Loss Data: 9.552e-02, Loss Eqns: 2.473e+00, Loss Aux: 3.066e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11445, It: 0, Loss Data: 9.733e-02, Loss Eqns: 2.482e+00, Loss Aux: 2.590e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11446, It: 0, Loss Data: 7.790e-02, Loss Eqns: 2.413e+00, Loss Aux: 2.855e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11447, It: 0, Loss Data: 9.065e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.434e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11448, It: 0, Loss Data: 9.273e-02, Loss Eqns: 2.454e+00, Loss Aux: 4.535e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11449, It: 0, Loss Data: 8.300e-02, Loss Eqns: 2.449e+00, Loss Aux: 4.810e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11450, It: 0, Loss Data: 8.990e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.684e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11451, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.411e+00, Loss Aux: 4.812e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11452, It: 0, Loss Data: 9.525e-02, Loss Eqns: 2.459e+00, Loss Aux: 4.513e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11453, It: 0, Loss Data: 9.821e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.416e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11454, It: 0, Loss Data: 7.931e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.768e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11455, It: 0, Loss Data: 8.269e-02, Loss Eqns: 2.324e+00, Loss Aux: 2.651e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11456, It: 0, Loss Data: 9.393e-02, Loss Eqns: 2.457e+00, Loss Aux: 2.981e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11457, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.471e+00, Loss Aux: 3.173e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11458, It: 0, Loss Data: 8.499e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.387e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11459, It: 0, Loss Data: 7.319e-02, Loss Eqns: 2.459e+00, Loss Aux: 4.010e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11460, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.447e+00, Loss Aux: 4.544e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11461, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.674e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11462, It: 0, Loss Data: 8.731e-02, Loss Eqns: 2.509e+00, Loss Aux: 4.731e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 11463, It: 0, Loss Data: 8.478e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.311e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11464, It: 0, Loss Data: 8.567e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.632e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11465, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.338e+00, Loss Aux: 2.825e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11466, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.310e+00, Loss Aux: 2.527e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11467, It: 0, Loss Data: 8.398e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.494e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 11468, It: 0, Loss Data: 8.876e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.018e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11469, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.617e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11470, It: 0, Loss Data: 7.614e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.103e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11471, It: 0, Loss Data: 8.380e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.054e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11472, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.428e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11473, It: 0, Loss Data: 1.222e-01, Loss Eqns: 2.467e+00, Loss Aux: 2.877e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11474, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.381e+00, Loss Aux: 4.827e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 11475, It: 0, Loss Data: 1.109e-01, Loss Eqns: 2.541e+00, Loss Aux: 5.745e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11476, It: 0, Loss Data: 9.576e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.058e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11477, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.516e+00, Loss Aux: 2.985e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11478, It: 0, Loss Data: 9.702e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.654e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11479, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.636e+00, Loss Aux: 4.263e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11480, It: 0, Loss Data: 8.284e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.339e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11481, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.539e+00, Loss Aux: 2.685e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11482, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.423e+00, Loss Aux: 3.446e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11483, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.460e+00, Loss Aux: 4.922e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11484, It: 0, Loss Data: 9.624e-02, Loss Eqns: 2.498e+00, Loss Aux: 4.516e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11485, It: 0, Loss Data: 8.370e-02, Loss Eqns: 2.487e+00, Loss Aux: 3.304e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11486, It: 0, Loss Data: 9.285e-02, Loss Eqns: 2.509e+00, Loss Aux: 2.739e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11487, It: 0, Loss Data: 7.316e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.183e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11488, It: 0, Loss Data: 9.433e-02, Loss Eqns: 2.370e+00, Loss Aux: 5.696e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11489, It: 0, Loss Data: 9.281e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.427e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11490, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.274e+00, Loss Aux: 2.466e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11491, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.338e+00, Loss Aux: 2.186e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11492, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.472e+00, Loss Aux: 3.293e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11493, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.261e+00, Loss Aux: 4.470e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11494, It: 0, Loss Data: 9.238e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.031e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11495, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.253e+00, Loss Aux: 3.268e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11496, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.316e+00, Loss Aux: 2.983e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11497, It: 0, Loss Data: 8.781e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.335e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11498, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.365e+00, Loss Aux: 3.872e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11499, It: 0, Loss Data: 8.564e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.459e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11500, It: 0, Loss Data: 9.885e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.700e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11501, It: 0, Loss Data: 8.811e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.747e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11502, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.314e+00, Loss Aux: 4.648e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11503, It: 0, Loss Data: 9.204e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.856e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11504, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.357e+00, Loss Aux: 3.305e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11505, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.303e+00, Loss Aux: 2.903e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11506, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.394e+00, Loss Aux: 2.821e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11507, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.321e+00, Loss Aux: 2.759e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11508, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.450e+00, Loss Aux: 2.886e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11509, It: 0, Loss Data: 8.300e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.312e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11510, It: 0, Loss Data: 9.243e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.821e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11511, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.462e+00, Loss Aux: 3.869e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11512, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.892e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11513, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.467e+00, Loss Aux: 4.302e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11514, It: 0, Loss Data: 7.801e-02, Loss Eqns: 2.503e+00, Loss Aux: 4.872e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11515, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.431e+00, Loss Aux: 4.555e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11516, It: 0, Loss Data: 8.267e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.870e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11517, It: 0, Loss Data: 9.267e-02, Loss Eqns: 2.505e+00, Loss Aux: 3.090e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11518, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.363e+00, Loss Aux: 2.975e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11519, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.310e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11520, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.476e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11521, It: 0, Loss Data: 9.907e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.731e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11522, It: 0, Loss Data: 8.440e-02, Loss Eqns: 2.443e+00, Loss Aux: 4.135e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11523, It: 0, Loss Data: 8.352e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.749e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11524, It: 0, Loss Data: 8.578e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.566e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11525, It: 0, Loss Data: 9.049e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.764e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11526, It: 0, Loss Data: 8.913e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.916e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11527, It: 0, Loss Data: 9.193e-02, Loss Eqns: 2.377e+00, Loss Aux: 2.924e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11528, It: 0, Loss Data: 8.619e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.436e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11529, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.308e+00, Loss Aux: 4.126e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11530, It: 0, Loss Data: 7.380e-02, Loss Eqns: 2.390e+00, Loss Aux: 4.330e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11531, It: 0, Loss Data: 9.043e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.674e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11532, It: 0, Loss Data: 9.464e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.001e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11533, It: 0, Loss Data: 8.256e-02, Loss Eqns: 2.322e+00, Loss Aux: 2.490e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11534, It: 0, Loss Data: 8.819e-02, Loss Eqns: 2.405e+00, Loss Aux: 2.864e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11535, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.584e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11536, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.445e+00, Loss Aux: 4.275e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11537, It: 0, Loss Data: 7.903e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.113e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11538, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.756e-02, Time: 0.240, Learning Rate: 1.0e-03\n",
      "Epoch: 11539, It: 0, Loss Data: 7.731e-02, Loss Eqns: 2.427e+00, Loss Aux: 3.894e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11540, It: 0, Loss Data: 8.556e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.049e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11541, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.045e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11542, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.322e+00, Loss Aux: 2.736e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11543, It: 0, Loss Data: 9.371e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.484e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11544, It: 0, Loss Data: 9.087e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.506e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11545, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.321e+00, Loss Aux: 4.185e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11546, It: 0, Loss Data: 8.595e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.723e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11547, It: 0, Loss Data: 8.152e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.506e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11548, It: 0, Loss Data: 8.524e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.070e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11549, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.596e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11550, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.289e+00, Loss Aux: 3.632e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11551, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.466e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11552, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.409e+00, Loss Aux: 4.002e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11553, It: 0, Loss Data: 8.674e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.467e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11554, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.451e+00, Loss Aux: 3.732e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11555, It: 0, Loss Data: 8.772e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.375e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11556, It: 0, Loss Data: 8.018e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.421e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11557, It: 0, Loss Data: 9.325e-02, Loss Eqns: 2.546e+00, Loss Aux: 3.294e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11558, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.439e+00, Loss Aux: 3.065e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11559, It: 0, Loss Data: 8.775e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.357e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11560, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.409e+00, Loss Aux: 4.134e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11561, It: 0, Loss Data: 1.383e-01, Loss Eqns: 2.773e+00, Loss Aux: 6.181e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11562, It: 0, Loss Data: 1.115e-01, Loss Eqns: 2.595e+00, Loss Aux: 3.143e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11563, It: 0, Loss Data: 1.382e-01, Loss Eqns: 2.766e+00, Loss Aux: 2.723e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11564, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.506e+00, Loss Aux: 4.468e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11565, It: 0, Loss Data: 1.219e-01, Loss Eqns: 2.802e+00, Loss Aux: 5.991e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11566, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.383e+00, Loss Aux: 3.607e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11567, It: 0, Loss Data: 1.290e-01, Loss Eqns: 2.649e+00, Loss Aux: 1.827e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11568, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.425e+00, Loss Aux: 2.750e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11569, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.805e+00, Loss Aux: 4.813e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11570, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.340e+00, Loss Aux: 5.961e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11571, It: 0, Loss Data: 1.197e-01, Loss Eqns: 2.600e+00, Loss Aux: 4.901e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 11572, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.428e+00, Loss Aux: 4.432e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11573, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.831e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11574, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.709e+00, Loss Aux: 5.303e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11575, It: 0, Loss Data: 9.866e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.043e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11576, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.565e+00, Loss Aux: 3.127e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11577, It: 0, Loss Data: 9.566e-02, Loss Eqns: 2.225e+00, Loss Aux: 3.801e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11578, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.501e+00, Loss Aux: 4.375e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11579, It: 0, Loss Data: 9.748e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.680e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11580, It: 0, Loss Data: 9.555e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.840e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11581, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.340e+00, Loss Aux: 2.802e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11582, It: 0, Loss Data: 9.682e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.553e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11583, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.466e+00, Loss Aux: 4.112e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11584, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.193e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11585, It: 0, Loss Data: 9.154e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.005e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11586, It: 0, Loss Data: 8.331e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.492e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11587, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.444e+00, Loss Aux: 4.884e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11588, It: 0, Loss Data: 9.457e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.899e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11589, It: 0, Loss Data: 8.809e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.393e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11590, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.267e+00, Loss Aux: 3.483e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11591, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.368e+00, Loss Aux: 3.911e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11592, It: 0, Loss Data: 8.857e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.742e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11593, It: 0, Loss Data: 9.736e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.106e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11594, It: 0, Loss Data: 8.798e-02, Loss Eqns: 2.372e+00, Loss Aux: 2.963e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11595, It: 0, Loss Data: 8.928e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.836e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11596, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.261e+00, Loss Aux: 4.471e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11597, It: 0, Loss Data: 8.797e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.874e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11598, It: 0, Loss Data: 9.009e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.442e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11599, It: 0, Loss Data: 8.440e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.119e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 11600, It: 0, Loss Data: 9.215e-02, Loss Eqns: 2.385e+00, Loss Aux: 4.563e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11601, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.064e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11602, It: 0, Loss Data: 9.225e-02, Loss Eqns: 2.471e+00, Loss Aux: 3.142e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11603, It: 0, Loss Data: 7.289e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.071e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11604, It: 0, Loss Data: 8.613e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.432e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11605, It: 0, Loss Data: 9.776e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.990e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 11606, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.346e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11607, It: 0, Loss Data: 7.591e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.449e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11608, It: 0, Loss Data: 9.417e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.217e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11609, It: 0, Loss Data: 8.323e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.693e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11610, It: 0, Loss Data: 8.756e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.478e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11611, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.330e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11612, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.117e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11613, It: 0, Loss Data: 8.093e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.153e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11614, It: 0, Loss Data: 9.200e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.685e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11615, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.336e+00, Loss Aux: 4.273e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11616, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.195e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11617, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.723e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11618, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.410e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11619, It: 0, Loss Data: 9.231e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.266e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11620, It: 0, Loss Data: 8.384e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.059e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11621, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.298e+00, Loss Aux: 4.622e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11622, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.985e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11623, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.041e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11624, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.463e+00, Loss Aux: 2.775e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11625, It: 0, Loss Data: 7.778e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.088e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11626, It: 0, Loss Data: 8.862e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.624e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11627, It: 0, Loss Data: 7.640e-02, Loss Eqns: 2.478e+00, Loss Aux: 3.785e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 11628, It: 0, Loss Data: 7.471e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.953e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11629, It: 0, Loss Data: 9.100e-02, Loss Eqns: 2.457e+00, Loss Aux: 4.042e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11630, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.725e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11631, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.434e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11632, It: 0, Loss Data: 8.008e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.771e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11633, It: 0, Loss Data: 9.728e-02, Loss Eqns: 2.344e+00, Loss Aux: 2.482e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11634, It: 0, Loss Data: 9.588e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.112e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11635, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.371e+00, Loss Aux: 4.237e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11636, It: 0, Loss Data: 8.741e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.591e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11637, It: 0, Loss Data: 7.618e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.235e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11638, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.672e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11639, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.512e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11640, It: 0, Loss Data: 8.058e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.163e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11641, It: 0, Loss Data: 8.188e-02, Loss Eqns: 2.435e+00, Loss Aux: 4.923e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11642, It: 0, Loss Data: 8.057e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.979e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11643, It: 0, Loss Data: 9.627e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.189e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11644, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.339e+00, Loss Aux: 3.150e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11645, It: 0, Loss Data: 7.842e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.916e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 11646, It: 0, Loss Data: 9.020e-02, Loss Eqns: 2.366e+00, Loss Aux: 2.967e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11647, It: 0, Loss Data: 8.320e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.103e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11648, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.336e+00, Loss Aux: 3.240e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11649, It: 0, Loss Data: 9.923e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.131e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11650, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.316e+00, Loss Aux: 4.514e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11651, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.133e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11652, It: 0, Loss Data: 9.722e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.480e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11653, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.131e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11654, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.960e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11655, It: 0, Loss Data: 9.941e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.083e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11656, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.487e+00, Loss Aux: 3.778e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11657, It: 0, Loss Data: 9.185e-02, Loss Eqns: 2.458e+00, Loss Aux: 4.133e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11658, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.446e+00, Loss Aux: 3.729e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11659, It: 0, Loss Data: 8.190e-02, Loss Eqns: 2.475e+00, Loss Aux: 3.166e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11660, It: 0, Loss Data: 7.833e-02, Loss Eqns: 2.493e+00, Loss Aux: 2.731e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11661, It: 0, Loss Data: 8.450e-02, Loss Eqns: 2.379e+00, Loss Aux: 2.744e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11662, It: 0, Loss Data: 8.336e-02, Loss Eqns: 2.409e+00, Loss Aux: 3.264e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11663, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.647e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11664, It: 0, Loss Data: 8.050e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.603e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11665, It: 0, Loss Data: 9.121e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.911e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11666, It: 0, Loss Data: 9.653e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.476e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11667, It: 0, Loss Data: 8.321e-02, Loss Eqns: 2.240e+00, Loss Aux: 4.534e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11668, It: 0, Loss Data: 1.190e-01, Loss Eqns: 2.267e+00, Loss Aux: 3.953e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11669, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.018e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 11670, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.354e+00, Loss Aux: 2.235e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 11671, It: 0, Loss Data: 8.672e-02, Loss Eqns: 2.317e+00, Loss Aux: 2.570e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11672, It: 0, Loss Data: 8.397e-02, Loss Eqns: 2.261e+00, Loss Aux: 3.591e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11673, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.492e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 11674, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.307e+00, Loss Aux: 5.050e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11675, It: 0, Loss Data: 8.636e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.919e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11676, It: 0, Loss Data: 8.355e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.997e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11677, It: 0, Loss Data: 7.559e-02, Loss Eqns: 2.454e+00, Loss Aux: 3.129e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11678, It: 0, Loss Data: 9.020e-02, Loss Eqns: 2.336e+00, Loss Aux: 2.906e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11679, It: 0, Loss Data: 9.009e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.326e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11680, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.437e+00, Loss Aux: 3.582e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11681, It: 0, Loss Data: 8.226e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.538e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11682, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.238e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11683, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.336e+00, Loss Aux: 2.782e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11684, It: 0, Loss Data: 8.173e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.507e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11685, It: 0, Loss Data: 9.884e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.442e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11686, It: 0, Loss Data: 8.166e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.783e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11687, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.541e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11688, It: 0, Loss Data: 9.081e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.215e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11689, It: 0, Loss Data: 7.773e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.318e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11690, It: 0, Loss Data: 8.990e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.477e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11691, It: 0, Loss Data: 8.895e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.265e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11692, It: 0, Loss Data: 8.955e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.124e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11693, It: 0, Loss Data: 8.952e-02, Loss Eqns: 2.253e+00, Loss Aux: 2.546e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11694, It: 0, Loss Data: 9.360e-02, Loss Eqns: 2.270e+00, Loss Aux: 2.685e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11695, It: 0, Loss Data: 1.268e-01, Loss Eqns: 2.661e+00, Loss Aux: 4.488e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 11696, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.472e+00, Loss Aux: 3.168e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11697, It: 0, Loss Data: 1.266e-01, Loss Eqns: 2.612e+00, Loss Aux: 2.970e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11698, It: 0, Loss Data: 1.117e-01, Loss Eqns: 2.337e+00, Loss Aux: 4.236e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11699, It: 0, Loss Data: 1.339e-01, Loss Eqns: 2.763e+00, Loss Aux: 5.201e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 11700, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.416e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11701, It: 0, Loss Data: 1.149e-01, Loss Eqns: 2.682e+00, Loss Aux: 2.582e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11702, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.203e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11703, It: 0, Loss Data: 1.226e-01, Loss Eqns: 2.738e+00, Loss Aux: 5.919e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 11704, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.698e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 11705, It: 0, Loss Data: 1.235e-01, Loss Eqns: 2.586e+00, Loss Aux: 2.588e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11706, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.299e+00, Loss Aux: 2.335e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11707, It: 0, Loss Data: 9.170e-02, Loss Eqns: 2.660e+00, Loss Aux: 3.541e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11708, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.424e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11709, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.520e+00, Loss Aux: 4.361e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11710, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.461e+00, Loss Aux: 3.997e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11711, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.423e+00, Loss Aux: 4.029e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11712, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.561e+00, Loss Aux: 3.431e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11713, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.425e+00, Loss Aux: 2.865e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11714, It: 0, Loss Data: 9.696e-02, Loss Eqns: 2.583e+00, Loss Aux: 3.240e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11715, It: 0, Loss Data: 8.916e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.239e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11716, It: 0, Loss Data: 9.433e-02, Loss Eqns: 2.491e+00, Loss Aux: 4.156e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11717, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.494e+00, Loss Aux: 3.378e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11718, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.523e+00, Loss Aux: 2.806e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11719, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.370e+00, Loss Aux: 3.310e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11720, It: 0, Loss Data: 8.245e-02, Loss Eqns: 2.515e+00, Loss Aux: 3.829e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11721, It: 0, Loss Data: 8.578e-02, Loss Eqns: 2.414e+00, Loss Aux: 3.672e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 11722, It: 0, Loss Data: 9.406e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.073e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11723, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.303e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11724, It: 0, Loss Data: 8.517e-02, Loss Eqns: 2.446e+00, Loss Aux: 4.192e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11725, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.390e+00, Loss Aux: 4.656e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11726, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.567e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11727, It: 0, Loss Data: 9.507e-02, Loss Eqns: 2.299e+00, Loss Aux: 2.946e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11728, It: 0, Loss Data: 7.738e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.120e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11729, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.636e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11730, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.748e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11731, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.434e+00, Loss Aux: 3.803e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11732, It: 0, Loss Data: 9.656e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.744e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11733, It: 0, Loss Data: 7.607e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.592e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11734, It: 0, Loss Data: 9.975e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.543e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11735, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.826e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11736, It: 0, Loss Data: 8.839e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.387e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11737, It: 0, Loss Data: 9.842e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.474e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11738, It: 0, Loss Data: 9.879e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.971e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11739, It: 0, Loss Data: 8.961e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.121e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11740, It: 0, Loss Data: 9.202e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.595e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11741, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.110e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11742, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.472e+00, Loss Aux: 3.723e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11743, It: 0, Loss Data: 9.469e-02, Loss Eqns: 2.373e+00, Loss Aux: 4.017e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11744, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.452e+00, Loss Aux: 4.005e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11745, It: 0, Loss Data: 7.908e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.627e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11746, It: 0, Loss Data: 8.604e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.670e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11747, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.818e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11748, It: 0, Loss Data: 7.321e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.934e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11749, It: 0, Loss Data: 9.030e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.137e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11750, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.856e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11751, It: 0, Loss Data: 8.407e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.491e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11752, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.097e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11753, It: 0, Loss Data: 9.749e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.109e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11754, It: 0, Loss Data: 7.718e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.395e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11755, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.635e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11756, It: 0, Loss Data: 8.907e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.681e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11757, It: 0, Loss Data: 8.596e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.429e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11758, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.427e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11759, It: 0, Loss Data: 9.027e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.634e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11760, It: 0, Loss Data: 8.447e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.645e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11761, It: 0, Loss Data: 8.257e-02, Loss Eqns: 2.265e+00, Loss Aux: 3.339e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11762, It: 0, Loss Data: 8.107e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.282e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11763, It: 0, Loss Data: 8.564e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.262e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11764, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.501e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11765, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.884e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11766, It: 0, Loss Data: 8.190e-02, Loss Eqns: 2.239e+00, Loss Aux: 3.755e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11767, It: 0, Loss Data: 9.483e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.051e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11768, It: 0, Loss Data: 8.832e-02, Loss Eqns: 2.301e+00, Loss Aux: 2.819e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11769, It: 0, Loss Data: 9.015e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.102e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11770, It: 0, Loss Data: 8.978e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.252e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11771, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.361e+00, Loss Aux: 3.447e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11772, It: 0, Loss Data: 8.644e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.729e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11773, It: 0, Loss Data: 8.880e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.700e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11774, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.785e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 11775, It: 0, Loss Data: 9.612e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.648e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11776, It: 0, Loss Data: 8.092e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.129e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11777, It: 0, Loss Data: 8.076e-02, Loss Eqns: 2.444e+00, Loss Aux: 2.964e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11778, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.278e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11779, It: 0, Loss Data: 9.622e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.384e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11780, It: 0, Loss Data: 9.752e-02, Loss Eqns: 2.404e+00, Loss Aux: 4.824e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11781, It: 0, Loss Data: 6.876e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.119e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11782, It: 0, Loss Data: 8.240e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.502e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11783, It: 0, Loss Data: 8.101e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.159e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11784, It: 0, Loss Data: 9.856e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.263e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11785, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.481e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11786, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.546e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11787, It: 0, Loss Data: 9.028e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.661e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11788, It: 0, Loss Data: 9.637e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.721e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11789, It: 0, Loss Data: 8.544e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.838e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11790, It: 0, Loss Data: 9.734e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.469e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 11791, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.059e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11792, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.381e+00, Loss Aux: 2.931e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11793, It: 0, Loss Data: 8.940e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.645e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11794, It: 0, Loss Data: 7.880e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.051e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11795, It: 0, Loss Data: 7.929e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.776e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11796, It: 0, Loss Data: 8.363e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.568e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11797, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.784e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11798, It: 0, Loss Data: 8.697e-02, Loss Eqns: 2.434e+00, Loss Aux: 4.044e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 11799, It: 0, Loss Data: 9.154e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.096e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11800, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.804e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11801, It: 0, Loss Data: 7.670e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.301e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11802, It: 0, Loss Data: 7.762e-02, Loss Eqns: 2.325e+00, Loss Aux: 2.980e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11803, It: 0, Loss Data: 8.741e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.250e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11804, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.522e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11805, It: 0, Loss Data: 9.444e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.668e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11806, It: 0, Loss Data: 8.264e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.791e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11807, It: 0, Loss Data: 8.882e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.984e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11808, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.249e+00, Loss Aux: 3.901e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11809, It: 0, Loss Data: 9.854e-02, Loss Eqns: 2.233e+00, Loss Aux: 3.425e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11810, It: 0, Loss Data: 8.665e-02, Loss Eqns: 2.310e+00, Loss Aux: 2.872e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 11811, It: 0, Loss Data: 8.915e-02, Loss Eqns: 2.294e+00, Loss Aux: 2.723e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 11812, It: 0, Loss Data: 9.623e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.099e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11813, It: 0, Loss Data: 8.931e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.759e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11814, It: 0, Loss Data: 9.002e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.925e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11815, It: 0, Loss Data: 9.401e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.724e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11816, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.617e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11817, It: 0, Loss Data: 8.157e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.198e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11818, It: 0, Loss Data: 8.940e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.001e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11819, It: 0, Loss Data: 7.394e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.450e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 11820, It: 0, Loss Data: 8.323e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.892e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11821, It: 0, Loss Data: 7.979e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.254e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11822, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.184e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11823, It: 0, Loss Data: 7.828e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.723e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11824, It: 0, Loss Data: 8.643e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.224e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11825, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.351e+00, Loss Aux: 2.808e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 11826, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.387e+00, Loss Aux: 2.898e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11827, It: 0, Loss Data: 8.982e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.564e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11828, It: 0, Loss Data: 9.260e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.116e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 11829, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.085e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11830, It: 0, Loss Data: 8.593e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.038e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11831, It: 0, Loss Data: 9.015e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.221e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11832, It: 0, Loss Data: 9.681e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.066e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11833, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.390e+00, Loss Aux: 3.101e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11834, It: 0, Loss Data: 8.843e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.711e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11835, It: 0, Loss Data: 7.938e-02, Loss Eqns: 2.482e+00, Loss Aux: 3.119e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11836, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.787e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11837, It: 0, Loss Data: 8.705e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.917e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11838, It: 0, Loss Data: 7.488e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.344e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11839, It: 0, Loss Data: 8.432e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.335e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11840, It: 0, Loss Data: 9.494e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.669e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11841, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.845e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11842, It: 0, Loss Data: 9.188e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.654e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 11843, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.141e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11844, It: 0, Loss Data: 9.275e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.065e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 11845, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.377e+00, Loss Aux: 3.976e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11846, It: 0, Loss Data: 8.546e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.343e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11847, It: 0, Loss Data: 9.917e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.315e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11848, It: 0, Loss Data: 9.107e-02, Loss Eqns: 2.406e+00, Loss Aux: 4.145e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 11849, It: 0, Loss Data: 8.145e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.956e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11850, It: 0, Loss Data: 8.800e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.133e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11851, It: 0, Loss Data: 8.651e-02, Loss Eqns: 2.439e+00, Loss Aux: 4.172e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11852, It: 0, Loss Data: 7.568e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.954e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11853, It: 0, Loss Data: 9.067e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.140e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11854, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.282e+00, Loss Aux: 2.941e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11855, It: 0, Loss Data: 8.207e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.105e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11856, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.421e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11857, It: 0, Loss Data: 8.388e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.652e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11858, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.911e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11859, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.664e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11860, It: 0, Loss Data: 8.297e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.262e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 11861, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.391e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11862, It: 0, Loss Data: 8.803e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.406e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 11863, It: 0, Loss Data: 8.405e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.866e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11864, It: 0, Loss Data: 9.380e-02, Loss Eqns: 2.375e+00, Loss Aux: 4.295e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11865, It: 0, Loss Data: 9.039e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.006e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11866, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.567e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11867, It: 0, Loss Data: 9.736e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.385e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11868, It: 0, Loss Data: 9.186e-02, Loss Eqns: 2.357e+00, Loss Aux: 3.351e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11869, It: 0, Loss Data: 9.367e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.160e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11870, It: 0, Loss Data: 7.647e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.060e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11871, It: 0, Loss Data: 7.852e-02, Loss Eqns: 2.453e+00, Loss Aux: 3.515e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11872, It: 0, Loss Data: 9.209e-02, Loss Eqns: 2.442e+00, Loss Aux: 4.219e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11873, It: 0, Loss Data: 7.937e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.321e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11874, It: 0, Loss Data: 9.929e-02, Loss Eqns: 2.459e+00, Loss Aux: 3.503e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11875, It: 0, Loss Data: 8.297e-02, Loss Eqns: 2.418e+00, Loss Aux: 2.891e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11876, It: 0, Loss Data: 9.680e-02, Loss Eqns: 2.328e+00, Loss Aux: 2.607e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11877, It: 0, Loss Data: 8.232e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.795e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11878, It: 0, Loss Data: 8.684e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.009e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11879, It: 0, Loss Data: 7.403e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.211e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11880, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.490e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11881, It: 0, Loss Data: 8.024e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.584e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11882, It: 0, Loss Data: 7.407e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.695e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 11883, It: 0, Loss Data: 8.162e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.653e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11884, It: 0, Loss Data: 9.423e-02, Loss Eqns: 2.487e+00, Loss Aux: 3.476e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11885, It: 0, Loss Data: 9.722e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.140e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11886, It: 0, Loss Data: 9.491e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.208e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11887, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.431e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11888, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.489e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11889, It: 0, Loss Data: 8.140e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.372e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11890, It: 0, Loss Data: 9.390e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.204e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11891, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.176e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11892, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.375e+00, Loss Aux: 3.075e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 11893, It: 0, Loss Data: 8.711e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.242e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11894, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.090e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11895, It: 0, Loss Data: 9.081e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.078e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11896, It: 0, Loss Data: 8.512e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.971e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11897, It: 0, Loss Data: 8.329e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.561e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11898, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.334e+00, Loss Aux: 2.589e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11899, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.273e+00, Loss Aux: 2.955e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11900, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.733e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 11901, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.183e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11902, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.635e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11903, It: 0, Loss Data: 8.821e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.230e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11904, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.232e+00, Loss Aux: 2.837e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11905, It: 0, Loss Data: 7.619e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.621e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11906, It: 0, Loss Data: 9.970e-02, Loss Eqns: 2.336e+00, Loss Aux: 2.467e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11907, It: 0, Loss Data: 8.378e-02, Loss Eqns: 2.288e+00, Loss Aux: 2.621e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11908, It: 0, Loss Data: 7.914e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.240e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 11909, It: 0, Loss Data: 8.303e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.808e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11910, It: 0, Loss Data: 8.588e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.938e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11911, It: 0, Loss Data: 8.742e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.555e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 11912, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.281e+00, Loss Aux: 3.352e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 11913, It: 0, Loss Data: 8.338e-02, Loss Eqns: 2.391e+00, Loss Aux: 3.599e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 11914, It: 0, Loss Data: 8.520e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.400e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11915, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.899e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11916, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.432e+00, Loss Aux: 2.719e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 11917, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.317e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 11918, It: 0, Loss Data: 8.384e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.390e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11919, It: 0, Loss Data: 8.550e-02, Loss Eqns: 2.278e+00, Loss Aux: 5.048e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11920, It: 0, Loss Data: 8.561e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.374e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11921, It: 0, Loss Data: 9.028e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.352e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11922, It: 0, Loss Data: 8.838e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.033e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11923, It: 0, Loss Data: 9.034e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.033e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11924, It: 0, Loss Data: 9.568e-02, Loss Eqns: 2.314e+00, Loss Aux: 2.771e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 11925, It: 0, Loss Data: 8.391e-02, Loss Eqns: 2.281e+00, Loss Aux: 2.496e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11926, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.356e+00, Loss Aux: 2.817e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 11927, It: 0, Loss Data: 7.714e-02, Loss Eqns: 2.319e+00, Loss Aux: 2.996e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11928, It: 0, Loss Data: 9.691e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.270e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11929, It: 0, Loss Data: 9.065e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.094e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 11930, It: 0, Loss Data: 8.744e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.733e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11931, It: 0, Loss Data: 9.497e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.475e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11932, It: 0, Loss Data: 8.438e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.069e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11933, It: 0, Loss Data: 9.399e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.276e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11934, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.306e+00, Loss Aux: 4.115e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 11935, It: 0, Loss Data: 8.102e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.966e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11936, It: 0, Loss Data: 7.712e-02, Loss Eqns: 2.453e+00, Loss Aux: 3.372e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 11937, It: 0, Loss Data: 8.811e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.759e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11938, It: 0, Loss Data: 9.545e-02, Loss Eqns: 2.276e+00, Loss Aux: 2.546e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11939, It: 0, Loss Data: 9.109e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.691e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 11940, It: 0, Loss Data: 9.526e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.154e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 11941, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.359e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11942, It: 0, Loss Data: 9.903e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.209e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11943, It: 0, Loss Data: 8.317e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.137e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11944, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.361e+00, Loss Aux: 2.973e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11945, It: 0, Loss Data: 8.028e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.513e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 11946, It: 0, Loss Data: 1.019e-01, Loss Eqns: 2.371e+00, Loss Aux: 5.065e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 11947, It: 0, Loss Data: 8.411e-02, Loss Eqns: 2.386e+00, Loss Aux: 5.541e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11948, It: 0, Loss Data: 8.043e-02, Loss Eqns: 2.453e+00, Loss Aux: 4.533e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 11949, It: 0, Loss Data: 8.929e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.831e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 11950, It: 0, Loss Data: 8.912e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.522e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11951, It: 0, Loss Data: 8.723e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.685e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 11952, It: 0, Loss Data: 8.882e-02, Loss Eqns: 2.478e+00, Loss Aux: 3.597e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 11953, It: 0, Loss Data: 9.848e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.450e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 11954, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.128e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11955, It: 0, Loss Data: 8.056e-02, Loss Eqns: 2.385e+00, Loss Aux: 2.622e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 11956, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.320e+00, Loss Aux: 2.557e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11957, It: 0, Loss Data: 9.604e-02, Loss Eqns: 2.383e+00, Loss Aux: 2.955e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11958, It: 0, Loss Data: 7.580e-02, Loss Eqns: 2.436e+00, Loss Aux: 2.909e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 11959, It: 0, Loss Data: 1.355e-01, Loss Eqns: 2.632e+00, Loss Aux: 2.200e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 11960, It: 0, Loss Data: 1.147e-01, Loss Eqns: 2.675e+00, Loss Aux: 6.184e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11961, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.456e+00, Loss Aux: 7.160e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 11962, It: 0, Loss Data: 1.035e-01, Loss Eqns: 2.873e+00, Loss Aux: 5.090e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 11963, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.565e+00, Loss Aux: 4.010e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11964, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.811e+00, Loss Aux: 4.120e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 11965, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.358e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 11966, It: 0, Loss Data: 9.992e-02, Loss Eqns: 2.648e+00, Loss Aux: 2.337e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11967, It: 0, Loss Data: 1.071e-01, Loss Eqns: 2.402e+00, Loss Aux: 2.883e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11968, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.673e+00, Loss Aux: 4.263e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11969, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.521e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 11970, It: 0, Loss Data: 1.205e-01, Loss Eqns: 2.548e+00, Loss Aux: 3.507e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 11971, It: 0, Loss Data: 8.099e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.226e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 11972, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.580e+00, Loss Aux: 4.138e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 11973, It: 0, Loss Data: 9.748e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.268e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11974, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.508e+00, Loss Aux: 4.209e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 11975, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.372e+00, Loss Aux: 3.985e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 11976, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.552e+00, Loss Aux: 3.496e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 11977, It: 0, Loss Data: 9.246e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.109e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11978, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.385e+00, Loss Aux: 3.619e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11979, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.340e+00, Loss Aux: 4.441e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 11980, It: 0, Loss Data: 9.298e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.205e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11981, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.353e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 11982, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.363e+00, Loss Aux: 2.806e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11983, It: 0, Loss Data: 8.737e-02, Loss Eqns: 2.517e+00, Loss Aux: 2.790e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 11984, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.540e+00, Loss Aux: 2.267e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 11985, It: 0, Loss Data: 9.673e-02, Loss Eqns: 2.666e+00, Loss Aux: 4.143e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 11986, It: 0, Loss Data: 9.615e-02, Loss Eqns: 2.394e+00, Loss Aux: 5.014e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11987, It: 0, Loss Data: 9.661e-02, Loss Eqns: 2.579e+00, Loss Aux: 4.236e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11988, It: 0, Loss Data: 9.365e-02, Loss Eqns: 2.541e+00, Loss Aux: 4.088e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 11989, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.529e+00, Loss Aux: 4.715e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11990, It: 0, Loss Data: 7.530e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.272e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 11991, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.519e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11992, It: 0, Loss Data: 8.095e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.271e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 11993, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.532e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 11994, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.172e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 11995, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.408e+00, Loss Aux: 2.900e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 11996, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.340e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 11997, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.370e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 11998, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.460e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 11999, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.342e+00, Loss Aux: 4.008e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12000, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.822e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12001, It: 0, Loss Data: 9.694e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.126e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12002, It: 0, Loss Data: 9.151e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.314e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12003, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.395e+00, Loss Aux: 4.119e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12004, It: 0, Loss Data: 9.665e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.978e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12005, It: 0, Loss Data: 8.509e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.001e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12006, It: 0, Loss Data: 8.524e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.951e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12007, It: 0, Loss Data: 8.849e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.514e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12008, It: 0, Loss Data: 8.006e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.283e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12009, It: 0, Loss Data: 7.325e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.326e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12010, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.304e+00, Loss Aux: 3.571e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12011, It: 0, Loss Data: 9.582e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.886e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12012, It: 0, Loss Data: 8.851e-02, Loss Eqns: 2.247e+00, Loss Aux: 3.954e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12013, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.712e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12014, It: 0, Loss Data: 8.700e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.611e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12015, It: 0, Loss Data: 8.040e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.664e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12016, It: 0, Loss Data: 8.931e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.670e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12017, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.064e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12018, It: 0, Loss Data: 9.690e-02, Loss Eqns: 2.452e+00, Loss Aux: 4.309e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12019, It: 0, Loss Data: 8.069e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.165e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12020, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.635e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12021, It: 0, Loss Data: 8.427e-02, Loss Eqns: 2.266e+00, Loss Aux: 3.417e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12022, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.352e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12023, It: 0, Loss Data: 9.591e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.444e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12024, It: 0, Loss Data: 8.785e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.839e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12025, It: 0, Loss Data: 9.257e-02, Loss Eqns: 2.398e+00, Loss Aux: 4.114e-02, Time: 0.145, Learning Rate: 1.0e-03\n",
      "Epoch: 12026, It: 0, Loss Data: 7.490e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.594e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12027, It: 0, Loss Data: 8.701e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.140e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12028, It: 0, Loss Data: 9.374e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.205e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12029, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.372e+00, Loss Aux: 3.691e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12030, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.782e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12031, It: 0, Loss Data: 7.624e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.124e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12032, It: 0, Loss Data: 8.151e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.157e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12033, It: 0, Loss Data: 9.049e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.543e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 12034, It: 0, Loss Data: 9.240e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.989e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12035, It: 0, Loss Data: 8.294e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.327e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12036, It: 0, Loss Data: 9.895e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.170e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 12037, It: 0, Loss Data: 8.297e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.535e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12038, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.815e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12039, It: 0, Loss Data: 8.994e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.549e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12040, It: 0, Loss Data: 8.090e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.261e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12041, It: 0, Loss Data: 8.920e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.380e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12042, It: 0, Loss Data: 8.580e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.027e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12043, It: 0, Loss Data: 9.783e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.990e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12044, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.229e+00, Loss Aux: 5.194e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12045, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.373e+00, Loss Aux: 4.262e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12046, It: 0, Loss Data: 9.116e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.103e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12047, It: 0, Loss Data: 8.957e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.278e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12048, It: 0, Loss Data: 7.633e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.087e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12049, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.485e+00, Loss Aux: 5.050e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12050, It: 0, Loss Data: 9.331e-02, Loss Eqns: 2.593e+00, Loss Aux: 3.332e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12051, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.176e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12052, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.585e+00, Loss Aux: 3.923e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12053, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.240e+00, Loss Aux: 3.686e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12054, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.500e+00, Loss Aux: 2.867e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 12055, It: 0, Loss Data: 9.255e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.802e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12056, It: 0, Loss Data: 1.076e-01, Loss Eqns: 2.639e+00, Loss Aux: 3.277e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12057, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.382e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12058, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.482e+00, Loss Aux: 3.190e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12059, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.120e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12060, It: 0, Loss Data: 8.406e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.500e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12061, It: 0, Loss Data: 7.963e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.975e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12062, It: 0, Loss Data: 8.678e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.420e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12063, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.850e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12064, It: 0, Loss Data: 8.546e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.305e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12065, It: 0, Loss Data: 8.512e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.341e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12066, It: 0, Loss Data: 7.962e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.763e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12067, It: 0, Loss Data: 9.305e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.363e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12068, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.233e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12069, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.000e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 12070, It: 0, Loss Data: 8.712e-02, Loss Eqns: 2.236e+00, Loss Aux: 3.423e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12071, It: 0, Loss Data: 9.517e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.099e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12072, It: 0, Loss Data: 8.936e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.340e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12073, It: 0, Loss Data: 8.471e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.277e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 12074, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.335e+00, Loss Aux: 3.395e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12075, It: 0, Loss Data: 8.049e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.698e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12076, It: 0, Loss Data: 8.218e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.911e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12077, It: 0, Loss Data: 1.256e-01, Loss Eqns: 2.649e+00, Loss Aux: 3.191e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12078, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.260e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12079, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.666e+00, Loss Aux: 4.249e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12080, It: 0, Loss Data: 9.983e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.398e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12081, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.548e+00, Loss Aux: 3.757e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12082, It: 0, Loss Data: 9.781e-02, Loss Eqns: 2.448e+00, Loss Aux: 5.244e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12083, It: 0, Loss Data: 1.169e-01, Loss Eqns: 2.547e+00, Loss Aux: 4.276e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12084, It: 0, Loss Data: 8.642e-02, Loss Eqns: 2.388e+00, Loss Aux: 2.167e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12085, It: 0, Loss Data: 9.960e-02, Loss Eqns: 2.490e+00, Loss Aux: 2.013e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12086, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.786e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12087, It: 0, Loss Data: 9.233e-02, Loss Eqns: 2.512e+00, Loss Aux: 4.615e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12088, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.298e+00, Loss Aux: 3.840e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12089, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.434e+00, Loss Aux: 3.123e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12090, It: 0, Loss Data: 9.542e-02, Loss Eqns: 2.441e+00, Loss Aux: 3.186e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12091, It: 0, Loss Data: 9.466e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.894e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12092, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.411e+00, Loss Aux: 3.907e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12093, It: 0, Loss Data: 9.893e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.565e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 12094, It: 0, Loss Data: 8.814e-02, Loss Eqns: 2.470e+00, Loss Aux: 3.769e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12095, It: 0, Loss Data: 7.776e-02, Loss Eqns: 2.432e+00, Loss Aux: 3.993e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12096, It: 0, Loss Data: 8.185e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.614e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12097, It: 0, Loss Data: 7.384e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.306e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12098, It: 0, Loss Data: 8.858e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.646e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12099, It: 0, Loss Data: 9.985e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.937e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12100, It: 0, Loss Data: 8.419e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.494e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12101, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.152e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12102, It: 0, Loss Data: 9.524e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.224e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12103, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.257e+00, Loss Aux: 3.130e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12104, It: 0, Loss Data: 8.935e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.676e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12105, It: 0, Loss Data: 1.120e-01, Loss Eqns: 2.270e+00, Loss Aux: 4.406e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12106, It: 0, Loss Data: 9.034e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.415e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12107, It: 0, Loss Data: 1.086e-01, Loss Eqns: 2.334e+00, Loss Aux: 3.774e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12108, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.270e+00, Loss Aux: 2.696e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12109, It: 0, Loss Data: 8.803e-02, Loss Eqns: 2.325e+00, Loss Aux: 2.339e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12110, It: 0, Loss Data: 9.377e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.163e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12111, It: 0, Loss Data: 7.619e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.649e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12112, It: 0, Loss Data: 8.247e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.733e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12113, It: 0, Loss Data: 7.708e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.065e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12114, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.145e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12115, It: 0, Loss Data: 7.922e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.708e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12116, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.259e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12117, It: 0, Loss Data: 7.700e-02, Loss Eqns: 2.406e+00, Loss Aux: 2.763e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12118, It: 0, Loss Data: 7.810e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.961e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12119, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.203e+00, Loss Aux: 3.167e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12120, It: 0, Loss Data: 9.134e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.332e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 12121, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.340e+00, Loss Aux: 3.590e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12122, It: 0, Loss Data: 8.027e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.269e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12123, It: 0, Loss Data: 9.182e-02, Loss Eqns: 2.384e+00, Loss Aux: 4.748e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12124, It: 0, Loss Data: 8.975e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.304e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12125, It: 0, Loss Data: 7.674e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.705e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12126, It: 0, Loss Data: 9.432e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.222e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 12127, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.293e+00, Loss Aux: 2.708e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12128, It: 0, Loss Data: 8.926e-02, Loss Eqns: 2.430e+00, Loss Aux: 2.916e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 12129, It: 0, Loss Data: 9.421e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.300e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12130, It: 0, Loss Data: 7.977e-02, Loss Eqns: 2.465e+00, Loss Aux: 3.478e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12131, It: 0, Loss Data: 8.906e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.349e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12132, It: 0, Loss Data: 8.122e-02, Loss Eqns: 2.431e+00, Loss Aux: 3.058e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12133, It: 0, Loss Data: 8.091e-02, Loss Eqns: 2.389e+00, Loss Aux: 2.917e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12134, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.301e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12135, It: 0, Loss Data: 7.900e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.085e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12136, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.883e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12137, It: 0, Loss Data: 7.043e-02, Loss Eqns: 2.344e+00, Loss Aux: 5.124e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12138, It: 0, Loss Data: 8.306e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.953e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12139, It: 0, Loss Data: 8.729e-02, Loss Eqns: 2.365e+00, Loss Aux: 2.847e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12140, It: 0, Loss Data: 8.883e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.264e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12141, It: 0, Loss Data: 8.199e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.118e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12142, It: 0, Loss Data: 7.497e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.773e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12143, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.259e+00, Loss Aux: 3.262e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12144, It: 0, Loss Data: 8.834e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.229e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12145, It: 0, Loss Data: 9.182e-02, Loss Eqns: 2.211e+00, Loss Aux: 3.815e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12146, It: 0, Loss Data: 9.657e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.506e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12147, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.245e+00, Loss Aux: 2.899e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12148, It: 0, Loss Data: 7.821e-02, Loss Eqns: 2.178e+00, Loss Aux: 3.034e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12149, It: 0, Loss Data: 8.576e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.763e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12150, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.190e+00, Loss Aux: 4.487e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12151, It: 0, Loss Data: 8.406e-02, Loss Eqns: 2.240e+00, Loss Aux: 3.909e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12152, It: 0, Loss Data: 9.610e-02, Loss Eqns: 2.207e+00, Loss Aux: 3.081e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12153, It: 0, Loss Data: 8.157e-02, Loss Eqns: 2.370e+00, Loss Aux: 2.525e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12154, It: 0, Loss Data: 8.410e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.595e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12155, It: 0, Loss Data: 8.850e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.571e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12156, It: 0, Loss Data: 8.364e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.558e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12157, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.318e+00, Loss Aux: 4.365e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12158, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.340e+00, Loss Aux: 3.712e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12159, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.627e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 12160, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.419e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12161, It: 0, Loss Data: 9.046e-02, Loss Eqns: 2.352e+00, Loss Aux: 2.881e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12162, It: 0, Loss Data: 8.559e-02, Loss Eqns: 2.305e+00, Loss Aux: 2.736e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12163, It: 0, Loss Data: 9.164e-02, Loss Eqns: 2.479e+00, Loss Aux: 3.068e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12164, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.441e+00, Loss Aux: 3.795e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12165, It: 0, Loss Data: 8.813e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.815e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12166, It: 0, Loss Data: 8.023e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.464e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12167, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.398e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12168, It: 0, Loss Data: 8.545e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.160e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12169, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.376e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12170, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.985e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12171, It: 0, Loss Data: 8.138e-02, Loss Eqns: 2.376e+00, Loss Aux: 2.861e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12172, It: 0, Loss Data: 9.628e-02, Loss Eqns: 2.309e+00, Loss Aux: 2.311e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12173, It: 0, Loss Data: 8.066e-02, Loss Eqns: 2.302e+00, Loss Aux: 2.898e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 12174, It: 0, Loss Data: 8.270e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.816e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12175, It: 0, Loss Data: 8.255e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.258e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12176, It: 0, Loss Data: 9.768e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.509e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12177, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.256e+00, Loss Aux: 3.062e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12178, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.040e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12179, It: 0, Loss Data: 9.006e-02, Loss Eqns: 2.283e+00, Loss Aux: 3.546e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12180, It: 0, Loss Data: 9.002e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.861e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12181, It: 0, Loss Data: 6.793e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.885e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12182, It: 0, Loss Data: 8.839e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.495e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12183, It: 0, Loss Data: 8.985e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.864e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12184, It: 0, Loss Data: 8.596e-02, Loss Eqns: 2.170e+00, Loss Aux: 3.996e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12185, It: 0, Loss Data: 9.364e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.422e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12186, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.311e+00, Loss Aux: 2.848e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12187, It: 0, Loss Data: 8.743e-02, Loss Eqns: 2.285e+00, Loss Aux: 2.846e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12188, It: 0, Loss Data: 8.397e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.049e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12189, It: 0, Loss Data: 8.894e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.404e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12190, It: 0, Loss Data: 8.284e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.436e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12191, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.198e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 12192, It: 0, Loss Data: 8.908e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.505e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12193, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.347e+00, Loss Aux: 4.663e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12194, It: 0, Loss Data: 9.592e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.730e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12195, It: 0, Loss Data: 9.837e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.057e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12196, It: 0, Loss Data: 8.612e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.219e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12197, It: 0, Loss Data: 7.903e-02, Loss Eqns: 2.412e+00, Loss Aux: 2.703e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12198, It: 0, Loss Data: 8.677e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.883e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12199, It: 0, Loss Data: 8.103e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.270e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12200, It: 0, Loss Data: 8.608e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.434e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12201, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.518e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12202, It: 0, Loss Data: 7.450e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.645e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12203, It: 0, Loss Data: 9.385e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.324e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12204, It: 0, Loss Data: 7.763e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.281e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12205, It: 0, Loss Data: 9.199e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.618e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12206, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.398e+00, Loss Aux: 2.570e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12207, It: 0, Loss Data: 1.049e-01, Loss Eqns: 2.671e+00, Loss Aux: 3.639e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12208, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.263e+00, Loss Aux: 3.626e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12209, It: 0, Loss Data: 9.838e-02, Loss Eqns: 2.554e+00, Loss Aux: 2.795e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12210, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.343e+00, Loss Aux: 2.948e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12211, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.640e+00, Loss Aux: 3.372e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12212, It: 0, Loss Data: 9.612e-02, Loss Eqns: 2.439e+00, Loss Aux: 3.542e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12213, It: 0, Loss Data: 8.612e-02, Loss Eqns: 2.507e+00, Loss Aux: 3.789e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 12214, It: 0, Loss Data: 9.160e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.294e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12215, It: 0, Loss Data: 8.775e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.158e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12216, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.772e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12217, It: 0, Loss Data: 8.385e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.621e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12218, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.077e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12219, It: 0, Loss Data: 9.734e-02, Loss Eqns: 2.236e+00, Loss Aux: 2.805e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12220, It: 0, Loss Data: 9.935e-02, Loss Eqns: 2.279e+00, Loss Aux: 1.984e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12221, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.261e+00, Loss Aux: 2.774e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12222, It: 0, Loss Data: 8.173e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.518e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12223, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.310e+00, Loss Aux: 4.684e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12224, It: 0, Loss Data: 9.031e-02, Loss Eqns: 2.387e+00, Loss Aux: 4.083e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12225, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.315e+00, Loss Aux: 3.766e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12226, It: 0, Loss Data: 7.646e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.705e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12227, It: 0, Loss Data: 9.413e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.573e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 12228, It: 0, Loss Data: 8.654e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.558e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 12229, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.643e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12230, It: 0, Loss Data: 8.410e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.133e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 12231, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.285e+00, Loss Aux: 4.152e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12232, It: 0, Loss Data: 8.712e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.831e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12233, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.498e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12234, It: 0, Loss Data: 8.758e-02, Loss Eqns: 2.268e+00, Loss Aux: 2.945e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12235, It: 0, Loss Data: 8.615e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.006e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12236, It: 0, Loss Data: 9.063e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.102e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12237, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.822e+00, Loss Aux: 5.768e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12238, It: 0, Loss Data: 7.371e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.862e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12239, It: 0, Loss Data: 1.097e-01, Loss Eqns: 2.573e+00, Loss Aux: 3.366e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12240, It: 0, Loss Data: 8.956e-02, Loss Eqns: 2.217e+00, Loss Aux: 3.278e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12241, It: 0, Loss Data: 1.189e-01, Loss Eqns: 2.498e+00, Loss Aux: 4.184e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12242, It: 0, Loss Data: 9.070e-02, Loss Eqns: 2.233e+00, Loss Aux: 3.833e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12243, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.495e+00, Loss Aux: 3.141e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 12244, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.137e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12245, It: 0, Loss Data: 9.748e-02, Loss Eqns: 2.662e+00, Loss Aux: 3.522e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12246, It: 0, Loss Data: 9.674e-02, Loss Eqns: 2.457e+00, Loss Aux: 3.823e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12247, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.495e+00, Loss Aux: 4.359e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12248, It: 0, Loss Data: 9.284e-02, Loss Eqns: 2.474e+00, Loss Aux: 4.354e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 12249, It: 0, Loss Data: 8.903e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.035e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12250, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.444e+00, Loss Aux: 2.403e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12251, It: 0, Loss Data: 9.893e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.001e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12252, It: 0, Loss Data: 9.500e-02, Loss Eqns: 2.492e+00, Loss Aux: 4.368e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12253, It: 0, Loss Data: 8.480e-02, Loss Eqns: 2.453e+00, Loss Aux: 4.858e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12254, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.342e+00, Loss Aux: 3.470e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12255, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.435e+00, Loss Aux: 3.085e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12256, It: 0, Loss Data: 9.685e-02, Loss Eqns: 2.526e+00, Loss Aux: 4.046e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12257, It: 0, Loss Data: 9.082e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.039e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12258, It: 0, Loss Data: 8.855e-02, Loss Eqns: 2.443e+00, Loss Aux: 3.799e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12259, It: 0, Loss Data: 8.467e-02, Loss Eqns: 2.519e+00, Loss Aux: 5.379e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12260, It: 0, Loss Data: 1.464e-01, Loss Eqns: 2.807e+00, Loss Aux: 2.875e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12261, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.351e+00, Loss Aux: 3.328e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12262, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.941e+00, Loss Aux: 4.733e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12263, It: 0, Loss Data: 8.058e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.534e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 12264, It: 0, Loss Data: 1.127e-01, Loss Eqns: 2.692e+00, Loss Aux: 2.596e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12265, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.287e+00, Loss Aux: 3.354e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12266, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.743e+00, Loss Aux: 4.910e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12267, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.367e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12268, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.641e+00, Loss Aux: 3.148e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12269, It: 0, Loss Data: 9.730e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.320e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12270, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.535e+00, Loss Aux: 3.901e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12271, It: 0, Loss Data: 8.716e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.430e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12272, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.278e+00, Loss Aux: 4.301e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12273, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.381e+00, Loss Aux: 4.538e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12274, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.217e+00, Loss Aux: 3.461e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12275, It: 0, Loss Data: 1.219e-01, Loss Eqns: 2.589e+00, Loss Aux: 3.589e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12276, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.321e+00, Loss Aux: 2.653e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12277, It: 0, Loss Data: 1.080e-01, Loss Eqns: 2.431e+00, Loss Aux: 2.294e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12278, It: 0, Loss Data: 9.968e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.253e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12279, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.486e+00, Loss Aux: 5.127e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12280, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.315e+00, Loss Aux: 6.235e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12281, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.574e+00, Loss Aux: 4.993e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12282, It: 0, Loss Data: 8.461e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.805e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12283, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.532e+00, Loss Aux: 3.511e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12284, It: 0, Loss Data: 7.513e-02, Loss Eqns: 2.414e+00, Loss Aux: 3.358e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12285, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.487e+00, Loss Aux: 3.864e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12286, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.448e+00, Loss Aux: 4.408e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12287, It: 0, Loss Data: 9.389e-02, Loss Eqns: 2.528e+00, Loss Aux: 4.413e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12288, It: 0, Loss Data: 8.224e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.547e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12289, It: 0, Loss Data: 9.212e-02, Loss Eqns: 2.399e+00, Loss Aux: 2.983e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12290, It: 0, Loss Data: 7.906e-02, Loss Eqns: 2.274e+00, Loss Aux: 2.965e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12291, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.627e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12292, It: 0, Loss Data: 7.979e-02, Loss Eqns: 2.430e+00, Loss Aux: 4.457e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12293, It: 0, Loss Data: 8.169e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.522e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12294, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.449e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12295, It: 0, Loss Data: 8.481e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.013e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12296, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.260e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12297, It: 0, Loss Data: 8.714e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.306e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12298, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.649e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12299, It: 0, Loss Data: 9.523e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.980e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12300, It: 0, Loss Data: 9.844e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.880e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12301, It: 0, Loss Data: 9.583e-02, Loss Eqns: 2.266e+00, Loss Aux: 3.526e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12302, It: 0, Loss Data: 8.077e-02, Loss Eqns: 2.281e+00, Loss Aux: 2.933e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12303, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.208e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12304, It: 0, Loss Data: 9.855e-02, Loss Eqns: 2.226e+00, Loss Aux: 3.706e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12305, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.997e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12306, It: 0, Loss Data: 9.966e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.295e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12307, It: 0, Loss Data: 8.237e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.903e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12308, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.837e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12309, It: 0, Loss Data: 7.749e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.894e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12310, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.389e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12311, It: 0, Loss Data: 8.973e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.357e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12312, It: 0, Loss Data: 7.712e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.835e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12313, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.579e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12314, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.375e+00, Loss Aux: 3.453e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12315, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.474e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12316, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.480e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12317, It: 0, Loss Data: 9.222e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.129e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12318, It: 0, Loss Data: 8.458e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.129e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12319, It: 0, Loss Data: 8.949e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.845e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12320, It: 0, Loss Data: 9.354e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.616e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 12321, It: 0, Loss Data: 9.438e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.216e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12322, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.521e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12323, It: 0, Loss Data: 7.902e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.294e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12324, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.437e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12325, It: 0, Loss Data: 8.317e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.947e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12326, It: 0, Loss Data: 8.695e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.490e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 12327, It: 0, Loss Data: 8.577e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.025e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12328, It: 0, Loss Data: 9.713e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.684e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12329, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.654e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12330, It: 0, Loss Data: 8.460e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.146e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 12331, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.358e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12332, It: 0, Loss Data: 8.252e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.563e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12333, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.315e+00, Loss Aux: 2.752e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12334, It: 0, Loss Data: 7.757e-02, Loss Eqns: 2.422e+00, Loss Aux: 2.837e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12335, It: 0, Loss Data: 8.695e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.245e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12336, It: 0, Loss Data: 8.233e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.730e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12337, It: 0, Loss Data: 8.689e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.811e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12338, It: 0, Loss Data: 7.601e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.643e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12339, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.654e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12340, It: 0, Loss Data: 8.095e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.027e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12341, It: 0, Loss Data: 9.064e-02, Loss Eqns: 2.217e+00, Loss Aux: 3.604e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12342, It: 0, Loss Data: 9.438e-02, Loss Eqns: 2.234e+00, Loss Aux: 3.376e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12343, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.627e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12344, It: 0, Loss Data: 8.250e-02, Loss Eqns: 2.159e+00, Loss Aux: 4.110e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12345, It: 0, Loss Data: 9.556e-02, Loss Eqns: 2.207e+00, Loss Aux: 4.497e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 12346, It: 0, Loss Data: 8.127e-02, Loss Eqns: 2.137e+00, Loss Aux: 4.140e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12347, It: 0, Loss Data: 9.743e-02, Loss Eqns: 2.281e+00, Loss Aux: 2.974e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12348, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.284e+00, Loss Aux: 2.680e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12349, It: 0, Loss Data: 8.721e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.141e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12350, It: 0, Loss Data: 8.539e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.095e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12351, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.065e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12352, It: 0, Loss Data: 7.825e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.394e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 12353, It: 0, Loss Data: 8.779e-02, Loss Eqns: 2.265e+00, Loss Aux: 3.208e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12354, It: 0, Loss Data: 9.802e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.144e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12355, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.292e+00, Loss Aux: 4.117e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12356, It: 0, Loss Data: 9.083e-02, Loss Eqns: 2.254e+00, Loss Aux: 2.932e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12357, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.309e+00, Loss Aux: 2.607e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12358, It: 0, Loss Data: 8.836e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.464e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12359, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.444e+00, Loss Aux: 4.719e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12360, It: 0, Loss Data: 9.864e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.475e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12361, It: 0, Loss Data: 8.646e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.039e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12362, It: 0, Loss Data: 8.270e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.123e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12363, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.329e+00, Loss Aux: 4.395e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12364, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.185e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12365, It: 0, Loss Data: 8.491e-02, Loss Eqns: 2.254e+00, Loss Aux: 3.318e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12366, It: 0, Loss Data: 8.939e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.020e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12367, It: 0, Loss Data: 9.054e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.247e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 12368, It: 0, Loss Data: 8.899e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.642e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12369, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.782e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12370, It: 0, Loss Data: 8.872e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.343e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12371, It: 0, Loss Data: 8.260e-02, Loss Eqns: 2.291e+00, Loss Aux: 2.830e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12372, It: 0, Loss Data: 8.964e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.280e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12373, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.282e+00, Loss Aux: 4.762e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12374, It: 0, Loss Data: 8.871e-02, Loss Eqns: 2.362e+00, Loss Aux: 5.460e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12375, It: 0, Loss Data: 7.223e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.487e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12376, It: 0, Loss Data: 7.945e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.631e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12377, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.359e+00, Loss Aux: 3.460e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12378, It: 0, Loss Data: 9.628e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.375e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12379, It: 0, Loss Data: 9.533e-02, Loss Eqns: 2.280e+00, Loss Aux: 2.722e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12380, It: 0, Loss Data: 8.257e-02, Loss Eqns: 2.273e+00, Loss Aux: 2.544e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12381, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.375e+00, Loss Aux: 2.949e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12382, It: 0, Loss Data: 9.874e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.805e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12383, It: 0, Loss Data: 8.676e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.271e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12384, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.944e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12385, It: 0, Loss Data: 7.880e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.294e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12386, It: 0, Loss Data: 8.172e-02, Loss Eqns: 2.498e+00, Loss Aux: 3.406e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12387, It: 0, Loss Data: 7.493e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.907e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12388, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.233e+00, Loss Aux: 4.181e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12389, It: 0, Loss Data: 7.795e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.052e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12390, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.297e+00, Loss Aux: 3.784e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12391, It: 0, Loss Data: 8.716e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.406e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12392, It: 0, Loss Data: 7.898e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.062e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12393, It: 0, Loss Data: 7.864e-02, Loss Eqns: 2.348e+00, Loss Aux: 2.985e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12394, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.354e+00, Loss Aux: 2.990e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12395, It: 0, Loss Data: 6.898e-02, Loss Eqns: 2.323e+00, Loss Aux: 2.932e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12396, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.015e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12397, It: 0, Loss Data: 8.394e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.376e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 12398, It: 0, Loss Data: 9.462e-02, Loss Eqns: 2.220e+00, Loss Aux: 3.797e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 12399, It: 0, Loss Data: 8.988e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.014e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12400, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.344e+00, Loss Aux: 3.529e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12401, It: 0, Loss Data: 7.650e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.168e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12402, It: 0, Loss Data: 7.447e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.455e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12403, It: 0, Loss Data: 8.077e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.145e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12404, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.578e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12405, It: 0, Loss Data: 9.850e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.891e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12406, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.361e+00, Loss Aux: 3.176e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12407, It: 0, Loss Data: 7.787e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.068e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12408, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.345e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12409, It: 0, Loss Data: 9.256e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.566e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12410, It: 0, Loss Data: 7.947e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.357e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12411, It: 0, Loss Data: 7.997e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.261e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12412, It: 0, Loss Data: 1.265e-01, Loss Eqns: 2.690e+00, Loss Aux: 2.355e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12413, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.836e+00, Loss Aux: 4.389e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12414, It: 0, Loss Data: 1.787e-01, Loss Eqns: 3.445e+00, Loss Aux: 8.200e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12415, It: 0, Loss Data: 2.195e-01, Loss Eqns: 4.728e+00, Loss Aux: 3.423e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12416, It: 0, Loss Data: 2.703e-01, Loss Eqns: 5.123e+00, Loss Aux: 3.547e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12417, It: 0, Loss Data: 1.667e-01, Loss Eqns: 3.782e+00, Loss Aux: 3.755e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12418, It: 0, Loss Data: 4.441e-01, Loss Eqns: 8.505e+00, Loss Aux: 1.297e-01, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12419, It: 0, Loss Data: 1.924e-01, Loss Eqns: 3.104e+00, Loss Aux: 7.609e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12420, It: 0, Loss Data: 2.182e-01, Loss Eqns: 4.308e+00, Loss Aux: 3.849e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12421, It: 0, Loss Data: 2.585e-01, Loss Eqns: 4.000e+00, Loss Aux: 3.224e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12422, It: 0, Loss Data: 1.801e-01, Loss Eqns: 2.996e+00, Loss Aux: 5.488e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12423, It: 0, Loss Data: 2.224e-01, Loss Eqns: 3.545e+00, Loss Aux: 6.657e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12424, It: 0, Loss Data: 1.649e-01, Loss Eqns: 2.639e+00, Loss Aux: 3.095e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12425, It: 0, Loss Data: 2.294e-01, Loss Eqns: 3.162e+00, Loss Aux: 1.428e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12426, It: 0, Loss Data: 1.712e-01, Loss Eqns: 2.892e+00, Loss Aux: 1.825e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12427, It: 0, Loss Data: 1.519e-01, Loss Eqns: 2.632e+00, Loss Aux: 7.543e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12428, It: 0, Loss Data: 1.814e-01, Loss Eqns: 3.035e+00, Loss Aux: 1.285e-01, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 12429, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.477e+00, Loss Aux: 1.306e-01, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 12430, It: 0, Loss Data: 1.491e-01, Loss Eqns: 2.643e+00, Loss Aux: 1.005e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12431, It: 0, Loss Data: 1.554e-01, Loss Eqns: 2.634e+00, Loss Aux: 7.831e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12432, It: 0, Loss Data: 1.588e-01, Loss Eqns: 2.253e+00, Loss Aux: 7.891e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12433, It: 0, Loss Data: 1.432e-01, Loss Eqns: 2.566e+00, Loss Aux: 7.465e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12434, It: 0, Loss Data: 1.309e-01, Loss Eqns: 2.330e+00, Loss Aux: 5.482e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12435, It: 0, Loss Data: 1.416e-01, Loss Eqns: 2.269e+00, Loss Aux: 2.921e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12436, It: 0, Loss Data: 1.347e-01, Loss Eqns: 2.297e+00, Loss Aux: 2.932e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 12437, It: 0, Loss Data: 1.264e-01, Loss Eqns: 2.212e+00, Loss Aux: 5.327e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12438, It: 0, Loss Data: 1.151e-01, Loss Eqns: 2.473e+00, Loss Aux: 7.460e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12439, It: 0, Loss Data: 1.165e-01, Loss Eqns: 2.499e+00, Loss Aux: 6.579e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12440, It: 0, Loss Data: 1.143e-01, Loss Eqns: 2.566e+00, Loss Aux: 4.102e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12441, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.583e+00, Loss Aux: 3.732e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12442, It: 0, Loss Data: 9.717e-02, Loss Eqns: 2.374e+00, Loss Aux: 5.050e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12443, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.525e+00, Loss Aux: 6.039e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12444, It: 0, Loss Data: 9.892e-02, Loss Eqns: 2.415e+00, Loss Aux: 5.074e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12445, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.409e+00, Loss Aux: 3.971e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12446, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.449e+00, Loss Aux: 3.753e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12447, It: 0, Loss Data: 1.060e-01, Loss Eqns: 2.448e+00, Loss Aux: 4.007e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12448, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.471e+00, Loss Aux: 4.778e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12449, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.382e+00, Loss Aux: 5.057e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12450, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.421e+00, Loss Aux: 5.243e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12451, It: 0, Loss Data: 9.724e-02, Loss Eqns: 2.514e+00, Loss Aux: 5.674e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12452, It: 0, Loss Data: 9.264e-02, Loss Eqns: 2.516e+00, Loss Aux: 6.233e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12453, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.566e+00, Loss Aux: 5.656e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12454, It: 0, Loss Data: 6.721e-02, Loss Eqns: 2.504e+00, Loss Aux: 4.228e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12455, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.456e+00, Loss Aux: 3.502e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12456, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.402e+00, Loss Aux: 3.542e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12457, It: 0, Loss Data: 9.865e-02, Loss Eqns: 2.478e+00, Loss Aux: 4.181e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12458, It: 0, Loss Data: 9.831e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.755e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12459, It: 0, Loss Data: 8.975e-02, Loss Eqns: 2.416e+00, Loss Aux: 4.735e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12460, It: 0, Loss Data: 8.661e-02, Loss Eqns: 2.485e+00, Loss Aux: 4.620e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12461, It: 0, Loss Data: 9.638e-02, Loss Eqns: 2.519e+00, Loss Aux: 4.443e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12462, It: 0, Loss Data: 8.392e-02, Loss Eqns: 2.443e+00, Loss Aux: 4.547e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12463, It: 0, Loss Data: 7.606e-02, Loss Eqns: 2.470e+00, Loss Aux: 4.796e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12464, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.693e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12465, It: 0, Loss Data: 9.058e-02, Loss Eqns: 2.474e+00, Loss Aux: 4.738e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12466, It: 0, Loss Data: 9.547e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.976e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12467, It: 0, Loss Data: 9.635e-02, Loss Eqns: 2.357e+00, Loss Aux: 5.364e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12468, It: 0, Loss Data: 8.107e-02, Loss Eqns: 2.360e+00, Loss Aux: 5.150e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12469, It: 0, Loss Data: 8.523e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.667e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12470, It: 0, Loss Data: 7.780e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.148e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12471, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.924e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12472, It: 0, Loss Data: 8.705e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.372e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12473, It: 0, Loss Data: 7.771e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.733e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12474, It: 0, Loss Data: 9.404e-02, Loss Eqns: 2.289e+00, Loss Aux: 5.126e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12475, It: 0, Loss Data: 9.822e-02, Loss Eqns: 2.328e+00, Loss Aux: 5.054e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12476, It: 0, Loss Data: 9.616e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.330e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12477, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.735e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12478, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.506e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12479, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.631e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12480, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.334e+00, Loss Aux: 3.809e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12481, It: 0, Loss Data: 9.553e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.857e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12482, It: 0, Loss Data: 9.823e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.764e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12483, It: 0, Loss Data: 9.222e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.002e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12484, It: 0, Loss Data: 8.296e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.754e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12485, It: 0, Loss Data: 8.916e-02, Loss Eqns: 2.325e+00, Loss Aux: 5.249e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12486, It: 0, Loss Data: 9.563e-02, Loss Eqns: 2.330e+00, Loss Aux: 5.512e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12487, It: 0, Loss Data: 9.677e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.961e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 12488, It: 0, Loss Data: 9.971e-02, Loss Eqns: 2.416e+00, Loss Aux: 4.359e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12489, It: 0, Loss Data: 8.722e-02, Loss Eqns: 2.384e+00, Loss Aux: 4.260e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12490, It: 0, Loss Data: 8.541e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.352e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 12491, It: 0, Loss Data: 9.520e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.415e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12492, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.331e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12493, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.126e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12494, It: 0, Loss Data: 8.279e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.083e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12495, It: 0, Loss Data: 9.516e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.850e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12496, It: 0, Loss Data: 7.956e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.640e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12497, It: 0, Loss Data: 8.909e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.764e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12498, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.394e+00, Loss Aux: 4.261e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12499, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.973e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12500, It: 0, Loss Data: 9.130e-02, Loss Eqns: 2.388e+00, Loss Aux: 5.310e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12501, It: 0, Loss Data: 8.371e-02, Loss Eqns: 2.390e+00, Loss Aux: 4.932e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12502, It: 0, Loss Data: 8.100e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.312e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12503, It: 0, Loss Data: 7.357e-02, Loss Eqns: 2.419e+00, Loss Aux: 4.228e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12504, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.459e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12505, It: 0, Loss Data: 8.147e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.377e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 12506, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.450e+00, Loss Aux: 3.990e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12507, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.037e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12508, It: 0, Loss Data: 8.899e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.980e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12509, It: 0, Loss Data: 8.642e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.792e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12510, It: 0, Loss Data: 8.266e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.283e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12511, It: 0, Loss Data: 9.001e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.469e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12512, It: 0, Loss Data: 9.355e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.010e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12513, It: 0, Loss Data: 8.609e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.214e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12514, It: 0, Loss Data: 8.605e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.060e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12515, It: 0, Loss Data: 8.279e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.754e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12516, It: 0, Loss Data: 8.326e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.675e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12517, It: 0, Loss Data: 9.866e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.958e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12518, It: 0, Loss Data: 8.349e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.404e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12519, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.294e+00, Loss Aux: 4.755e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12520, It: 0, Loss Data: 8.954e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.350e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12521, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.238e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12522, It: 0, Loss Data: 8.249e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.030e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12523, It: 0, Loss Data: 9.663e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.967e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12524, It: 0, Loss Data: 9.228e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.013e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12525, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.948e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12526, It: 0, Loss Data: 9.996e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.982e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12527, It: 0, Loss Data: 8.860e-02, Loss Eqns: 2.373e+00, Loss Aux: 4.362e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12528, It: 0, Loss Data: 7.697e-02, Loss Eqns: 2.409e+00, Loss Aux: 4.789e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12529, It: 0, Loss Data: 9.658e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.827e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12530, It: 0, Loss Data: 6.610e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.047e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12531, It: 0, Loss Data: 7.660e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.809e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12532, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.902e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12533, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.392e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12534, It: 0, Loss Data: 8.444e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.416e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12535, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.946e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12536, It: 0, Loss Data: 8.045e-02, Loss Eqns: 2.283e+00, Loss Aux: 3.499e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12537, It: 0, Loss Data: 8.872e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.173e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12538, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.308e+00, Loss Aux: 3.130e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12539, It: 0, Loss Data: 9.636e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.397e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12540, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.856e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12541, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.448e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12542, It: 0, Loss Data: 8.774e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.506e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12543, It: 0, Loss Data: 9.710e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.801e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12544, It: 0, Loss Data: 9.052e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.828e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12545, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.409e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12546, It: 0, Loss Data: 8.954e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.913e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12547, It: 0, Loss Data: 7.766e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.844e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12548, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.423e+00, Loss Aux: 4.351e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12549, It: 0, Loss Data: 9.482e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.531e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12550, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.295e+00, Loss Aux: 3.999e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12551, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.504e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12552, It: 0, Loss Data: 7.956e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.457e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12553, It: 0, Loss Data: 8.601e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.082e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12554, It: 0, Loss Data: 7.968e-02, Loss Eqns: 2.411e+00, Loss Aux: 4.582e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12555, It: 0, Loss Data: 9.613e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.888e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12556, It: 0, Loss Data: 8.653e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.760e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12557, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.185e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12558, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.058e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12559, It: 0, Loss Data: 8.807e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.158e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 12560, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.400e+00, Loss Aux: 4.146e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12561, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.511e+00, Loss Aux: 3.870e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12562, It: 0, Loss Data: 6.946e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.181e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12563, It: 0, Loss Data: 8.245e-02, Loss Eqns: 2.415e+00, Loss Aux: 3.145e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12564, It: 0, Loss Data: 9.741e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.044e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12565, It: 0, Loss Data: 8.582e-02, Loss Eqns: 2.413e+00, Loss Aux: 4.293e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12566, It: 0, Loss Data: 9.470e-02, Loss Eqns: 2.451e+00, Loss Aux: 3.971e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12567, It: 0, Loss Data: 6.994e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.537e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12568, It: 0, Loss Data: 8.888e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.781e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12569, It: 0, Loss Data: 7.919e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.457e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12570, It: 0, Loss Data: 9.258e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.551e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12571, It: 0, Loss Data: 9.181e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.898e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12572, It: 0, Loss Data: 8.663e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.591e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12573, It: 0, Loss Data: 9.963e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.749e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12574, It: 0, Loss Data: 7.392e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.190e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12575, It: 0, Loss Data: 8.379e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.336e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12576, It: 0, Loss Data: 9.456e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.299e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12577, It: 0, Loss Data: 7.636e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.921e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12578, It: 0, Loss Data: 7.653e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.492e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12579, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.817e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12580, It: 0, Loss Data: 8.661e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.881e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 12581, It: 0, Loss Data: 9.634e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.490e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12582, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.349e+00, Loss Aux: 3.522e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 12583, It: 0, Loss Data: 8.186e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.089e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12584, It: 0, Loss Data: 8.745e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.088e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12585, It: 0, Loss Data: 8.890e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.643e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 12586, It: 0, Loss Data: 9.171e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.426e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12587, It: 0, Loss Data: 8.509e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.891e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12588, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.784e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12589, It: 0, Loss Data: 8.230e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.628e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12590, It: 0, Loss Data: 9.194e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.314e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12591, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.190e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12592, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.420e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12593, It: 0, Loss Data: 9.384e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.719e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12594, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.824e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12595, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.308e+00, Loss Aux: 2.863e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12596, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.383e+00, Loss Aux: 2.661e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12597, It: 0, Loss Data: 8.104e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.377e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12598, It: 0, Loss Data: 9.313e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.937e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12599, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.495e+00, Loss Aux: 3.869e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12600, It: 0, Loss Data: 8.695e-02, Loss Eqns: 2.435e+00, Loss Aux: 3.736e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12601, It: 0, Loss Data: 7.364e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.001e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12602, It: 0, Loss Data: 7.342e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.211e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12603, It: 0, Loss Data: 8.397e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.784e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12604, It: 0, Loss Data: 8.640e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.771e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12605, It: 0, Loss Data: 9.390e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.155e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12606, It: 0, Loss Data: 9.558e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.744e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12607, It: 0, Loss Data: 8.260e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.702e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12608, It: 0, Loss Data: 9.356e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.936e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12609, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.733e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12610, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.458e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12611, It: 0, Loss Data: 9.558e-02, Loss Eqns: 2.245e+00, Loss Aux: 3.205e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12612, It: 0, Loss Data: 7.373e-02, Loss Eqns: 2.272e+00, Loss Aux: 3.459e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12613, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.204e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12614, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.345e+00, Loss Aux: 5.010e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12615, It: 0, Loss Data: 9.266e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.889e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12616, It: 0, Loss Data: 8.521e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.892e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12617, It: 0, Loss Data: 8.198e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.308e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12618, It: 0, Loss Data: 8.890e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.719e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 12619, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.337e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12620, It: 0, Loss Data: 8.902e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.056e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12621, It: 0, Loss Data: 7.650e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.272e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12622, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.085e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12623, It: 0, Loss Data: 7.636e-02, Loss Eqns: 2.345e+00, Loss Aux: 2.966e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12624, It: 0, Loss Data: 8.984e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.424e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12625, It: 0, Loss Data: 8.405e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.006e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12626, It: 0, Loss Data: 9.818e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.477e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12627, It: 0, Loss Data: 8.634e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.424e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12628, It: 0, Loss Data: 8.733e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.341e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12629, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.662e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12630, It: 0, Loss Data: 8.992e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.747e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12631, It: 0, Loss Data: 7.543e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.141e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12632, It: 0, Loss Data: 7.806e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.716e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12633, It: 0, Loss Data: 8.073e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.551e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12634, It: 0, Loss Data: 9.180e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.605e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12635, It: 0, Loss Data: 9.596e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.815e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12636, It: 0, Loss Data: 7.161e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.812e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12637, It: 0, Loss Data: 7.819e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.595e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 12638, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.262e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12639, It: 0, Loss Data: 9.405e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.058e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12640, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.272e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12641, It: 0, Loss Data: 8.378e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.694e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12642, It: 0, Loss Data: 9.354e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.787e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12643, It: 0, Loss Data: 8.175e-02, Loss Eqns: 2.242e+00, Loss Aux: 3.642e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12644, It: 0, Loss Data: 7.659e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.868e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12645, It: 0, Loss Data: 8.187e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.053e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12646, It: 0, Loss Data: 8.187e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.924e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12647, It: 0, Loss Data: 9.911e-02, Loss Eqns: 2.219e+00, Loss Aux: 3.871e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12648, It: 0, Loss Data: 9.632e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.143e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12649, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.284e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12650, It: 0, Loss Data: 8.045e-02, Loss Eqns: 2.385e+00, Loss Aux: 4.029e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12651, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.281e+00, Loss Aux: 3.588e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12652, It: 0, Loss Data: 8.260e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.232e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12653, It: 0, Loss Data: 1.014e-01, Loss Eqns: 2.364e+00, Loss Aux: 3.469e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12654, It: 0, Loss Data: 7.784e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.676e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12655, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.563e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12656, It: 0, Loss Data: 8.539e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.653e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12657, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.681e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12658, It: 0, Loss Data: 9.756e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.618e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12659, It: 0, Loss Data: 8.544e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.595e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12660, It: 0, Loss Data: 7.576e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.662e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12661, It: 0, Loss Data: 7.763e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.667e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12662, It: 0, Loss Data: 8.380e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.820e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12663, It: 0, Loss Data: 7.545e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.700e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12664, It: 0, Loss Data: 8.421e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.785e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12665, It: 0, Loss Data: 7.972e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.671e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12666, It: 0, Loss Data: 8.737e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.445e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12667, It: 0, Loss Data: 8.017e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.297e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12668, It: 0, Loss Data: 9.002e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.582e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12669, It: 0, Loss Data: 8.793e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.440e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12670, It: 0, Loss Data: 9.103e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.225e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12671, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.315e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 12672, It: 0, Loss Data: 8.075e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.754e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12673, It: 0, Loss Data: 8.734e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.631e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12674, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.294e+00, Loss Aux: 3.585e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12675, It: 0, Loss Data: 8.252e-02, Loss Eqns: 2.272e+00, Loss Aux: 3.597e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12676, It: 0, Loss Data: 9.764e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.188e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 12677, It: 0, Loss Data: 7.649e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.049e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12678, It: 0, Loss Data: 8.426e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.147e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12679, It: 0, Loss Data: 8.283e-02, Loss Eqns: 2.238e+00, Loss Aux: 3.675e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12680, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.253e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12681, It: 0, Loss Data: 8.578e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.813e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12682, It: 0, Loss Data: 7.498e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.377e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12683, It: 0, Loss Data: 7.835e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.330e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12684, It: 0, Loss Data: 9.151e-02, Loss Eqns: 2.241e+00, Loss Aux: 3.670e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12685, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.216e+00, Loss Aux: 3.870e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12686, It: 0, Loss Data: 9.086e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.722e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12687, It: 0, Loss Data: 7.547e-02, Loss Eqns: 2.199e+00, Loss Aux: 3.394e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12688, It: 0, Loss Data: 8.957e-02, Loss Eqns: 2.200e+00, Loss Aux: 3.436e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12689, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.318e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12690, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.069e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12691, It: 0, Loss Data: 8.406e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.073e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12692, It: 0, Loss Data: 9.356e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.447e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12693, It: 0, Loss Data: 8.044e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.856e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12694, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.071e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12695, It: 0, Loss Data: 9.086e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.169e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12696, It: 0, Loss Data: 7.705e-02, Loss Eqns: 2.208e+00, Loss Aux: 3.367e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12697, It: 0, Loss Data: 8.367e-02, Loss Eqns: 2.253e+00, Loss Aux: 3.086e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12698, It: 0, Loss Data: 8.414e-02, Loss Eqns: 2.292e+00, Loss Aux: 2.902e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12699, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.308e+00, Loss Aux: 3.227e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12700, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.243e+00, Loss Aux: 3.669e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12701, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.063e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12702, It: 0, Loss Data: 8.592e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.831e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12703, It: 0, Loss Data: 8.829e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.609e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12704, It: 0, Loss Data: 1.078e-01, Loss Eqns: 2.294e+00, Loss Aux: 3.801e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12705, It: 0, Loss Data: 9.144e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.578e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12706, It: 0, Loss Data: 9.205e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.345e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12707, It: 0, Loss Data: 9.214e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.140e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12708, It: 0, Loss Data: 9.680e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.019e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12709, It: 0, Loss Data: 8.096e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.132e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12710, It: 0, Loss Data: 8.966e-02, Loss Eqns: 2.493e+00, Loss Aux: 3.041e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12711, It: 0, Loss Data: 8.262e-02, Loss Eqns: 2.420e+00, Loss Aux: 2.804e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12712, It: 0, Loss Data: 9.056e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.088e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12713, It: 0, Loss Data: 8.985e-02, Loss Eqns: 2.443e+00, Loss Aux: 4.662e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 12714, It: 0, Loss Data: 8.936e-02, Loss Eqns: 2.394e+00, Loss Aux: 5.006e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12715, It: 0, Loss Data: 7.853e-02, Loss Eqns: 2.428e+00, Loss Aux: 4.649e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12716, It: 0, Loss Data: 8.116e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.738e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12717, It: 0, Loss Data: 9.180e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.247e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12718, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.471e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12719, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.129e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12720, It: 0, Loss Data: 9.397e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.632e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12721, It: 0, Loss Data: 9.560e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.254e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12722, It: 0, Loss Data: 8.424e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.133e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12723, It: 0, Loss Data: 8.245e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.660e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12724, It: 0, Loss Data: 9.525e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.589e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12725, It: 0, Loss Data: 8.435e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.476e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12726, It: 0, Loss Data: 8.774e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.494e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12727, It: 0, Loss Data: 7.682e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.614e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12728, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.729e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12729, It: 0, Loss Data: 8.416e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.644e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12730, It: 0, Loss Data: 7.301e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.287e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12731, It: 0, Loss Data: 8.239e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.197e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12732, It: 0, Loss Data: 9.381e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.899e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12733, It: 0, Loss Data: 9.771e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.923e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12734, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.283e+00, Loss Aux: 3.044e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12735, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.289e+00, Loss Aux: 2.612e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12736, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.260e+00, Loss Aux: 3.171e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 12737, It: 0, Loss Data: 9.013e-02, Loss Eqns: 2.402e+00, Loss Aux: 4.034e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12738, It: 0, Loss Data: 9.229e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.964e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12739, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.218e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12740, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.355e+00, Loss Aux: 2.733e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 12741, It: 0, Loss Data: 8.996e-02, Loss Eqns: 2.393e+00, Loss Aux: 2.631e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 12742, It: 0, Loss Data: 8.528e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.446e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12743, It: 0, Loss Data: 8.311e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.367e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12744, It: 0, Loss Data: 8.006e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.277e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12745, It: 0, Loss Data: 8.510e-02, Loss Eqns: 2.398e+00, Loss Aux: 4.179e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12746, It: 0, Loss Data: 8.366e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.377e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12747, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.390e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12748, It: 0, Loss Data: 8.236e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.839e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12749, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.387e+00, Loss Aux: 2.883e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12750, It: 0, Loss Data: 8.079e-02, Loss Eqns: 2.374e+00, Loss Aux: 2.672e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12751, It: 0, Loss Data: 8.178e-02, Loss Eqns: 2.257e+00, Loss Aux: 2.846e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12752, It: 0, Loss Data: 8.835e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.290e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12753, It: 0, Loss Data: 9.750e-02, Loss Eqns: 2.290e+00, Loss Aux: 2.936e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12754, It: 0, Loss Data: 9.910e-02, Loss Eqns: 2.356e+00, Loss Aux: 2.672e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12755, It: 0, Loss Data: 9.871e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.366e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12756, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.122e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12757, It: 0, Loss Data: 9.533e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.502e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12758, It: 0, Loss Data: 7.630e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.166e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12759, It: 0, Loss Data: 8.151e-02, Loss Eqns: 2.464e+00, Loss Aux: 3.616e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12760, It: 0, Loss Data: 7.469e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.438e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12761, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.396e+00, Loss Aux: 3.351e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12762, It: 0, Loss Data: 8.390e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.193e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12763, It: 0, Loss Data: 9.881e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.459e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12764, It: 0, Loss Data: 8.890e-02, Loss Eqns: 2.422e+00, Loss Aux: 3.842e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12765, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.882e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12766, It: 0, Loss Data: 9.092e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.119e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12767, It: 0, Loss Data: 9.025e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.649e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12768, It: 0, Loss Data: 9.496e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.067e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12769, It: 0, Loss Data: 8.489e-02, Loss Eqns: 2.290e+00, Loss Aux: 2.528e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12770, It: 0, Loss Data: 9.350e-02, Loss Eqns: 2.297e+00, Loss Aux: 2.600e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12771, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.435e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12772, It: 0, Loss Data: 8.617e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.628e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12773, It: 0, Loss Data: 9.579e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.813e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12774, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.767e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12775, It: 0, Loss Data: 8.539e-02, Loss Eqns: 2.446e+00, Loss Aux: 3.213e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12776, It: 0, Loss Data: 7.930e-02, Loss Eqns: 2.388e+00, Loss Aux: 3.329e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12777, It: 0, Loss Data: 9.278e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.430e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12778, It: 0, Loss Data: 9.204e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.470e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12779, It: 0, Loss Data: 8.836e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.502e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12780, It: 0, Loss Data: 9.040e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.031e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12781, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.030e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12782, It: 0, Loss Data: 8.293e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.687e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12783, It: 0, Loss Data: 7.693e-02, Loss Eqns: 2.468e+00, Loss Aux: 2.923e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12784, It: 0, Loss Data: 7.957e-02, Loss Eqns: 2.339e+00, Loss Aux: 2.435e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12785, It: 0, Loss Data: 7.234e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.203e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12786, It: 0, Loss Data: 8.633e-02, Loss Eqns: 2.375e+00, Loss Aux: 5.439e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12787, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.288e+00, Loss Aux: 5.893e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12788, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.292e+00, Loss Aux: 4.122e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12789, It: 0, Loss Data: 8.971e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.134e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12790, It: 0, Loss Data: 8.770e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.763e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12791, It: 0, Loss Data: 9.146e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.086e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12792, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.371e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12793, It: 0, Loss Data: 7.126e-02, Loss Eqns: 2.342e+00, Loss Aux: 2.709e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 12794, It: 0, Loss Data: 9.258e-02, Loss Eqns: 2.411e+00, Loss Aux: 2.769e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12795, It: 0, Loss Data: 9.728e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.397e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12796, It: 0, Loss Data: 8.010e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.363e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12797, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.211e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12798, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.192e+00, Loss Aux: 3.393e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12799, It: 0, Loss Data: 9.267e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.422e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12800, It: 0, Loss Data: 9.565e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.415e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12801, It: 0, Loss Data: 8.928e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.345e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12802, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.554e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12803, It: 0, Loss Data: 7.943e-02, Loss Eqns: 2.276e+00, Loss Aux: 3.099e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12804, It: 0, Loss Data: 9.120e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.612e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12805, It: 0, Loss Data: 9.352e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.363e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 12806, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.331e+00, Loss Aux: 4.226e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12807, It: 0, Loss Data: 9.818e-02, Loss Eqns: 2.354e+00, Loss Aux: 2.660e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 12808, It: 0, Loss Data: 9.775e-02, Loss Eqns: 2.326e+00, Loss Aux: 2.187e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12809, It: 0, Loss Data: 9.558e-02, Loss Eqns: 2.260e+00, Loss Aux: 2.840e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12810, It: 0, Loss Data: 9.953e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.121e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 12811, It: 0, Loss Data: 1.288e-01, Loss Eqns: 2.228e+00, Loss Aux: 4.416e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12812, It: 0, Loss Data: 8.425e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.785e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12813, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.336e+00, Loss Aux: 3.507e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12814, It: 0, Loss Data: 8.970e-02, Loss Eqns: 2.445e+00, Loss Aux: 4.209e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12815, It: 0, Loss Data: 8.097e-02, Loss Eqns: 2.386e+00, Loss Aux: 5.235e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12816, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.297e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12817, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.422e+00, Loss Aux: 4.154e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12818, It: 0, Loss Data: 8.545e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.591e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12819, It: 0, Loss Data: 1.192e-01, Loss Eqns: 3.034e+00, Loss Aux: 5.150e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12820, It: 0, Loss Data: 1.336e-01, Loss Eqns: 3.660e+00, Loss Aux: 3.035e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 12821, It: 0, Loss Data: 1.347e-01, Loss Eqns: 3.360e+00, Loss Aux: 2.690e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12822, It: 0, Loss Data: 9.746e-02, Loss Eqns: 3.300e+00, Loss Aux: 3.561e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12823, It: 0, Loss Data: 1.280e-01, Loss Eqns: 2.829e+00, Loss Aux: 3.457e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12824, It: 0, Loss Data: 1.177e-01, Loss Eqns: 3.150e+00, Loss Aux: 2.880e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12825, It: 0, Loss Data: 1.210e-01, Loss Eqns: 3.018e+00, Loss Aux: 3.090e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12826, It: 0, Loss Data: 1.631e-01, Loss Eqns: 5.683e+00, Loss Aux: 5.829e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12827, It: 0, Loss Data: 1.496e-01, Loss Eqns: 4.325e+00, Loss Aux: 4.911e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12828, It: 0, Loss Data: 1.919e-01, Loss Eqns: 5.349e+00, Loss Aux: 4.208e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12829, It: 0, Loss Data: 1.321e-01, Loss Eqns: 4.287e+00, Loss Aux: 5.574e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12830, It: 0, Loss Data: 1.532e-01, Loss Eqns: 4.766e+00, Loss Aux: 6.454e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12831, It: 0, Loss Data: 1.213e-01, Loss Eqns: 3.788e+00, Loss Aux: 3.439e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12832, It: 0, Loss Data: 1.687e-01, Loss Eqns: 3.556e+00, Loss Aux: 2.316e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 12833, It: 0, Loss Data: 1.817e-01, Loss Eqns: 3.488e+00, Loss Aux: 3.805e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12834, It: 0, Loss Data: 1.561e-01, Loss Eqns: 3.192e+00, Loss Aux: 6.522e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12835, It: 0, Loss Data: 1.476e-01, Loss Eqns: 3.321e+00, Loss Aux: 6.030e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12836, It: 0, Loss Data: 1.305e-01, Loss Eqns: 2.823e+00, Loss Aux: 4.015e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12837, It: 0, Loss Data: 1.689e-01, Loss Eqns: 2.981e+00, Loss Aux: 3.317e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12838, It: 0, Loss Data: 1.499e-01, Loss Eqns: 2.935e+00, Loss Aux: 3.234e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12839, It: 0, Loss Data: 1.557e-01, Loss Eqns: 2.612e+00, Loss Aux: 5.351e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 12840, It: 0, Loss Data: 1.455e-01, Loss Eqns: 2.570e+00, Loss Aux: 6.116e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12841, It: 0, Loss Data: 1.165e-01, Loss Eqns: 2.617e+00, Loss Aux: 5.451e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12842, It: 0, Loss Data: 1.449e-01, Loss Eqns: 2.633e+00, Loss Aux: 4.350e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12843, It: 0, Loss Data: 1.469e-01, Loss Eqns: 2.758e+00, Loss Aux: 4.181e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12844, It: 0, Loss Data: 1.456e-01, Loss Eqns: 2.580e+00, Loss Aux: 4.593e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12845, It: 0, Loss Data: 1.251e-01, Loss Eqns: 2.497e+00, Loss Aux: 4.472e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12846, It: 0, Loss Data: 1.077e-01, Loss Eqns: 2.688e+00, Loss Aux: 4.221e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12847, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.593e+00, Loss Aux: 3.796e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12848, It: 0, Loss Data: 1.369e-01, Loss Eqns: 2.585e+00, Loss Aux: 4.634e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12849, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.513e+00, Loss Aux: 5.516e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12850, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.449e+00, Loss Aux: 4.220e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12851, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.553e+00, Loss Aux: 3.458e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12852, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.403e+00, Loss Aux: 3.774e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12853, It: 0, Loss Data: 1.135e-01, Loss Eqns: 2.472e+00, Loss Aux: 5.011e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12854, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.465e+00, Loss Aux: 5.201e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12855, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.416e+00, Loss Aux: 4.489e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12856, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.546e+00, Loss Aux: 3.754e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12857, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.498e+00, Loss Aux: 4.142e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12858, It: 0, Loss Data: 9.962e-02, Loss Eqns: 2.530e+00, Loss Aux: 5.377e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12859, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.452e+00, Loss Aux: 5.805e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12860, It: 0, Loss Data: 9.124e-02, Loss Eqns: 2.484e+00, Loss Aux: 4.848e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12861, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.454e+00, Loss Aux: 3.865e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12862, It: 0, Loss Data: 9.531e-02, Loss Eqns: 2.423e+00, Loss Aux: 3.564e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12863, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.329e+00, Loss Aux: 3.965e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12864, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.347e+00, Loss Aux: 4.807e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12865, It: 0, Loss Data: 1.087e-01, Loss Eqns: 2.387e+00, Loss Aux: 5.197e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12866, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.084e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12867, It: 0, Loss Data: 1.116e-01, Loss Eqns: 2.401e+00, Loss Aux: 4.552e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12868, It: 0, Loss Data: 9.545e-02, Loss Eqns: 2.469e+00, Loss Aux: 3.615e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12869, It: 0, Loss Data: 1.037e-01, Loss Eqns: 2.544e+00, Loss Aux: 5.134e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12870, It: 0, Loss Data: 1.693e-01, Loss Eqns: 2.720e+00, Loss Aux: 2.938e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12871, It: 0, Loss Data: 9.248e-02, Loss Eqns: 2.483e+00, Loss Aux: 4.295e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12872, It: 0, Loss Data: 1.416e-01, Loss Eqns: 2.610e+00, Loss Aux: 7.597e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12873, It: 0, Loss Data: 1.244e-01, Loss Eqns: 2.544e+00, Loss Aux: 6.634e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12874, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.425e+00, Loss Aux: 3.592e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 12875, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.514e+00, Loss Aux: 3.711e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12876, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.378e+00, Loss Aux: 5.714e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12877, It: 0, Loss Data: 1.307e-01, Loss Eqns: 2.337e+00, Loss Aux: 6.846e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12878, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.455e+00, Loss Aux: 5.132e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 12879, It: 0, Loss Data: 1.113e-01, Loss Eqns: 2.401e+00, Loss Aux: 4.125e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12880, It: 0, Loss Data: 1.070e-01, Loss Eqns: 2.346e+00, Loss Aux: 3.986e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12881, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.348e+00, Loss Aux: 5.352e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12882, It: 0, Loss Data: 1.161e-01, Loss Eqns: 2.360e+00, Loss Aux: 6.015e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12883, It: 0, Loss Data: 8.590e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.791e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12884, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.070e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12885, It: 0, Loss Data: 9.672e-02, Loss Eqns: 2.336e+00, Loss Aux: 5.065e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 12886, It: 0, Loss Data: 9.840e-02, Loss Eqns: 2.347e+00, Loss Aux: 6.742e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 12887, It: 0, Loss Data: 9.882e-02, Loss Eqns: 2.292e+00, Loss Aux: 7.224e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12888, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.296e+00, Loss Aux: 5.410e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 12889, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.335e+00, Loss Aux: 3.987e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12890, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.688e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 12891, It: 0, Loss Data: 9.295e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.495e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12892, It: 0, Loss Data: 1.075e-01, Loss Eqns: 2.231e+00, Loss Aux: 5.687e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 12893, It: 0, Loss Data: 9.219e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.588e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 12894, It: 0, Loss Data: 9.916e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.940e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 12895, It: 0, Loss Data: 8.827e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.239e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 12896, It: 0, Loss Data: 9.957e-02, Loss Eqns: 2.474e+00, Loss Aux: 5.419e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12897, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.407e+00, Loss Aux: 5.957e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12898, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.978e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12899, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.282e+00, Loss Aux: 4.064e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12900, It: 0, Loss Data: 9.596e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.115e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12901, It: 0, Loss Data: 7.814e-02, Loss Eqns: 2.369e+00, Loss Aux: 5.368e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12902, It: 0, Loss Data: 1.094e-01, Loss Eqns: 2.319e+00, Loss Aux: 6.650e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 12903, It: 0, Loss Data: 9.784e-02, Loss Eqns: 2.408e+00, Loss Aux: 5.741e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 12904, It: 0, Loss Data: 9.583e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.206e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 12905, It: 0, Loss Data: 9.787e-02, Loss Eqns: 2.469e+00, Loss Aux: 3.788e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12906, It: 0, Loss Data: 8.134e-02, Loss Eqns: 2.482e+00, Loss Aux: 4.136e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 12907, It: 0, Loss Data: 9.053e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.303e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 12908, It: 0, Loss Data: 1.051e-01, Loss Eqns: 2.429e+00, Loss Aux: 4.156e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12909, It: 0, Loss Data: 9.459e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.139e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12910, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.398e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12911, It: 0, Loss Data: 9.921e-02, Loss Eqns: 2.347e+00, Loss Aux: 5.018e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 12912, It: 0, Loss Data: 9.148e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.676e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12913, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.342e+00, Loss Aux: 5.539e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12914, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.413e+00, Loss Aux: 5.466e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12915, It: 0, Loss Data: 8.083e-02, Loss Eqns: 2.359e+00, Loss Aux: 5.106e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12916, It: 0, Loss Data: 8.993e-02, Loss Eqns: 2.353e+00, Loss Aux: 5.033e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12917, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.401e+00, Loss Aux: 5.001e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12918, It: 0, Loss Data: 9.000e-02, Loss Eqns: 2.487e+00, Loss Aux: 4.581e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12919, It: 0, Loss Data: 8.292e-02, Loss Eqns: 2.447e+00, Loss Aux: 3.822e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12920, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.417e+00, Loss Aux: 3.751e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12921, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.437e+00, Loss Aux: 4.388e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12922, It: 0, Loss Data: 7.368e-02, Loss Eqns: 2.383e+00, Loss Aux: 5.161e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12923, It: 0, Loss Data: 9.812e-02, Loss Eqns: 2.390e+00, Loss Aux: 5.616e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12924, It: 0, Loss Data: 8.171e-02, Loss Eqns: 2.329e+00, Loss Aux: 5.654e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 12925, It: 0, Loss Data: 9.357e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.473e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 12926, It: 0, Loss Data: 9.394e-02, Loss Eqns: 2.394e+00, Loss Aux: 5.144e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12927, It: 0, Loss Data: 9.184e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.355e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 12928, It: 0, Loss Data: 9.591e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.646e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12929, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.317e+00, Loss Aux: 3.730e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12930, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.312e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 12931, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.319e+00, Loss Aux: 5.384e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12932, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.341e+00, Loss Aux: 5.817e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12933, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.401e+00, Loss Aux: 5.189e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 12934, It: 0, Loss Data: 9.974e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.484e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12935, It: 0, Loss Data: 9.766e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.105e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12936, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.345e+00, Loss Aux: 4.605e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 12937, It: 0, Loss Data: 8.501e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.896e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12938, It: 0, Loss Data: 7.493e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.806e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12939, It: 0, Loss Data: 8.207e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.426e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12940, It: 0, Loss Data: 8.532e-02, Loss Eqns: 2.521e+00, Loss Aux: 3.853e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12941, It: 0, Loss Data: 8.014e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.814e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12942, It: 0, Loss Data: 8.700e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.575e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12943, It: 0, Loss Data: 9.905e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.726e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12944, It: 0, Loss Data: 8.213e-02, Loss Eqns: 2.404e+00, Loss Aux: 4.290e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12945, It: 0, Loss Data: 9.162e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.240e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12946, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.420e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12947, It: 0, Loss Data: 9.688e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.550e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 12948, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.449e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 12949, It: 0, Loss Data: 8.729e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.876e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 12950, It: 0, Loss Data: 8.296e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.520e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 12951, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.363e+00, Loss Aux: 5.519e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12952, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.316e+00, Loss Aux: 5.036e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12953, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.340e+00, Loss Aux: 3.851e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 12954, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.313e+00, Loss Aux: 4.051e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12955, It: 0, Loss Data: 7.962e-02, Loss Eqns: 2.412e+00, Loss Aux: 5.285e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 12956, It: 0, Loss Data: 8.327e-02, Loss Eqns: 2.324e+00, Loss Aux: 5.562e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 12957, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.345e+00, Loss Aux: 4.222e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12958, It: 0, Loss Data: 9.132e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.122e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12959, It: 0, Loss Data: 9.373e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.172e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 12960, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.420e+00, Loss Aux: 4.455e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 12961, It: 0, Loss Data: 9.181e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.530e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12962, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.291e+00, Loss Aux: 5.250e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 12963, It: 0, Loss Data: 9.581e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.533e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 12964, It: 0, Loss Data: 8.852e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.376e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12965, It: 0, Loss Data: 9.450e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.709e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12966, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.335e+00, Loss Aux: 4.360e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12967, It: 0, Loss Data: 8.871e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.916e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 12968, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.039e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 12969, It: 0, Loss Data: 8.936e-02, Loss Eqns: 2.389e+00, Loss Aux: 5.035e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12970, It: 0, Loss Data: 8.371e-02, Loss Eqns: 2.334e+00, Loss Aux: 5.426e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 12971, It: 0, Loss Data: 8.093e-02, Loss Eqns: 2.391e+00, Loss Aux: 5.156e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 12972, It: 0, Loss Data: 8.812e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.761e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12973, It: 0, Loss Data: 7.732e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.808e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 12974, It: 0, Loss Data: 1.043e-01, Loss Eqns: 2.300e+00, Loss Aux: 4.514e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12975, It: 0, Loss Data: 8.585e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.215e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 12976, It: 0, Loss Data: 9.051e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.099e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12977, It: 0, Loss Data: 9.038e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.432e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 12978, It: 0, Loss Data: 8.360e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.983e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12979, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.851e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 12980, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.373e+00, Loss Aux: 4.513e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 12981, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.376e+00, Loss Aux: 4.114e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 12982, It: 0, Loss Data: 8.914e-02, Loss Eqns: 2.411e+00, Loss Aux: 4.268e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 12983, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.389e+00, Loss Aux: 4.472e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12984, It: 0, Loss Data: 7.642e-02, Loss Eqns: 2.407e+00, Loss Aux: 4.478e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 12985, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.625e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 12986, It: 0, Loss Data: 9.827e-02, Loss Eqns: 2.387e+00, Loss Aux: 5.172e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 12987, It: 0, Loss Data: 8.716e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.592e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12988, It: 0, Loss Data: 8.479e-02, Loss Eqns: 2.354e+00, Loss Aux: 5.362e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12989, It: 0, Loss Data: 9.851e-02, Loss Eqns: 2.479e+00, Loss Aux: 4.799e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 12990, It: 0, Loss Data: 8.637e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.888e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 12991, It: 0, Loss Data: 8.424e-02, Loss Eqns: 2.371e+00, Loss Aux: 5.423e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 12992, It: 0, Loss Data: 9.080e-02, Loss Eqns: 2.346e+00, Loss Aux: 5.131e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 12993, It: 0, Loss Data: 8.668e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.224e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 12994, It: 0, Loss Data: 9.770e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.854e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 12995, It: 0, Loss Data: 7.950e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.387e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 12996, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.328e+00, Loss Aux: 5.287e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12997, It: 0, Loss Data: 1.111e-01, Loss Eqns: 2.286e+00, Loss Aux: 5.499e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 12998, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.264e+00, Loss Aux: 4.282e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 12999, It: 0, Loss Data: 9.149e-02, Loss Eqns: 2.390e+00, Loss Aux: 3.674e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13000, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.638e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13001, It: 0, Loss Data: 9.726e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.118e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 13002, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.377e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13003, It: 0, Loss Data: 8.427e-02, Loss Eqns: 2.438e+00, Loss Aux: 4.203e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13004, It: 0, Loss Data: 7.996e-02, Loss Eqns: 2.450e+00, Loss Aux: 4.250e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13005, It: 0, Loss Data: 9.082e-02, Loss Eqns: 2.402e+00, Loss Aux: 4.266e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13006, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.705e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13007, It: 0, Loss Data: 8.919e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.751e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13008, It: 0, Loss Data: 7.090e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.503e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13009, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.223e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13010, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.404e+00, Loss Aux: 4.446e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13011, It: 0, Loss Data: 8.649e-02, Loss Eqns: 2.362e+00, Loss Aux: 5.242e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13012, It: 0, Loss Data: 7.739e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.426e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13013, It: 0, Loss Data: 7.895e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.643e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 13014, It: 0, Loss Data: 9.270e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.871e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13015, It: 0, Loss Data: 9.132e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.892e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13016, It: 0, Loss Data: 8.929e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.923e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13017, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.150e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13018, It: 0, Loss Data: 8.451e-02, Loss Eqns: 2.299e+00, Loss Aux: 5.051e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13019, It: 0, Loss Data: 9.412e-02, Loss Eqns: 2.304e+00, Loss Aux: 5.067e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13020, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.845e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13021, It: 0, Loss Data: 9.908e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.390e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 13022, It: 0, Loss Data: 9.286e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.315e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13023, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.346e+00, Loss Aux: 4.252e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13024, It: 0, Loss Data: 8.712e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.433e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13025, It: 0, Loss Data: 9.447e-02, Loss Eqns: 2.252e+00, Loss Aux: 3.374e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13026, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.900e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13027, It: 0, Loss Data: 9.129e-02, Loss Eqns: 2.454e+00, Loss Aux: 4.119e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13028, It: 0, Loss Data: 9.621e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.213e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13029, It: 0, Loss Data: 7.800e-02, Loss Eqns: 2.407e+00, Loss Aux: 4.686e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13030, It: 0, Loss Data: 7.884e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.984e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13031, It: 0, Loss Data: 9.068e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.412e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13032, It: 0, Loss Data: 8.364e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.854e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13033, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.392e+00, Loss Aux: 4.381e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13034, It: 0, Loss Data: 9.129e-02, Loss Eqns: 2.300e+00, Loss Aux: 5.321e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13035, It: 0, Loss Data: 8.322e-02, Loss Eqns: 2.317e+00, Loss Aux: 5.619e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13036, It: 0, Loss Data: 9.881e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.610e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13037, It: 0, Loss Data: 8.904e-02, Loss Eqns: 2.407e+00, Loss Aux: 3.483e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13038, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.858e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13039, It: 0, Loss Data: 7.626e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.347e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13040, It: 0, Loss Data: 7.909e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.527e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13041, It: 0, Loss Data: 8.704e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.300e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13042, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.352e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13043, It: 0, Loss Data: 7.675e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.677e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13044, It: 0, Loss Data: 9.067e-02, Loss Eqns: 2.266e+00, Loss Aux: 5.248e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13045, It: 0, Loss Data: 7.537e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.852e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13046, It: 0, Loss Data: 9.890e-02, Loss Eqns: 2.230e+00, Loss Aux: 3.841e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13047, It: 0, Loss Data: 8.398e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.699e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 13048, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.235e+00, Loss Aux: 4.528e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13049, It: 0, Loss Data: 9.578e-02, Loss Eqns: 2.361e+00, Loss Aux: 5.189e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 13050, It: 0, Loss Data: 9.337e-02, Loss Eqns: 2.283e+00, Loss Aux: 5.199e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13051, It: 0, Loss Data: 8.070e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.478e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13052, It: 0, Loss Data: 9.164e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.125e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13053, It: 0, Loss Data: 8.922e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.108e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13054, It: 0, Loss Data: 9.120e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.706e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13055, It: 0, Loss Data: 8.953e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.484e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13056, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.409e+00, Loss Aux: 3.824e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13057, It: 0, Loss Data: 7.758e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.595e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13058, It: 0, Loss Data: 7.930e-02, Loss Eqns: 2.386e+00, Loss Aux: 5.387e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13059, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.363e+00, Loss Aux: 5.396e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13060, It: 0, Loss Data: 8.156e-02, Loss Eqns: 2.345e+00, Loss Aux: 5.393e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13061, It: 0, Loss Data: 7.675e-02, Loss Eqns: 2.431e+00, Loss Aux: 5.521e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13062, It: 0, Loss Data: 8.972e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.865e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13063, It: 0, Loss Data: 7.306e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.146e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13064, It: 0, Loss Data: 7.976e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.858e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13065, It: 0, Loss Data: 8.841e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.804e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13066, It: 0, Loss Data: 9.439e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.793e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13067, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.041e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13068, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.215e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13069, It: 0, Loss Data: 9.743e-02, Loss Eqns: 2.346e+00, Loss Aux: 5.084e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13070, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.661e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13071, It: 0, Loss Data: 8.793e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.845e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13072, It: 0, Loss Data: 8.841e-02, Loss Eqns: 2.258e+00, Loss Aux: 3.912e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13073, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.035e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13074, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.175e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13075, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.293e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13076, It: 0, Loss Data: 8.211e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.367e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13077, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.815e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13078, It: 0, Loss Data: 7.779e-02, Loss Eqns: 2.271e+00, Loss Aux: 5.045e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13079, It: 0, Loss Data: 8.098e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.252e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13080, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.228e-02, Time: 0.224, Learning Rate: 1.0e-03\n",
      "Epoch: 13081, It: 0, Loss Data: 8.200e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.846e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13082, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.218e+00, Loss Aux: 4.247e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13083, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.215e+00, Loss Aux: 3.805e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 13084, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.225e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13085, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.543e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13086, It: 0, Loss Data: 9.983e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.206e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13087, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.324e+00, Loss Aux: 3.140e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13088, It: 0, Loss Data: 9.104e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.139e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13089, It: 0, Loss Data: 9.357e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.890e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13090, It: 0, Loss Data: 8.197e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.565e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13091, It: 0, Loss Data: 8.006e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.468e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13092, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.002e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13093, It: 0, Loss Data: 8.392e-02, Loss Eqns: 2.437e+00, Loss Aux: 3.757e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13094, It: 0, Loss Data: 9.575e-02, Loss Eqns: 2.420e+00, Loss Aux: 3.666e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13095, It: 0, Loss Data: 8.214e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.831e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13096, It: 0, Loss Data: 7.584e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.781e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13097, It: 0, Loss Data: 8.238e-02, Loss Eqns: 2.347e+00, Loss Aux: 5.467e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13098, It: 0, Loss Data: 8.545e-02, Loss Eqns: 2.340e+00, Loss Aux: 5.134e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13099, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.301e+00, Loss Aux: 4.333e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13100, It: 0, Loss Data: 9.952e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.541e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13101, It: 0, Loss Data: 8.528e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.226e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13102, It: 0, Loss Data: 8.376e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.711e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13103, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.851e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13104, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.715e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13105, It: 0, Loss Data: 9.486e-02, Loss Eqns: 2.318e+00, Loss Aux: 5.766e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13106, It: 0, Loss Data: 8.985e-02, Loss Eqns: 2.303e+00, Loss Aux: 5.368e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13107, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.565e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13108, It: 0, Loss Data: 8.386e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.913e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13109, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.775e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13110, It: 0, Loss Data: 9.113e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.103e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13111, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.570e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13112, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.304e+00, Loss Aux: 5.013e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13113, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.709e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 13114, It: 0, Loss Data: 9.483e-02, Loss Eqns: 2.407e+00, Loss Aux: 4.156e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13115, It: 0, Loss Data: 8.874e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.950e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13116, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.342e+00, Loss Aux: 4.498e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13117, It: 0, Loss Data: 8.845e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.559e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13118, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.133e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13119, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.274e+00, Loss Aux: 4.228e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13120, It: 0, Loss Data: 9.089e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.272e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13121, It: 0, Loss Data: 6.913e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.183e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13122, It: 0, Loss Data: 8.220e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.260e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13123, It: 0, Loss Data: 7.896e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.486e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13124, It: 0, Loss Data: 9.857e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.628e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13125, It: 0, Loss Data: 8.509e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.639e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13126, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.858e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13127, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.442e+00, Loss Aux: 4.423e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 13128, It: 0, Loss Data: 7.510e-02, Loss Eqns: 2.269e+00, Loss Aux: 3.943e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13129, It: 0, Loss Data: 9.529e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.914e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13130, It: 0, Loss Data: 8.311e-02, Loss Eqns: 2.421e+00, Loss Aux: 4.074e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13131, It: 0, Loss Data: 9.878e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.430e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13132, It: 0, Loss Data: 9.339e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.287e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13133, It: 0, Loss Data: 7.893e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.380e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13134, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.336e+00, Loss Aux: 4.492e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13135, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.303e+00, Loss Aux: 4.615e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13136, It: 0, Loss Data: 8.639e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.339e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13137, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.766e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 13138, It: 0, Loss Data: 8.824e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.860e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13139, It: 0, Loss Data: 7.843e-02, Loss Eqns: 2.438e+00, Loss Aux: 4.259e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13140, It: 0, Loss Data: 7.782e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.260e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13141, It: 0, Loss Data: 7.715e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.089e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13142, It: 0, Loss Data: 8.488e-02, Loss Eqns: 2.395e+00, Loss Aux: 3.796e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13143, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.437e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13144, It: 0, Loss Data: 9.395e-02, Loss Eqns: 2.451e+00, Loss Aux: 5.551e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13145, It: 0, Loss Data: 8.439e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.928e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13146, It: 0, Loss Data: 7.576e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.753e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13147, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.325e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13148, It: 0, Loss Data: 8.337e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.037e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13149, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.558e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 13150, It: 0, Loss Data: 8.310e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.694e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13151, It: 0, Loss Data: 9.441e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.669e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13152, It: 0, Loss Data: 8.324e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.613e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13153, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.729e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13154, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.297e+00, Loss Aux: 4.860e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13155, It: 0, Loss Data: 9.090e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.150e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13156, It: 0, Loss Data: 8.968e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.527e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13157, It: 0, Loss Data: 8.271e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.840e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13158, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.945e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13159, It: 0, Loss Data: 9.306e-02, Loss Eqns: 2.295e+00, Loss Aux: 5.411e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13160, It: 0, Loss Data: 8.834e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.306e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13161, It: 0, Loss Data: 8.181e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.641e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13162, It: 0, Loss Data: 9.881e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.347e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13163, It: 0, Loss Data: 9.492e-02, Loss Eqns: 2.293e+00, Loss Aux: 5.144e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 13164, It: 0, Loss Data: 8.405e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.049e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13165, It: 0, Loss Data: 9.044e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.186e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13166, It: 0, Loss Data: 8.479e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.415e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13167, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.448e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13168, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.706e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13169, It: 0, Loss Data: 9.645e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.847e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13170, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.436e+00, Loss Aux: 4.256e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13171, It: 0, Loss Data: 7.669e-02, Loss Eqns: 2.375e+00, Loss Aux: 4.805e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13172, It: 0, Loss Data: 7.523e-02, Loss Eqns: 2.307e+00, Loss Aux: 5.188e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13173, It: 0, Loss Data: 9.085e-02, Loss Eqns: 2.286e+00, Loss Aux: 5.271e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13174, It: 0, Loss Data: 9.062e-02, Loss Eqns: 2.430e+00, Loss Aux: 4.748e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13175, It: 0, Loss Data: 8.756e-02, Loss Eqns: 2.431e+00, Loss Aux: 4.045e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13176, It: 0, Loss Data: 9.328e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.391e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13177, It: 0, Loss Data: 8.103e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.267e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13178, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.387e+00, Loss Aux: 3.863e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13179, It: 0, Loss Data: 9.626e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.332e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13180, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.775e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13181, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.430e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13182, It: 0, Loss Data: 9.369e-02, Loss Eqns: 2.403e+00, Loss Aux: 4.073e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13183, It: 0, Loss Data: 8.713e-02, Loss Eqns: 2.405e+00, Loss Aux: 5.211e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13184, It: 0, Loss Data: 8.096e-02, Loss Eqns: 2.410e+00, Loss Aux: 5.066e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 13185, It: 0, Loss Data: 8.317e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.186e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13186, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.419e+00, Loss Aux: 4.405e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13187, It: 0, Loss Data: 7.549e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.864e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13188, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.380e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13189, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.428e+00, Loss Aux: 3.815e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13190, It: 0, Loss Data: 7.604e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.826e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13191, It: 0, Loss Data: 8.087e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.334e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13192, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.637e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 13193, It: 0, Loss Data: 9.562e-02, Loss Eqns: 2.388e+00, Loss Aux: 4.405e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13194, It: 0, Loss Data: 9.315e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.969e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13195, It: 0, Loss Data: 9.892e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.304e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13196, It: 0, Loss Data: 8.844e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.681e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13197, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.611e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13198, It: 0, Loss Data: 8.903e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.115e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13199, It: 0, Loss Data: 9.603e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.666e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13200, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.366e+00, Loss Aux: 3.637e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13201, It: 0, Loss Data: 8.686e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.711e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13202, It: 0, Loss Data: 9.551e-02, Loss Eqns: 2.426e+00, Loss Aux: 4.340e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13203, It: 0, Loss Data: 8.613e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.656e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13204, It: 0, Loss Data: 8.438e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.658e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13205, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.489e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13206, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.320e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13207, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.409e+00, Loss Aux: 4.387e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13208, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.431e+00, Loss Aux: 4.641e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13209, It: 0, Loss Data: 8.073e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.929e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13210, It: 0, Loss Data: 7.557e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.416e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13211, It: 0, Loss Data: 8.369e-02, Loss Eqns: 2.306e+00, Loss Aux: 5.685e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13212, It: 0, Loss Data: 9.803e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.932e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13213, It: 0, Loss Data: 8.244e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.271e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13214, It: 0, Loss Data: 7.718e-02, Loss Eqns: 2.329e+00, Loss Aux: 2.873e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13215, It: 0, Loss Data: 7.676e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.127e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13216, It: 0, Loss Data: 8.346e-02, Loss Eqns: 2.248e+00, Loss Aux: 5.578e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13217, It: 0, Loss Data: 9.492e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.878e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13218, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.183e+00, Loss Aux: 4.218e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13219, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.254e+00, Loss Aux: 4.018e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13220, It: 0, Loss Data: 9.159e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.362e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13221, It: 0, Loss Data: 8.783e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.482e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13222, It: 0, Loss Data: 8.646e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.167e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13223, It: 0, Loss Data: 8.547e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.078e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13224, It: 0, Loss Data: 9.127e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.336e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13225, It: 0, Loss Data: 7.430e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.480e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13226, It: 0, Loss Data: 8.048e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.568e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13227, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.738e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13228, It: 0, Loss Data: 9.682e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.918e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13229, It: 0, Loss Data: 9.010e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.972e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13230, It: 0, Loss Data: 8.409e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.602e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13231, It: 0, Loss Data: 9.045e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.689e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13232, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.075e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13233, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.274e+00, Loss Aux: 2.854e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13234, It: 0, Loss Data: 8.220e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.612e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13235, It: 0, Loss Data: 8.472e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.987e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13236, It: 0, Loss Data: 8.258e-02, Loss Eqns: 2.333e+00, Loss Aux: 5.687e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13237, It: 0, Loss Data: 7.743e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.973e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13238, It: 0, Loss Data: 8.940e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.228e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 13239, It: 0, Loss Data: 1.561e-01, Loss Eqns: 3.038e+00, Loss Aux: 6.957e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13240, It: 0, Loss Data: 3.151e-01, Loss Eqns: 4.084e+00, Loss Aux: 2.897e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13241, It: 0, Loss Data: 1.726e-01, Loss Eqns: 3.303e+00, Loss Aux: 5.802e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13242, It: 0, Loss Data: 1.967e-01, Loss Eqns: 3.083e+00, Loss Aux: 1.453e-01, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13243, It: 0, Loss Data: 2.017e-01, Loss Eqns: 2.927e+00, Loss Aux: 1.249e-01, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13244, It: 0, Loss Data: 1.271e-01, Loss Eqns: 2.508e+00, Loss Aux: 6.867e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 13245, It: 0, Loss Data: 2.046e-01, Loss Eqns: 3.077e+00, Loss Aux: 4.477e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13246, It: 0, Loss Data: 1.225e-01, Loss Eqns: 2.484e+00, Loss Aux: 3.840e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13247, It: 0, Loss Data: 1.832e-01, Loss Eqns: 2.803e+00, Loss Aux: 5.625e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 13248, It: 0, Loss Data: 1.431e-01, Loss Eqns: 2.539e+00, Loss Aux: 4.661e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13249, It: 0, Loss Data: 1.524e-01, Loss Eqns: 2.656e+00, Loss Aux: 3.353e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13250, It: 0, Loss Data: 1.501e-01, Loss Eqns: 2.575e+00, Loss Aux: 3.167e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13251, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.256e+00, Loss Aux: 5.320e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13252, It: 0, Loss Data: 1.608e-01, Loss Eqns: 2.307e+00, Loss Aux: 8.919e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13253, It: 0, Loss Data: 1.338e-01, Loss Eqns: 2.404e+00, Loss Aux: 8.593e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13254, It: 0, Loss Data: 1.347e-01, Loss Eqns: 2.253e+00, Loss Aux: 6.863e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13255, It: 0, Loss Data: 1.402e-01, Loss Eqns: 2.281e+00, Loss Aux: 5.285e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13256, It: 0, Loss Data: 1.179e-01, Loss Eqns: 2.283e+00, Loss Aux: 5.023e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13257, It: 0, Loss Data: 1.270e-01, Loss Eqns: 2.270e+00, Loss Aux: 5.216e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13258, It: 0, Loss Data: 1.292e-01, Loss Eqns: 2.400e+00, Loss Aux: 4.762e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13259, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.396e+00, Loss Aux: 3.880e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13260, It: 0, Loss Data: 1.039e-01, Loss Eqns: 2.447e+00, Loss Aux: 3.217e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13261, It: 0, Loss Data: 9.503e-02, Loss Eqns: 2.490e+00, Loss Aux: 4.322e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13262, It: 0, Loss Data: 9.853e-02, Loss Eqns: 2.494e+00, Loss Aux: 6.368e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13263, It: 0, Loss Data: 7.635e-02, Loss Eqns: 2.410e+00, Loss Aux: 7.201e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13264, It: 0, Loss Data: 9.400e-02, Loss Eqns: 2.382e+00, Loss Aux: 6.788e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13265, It: 0, Loss Data: 9.263e-02, Loss Eqns: 2.475e+00, Loss Aux: 6.191e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 13266, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.391e+00, Loss Aux: 6.001e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13267, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.363e+00, Loss Aux: 5.768e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13268, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.394e+00, Loss Aux: 5.062e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13269, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.446e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13270, It: 0, Loss Data: 8.382e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.199e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13271, It: 0, Loss Data: 1.041e-01, Loss Eqns: 2.383e+00, Loss Aux: 4.187e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13272, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.566e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13273, It: 0, Loss Data: 9.646e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.848e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13274, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.379e+00, Loss Aux: 5.318e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13275, It: 0, Loss Data: 9.904e-02, Loss Eqns: 2.330e+00, Loss Aux: 5.806e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13276, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.912e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13277, It: 0, Loss Data: 9.789e-02, Loss Eqns: 2.365e+00, Loss Aux: 5.964e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13278, It: 0, Loss Data: 9.558e-02, Loss Eqns: 2.318e+00, Loss Aux: 5.569e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13279, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.309e+00, Loss Aux: 5.512e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13280, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.292e+00, Loss Aux: 5.015e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13281, It: 0, Loss Data: 9.638e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.143e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13282, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.337e+00, Loss Aux: 3.924e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13283, It: 0, Loss Data: 8.471e-02, Loss Eqns: 2.387e+00, Loss Aux: 4.149e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13284, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.285e+00, Loss Aux: 4.929e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13285, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.322e+00, Loss Aux: 5.242e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13286, It: 0, Loss Data: 7.842e-02, Loss Eqns: 2.260e+00, Loss Aux: 5.090e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13287, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.815e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13288, It: 0, Loss Data: 9.732e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.888e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13289, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.977e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13290, It: 0, Loss Data: 9.697e-02, Loss Eqns: 2.412e+00, Loss Aux: 5.077e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13291, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.992e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13292, It: 0, Loss Data: 9.311e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.949e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13293, It: 0, Loss Data: 9.585e-02, Loss Eqns: 2.406e+00, Loss Aux: 4.758e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13294, It: 0, Loss Data: 8.269e-02, Loss Eqns: 2.387e+00, Loss Aux: 4.462e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13295, It: 0, Loss Data: 7.760e-02, Loss Eqns: 2.444e+00, Loss Aux: 4.338e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13296, It: 0, Loss Data: 8.093e-02, Loss Eqns: 2.398e+00, Loss Aux: 4.472e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13297, It: 0, Loss Data: 9.898e-02, Loss Eqns: 2.436e+00, Loss Aux: 4.177e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13298, It: 0, Loss Data: 9.220e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.414e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13299, It: 0, Loss Data: 9.046e-02, Loss Eqns: 2.387e+00, Loss Aux: 5.545e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13300, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.379e+00, Loss Aux: 6.034e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13301, It: 0, Loss Data: 7.093e-02, Loss Eqns: 2.384e+00, Loss Aux: 5.579e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13302, It: 0, Loss Data: 8.439e-02, Loss Eqns: 2.444e+00, Loss Aux: 4.714e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13303, It: 0, Loss Data: 9.939e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.854e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13304, It: 0, Loss Data: 8.459e-02, Loss Eqns: 2.444e+00, Loss Aux: 4.645e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13305, It: 0, Loss Data: 9.667e-02, Loss Eqns: 2.446e+00, Loss Aux: 4.926e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13306, It: 0, Loss Data: 9.175e-02, Loss Eqns: 2.384e+00, Loss Aux: 4.114e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13307, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.456e+00, Loss Aux: 4.178e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13308, It: 0, Loss Data: 9.400e-02, Loss Eqns: 2.218e+00, Loss Aux: 4.785e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13309, It: 0, Loss Data: 9.234e-02, Loss Eqns: 2.371e+00, Loss Aux: 5.497e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13310, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.332e+00, Loss Aux: 4.980e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13311, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.381e+00, Loss Aux: 3.904e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13312, It: 0, Loss Data: 8.482e-02, Loss Eqns: 2.397e+00, Loss Aux: 3.890e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13313, It: 0, Loss Data: 9.018e-02, Loss Eqns: 2.430e+00, Loss Aux: 4.778e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13314, It: 0, Loss Data: 7.870e-02, Loss Eqns: 2.401e+00, Loss Aux: 5.637e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13315, It: 0, Loss Data: 9.508e-02, Loss Eqns: 2.307e+00, Loss Aux: 5.493e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13316, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.346e+00, Loss Aux: 4.862e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13317, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.318e+00, Loss Aux: 4.774e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 13318, It: 0, Loss Data: 8.227e-02, Loss Eqns: 2.413e+00, Loss Aux: 4.842e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13319, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.335e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13320, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.398e+00, Loss Aux: 4.081e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13321, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.410e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13322, It: 0, Loss Data: 9.894e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.028e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13323, It: 0, Loss Data: 8.409e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.846e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13324, It: 0, Loss Data: 1.103e-01, Loss Eqns: 2.346e+00, Loss Aux: 4.418e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13325, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.276e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13326, It: 0, Loss Data: 8.709e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.379e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13327, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.413e+00, Loss Aux: 4.544e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13328, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.918e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13329, It: 0, Loss Data: 8.721e-02, Loss Eqns: 2.328e+00, Loss Aux: 5.473e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13330, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.339e+00, Loss Aux: 5.904e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13331, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.392e+00, Loss Aux: 5.206e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13332, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.452e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13333, It: 0, Loss Data: 8.311e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.043e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13334, It: 0, Loss Data: 8.223e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.496e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13335, It: 0, Loss Data: 8.410e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.990e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13336, It: 0, Loss Data: 1.020e-01, Loss Eqns: 2.318e+00, Loss Aux: 4.915e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13337, It: 0, Loss Data: 9.556e-02, Loss Eqns: 2.174e+00, Loss Aux: 4.362e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13338, It: 0, Loss Data: 9.483e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.167e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13339, It: 0, Loss Data: 9.053e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.451e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13340, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.833e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13341, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.945e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13342, It: 0, Loss Data: 7.515e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.043e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13343, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.347e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13344, It: 0, Loss Data: 6.837e-02, Loss Eqns: 2.303e+00, Loss Aux: 5.593e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13345, It: 0, Loss Data: 9.520e-02, Loss Eqns: 2.311e+00, Loss Aux: 5.515e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13346, It: 0, Loss Data: 9.044e-02, Loss Eqns: 2.349e+00, Loss Aux: 5.135e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13347, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.546e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13348, It: 0, Loss Data: 1.199e-01, Loss Eqns: 2.378e+00, Loss Aux: 3.739e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13349, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.533e+00, Loss Aux: 4.800e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13350, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.517e+00, Loss Aux: 4.613e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13351, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.417e+00, Loss Aux: 3.682e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13352, It: 0, Loss Data: 1.082e-01, Loss Eqns: 2.392e+00, Loss Aux: 3.975e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13353, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.315e+00, Loss Aux: 5.409e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13354, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.506e+00, Loss Aux: 6.626e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13355, It: 0, Loss Data: 9.042e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.987e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13356, It: 0, Loss Data: 1.264e-01, Loss Eqns: 2.409e+00, Loss Aux: 3.911e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13357, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.048e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13358, It: 0, Loss Data: 1.121e-01, Loss Eqns: 2.336e+00, Loss Aux: 5.733e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13359, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.308e+00, Loss Aux: 6.277e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13360, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.264e+00, Loss Aux: 5.037e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13361, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.249e+00, Loss Aux: 3.861e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13362, It: 0, Loss Data: 9.521e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.574e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13363, It: 0, Loss Data: 1.114e-01, Loss Eqns: 2.439e+00, Loss Aux: 4.089e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13364, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.370e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13365, It: 0, Loss Data: 9.456e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.411e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13366, It: 0, Loss Data: 8.854e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.443e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13367, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.428e+00, Loss Aux: 4.722e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13368, It: 0, Loss Data: 9.195e-02, Loss Eqns: 2.469e+00, Loss Aux: 4.909e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13369, It: 0, Loss Data: 7.900e-02, Loss Eqns: 2.339e+00, Loss Aux: 5.128e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13370, It: 0, Loss Data: 9.133e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.958e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13371, It: 0, Loss Data: 9.188e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.876e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13372, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.462e+00, Loss Aux: 4.759e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13373, It: 0, Loss Data: 9.689e-02, Loss Eqns: 2.326e+00, Loss Aux: 5.025e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13374, It: 0, Loss Data: 8.744e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.782e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13375, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.645e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13376, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.347e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13377, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.879e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13378, It: 0, Loss Data: 9.913e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.724e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13379, It: 0, Loss Data: 8.630e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.544e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13380, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.368e+00, Loss Aux: 5.359e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13381, It: 0, Loss Data: 8.156e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.230e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 13382, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.404e+00, Loss Aux: 4.675e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13383, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.616e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13384, It: 0, Loss Data: 8.382e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.818e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13385, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.907e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13386, It: 0, Loss Data: 8.601e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.723e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13387, It: 0, Loss Data: 8.745e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.206e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13388, It: 0, Loss Data: 8.928e-02, Loss Eqns: 2.463e+00, Loss Aux: 4.040e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13389, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.410e+00, Loss Aux: 4.369e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13390, It: 0, Loss Data: 8.080e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.698e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13391, It: 0, Loss Data: 8.330e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.741e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13392, It: 0, Loss Data: 7.694e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.605e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13393, It: 0, Loss Data: 7.784e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.439e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13394, It: 0, Loss Data: 9.236e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.578e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13395, It: 0, Loss Data: 8.903e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.979e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13396, It: 0, Loss Data: 7.742e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.727e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13397, It: 0, Loss Data: 9.709e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.317e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13398, It: 0, Loss Data: 9.575e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.061e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13399, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.143e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 13400, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.484e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13401, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.329e+00, Loss Aux: 4.615e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13402, It: 0, Loss Data: 7.750e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.904e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13403, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.935e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13404, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.323e+00, Loss Aux: 4.745e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13405, It: 0, Loss Data: 9.158e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.611e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13406, It: 0, Loss Data: 9.326e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.844e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13407, It: 0, Loss Data: 8.956e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.964e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13408, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.725e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13409, It: 0, Loss Data: 8.108e-02, Loss Eqns: 2.416e+00, Loss Aux: 4.479e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13410, It: 0, Loss Data: 9.336e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.666e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13411, It: 0, Loss Data: 7.765e-02, Loss Eqns: 2.430e+00, Loss Aux: 4.923e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13412, It: 0, Loss Data: 8.017e-02, Loss Eqns: 2.406e+00, Loss Aux: 5.120e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 13413, It: 0, Loss Data: 9.517e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.587e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13414, It: 0, Loss Data: 7.771e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.850e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13415, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.627e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13416, It: 0, Loss Data: 8.714e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.017e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13417, It: 0, Loss Data: 8.967e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.515e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13418, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.501e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13419, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.441e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13420, It: 0, Loss Data: 8.660e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.330e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13421, It: 0, Loss Data: 7.742e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.636e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13422, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.755e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13423, It: 0, Loss Data: 9.692e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.639e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13424, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.412e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13425, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.741e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13426, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.815e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13427, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.791e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13428, It: 0, Loss Data: 8.555e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.675e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 13429, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.876e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13430, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.280e+00, Loss Aux: 4.622e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13431, It: 0, Loss Data: 8.305e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.882e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13432, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.643e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 13433, It: 0, Loss Data: 8.116e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.034e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 13434, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.645e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13435, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.713e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13436, It: 0, Loss Data: 7.026e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.149e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13437, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.378e+00, Loss Aux: 3.988e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13438, It: 0, Loss Data: 9.068e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.193e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13439, It: 0, Loss Data: 9.605e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.691e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13440, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.334e+00, Loss Aux: 5.118e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13441, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.742e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13442, It: 0, Loss Data: 7.655e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.074e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13443, It: 0, Loss Data: 9.533e-02, Loss Eqns: 2.437e+00, Loss Aux: 3.809e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13444, It: 0, Loss Data: 8.091e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.380e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13445, It: 0, Loss Data: 9.353e-02, Loss Eqns: 2.439e+00, Loss Aux: 5.204e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13446, It: 0, Loss Data: 8.015e-02, Loss Eqns: 2.446e+00, Loss Aux: 4.877e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13447, It: 0, Loss Data: 8.114e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.349e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13448, It: 0, Loss Data: 8.157e-02, Loss Eqns: 2.435e+00, Loss Aux: 4.194e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13449, It: 0, Loss Data: 9.577e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.382e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 13450, It: 0, Loss Data: 8.754e-02, Loss Eqns: 2.464e+00, Loss Aux: 4.691e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13451, It: 0, Loss Data: 8.197e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.272e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13452, It: 0, Loss Data: 7.960e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.245e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13453, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.372e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13454, It: 0, Loss Data: 8.197e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.773e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13455, It: 0, Loss Data: 7.846e-02, Loss Eqns: 2.283e+00, Loss Aux: 5.821e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13456, It: 0, Loss Data: 9.966e-02, Loss Eqns: 2.338e+00, Loss Aux: 5.554e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13457, It: 0, Loss Data: 8.838e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.244e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13458, It: 0, Loss Data: 9.898e-02, Loss Eqns: 2.242e+00, Loss Aux: 3.797e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13459, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.111e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13460, It: 0, Loss Data: 8.315e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.225e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13461, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.371e+00, Loss Aux: 3.750e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13462, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.333e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13463, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.810e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13464, It: 0, Loss Data: 9.637e-02, Loss Eqns: 2.337e+00, Loss Aux: 5.157e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13465, It: 0, Loss Data: 8.304e-02, Loss Eqns: 2.343e+00, Loss Aux: 5.911e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13466, It: 0, Loss Data: 8.169e-02, Loss Eqns: 2.366e+00, Loss Aux: 5.528e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13467, It: 0, Loss Data: 8.215e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.864e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 13468, It: 0, Loss Data: 1.031e-01, Loss Eqns: 2.274e+00, Loss Aux: 4.417e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13469, It: 0, Loss Data: 7.991e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.328e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13470, It: 0, Loss Data: 8.948e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.002e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13471, It: 0, Loss Data: 1.065e-01, Loss Eqns: 2.282e+00, Loss Aux: 3.626e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13472, It: 0, Loss Data: 7.851e-02, Loss Eqns: 2.265e+00, Loss Aux: 3.416e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13473, It: 0, Loss Data: 9.217e-02, Loss Eqns: 2.252e+00, Loss Aux: 3.483e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13474, It: 0, Loss Data: 8.730e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.034e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 13475, It: 0, Loss Data: 8.390e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.769e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13476, It: 0, Loss Data: 9.356e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.959e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13477, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.478e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13478, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.172e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13479, It: 0, Loss Data: 7.546e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.376e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13480, It: 0, Loss Data: 8.529e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.662e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13481, It: 0, Loss Data: 8.577e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.541e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13482, It: 0, Loss Data: 6.600e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.073e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13483, It: 0, Loss Data: 8.138e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.064e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 13484, It: 0, Loss Data: 9.391e-02, Loss Eqns: 2.178e+00, Loss Aux: 4.665e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13485, It: 0, Loss Data: 7.839e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.755e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13486, It: 0, Loss Data: 8.903e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.030e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13487, It: 0, Loss Data: 9.095e-02, Loss Eqns: 2.226e+00, Loss Aux: 3.753e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13488, It: 0, Loss Data: 9.041e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.929e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13489, It: 0, Loss Data: 8.212e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.988e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13490, It: 0, Loss Data: 9.189e-02, Loss Eqns: 2.174e+00, Loss Aux: 5.513e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13491, It: 0, Loss Data: 9.674e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.543e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13492, It: 0, Loss Data: 9.710e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.451e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13493, It: 0, Loss Data: 1.142e-01, Loss Eqns: 2.287e+00, Loss Aux: 3.652e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 13494, It: 0, Loss Data: 9.172e-02, Loss Eqns: 2.351e+00, Loss Aux: 5.182e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13495, It: 0, Loss Data: 8.528e-02, Loss Eqns: 2.294e+00, Loss Aux: 5.632e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13496, It: 0, Loss Data: 8.213e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.698e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13497, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.212e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13498, It: 0, Loss Data: 9.002e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.674e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13499, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.929e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13500, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.371e+00, Loss Aux: 5.099e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13501, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.695e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13502, It: 0, Loss Data: 8.634e-02, Loss Eqns: 2.386e+00, Loss Aux: 4.225e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13503, It: 0, Loss Data: 8.619e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.923e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13504, It: 0, Loss Data: 8.313e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.783e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13505, It: 0, Loss Data: 1.012e-01, Loss Eqns: 2.320e+00, Loss Aux: 3.642e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13506, It: 0, Loss Data: 7.765e-02, Loss Eqns: 2.418e+00, Loss Aux: 3.910e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13507, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.126e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13508, It: 0, Loss Data: 7.925e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.713e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13509, It: 0, Loss Data: 7.996e-02, Loss Eqns: 2.350e+00, Loss Aux: 5.416e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13510, It: 0, Loss Data: 9.010e-02, Loss Eqns: 2.367e+00, Loss Aux: 5.388e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13511, It: 0, Loss Data: 8.528e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.944e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13512, It: 0, Loss Data: 8.573e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.707e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13513, It: 0, Loss Data: 9.928e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.430e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13514, It: 0, Loss Data: 8.756e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.498e-02, Time: 0.144, Learning Rate: 1.0e-03\n",
      "Epoch: 13515, It: 0, Loss Data: 8.991e-02, Loss Eqns: 2.485e+00, Loss Aux: 4.347e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13516, It: 0, Loss Data: 8.347e-02, Loss Eqns: 2.430e+00, Loss Aux: 3.989e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13517, It: 0, Loss Data: 8.990e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.744e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13518, It: 0, Loss Data: 8.106e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.486e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13519, It: 0, Loss Data: 8.521e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.578e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13520, It: 0, Loss Data: 8.704e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.160e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13521, It: 0, Loss Data: 9.193e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.812e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 13522, It: 0, Loss Data: 9.177e-02, Loss Eqns: 2.449e+00, Loss Aux: 4.779e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13523, It: 0, Loss Data: 9.013e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.582e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 13524, It: 0, Loss Data: 7.855e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.323e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13525, It: 0, Loss Data: 9.298e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.312e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13526, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.296e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13527, It: 0, Loss Data: 9.629e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.321e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13528, It: 0, Loss Data: 8.162e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.612e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13529, It: 0, Loss Data: 8.446e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.769e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13530, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.382e+00, Loss Aux: 4.573e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13531, It: 0, Loss Data: 7.628e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.612e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13532, It: 0, Loss Data: 8.660e-02, Loss Eqns: 2.421e+00, Loss Aux: 4.523e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13533, It: 0, Loss Data: 9.811e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.454e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13534, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.012e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13535, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.583e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13536, It: 0, Loss Data: 7.754e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.464e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13537, It: 0, Loss Data: 8.545e-02, Loss Eqns: 2.399e+00, Loss Aux: 3.551e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13538, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.357e+00, Loss Aux: 3.911e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13539, It: 0, Loss Data: 8.624e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.013e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13540, It: 0, Loss Data: 8.385e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.892e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13541, It: 0, Loss Data: 8.304e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.417e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 13542, It: 0, Loss Data: 8.576e-02, Loss Eqns: 2.303e+00, Loss Aux: 5.327e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13543, It: 0, Loss Data: 8.404e-02, Loss Eqns: 2.404e+00, Loss Aux: 5.759e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13544, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.244e+00, Loss Aux: 5.572e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13545, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.362e+00, Loss Aux: 4.417e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13546, It: 0, Loss Data: 8.336e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.908e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13547, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.086e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13548, It: 0, Loss Data: 9.522e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.267e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13549, It: 0, Loss Data: 8.704e-02, Loss Eqns: 2.381e+00, Loss Aux: 4.295e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13550, It: 0, Loss Data: 7.246e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.928e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13551, It: 0, Loss Data: 8.763e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.611e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13552, It: 0, Loss Data: 7.792e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.981e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13553, It: 0, Loss Data: 7.461e-02, Loss Eqns: 2.395e+00, Loss Aux: 4.677e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13554, It: 0, Loss Data: 7.970e-02, Loss Eqns: 2.473e+00, Loss Aux: 4.981e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13555, It: 0, Loss Data: 9.374e-02, Loss Eqns: 2.351e+00, Loss Aux: 5.034e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13556, It: 0, Loss Data: 9.135e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.512e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13557, It: 0, Loss Data: 9.316e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.910e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13558, It: 0, Loss Data: 9.466e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.594e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13559, It: 0, Loss Data: 7.682e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.223e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13560, It: 0, Loss Data: 7.661e-02, Loss Eqns: 2.405e+00, Loss Aux: 3.435e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13561, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.461e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13562, It: 0, Loss Data: 7.549e-02, Loss Eqns: 2.418e+00, Loss Aux: 4.642e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13563, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.064e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13564, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.803e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13565, It: 0, Loss Data: 9.852e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.156e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13566, It: 0, Loss Data: 8.298e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.868e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13567, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.572e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13568, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.451e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13569, It: 0, Loss Data: 9.408e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.252e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13570, It: 0, Loss Data: 8.343e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.684e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13571, It: 0, Loss Data: 9.015e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.391e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13572, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.845e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13573, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.857e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13574, It: 0, Loss Data: 9.010e-02, Loss Eqns: 2.282e+00, Loss Aux: 5.055e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13575, It: 0, Loss Data: 1.072e-01, Loss Eqns: 2.367e+00, Loss Aux: 5.024e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13576, It: 0, Loss Data: 8.732e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.624e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13577, It: 0, Loss Data: 8.966e-02, Loss Eqns: 2.463e+00, Loss Aux: 3.858e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13578, It: 0, Loss Data: 9.138e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.351e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13579, It: 0, Loss Data: 8.264e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.945e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13580, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.420e+00, Loss Aux: 5.057e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13581, It: 0, Loss Data: 8.012e-02, Loss Eqns: 2.370e+00, Loss Aux: 5.302e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13582, It: 0, Loss Data: 7.464e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.582e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 13583, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.341e+00, Loss Aux: 4.467e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13584, It: 0, Loss Data: 8.567e-02, Loss Eqns: 2.429e+00, Loss Aux: 4.316e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13585, It: 0, Loss Data: 7.530e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.490e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 13586, It: 0, Loss Data: 8.510e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.495e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13587, It: 0, Loss Data: 8.494e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.281e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13588, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.251e+00, Loss Aux: 5.093e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13589, It: 0, Loss Data: 8.096e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.955e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13590, It: 0, Loss Data: 8.914e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.334e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13591, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.989e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13592, It: 0, Loss Data: 9.054e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.296e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13593, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.327e+00, Loss Aux: 5.039e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13594, It: 0, Loss Data: 8.628e-02, Loss Eqns: 2.290e+00, Loss Aux: 5.329e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13595, It: 0, Loss Data: 8.105e-02, Loss Eqns: 2.230e+00, Loss Aux: 4.776e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13596, It: 0, Loss Data: 9.576e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.794e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13597, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.084e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13598, It: 0, Loss Data: 7.902e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.297e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13599, It: 0, Loss Data: 8.208e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.137e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13600, It: 0, Loss Data: 9.641e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.545e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13601, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.122e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13602, It: 0, Loss Data: 8.278e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.849e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13603, It: 0, Loss Data: 8.082e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.139e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13604, It: 0, Loss Data: 9.938e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.146e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13605, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.010e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13606, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.831e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13607, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.099e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13608, It: 0, Loss Data: 8.850e-02, Loss Eqns: 2.220e+00, Loss Aux: 5.591e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13609, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.316e+00, Loss Aux: 6.559e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13610, It: 0, Loss Data: 7.751e-02, Loss Eqns: 2.321e+00, Loss Aux: 5.994e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13611, It: 0, Loss Data: 9.559e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.268e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13612, It: 0, Loss Data: 8.936e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.262e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13613, It: 0, Loss Data: 8.557e-02, Loss Eqns: 2.421e+00, Loss Aux: 3.270e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13614, It: 0, Loss Data: 8.307e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.935e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 13615, It: 0, Loss Data: 8.368e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.387e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13616, It: 0, Loss Data: 9.449e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.788e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13617, It: 0, Loss Data: 7.481e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.293e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13618, It: 0, Loss Data: 8.123e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.552e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13619, It: 0, Loss Data: 8.653e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.585e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13620, It: 0, Loss Data: 8.907e-02, Loss Eqns: 2.369e+00, Loss Aux: 5.258e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13621, It: 0, Loss Data: 7.652e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.704e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13622, It: 0, Loss Data: 8.864e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.325e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13623, It: 0, Loss Data: 8.718e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.950e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13624, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.358e+00, Loss Aux: 4.354e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 13625, It: 0, Loss Data: 8.640e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.307e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13626, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.819e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13627, It: 0, Loss Data: 8.374e-02, Loss Eqns: 2.409e+00, Loss Aux: 3.770e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13628, It: 0, Loss Data: 8.721e-02, Loss Eqns: 2.428e+00, Loss Aux: 4.347e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13629, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.402e+00, Loss Aux: 4.358e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13630, It: 0, Loss Data: 7.717e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.024e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13631, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.361e+00, Loss Aux: 4.140e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13632, It: 0, Loss Data: 7.638e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.377e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13633, It: 0, Loss Data: 7.706e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.600e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13634, It: 0, Loss Data: 8.343e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.420e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13635, It: 0, Loss Data: 9.320e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.979e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13636, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.034e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13637, It: 0, Loss Data: 9.174e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.275e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13638, It: 0, Loss Data: 7.537e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.620e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13639, It: 0, Loss Data: 8.110e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.259e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13640, It: 0, Loss Data: 7.027e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.897e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13641, It: 0, Loss Data: 8.691e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.590e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13642, It: 0, Loss Data: 9.274e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.764e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13643, It: 0, Loss Data: 7.537e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.116e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13644, It: 0, Loss Data: 9.524e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.763e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13645, It: 0, Loss Data: 9.274e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.924e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13646, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.633e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13647, It: 0, Loss Data: 9.428e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.296e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13648, It: 0, Loss Data: 9.034e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.000e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13649, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.011e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13650, It: 0, Loss Data: 9.194e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.888e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13651, It: 0, Loss Data: 9.053e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.810e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13652, It: 0, Loss Data: 7.501e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.944e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13653, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.222e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13654, It: 0, Loss Data: 8.294e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.166e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13655, It: 0, Loss Data: 9.785e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.637e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13656, It: 0, Loss Data: 8.450e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.699e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13657, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.264e+00, Loss Aux: 3.834e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13658, It: 0, Loss Data: 9.245e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.911e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13659, It: 0, Loss Data: 9.271e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.279e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13660, It: 0, Loss Data: 9.004e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.673e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13661, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.800e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13662, It: 0, Loss Data: 8.880e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.636e-02, Time: 0.234, Learning Rate: 1.0e-03\n",
      "Epoch: 13663, It: 0, Loss Data: 9.667e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.652e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13664, It: 0, Loss Data: 7.561e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.374e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13665, It: 0, Loss Data: 8.193e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.925e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13666, It: 0, Loss Data: 8.453e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.017e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13667, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.402e+00, Loss Aux: 4.455e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13668, It: 0, Loss Data: 7.680e-02, Loss Eqns: 2.422e+00, Loss Aux: 5.258e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13669, It: 0, Loss Data: 9.018e-02, Loss Eqns: 2.439e+00, Loss Aux: 4.769e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13670, It: 0, Loss Data: 7.122e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.701e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13671, It: 0, Loss Data: 8.846e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.684e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13672, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.318e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13673, It: 0, Loss Data: 8.468e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.593e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 13674, It: 0, Loss Data: 9.268e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.561e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13675, It: 0, Loss Data: 8.810e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.493e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13676, It: 0, Loss Data: 8.276e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.345e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13677, It: 0, Loss Data: 8.201e-02, Loss Eqns: 2.393e+00, Loss Aux: 4.207e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13678, It: 0, Loss Data: 7.528e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.769e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13679, It: 0, Loss Data: 8.690e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.450e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13680, It: 0, Loss Data: 9.956e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.168e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 13681, It: 0, Loss Data: 7.188e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.400e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13682, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.090e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13683, It: 0, Loss Data: 7.559e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.630e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13684, It: 0, Loss Data: 9.170e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.986e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13685, It: 0, Loss Data: 8.886e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.633e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13686, It: 0, Loss Data: 8.741e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.660e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13687, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.241e+00, Loss Aux: 3.141e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13688, It: 0, Loss Data: 8.217e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.118e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 13689, It: 0, Loss Data: 9.833e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.753e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13690, It: 0, Loss Data: 8.315e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.484e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13691, It: 0, Loss Data: 8.529e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.628e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13692, It: 0, Loss Data: 9.670e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.508e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 13693, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.932e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13694, It: 0, Loss Data: 7.881e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.839e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13695, It: 0, Loss Data: 7.457e-02, Loss Eqns: 2.409e+00, Loss Aux: 4.107e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 13696, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.495e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 13697, It: 0, Loss Data: 7.777e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.570e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13698, It: 0, Loss Data: 9.199e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.326e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 13699, It: 0, Loss Data: 8.850e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.063e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13700, It: 0, Loss Data: 8.350e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.997e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13701, It: 0, Loss Data: 8.693e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.053e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13702, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.654e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13703, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.601e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13704, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.958e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13705, It: 0, Loss Data: 7.898e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.928e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13706, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.349e+00, Loss Aux: 3.799e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13707, It: 0, Loss Data: 8.429e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.010e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13708, It: 0, Loss Data: 8.311e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.085e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13709, It: 0, Loss Data: 9.426e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.224e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 13710, It: 0, Loss Data: 7.952e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.267e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13711, It: 0, Loss Data: 8.649e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.662e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13712, It: 0, Loss Data: 8.362e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.595e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13713, It: 0, Loss Data: 8.614e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.046e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13714, It: 0, Loss Data: 7.682e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.051e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13715, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.414e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13716, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.508e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13717, It: 0, Loss Data: 8.992e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.785e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13718, It: 0, Loss Data: 9.339e-02, Loss Eqns: 2.413e+00, Loss Aux: 3.607e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13719, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.390e+00, Loss Aux: 4.080e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13720, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.531e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13721, It: 0, Loss Data: 7.976e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.854e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13722, It: 0, Loss Data: 8.093e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.929e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13723, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.290e+00, Loss Aux: 4.632e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13724, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.996e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13725, It: 0, Loss Data: 7.526e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.670e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13726, It: 0, Loss Data: 7.606e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.966e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13727, It: 0, Loss Data: 9.485e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.354e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 13728, It: 0, Loss Data: 7.536e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.861e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13729, It: 0, Loss Data: 7.532e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.825e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13730, It: 0, Loss Data: 9.054e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.720e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13731, It: 0, Loss Data: 9.378e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.136e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13732, It: 0, Loss Data: 9.043e-02, Loss Eqns: 2.233e+00, Loss Aux: 3.742e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13733, It: 0, Loss Data: 9.822e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.883e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13734, It: 0, Loss Data: 9.454e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.200e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13735, It: 0, Loss Data: 8.968e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.163e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13736, It: 0, Loss Data: 7.784e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.924e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13737, It: 0, Loss Data: 7.864e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.231e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13738, It: 0, Loss Data: 8.226e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.115e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13739, It: 0, Loss Data: 9.428e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.591e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13740, It: 0, Loss Data: 9.098e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.777e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13741, It: 0, Loss Data: 8.446e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.472e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13742, It: 0, Loss Data: 1.003e-01, Loss Eqns: 2.337e+00, Loss Aux: 4.760e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13743, It: 0, Loss Data: 9.624e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.181e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13744, It: 0, Loss Data: 8.125e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.819e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13745, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.173e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13746, It: 0, Loss Data: 7.706e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.295e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13747, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.916e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13748, It: 0, Loss Data: 8.856e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.616e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13749, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.829e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13750, It: 0, Loss Data: 8.676e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.756e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13751, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.868e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13752, It: 0, Loss Data: 7.571e-02, Loss Eqns: 2.384e+00, Loss Aux: 4.255e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13753, It: 0, Loss Data: 1.032e-01, Loss Eqns: 2.354e+00, Loss Aux: 4.870e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13754, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.874e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 13755, It: 0, Loss Data: 8.834e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.821e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13756, It: 0, Loss Data: 8.919e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.202e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13757, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.800e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13758, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.087e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13759, It: 0, Loss Data: 8.039e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.756e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13760, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.305e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13761, It: 0, Loss Data: 8.674e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.951e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13762, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.384e+00, Loss Aux: 4.520e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13763, It: 0, Loss Data: 9.602e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.661e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13764, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.425e+00, Loss Aux: 4.307e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13765, It: 0, Loss Data: 8.154e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.061e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13766, It: 0, Loss Data: 8.169e-02, Loss Eqns: 2.432e+00, Loss Aux: 4.060e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13767, It: 0, Loss Data: 8.206e-02, Loss Eqns: 2.387e+00, Loss Aux: 4.131e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13768, It: 0, Loss Data: 9.544e-02, Loss Eqns: 2.510e+00, Loss Aux: 4.229e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13769, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.465e+00, Loss Aux: 4.672e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 13770, It: 0, Loss Data: 9.136e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.471e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13771, It: 0, Loss Data: 8.628e-02, Loss Eqns: 2.375e+00, Loss Aux: 4.189e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 13772, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.328e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13773, It: 0, Loss Data: 7.187e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.583e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13774, It: 0, Loss Data: 8.442e-02, Loss Eqns: 2.456e+00, Loss Aux: 4.071e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13775, It: 0, Loss Data: 7.647e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.227e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13776, It: 0, Loss Data: 8.897e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.654e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13777, It: 0, Loss Data: 7.745e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.402e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13778, It: 0, Loss Data: 7.465e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.944e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13779, It: 0, Loss Data: 7.516e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.725e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13780, It: 0, Loss Data: 8.243e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.835e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13781, It: 0, Loss Data: 7.989e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.060e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13782, It: 0, Loss Data: 9.308e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.505e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 13783, It: 0, Loss Data: 8.448e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.581e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13784, It: 0, Loss Data: 9.535e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.288e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 13785, It: 0, Loss Data: 8.656e-02, Loss Eqns: 2.202e+00, Loss Aux: 4.071e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13786, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.192e+00, Loss Aux: 4.339e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13787, It: 0, Loss Data: 8.633e-02, Loss Eqns: 2.234e+00, Loss Aux: 4.371e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13788, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.192e+00, Loss Aux: 4.129e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13789, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.986e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13790, It: 0, Loss Data: 8.266e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.303e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13791, It: 0, Loss Data: 8.682e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.545e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13792, It: 0, Loss Data: 9.798e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.368e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13793, It: 0, Loss Data: 7.820e-02, Loss Eqns: 2.236e+00, Loss Aux: 3.724e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13794, It: 0, Loss Data: 9.671e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.546e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13795, It: 0, Loss Data: 8.089e-02, Loss Eqns: 2.416e+00, Loss Aux: 3.823e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13796, It: 0, Loss Data: 9.153e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.503e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13797, It: 0, Loss Data: 7.736e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.156e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13798, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.737e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13799, It: 0, Loss Data: 7.452e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.545e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13800, It: 0, Loss Data: 9.417e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.071e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13801, It: 0, Loss Data: 9.992e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.956e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13802, It: 0, Loss Data: 9.811e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.521e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13803, It: 0, Loss Data: 9.401e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.013e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13804, It: 0, Loss Data: 7.849e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.965e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 13805, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.440e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13806, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.137e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13807, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.389e+00, Loss Aux: 3.565e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13808, It: 0, Loss Data: 8.519e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.903e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13809, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.573e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13810, It: 0, Loss Data: 9.672e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.814e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13811, It: 0, Loss Data: 8.109e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.549e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 13812, It: 0, Loss Data: 7.779e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.589e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13813, It: 0, Loss Data: 9.725e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.727e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13814, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.585e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13815, It: 0, Loss Data: 9.268e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.316e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13816, It: 0, Loss Data: 8.541e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.498e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13817, It: 0, Loss Data: 9.499e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.212e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 13818, It: 0, Loss Data: 7.673e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.239e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13819, It: 0, Loss Data: 8.259e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.619e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13820, It: 0, Loss Data: 7.909e-02, Loss Eqns: 2.436e+00, Loss Aux: 3.776e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13821, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.790e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13822, It: 0, Loss Data: 8.194e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.071e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13823, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.132e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13824, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.882e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13825, It: 0, Loss Data: 7.870e-02, Loss Eqns: 2.379e+00, Loss Aux: 5.011e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13826, It: 0, Loss Data: 8.187e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.509e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13827, It: 0, Loss Data: 7.982e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.785e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 13828, It: 0, Loss Data: 7.943e-02, Loss Eqns: 2.350e+00, Loss Aux: 3.409e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13829, It: 0, Loss Data: 9.156e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.282e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13830, It: 0, Loss Data: 9.284e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.421e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 13831, It: 0, Loss Data: 9.957e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.571e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13832, It: 0, Loss Data: 9.371e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.591e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13833, It: 0, Loss Data: 8.218e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.981e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13834, It: 0, Loss Data: 8.750e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.460e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13835, It: 0, Loss Data: 8.363e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.316e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13836, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.370e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13837, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.385e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13838, It: 0, Loss Data: 7.590e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.284e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13839, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.395e+00, Loss Aux: 4.224e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13840, It: 0, Loss Data: 8.854e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.130e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13841, It: 0, Loss Data: 8.682e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.057e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13842, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.858e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 13843, It: 0, Loss Data: 7.956e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.491e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 13844, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.589e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13845, It: 0, Loss Data: 8.417e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.014e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13846, It: 0, Loss Data: 9.947e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.140e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13847, It: 0, Loss Data: 9.106e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.071e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 13848, It: 0, Loss Data: 9.788e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.093e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13849, It: 0, Loss Data: 7.964e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.403e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 13850, It: 0, Loss Data: 8.467e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.615e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 13851, It: 0, Loss Data: 7.279e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.427e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13852, It: 0, Loss Data: 8.628e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.152e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13853, It: 0, Loss Data: 7.984e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.427e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13854, It: 0, Loss Data: 8.137e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.747e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13855, It: 0, Loss Data: 8.888e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.926e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13856, It: 0, Loss Data: 9.283e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.598e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13857, It: 0, Loss Data: 7.706e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.594e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 13858, It: 0, Loss Data: 7.638e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.541e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13859, It: 0, Loss Data: 7.749e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.584e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 13860, It: 0, Loss Data: 8.285e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.928e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13861, It: 0, Loss Data: 8.460e-02, Loss Eqns: 2.230e+00, Loss Aux: 4.243e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13862, It: 0, Loss Data: 7.096e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.500e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13863, It: 0, Loss Data: 8.508e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.434e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13864, It: 0, Loss Data: 8.550e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.341e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13865, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.275e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13866, It: 0, Loss Data: 9.400e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.342e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13867, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.173e+00, Loss Aux: 4.225e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13868, It: 0, Loss Data: 9.064e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.154e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13869, It: 0, Loss Data: 9.770e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.817e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13870, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.973e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13871, It: 0, Loss Data: 9.199e-02, Loss Eqns: 2.229e+00, Loss Aux: 3.403e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13872, It: 0, Loss Data: 9.528e-02, Loss Eqns: 2.222e+00, Loss Aux: 3.004e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13873, It: 0, Loss Data: 7.632e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.073e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13874, It: 0, Loss Data: 9.363e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.057e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13875, It: 0, Loss Data: 9.004e-02, Loss Eqns: 2.275e+00, Loss Aux: 5.250e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13876, It: 0, Loss Data: 8.208e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.069e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13877, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.261e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13878, It: 0, Loss Data: 8.702e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.703e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13879, It: 0, Loss Data: 1.038e-01, Loss Eqns: 2.331e+00, Loss Aux: 4.896e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13880, It: 0, Loss Data: 8.303e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.716e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13881, It: 0, Loss Data: 7.685e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.821e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13882, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.058e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13883, It: 0, Loss Data: 8.909e-02, Loss Eqns: 2.349e+00, Loss Aux: 2.856e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13884, It: 0, Loss Data: 8.693e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.221e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 13885, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.738e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13886, It: 0, Loss Data: 7.628e-02, Loss Eqns: 2.383e+00, Loss Aux: 3.963e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13887, It: 0, Loss Data: 8.139e-02, Loss Eqns: 2.410e+00, Loss Aux: 4.283e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13888, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.392e+00, Loss Aux: 5.387e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13889, It: 0, Loss Data: 8.496e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.764e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13890, It: 0, Loss Data: 8.594e-02, Loss Eqns: 2.326e+00, Loss Aux: 5.366e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13891, It: 0, Loss Data: 7.888e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.933e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13892, It: 0, Loss Data: 7.969e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.190e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 13893, It: 0, Loss Data: 8.155e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.071e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13894, It: 0, Loss Data: 9.304e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.504e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 13895, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.767e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13896, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.423e+00, Loss Aux: 3.711e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 13897, It: 0, Loss Data: 7.729e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.757e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13898, It: 0, Loss Data: 9.053e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.293e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13899, It: 0, Loss Data: 8.675e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.735e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13900, It: 0, Loss Data: 9.065e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.167e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13901, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.684e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13902, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.331e+00, Loss Aux: 4.023e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13903, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.406e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13904, It: 0, Loss Data: 8.664e-02, Loss Eqns: 2.413e+00, Loss Aux: 4.316e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13905, It: 0, Loss Data: 8.630e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.454e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13906, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.445e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13907, It: 0, Loss Data: 8.971e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.960e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13908, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.488e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 13909, It: 0, Loss Data: 8.044e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.261e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 13910, It: 0, Loss Data: 8.000e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.454e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13911, It: 0, Loss Data: 7.710e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.833e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 13912, It: 0, Loss Data: 7.683e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.406e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13913, It: 0, Loss Data: 8.715e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.519e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 13914, It: 0, Loss Data: 8.077e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.100e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13915, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.250e+00, Loss Aux: 3.864e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 13916, It: 0, Loss Data: 9.861e-02, Loss Eqns: 2.230e+00, Loss Aux: 3.861e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 13917, It: 0, Loss Data: 9.597e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.160e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13918, It: 0, Loss Data: 8.253e-02, Loss Eqns: 2.217e+00, Loss Aux: 4.601e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13919, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.305e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13920, It: 0, Loss Data: 8.271e-02, Loss Eqns: 2.223e+00, Loss Aux: 3.452e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13921, It: 0, Loss Data: 7.602e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.538e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 13922, It: 0, Loss Data: 9.584e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.519e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13923, It: 0, Loss Data: 9.722e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.491e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 13924, It: 0, Loss Data: 9.803e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.370e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13925, It: 0, Loss Data: 8.616e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.814e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 13926, It: 0, Loss Data: 9.552e-02, Loss Eqns: 2.211e+00, Loss Aux: 3.803e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13927, It: 0, Loss Data: 1.079e-01, Loss Eqns: 2.273e+00, Loss Aux: 3.877e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13928, It: 0, Loss Data: 7.532e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.629e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13929, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.424e+00, Loss Aux: 3.288e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 13930, It: 0, Loss Data: 8.558e-02, Loss Eqns: 2.365e+00, Loss Aux: 3.697e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13931, It: 0, Loss Data: 9.091e-02, Loss Eqns: 2.372e+00, Loss Aux: 5.162e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13932, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.286e+00, Loss Aux: 5.875e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13933, It: 0, Loss Data: 8.032e-02, Loss Eqns: 2.212e+00, Loss Aux: 4.543e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13934, It: 0, Loss Data: 8.697e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.137e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13935, It: 0, Loss Data: 7.422e-02, Loss Eqns: 2.331e+00, Loss Aux: 2.817e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 13936, It: 0, Loss Data: 1.007e-01, Loss Eqns: 2.292e+00, Loss Aux: 3.704e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13937, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.861e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13938, It: 0, Loss Data: 1.093e-01, Loss Eqns: 2.245e+00, Loss Aux: 4.204e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 13939, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.575e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13940, It: 0, Loss Data: 8.095e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.171e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13941, It: 0, Loss Data: 8.870e-02, Loss Eqns: 2.296e+00, Loss Aux: 5.222e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13942, It: 0, Loss Data: 8.970e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.802e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13943, It: 0, Loss Data: 9.426e-02, Loss Eqns: 2.400e+00, Loss Aux: 3.507e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13944, It: 0, Loss Data: 8.455e-02, Loss Eqns: 2.335e+00, Loss Aux: 3.494e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13945, It: 0, Loss Data: 9.320e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.223e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13946, It: 0, Loss Data: 8.531e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.067e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13947, It: 0, Loss Data: 7.497e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.713e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13948, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.105e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13949, It: 0, Loss Data: 8.918e-02, Loss Eqns: 2.404e+00, Loss Aux: 4.434e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 13950, It: 0, Loss Data: 8.106e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.624e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13951, It: 0, Loss Data: 9.005e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.330e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13952, It: 0, Loss Data: 9.595e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.517e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13953, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.640e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 13954, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.048e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13955, It: 0, Loss Data: 8.006e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.826e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13956, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.582e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13957, It: 0, Loss Data: 8.378e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.366e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 13958, It: 0, Loss Data: 8.748e-02, Loss Eqns: 2.213e+00, Loss Aux: 3.399e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13959, It: 0, Loss Data: 7.804e-02, Loss Eqns: 2.357e+00, Loss Aux: 3.679e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 13960, It: 0, Loss Data: 8.022e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.146e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 13961, It: 0, Loss Data: 7.299e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.774e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13962, It: 0, Loss Data: 8.416e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.759e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13963, It: 0, Loss Data: 7.397e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.145e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 13964, It: 0, Loss Data: 9.739e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.699e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 13965, It: 0, Loss Data: 8.282e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.341e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 13966, It: 0, Loss Data: 8.529e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.093e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 13967, It: 0, Loss Data: 8.163e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.169e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13968, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.297e+00, Loss Aux: 4.355e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 13969, It: 0, Loss Data: 9.275e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.429e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13970, It: 0, Loss Data: 7.896e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.560e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 13971, It: 0, Loss Data: 7.176e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.280e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13972, It: 0, Loss Data: 8.050e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.329e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13973, It: 0, Loss Data: 8.726e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.942e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 13974, It: 0, Loss Data: 8.016e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.619e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13975, It: 0, Loss Data: 7.062e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.637e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13976, It: 0, Loss Data: 9.050e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.419e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 13977, It: 0, Loss Data: 7.653e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.225e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 13978, It: 0, Loss Data: 8.481e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.855e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 13979, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.748e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13980, It: 0, Loss Data: 7.870e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.838e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13981, It: 0, Loss Data: 9.590e-02, Loss Eqns: 2.249e+00, Loss Aux: 3.825e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 13982, It: 0, Loss Data: 8.967e-02, Loss Eqns: 2.243e+00, Loss Aux: 3.694e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 13983, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.777e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 13984, It: 0, Loss Data: 9.633e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.745e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 13985, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.956e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 13986, It: 0, Loss Data: 8.345e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.224e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 13987, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.290e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 13988, It: 0, Loss Data: 8.799e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.391e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13989, It: 0, Loss Data: 8.323e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.260e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 13990, It: 0, Loss Data: 8.814e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.261e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13991, It: 0, Loss Data: 8.941e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.105e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 13992, It: 0, Loss Data: 7.166e-02, Loss Eqns: 2.424e+00, Loss Aux: 4.760e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 13993, It: 0, Loss Data: 8.880e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.411e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 13994, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.703e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13995, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.370e+00, Loss Aux: 3.181e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 13996, It: 0, Loss Data: 8.776e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.268e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 13997, It: 0, Loss Data: 9.000e-02, Loss Eqns: 2.412e+00, Loss Aux: 3.789e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 13998, It: 0, Loss Data: 8.320e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.077e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 13999, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.371e+00, Loss Aux: 3.696e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14000, It: 0, Loss Data: 7.989e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.628e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14001, It: 0, Loss Data: 7.982e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.070e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14002, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.714e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14003, It: 0, Loss Data: 7.701e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.522e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14004, It: 0, Loss Data: 7.248e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.289e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 14005, It: 0, Loss Data: 8.633e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.876e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14006, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.386e+00, Loss Aux: 3.609e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14007, It: 0, Loss Data: 6.917e-02, Loss Eqns: 2.386e+00, Loss Aux: 3.504e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 14008, It: 0, Loss Data: 8.967e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.456e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14009, It: 0, Loss Data: 7.781e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.032e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14010, It: 0, Loss Data: 8.041e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.759e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14011, It: 0, Loss Data: 8.509e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.496e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14012, It: 0, Loss Data: 8.933e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.578e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14013, It: 0, Loss Data: 7.958e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.518e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14014, It: 0, Loss Data: 1.068e-01, Loss Eqns: 2.296e+00, Loss Aux: 3.686e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14015, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.919e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14016, It: 0, Loss Data: 7.512e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.121e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14017, It: 0, Loss Data: 7.703e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.769e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14018, It: 0, Loss Data: 8.705e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.966e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14019, It: 0, Loss Data: 8.307e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.611e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14020, It: 0, Loss Data: 7.991e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.542e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14021, It: 0, Loss Data: 8.888e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.147e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14022, It: 0, Loss Data: 8.002e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.991e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14023, It: 0, Loss Data: 9.375e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.927e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14024, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.147e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14025, It: 0, Loss Data: 9.101e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.409e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14026, It: 0, Loss Data: 8.070e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.025e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14027, It: 0, Loss Data: 8.706e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.453e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 14028, It: 0, Loss Data: 8.340e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.170e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14029, It: 0, Loss Data: 9.240e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.046e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14030, It: 0, Loss Data: 7.938e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.496e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14031, It: 0, Loss Data: 7.653e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.893e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 14032, It: 0, Loss Data: 8.390e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.975e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14033, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.212e+00, Loss Aux: 5.747e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 14034, It: 0, Loss Data: 8.310e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.306e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14035, It: 0, Loss Data: 8.997e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.832e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14036, It: 0, Loss Data: 7.945e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.333e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14037, It: 0, Loss Data: 7.237e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.744e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14038, It: 0, Loss Data: 1.011e-01, Loss Eqns: 2.270e+00, Loss Aux: 4.146e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14039, It: 0, Loss Data: 8.856e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.434e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14040, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.191e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14041, It: 0, Loss Data: 8.884e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.535e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14042, It: 0, Loss Data: 9.778e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.718e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14043, It: 0, Loss Data: 8.258e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.051e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14044, It: 0, Loss Data: 9.467e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.447e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14045, It: 0, Loss Data: 7.318e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.352e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14046, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.403e+00, Loss Aux: 4.262e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14047, It: 0, Loss Data: 8.571e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.095e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14048, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.757e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14049, It: 0, Loss Data: 9.143e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.095e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14050, It: 0, Loss Data: 8.243e-02, Loss Eqns: 2.284e+00, Loss Aux: 5.157e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 14051, It: 0, Loss Data: 8.900e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.756e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14052, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.274e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14053, It: 0, Loss Data: 8.248e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.597e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14054, It: 0, Loss Data: 7.904e-02, Loss Eqns: 2.208e+00, Loss Aux: 4.075e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14055, It: 0, Loss Data: 9.379e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.469e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14056, It: 0, Loss Data: 7.734e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.049e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14057, It: 0, Loss Data: 8.117e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.844e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14058, It: 0, Loss Data: 9.771e-02, Loss Eqns: 2.437e+00, Loss Aux: 4.690e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14059, It: 0, Loss Data: 8.332e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.517e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14060, It: 0, Loss Data: 9.132e-02, Loss Eqns: 2.351e+00, Loss Aux: 3.803e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14061, It: 0, Loss Data: 9.525e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.581e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14062, It: 0, Loss Data: 9.101e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.190e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14063, It: 0, Loss Data: 9.819e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.908e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14064, It: 0, Loss Data: 8.519e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.315e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14065, It: 0, Loss Data: 8.340e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.082e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14066, It: 0, Loss Data: 8.686e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.805e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14067, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.477e+00, Loss Aux: 4.063e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14068, It: 0, Loss Data: 8.276e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.098e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14069, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.907e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14070, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.034e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14071, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.169e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14072, It: 0, Loss Data: 8.259e-02, Loss Eqns: 2.263e+00, Loss Aux: 3.543e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14073, It: 0, Loss Data: 8.294e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.389e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14074, It: 0, Loss Data: 7.337e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.520e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14075, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.923e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14076, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.390e+00, Loss Aux: 3.785e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14077, It: 0, Loss Data: 8.126e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.650e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14078, It: 0, Loss Data: 8.091e-02, Loss Eqns: 2.341e+00, Loss Aux: 3.657e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14079, It: 0, Loss Data: 9.746e-02, Loss Eqns: 2.252e+00, Loss Aux: 3.980e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14080, It: 0, Loss Data: 9.180e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.311e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14081, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.621e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14082, It: 0, Loss Data: 7.664e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.108e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14083, It: 0, Loss Data: 8.435e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.765e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14084, It: 0, Loss Data: 7.877e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.213e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14085, It: 0, Loss Data: 8.573e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.716e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14086, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.318e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14087, It: 0, Loss Data: 7.528e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.413e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14088, It: 0, Loss Data: 9.675e-02, Loss Eqns: 2.333e+00, Loss Aux: 2.936e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14089, It: 0, Loss Data: 8.435e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.745e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14090, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.674e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14091, It: 0, Loss Data: 9.363e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.420e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14092, It: 0, Loss Data: 8.089e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.756e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14093, It: 0, Loss Data: 8.421e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.708e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14094, It: 0, Loss Data: 8.511e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.961e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14095, It: 0, Loss Data: 9.510e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.665e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 14096, It: 0, Loss Data: 8.595e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.421e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14097, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.247e+00, Loss Aux: 3.772e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14098, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.143e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14099, It: 0, Loss Data: 7.641e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.242e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14100, It: 0, Loss Data: 7.888e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.859e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 14101, It: 0, Loss Data: 8.803e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.357e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14102, It: 0, Loss Data: 8.551e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.228e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14103, It: 0, Loss Data: 6.757e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.898e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14104, It: 0, Loss Data: 8.772e-02, Loss Eqns: 2.251e+00, Loss Aux: 5.110e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14105, It: 0, Loss Data: 8.229e-02, Loss Eqns: 2.222e+00, Loss Aux: 5.224e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 14106, It: 0, Loss Data: 8.148e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.410e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14107, It: 0, Loss Data: 9.887e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.598e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14108, It: 0, Loss Data: 8.178e-02, Loss Eqns: 2.263e+00, Loss Aux: 2.982e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14109, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.330e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14110, It: 0, Loss Data: 7.611e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.012e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14111, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.219e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14112, It: 0, Loss Data: 8.458e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.754e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14113, It: 0, Loss Data: 8.211e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.456e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14114, It: 0, Loss Data: 8.222e-02, Loss Eqns: 2.356e+00, Loss Aux: 3.428e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14115, It: 0, Loss Data: 7.449e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.273e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14116, It: 0, Loss Data: 7.904e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.485e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14117, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.987e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14118, It: 0, Loss Data: 7.809e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.742e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 14119, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.842e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14120, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.875e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14121, It: 0, Loss Data: 6.978e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.450e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14122, It: 0, Loss Data: 9.599e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.488e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14123, It: 0, Loss Data: 8.915e-02, Loss Eqns: 2.357e+00, Loss Aux: 3.959e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14124, It: 0, Loss Data: 7.957e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.437e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 14125, It: 0, Loss Data: 7.491e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.257e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14126, It: 0, Loss Data: 9.796e-02, Loss Eqns: 2.196e+00, Loss Aux: 3.852e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14127, It: 0, Loss Data: 7.332e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.376e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14128, It: 0, Loss Data: 8.404e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.402e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14129, It: 0, Loss Data: 7.439e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.888e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 14130, It: 0, Loss Data: 9.471e-02, Loss Eqns: 2.208e+00, Loss Aux: 4.000e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14131, It: 0, Loss Data: 9.141e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.484e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14132, It: 0, Loss Data: 9.494e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.371e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14133, It: 0, Loss Data: 8.126e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.000e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14134, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.461e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14135, It: 0, Loss Data: 8.900e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.387e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14136, It: 0, Loss Data: 7.844e-02, Loss Eqns: 2.226e+00, Loss Aux: 3.887e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14137, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.050e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14138, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.257e+00, Loss Aux: 3.903e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14139, It: 0, Loss Data: 9.521e-02, Loss Eqns: 2.154e+00, Loss Aux: 3.815e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14140, It: 0, Loss Data: 9.599e-02, Loss Eqns: 2.166e+00, Loss Aux: 3.980e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14141, It: 0, Loss Data: 8.536e-02, Loss Eqns: 2.227e+00, Loss Aux: 3.902e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14142, It: 0, Loss Data: 8.199e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.044e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14143, It: 0, Loss Data: 9.223e-02, Loss Eqns: 2.223e+00, Loss Aux: 3.710e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14144, It: 0, Loss Data: 9.699e-02, Loss Eqns: 2.176e+00, Loss Aux: 3.601e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14145, It: 0, Loss Data: 7.877e-02, Loss Eqns: 2.179e+00, Loss Aux: 4.391e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 14146, It: 0, Loss Data: 8.263e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.826e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14147, It: 0, Loss Data: 7.409e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.510e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14148, It: 0, Loss Data: 8.562e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.798e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14149, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.301e+00, Loss Aux: 3.044e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14150, It: 0, Loss Data: 9.352e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.026e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14151, It: 0, Loss Data: 8.734e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.022e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14152, It: 0, Loss Data: 7.501e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.017e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14153, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.848e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14154, It: 0, Loss Data: 8.085e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.075e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14155, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.226e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14156, It: 0, Loss Data: 8.013e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.755e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14157, It: 0, Loss Data: 7.447e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.596e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14158, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.956e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14159, It: 0, Loss Data: 8.936e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.351e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 14160, It: 0, Loss Data: 8.582e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.876e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14161, It: 0, Loss Data: 7.395e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.081e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14162, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.239e+00, Loss Aux: 3.597e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14163, It: 0, Loss Data: 8.896e-02, Loss Eqns: 2.283e+00, Loss Aux: 3.142e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14164, It: 0, Loss Data: 8.582e-02, Loss Eqns: 2.327e+00, Loss Aux: 2.838e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14165, It: 0, Loss Data: 8.962e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.882e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14166, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.663e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14167, It: 0, Loss Data: 7.834e-02, Loss Eqns: 2.408e+00, Loss Aux: 4.253e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14168, It: 0, Loss Data: 8.373e-02, Loss Eqns: 2.374e+00, Loss Aux: 3.867e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 14169, It: 0, Loss Data: 8.425e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.409e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14170, It: 0, Loss Data: 8.540e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.515e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14171, It: 0, Loss Data: 8.643e-02, Loss Eqns: 2.426e+00, Loss Aux: 3.836e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14172, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.320e+00, Loss Aux: 4.105e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14173, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.457e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14174, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.132e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14175, It: 0, Loss Data: 8.250e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.151e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14176, It: 0, Loss Data: 8.473e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.148e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14177, It: 0, Loss Data: 8.024e-02, Loss Eqns: 2.408e+00, Loss Aux: 3.915e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14178, It: 0, Loss Data: 9.297e-02, Loss Eqns: 2.429e+00, Loss Aux: 3.713e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14179, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.112e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14180, It: 0, Loss Data: 9.142e-02, Loss Eqns: 2.269e+00, Loss Aux: 2.850e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14181, It: 0, Loss Data: 9.094e-02, Loss Eqns: 2.380e+00, Loss Aux: 3.454e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14182, It: 0, Loss Data: 8.550e-02, Loss Eqns: 2.390e+00, Loss Aux: 4.842e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14183, It: 0, Loss Data: 8.076e-02, Loss Eqns: 2.282e+00, Loss Aux: 5.168e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 14184, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.990e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14185, It: 0, Loss Data: 7.554e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.869e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14186, It: 0, Loss Data: 8.895e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.144e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14187, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.804e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14188, It: 0, Loss Data: 8.967e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.319e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14189, It: 0, Loss Data: 9.549e-02, Loss Eqns: 2.402e+00, Loss Aux: 3.308e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14190, It: 0, Loss Data: 8.360e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.422e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14191, It: 0, Loss Data: 8.278e-02, Loss Eqns: 2.372e+00, Loss Aux: 3.571e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14192, It: 0, Loss Data: 8.430e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.205e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14193, It: 0, Loss Data: 9.198e-02, Loss Eqns: 2.258e+00, Loss Aux: 3.176e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14194, It: 0, Loss Data: 7.381e-02, Loss Eqns: 2.261e+00, Loss Aux: 3.235e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14195, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.962e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14196, It: 0, Loss Data: 8.591e-02, Loss Eqns: 2.279e+00, Loss Aux: 5.378e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14197, It: 0, Loss Data: 9.176e-02, Loss Eqns: 2.272e+00, Loss Aux: 5.591e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 14198, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.695e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14199, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.149e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14200, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.877e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14201, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.907e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14202, It: 0, Loss Data: 8.798e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.906e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14203, It: 0, Loss Data: 8.729e-02, Loss Eqns: 2.279e+00, Loss Aux: 3.477e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14204, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.367e+00, Loss Aux: 3.295e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14205, It: 0, Loss Data: 8.481e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.560e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14206, It: 0, Loss Data: 9.056e-02, Loss Eqns: 2.444e+00, Loss Aux: 3.327e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14207, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.369e+00, Loss Aux: 3.378e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14208, It: 0, Loss Data: 8.463e-02, Loss Eqns: 2.355e+00, Loss Aux: 3.754e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14209, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.308e+00, Loss Aux: 4.704e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14210, It: 0, Loss Data: 8.576e-02, Loss Eqns: 2.252e+00, Loss Aux: 5.002e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14211, It: 0, Loss Data: 8.481e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.261e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14212, It: 0, Loss Data: 7.226e-02, Loss Eqns: 2.419e+00, Loss Aux: 3.556e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14213, It: 0, Loss Data: 7.004e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.360e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 14214, It: 0, Loss Data: 7.244e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.144e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14215, It: 0, Loss Data: 7.948e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.076e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14216, It: 0, Loss Data: 8.489e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.312e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14217, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.384e+00, Loss Aux: 3.442e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14218, It: 0, Loss Data: 7.696e-02, Loss Eqns: 2.220e+00, Loss Aux: 3.837e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14219, It: 0, Loss Data: 9.080e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.090e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14220, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.485e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14221, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.267e+00, Loss Aux: 3.080e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14222, It: 0, Loss Data: 7.933e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.193e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14223, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.374e+00, Loss Aux: 5.290e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14224, It: 0, Loss Data: 7.690e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.752e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14225, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.457e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14226, It: 0, Loss Data: 9.487e-02, Loss Eqns: 2.291e+00, Loss Aux: 2.950e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14227, It: 0, Loss Data: 7.667e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.074e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14228, It: 0, Loss Data: 7.974e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.980e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14229, It: 0, Loss Data: 8.231e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.179e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14230, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.811e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14231, It: 0, Loss Data: 8.743e-02, Loss Eqns: 2.334e+00, Loss Aux: 3.920e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14232, It: 0, Loss Data: 9.246e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.183e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14233, It: 0, Loss Data: 7.394e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.555e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14234, It: 0, Loss Data: 8.374e-02, Loss Eqns: 2.294e+00, Loss Aux: 2.998e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14235, It: 0, Loss Data: 8.813e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.412e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14236, It: 0, Loss Data: 7.988e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.208e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14237, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.194e+00, Loss Aux: 4.100e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14238, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.366e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14239, It: 0, Loss Data: 7.506e-02, Loss Eqns: 2.391e+00, Loss Aux: 2.985e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14240, It: 0, Loss Data: 8.622e-02, Loss Eqns: 2.295e+00, Loss Aux: 3.637e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14241, It: 0, Loss Data: 8.512e-02, Loss Eqns: 2.205e+00, Loss Aux: 5.040e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14242, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.363e+00, Loss Aux: 5.045e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14243, It: 0, Loss Data: 7.204e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.965e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14244, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.006e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14245, It: 0, Loss Data: 8.922e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.418e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 14246, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.867e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14247, It: 0, Loss Data: 9.074e-02, Loss Eqns: 2.346e+00, Loss Aux: 2.891e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14248, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.400e+00, Loss Aux: 3.384e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14249, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.058e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14250, It: 0, Loss Data: 8.013e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.203e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14251, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.106e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14252, It: 0, Loss Data: 8.050e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.193e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14253, It: 0, Loss Data: 7.073e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.776e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14254, It: 0, Loss Data: 9.116e-02, Loss Eqns: 2.379e+00, Loss Aux: 4.928e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14255, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.585e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14256, It: 0, Loss Data: 8.158e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.009e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14257, It: 0, Loss Data: 9.046e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.701e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14258, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.252e+00, Loss Aux: 3.992e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14259, It: 0, Loss Data: 8.124e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.333e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14260, It: 0, Loss Data: 8.153e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.028e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14261, It: 0, Loss Data: 7.865e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.062e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14262, It: 0, Loss Data: 8.766e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.705e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14263, It: 0, Loss Data: 9.024e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.451e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14264, It: 0, Loss Data: 8.981e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.662e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14265, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.189e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14266, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.474e+00, Loss Aux: 2.816e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14267, It: 0, Loss Data: 1.461e-01, Loss Eqns: 4.738e+00, Loss Aux: 6.316e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14268, It: 0, Loss Data: 1.962e-01, Loss Eqns: 6.689e+00, Loss Aux: 5.307e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14269, It: 0, Loss Data: 1.819e-01, Loss Eqns: 5.678e+00, Loss Aux: 6.314e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14270, It: 0, Loss Data: 1.371e-01, Loss Eqns: 4.786e+00, Loss Aux: 7.416e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14271, It: 0, Loss Data: 1.435e-01, Loss Eqns: 4.631e+00, Loss Aux: 3.726e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14272, It: 0, Loss Data: 1.907e-01, Loss Eqns: 4.059e+00, Loss Aux: 1.545e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 14273, It: 0, Loss Data: 1.834e-01, Loss Eqns: 4.156e+00, Loss Aux: 3.436e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14274, It: 0, Loss Data: 1.816e-01, Loss Eqns: 3.734e+00, Loss Aux: 9.633e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14275, It: 0, Loss Data: 1.293e-01, Loss Eqns: 3.345e+00, Loss Aux: 7.779e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 14276, It: 0, Loss Data: 1.453e-01, Loss Eqns: 2.999e+00, Loss Aux: 5.576e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14277, It: 0, Loss Data: 1.348e-01, Loss Eqns: 3.452e+00, Loss Aux: 5.101e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14278, It: 0, Loss Data: 1.762e-01, Loss Eqns: 2.739e+00, Loss Aux: 8.321e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14279, It: 0, Loss Data: 1.204e-01, Loss Eqns: 2.610e+00, Loss Aux: 6.963e-02, Time: 0.143, Learning Rate: 1.0e-03\n",
      "Epoch: 14280, It: 0, Loss Data: 1.577e-01, Loss Eqns: 2.822e+00, Loss Aux: 5.662e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14281, It: 0, Loss Data: 1.574e-01, Loss Eqns: 2.767e+00, Loss Aux: 4.852e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14282, It: 0, Loss Data: 1.372e-01, Loss Eqns: 2.696e+00, Loss Aux: 7.047e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14283, It: 0, Loss Data: 1.414e-01, Loss Eqns: 2.467e+00, Loss Aux: 7.436e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14284, It: 0, Loss Data: 1.198e-01, Loss Eqns: 2.748e+00, Loss Aux: 3.873e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14285, It: 0, Loss Data: 1.204e-01, Loss Eqns: 2.827e+00, Loss Aux: 2.676e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14286, It: 0, Loss Data: 1.066e-01, Loss Eqns: 2.660e+00, Loss Aux: 3.349e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14287, It: 0, Loss Data: 1.274e-01, Loss Eqns: 2.389e+00, Loss Aux: 7.630e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14288, It: 0, Loss Data: 1.173e-01, Loss Eqns: 2.363e+00, Loss Aux: 9.829e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14289, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.393e+00, Loss Aux: 8.996e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14290, It: 0, Loss Data: 1.160e-01, Loss Eqns: 2.397e+00, Loss Aux: 7.881e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14291, It: 0, Loss Data: 1.050e-01, Loss Eqns: 2.531e+00, Loss Aux: 6.745e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14292, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.383e+00, Loss Aux: 6.587e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14293, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.354e+00, Loss Aux: 6.589e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14294, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.356e+00, Loss Aux: 6.303e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14295, It: 0, Loss Data: 9.565e-02, Loss Eqns: 2.469e+00, Loss Aux: 5.604e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14296, It: 0, Loss Data: 9.073e-02, Loss Eqns: 2.393e+00, Loss Aux: 4.923e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14297, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.423e+00, Loss Aux: 5.085e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14298, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.376e+00, Loss Aux: 5.500e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14299, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.379e+00, Loss Aux: 5.216e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14300, It: 0, Loss Data: 8.981e-02, Loss Eqns: 2.391e+00, Loss Aux: 5.111e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14301, It: 0, Loss Data: 9.534e-02, Loss Eqns: 2.365e+00, Loss Aux: 5.192e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14302, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.353e+00, Loss Aux: 5.378e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14303, It: 0, Loss Data: 9.752e-02, Loss Eqns: 2.351e+00, Loss Aux: 5.556e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14304, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.333e+00, Loss Aux: 5.136e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14305, It: 0, Loss Data: 8.993e-02, Loss Eqns: 2.402e+00, Loss Aux: 5.429e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14306, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.396e+00, Loss Aux: 5.939e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14307, It: 0, Loss Data: 9.997e-02, Loss Eqns: 2.371e+00, Loss Aux: 5.886e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14308, It: 0, Loss Data: 9.315e-02, Loss Eqns: 2.364e+00, Loss Aux: 5.122e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14309, It: 0, Loss Data: 9.854e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.303e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14310, It: 0, Loss Data: 9.036e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.193e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14311, It: 0, Loss Data: 8.831e-02, Loss Eqns: 2.444e+00, Loss Aux: 4.358e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14312, It: 0, Loss Data: 9.386e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.345e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14313, It: 0, Loss Data: 8.484e-02, Loss Eqns: 2.391e+00, Loss Aux: 4.605e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14314, It: 0, Loss Data: 9.310e-02, Loss Eqns: 2.373e+00, Loss Aux: 5.197e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14315, It: 0, Loss Data: 1.024e-01, Loss Eqns: 2.401e+00, Loss Aux: 5.355e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14316, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.459e+00, Loss Aux: 5.094e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14317, It: 0, Loss Data: 8.345e-02, Loss Eqns: 2.295e+00, Loss Aux: 5.329e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14318, It: 0, Loss Data: 8.114e-02, Loss Eqns: 2.320e+00, Loss Aux: 6.235e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14319, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.265e+00, Loss Aux: 5.861e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14320, It: 0, Loss Data: 7.489e-02, Loss Eqns: 2.336e+00, Loss Aux: 5.058e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14321, It: 0, Loss Data: 9.511e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.877e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14322, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.417e+00, Loss Aux: 5.164e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14323, It: 0, Loss Data: 8.960e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.873e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 14324, It: 0, Loss Data: 8.827e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.465e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 14325, It: 0, Loss Data: 8.693e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.599e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14326, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.349e+00, Loss Aux: 5.061e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14327, It: 0, Loss Data: 7.371e-02, Loss Eqns: 2.351e+00, Loss Aux: 5.184e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14328, It: 0, Loss Data: 9.839e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.747e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14329, It: 0, Loss Data: 8.941e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.285e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14330, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.646e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14331, It: 0, Loss Data: 9.780e-02, Loss Eqns: 2.266e+00, Loss Aux: 5.449e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14332, It: 0, Loss Data: 7.922e-02, Loss Eqns: 2.319e+00, Loss Aux: 6.154e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14333, It: 0, Loss Data: 9.400e-02, Loss Eqns: 2.284e+00, Loss Aux: 6.220e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14334, It: 0, Loss Data: 8.385e-02, Loss Eqns: 2.292e+00, Loss Aux: 5.651e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14335, It: 0, Loss Data: 8.238e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.820e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 14336, It: 0, Loss Data: 8.861e-02, Loss Eqns: 2.441e+00, Loss Aux: 4.698e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14337, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.354e+00, Loss Aux: 5.365e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14338, It: 0, Loss Data: 9.582e-02, Loss Eqns: 2.322e+00, Loss Aux: 6.248e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14339, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.318e+00, Loss Aux: 6.203e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14340, It: 0, Loss Data: 8.124e-02, Loss Eqns: 2.345e+00, Loss Aux: 5.608e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 14341, It: 0, Loss Data: 7.807e-02, Loss Eqns: 2.386e+00, Loss Aux: 4.595e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14342, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.386e+00, Loss Aux: 4.213e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14343, It: 0, Loss Data: 9.443e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.996e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14344, It: 0, Loss Data: 8.267e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.426e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14345, It: 0, Loss Data: 8.469e-02, Loss Eqns: 2.301e+00, Loss Aux: 5.404e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14346, It: 0, Loss Data: 8.687e-02, Loss Eqns: 2.325e+00, Loss Aux: 6.277e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14347, It: 0, Loss Data: 8.671e-02, Loss Eqns: 2.275e+00, Loss Aux: 6.022e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14348, It: 0, Loss Data: 9.728e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.910e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14349, It: 0, Loss Data: 9.979e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.254e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14350, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.458e+00, Loss Aux: 4.451e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14351, It: 0, Loss Data: 1.059e-01, Loss Eqns: 2.343e+00, Loss Aux: 5.619e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14352, It: 0, Loss Data: 9.018e-02, Loss Eqns: 2.239e+00, Loss Aux: 5.610e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14353, It: 0, Loss Data: 9.763e-02, Loss Eqns: 2.403e+00, Loss Aux: 5.566e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14354, It: 0, Loss Data: 8.791e-02, Loss Eqns: 2.385e+00, Loss Aux: 5.692e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14355, It: 0, Loss Data: 9.712e-02, Loss Eqns: 2.426e+00, Loss Aux: 5.271e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14356, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.510e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14357, It: 0, Loss Data: 1.088e-01, Loss Eqns: 2.378e+00, Loss Aux: 4.907e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14358, It: 0, Loss Data: 8.738e-02, Loss Eqns: 2.337e+00, Loss Aux: 6.255e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14359, It: 0, Loss Data: 8.552e-02, Loss Eqns: 2.399e+00, Loss Aux: 6.244e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14360, It: 0, Loss Data: 9.232e-02, Loss Eqns: 2.324e+00, Loss Aux: 5.430e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14361, It: 0, Loss Data: 9.380e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.930e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14362, It: 0, Loss Data: 8.780e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.702e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14363, It: 0, Loss Data: 7.350e-02, Loss Eqns: 2.392e+00, Loss Aux: 3.934e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14364, It: 0, Loss Data: 1.017e-01, Loss Eqns: 2.329e+00, Loss Aux: 3.436e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14365, It: 0, Loss Data: 9.493e-02, Loss Eqns: 2.364e+00, Loss Aux: 3.850e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14366, It: 0, Loss Data: 7.460e-02, Loss Eqns: 2.343e+00, Loss Aux: 5.761e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14367, It: 0, Loss Data: 9.259e-02, Loss Eqns: 2.342e+00, Loss Aux: 6.761e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14368, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.307e+00, Loss Aux: 5.514e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14369, It: 0, Loss Data: 8.188e-02, Loss Eqns: 2.324e+00, Loss Aux: 5.106e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14370, It: 0, Loss Data: 9.401e-02, Loss Eqns: 2.341e+00, Loss Aux: 5.562e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14371, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.737e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14372, It: 0, Loss Data: 8.881e-02, Loss Eqns: 2.321e+00, Loss Aux: 5.115e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14373, It: 0, Loss Data: 7.165e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.997e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14374, It: 0, Loss Data: 9.499e-02, Loss Eqns: 2.284e+00, Loss Aux: 5.142e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14375, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.892e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14376, It: 0, Loss Data: 1.104e-01, Loss Eqns: 2.372e+00, Loss Aux: 4.374e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14377, It: 0, Loss Data: 8.559e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.237e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 14378, It: 0, Loss Data: 7.789e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.480e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14379, It: 0, Loss Data: 8.919e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.838e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14380, It: 0, Loss Data: 9.360e-02, Loss Eqns: 2.333e+00, Loss Aux: 5.070e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14381, It: 0, Loss Data: 8.840e-02, Loss Eqns: 2.281e+00, Loss Aux: 5.522e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14382, It: 0, Loss Data: 9.228e-02, Loss Eqns: 2.372e+00, Loss Aux: 6.214e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14383, It: 0, Loss Data: 8.464e-02, Loss Eqns: 2.325e+00, Loss Aux: 5.212e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14384, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.294e+00, Loss Aux: 4.378e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14385, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.470e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14386, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.999e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14387, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.894e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14388, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.368e+00, Loss Aux: 4.340e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14389, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.394e+00, Loss Aux: 4.346e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14390, It: 0, Loss Data: 8.642e-02, Loss Eqns: 2.288e+00, Loss Aux: 5.001e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14391, It: 0, Loss Data: 8.719e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.806e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14392, It: 0, Loss Data: 7.586e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.637e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14393, It: 0, Loss Data: 8.467e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.551e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14394, It: 0, Loss Data: 8.862e-02, Loss Eqns: 2.455e+00, Loss Aux: 4.745e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14395, It: 0, Loss Data: 6.883e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.714e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14396, It: 0, Loss Data: 9.403e-02, Loss Eqns: 2.393e+00, Loss Aux: 4.684e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14397, It: 0, Loss Data: 8.315e-02, Loss Eqns: 2.393e+00, Loss Aux: 5.402e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14398, It: 0, Loss Data: 8.734e-02, Loss Eqns: 2.330e+00, Loss Aux: 6.617e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14399, It: 0, Loss Data: 8.616e-02, Loss Eqns: 2.463e+00, Loss Aux: 6.034e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14400, It: 0, Loss Data: 8.491e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.811e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14401, It: 0, Loss Data: 8.914e-02, Loss Eqns: 2.411e+00, Loss Aux: 4.206e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14402, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.433e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14403, It: 0, Loss Data: 9.220e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.553e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14404, It: 0, Loss Data: 7.629e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.473e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14405, It: 0, Loss Data: 9.009e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.554e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14406, It: 0, Loss Data: 8.022e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.804e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14407, It: 0, Loss Data: 7.743e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.697e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14408, It: 0, Loss Data: 8.069e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.437e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14409, It: 0, Loss Data: 8.718e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.474e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14410, It: 0, Loss Data: 8.360e-02, Loss Eqns: 2.323e+00, Loss Aux: 5.229e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14411, It: 0, Loss Data: 8.302e-02, Loss Eqns: 2.302e+00, Loss Aux: 5.913e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14412, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.312e+00, Loss Aux: 5.693e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14413, It: 0, Loss Data: 9.021e-02, Loss Eqns: 2.246e+00, Loss Aux: 5.263e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14414, It: 0, Loss Data: 9.104e-02, Loss Eqns: 2.371e+00, Loss Aux: 5.109e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14415, It: 0, Loss Data: 9.082e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.989e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14416, It: 0, Loss Data: 7.936e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.106e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14417, It: 0, Loss Data: 8.256e-02, Loss Eqns: 2.259e+00, Loss Aux: 3.584e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14418, It: 0, Loss Data: 9.468e-02, Loss Eqns: 2.253e+00, Loss Aux: 3.702e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14419, It: 0, Loss Data: 8.941e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.257e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14420, It: 0, Loss Data: 8.276e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.931e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14421, It: 0, Loss Data: 8.196e-02, Loss Eqns: 2.219e+00, Loss Aux: 5.071e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14422, It: 0, Loss Data: 7.643e-02, Loss Eqns: 2.282e+00, Loss Aux: 5.023e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14423, It: 0, Loss Data: 8.736e-02, Loss Eqns: 2.227e+00, Loss Aux: 5.627e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14424, It: 0, Loss Data: 8.550e-02, Loss Eqns: 2.206e+00, Loss Aux: 5.954e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14425, It: 0, Loss Data: 8.911e-02, Loss Eqns: 2.328e+00, Loss Aux: 5.239e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14426, It: 0, Loss Data: 8.595e-02, Loss Eqns: 2.231e+00, Loss Aux: 4.714e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14427, It: 0, Loss Data: 9.481e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.596e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14428, It: 0, Loss Data: 8.449e-02, Loss Eqns: 2.191e+00, Loss Aux: 4.221e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14429, It: 0, Loss Data: 9.910e-02, Loss Eqns: 2.193e+00, Loss Aux: 4.363e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14430, It: 0, Loss Data: 8.396e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.551e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 14431, It: 0, Loss Data: 9.391e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.240e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14432, It: 0, Loss Data: 9.784e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.210e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14433, It: 0, Loss Data: 8.938e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.838e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14434, It: 0, Loss Data: 8.101e-02, Loss Eqns: 2.364e+00, Loss Aux: 5.367e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14435, It: 0, Loss Data: 8.271e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.010e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14436, It: 0, Loss Data: 7.989e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.182e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14437, It: 0, Loss Data: 7.947e-02, Loss Eqns: 2.415e+00, Loss Aux: 4.198e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14438, It: 0, Loss Data: 7.501e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.707e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14439, It: 0, Loss Data: 7.935e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.697e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14440, It: 0, Loss Data: 7.793e-02, Loss Eqns: 2.393e+00, Loss Aux: 4.692e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14441, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.960e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14442, It: 0, Loss Data: 8.416e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.920e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14443, It: 0, Loss Data: 8.851e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.665e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14444, It: 0, Loss Data: 8.575e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.103e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14445, It: 0, Loss Data: 8.591e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.902e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14446, It: 0, Loss Data: 8.912e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.156e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14447, It: 0, Loss Data: 9.105e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.524e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14448, It: 0, Loss Data: 8.796e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.860e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 14449, It: 0, Loss Data: 8.427e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.993e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14450, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.387e+00, Loss Aux: 4.913e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14451, It: 0, Loss Data: 7.473e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.767e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14452, It: 0, Loss Data: 9.843e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.657e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 14453, It: 0, Loss Data: 8.641e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.797e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14454, It: 0, Loss Data: 7.936e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.815e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14455, It: 0, Loss Data: 9.448e-02, Loss Eqns: 2.330e+00, Loss Aux: 5.226e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14456, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.357e+00, Loss Aux: 5.155e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14457, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.641e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14458, It: 0, Loss Data: 8.191e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.188e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14459, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.514e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14460, It: 0, Loss Data: 8.251e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.199e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14461, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.311e+00, Loss Aux: 3.979e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14462, It: 0, Loss Data: 8.745e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.836e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14463, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.274e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14464, It: 0, Loss Data: 9.187e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.797e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14465, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.366e+00, Loss Aux: 5.094e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14466, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.726e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14467, It: 0, Loss Data: 8.086e-02, Loss Eqns: 2.263e+00, Loss Aux: 5.430e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 14468, It: 0, Loss Data: 7.559e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.739e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14469, It: 0, Loss Data: 8.756e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.982e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14470, It: 0, Loss Data: 9.323e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.154e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14471, It: 0, Loss Data: 8.926e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.426e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14472, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.691e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14473, It: 0, Loss Data: 8.395e-02, Loss Eqns: 2.222e+00, Loss Aux: 4.860e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14474, It: 0, Loss Data: 8.653e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.200e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14475, It: 0, Loss Data: 1.022e-01, Loss Eqns: 2.374e+00, Loss Aux: 3.791e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14476, It: 0, Loss Data: 9.700e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.043e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14477, It: 0, Loss Data: 8.556e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.775e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14478, It: 0, Loss Data: 7.746e-02, Loss Eqns: 2.402e+00, Loss Aux: 5.626e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14479, It: 0, Loss Data: 8.562e-02, Loss Eqns: 2.290e+00, Loss Aux: 5.415e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 14480, It: 0, Loss Data: 8.122e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.732e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14481, It: 0, Loss Data: 7.798e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.791e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14482, It: 0, Loss Data: 8.395e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.885e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14483, It: 0, Loss Data: 8.620e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.534e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14484, It: 0, Loss Data: 8.816e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.225e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14485, It: 0, Loss Data: 8.644e-02, Loss Eqns: 2.354e+00, Loss Aux: 3.947e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14486, It: 0, Loss Data: 8.316e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.836e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14487, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.398e+00, Loss Aux: 3.887e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14488, It: 0, Loss Data: 7.962e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.495e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14489, It: 0, Loss Data: 8.737e-02, Loss Eqns: 2.404e+00, Loss Aux: 4.810e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 14490, It: 0, Loss Data: 8.209e-02, Loss Eqns: 2.332e+00, Loss Aux: 5.295e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14491, It: 0, Loss Data: 8.609e-02, Loss Eqns: 2.301e+00, Loss Aux: 5.440e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14492, It: 0, Loss Data: 7.076e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.786e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14493, It: 0, Loss Data: 8.244e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.463e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 14494, It: 0, Loss Data: 8.659e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.601e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14495, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.277e+00, Loss Aux: 5.108e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14496, It: 0, Loss Data: 9.183e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.926e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14497, It: 0, Loss Data: 8.318e-02, Loss Eqns: 2.386e+00, Loss Aux: 4.539e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14498, It: 0, Loss Data: 8.099e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.286e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14499, It: 0, Loss Data: 8.890e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.126e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14500, It: 0, Loss Data: 9.022e-02, Loss Eqns: 2.368e+00, Loss Aux: 3.637e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14501, It: 0, Loss Data: 9.249e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.512e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14502, It: 0, Loss Data: 9.553e-02, Loss Eqns: 2.404e+00, Loss Aux: 4.328e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14503, It: 0, Loss Data: 8.490e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.920e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14504, It: 0, Loss Data: 8.511e-02, Loss Eqns: 2.264e+00, Loss Aux: 5.201e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14505, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.314e+00, Loss Aux: 5.271e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14506, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.413e+00, Loss Aux: 5.030e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14507, It: 0, Loss Data: 9.569e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.261e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14508, It: 0, Loss Data: 8.611e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.659e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14509, It: 0, Loss Data: 8.215e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.757e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14510, It: 0, Loss Data: 7.996e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.291e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14511, It: 0, Loss Data: 8.693e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.049e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14512, It: 0, Loss Data: 9.693e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.186e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14513, It: 0, Loss Data: 7.621e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.369e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14514, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.677e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14515, It: 0, Loss Data: 8.393e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.568e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14516, It: 0, Loss Data: 8.769e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.150e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14517, It: 0, Loss Data: 8.179e-02, Loss Eqns: 2.226e+00, Loss Aux: 3.967e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14518, It: 0, Loss Data: 9.175e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.824e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14519, It: 0, Loss Data: 7.872e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.891e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14520, It: 0, Loss Data: 8.454e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.222e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14521, It: 0, Loss Data: 8.963e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.884e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14522, It: 0, Loss Data: 8.733e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.402e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14523, It: 0, Loss Data: 8.736e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.707e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14524, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.586e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14525, It: 0, Loss Data: 8.101e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.387e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14526, It: 0, Loss Data: 7.928e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.555e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14527, It: 0, Loss Data: 7.515e-02, Loss Eqns: 2.357e+00, Loss Aux: 4.662e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14528, It: 0, Loss Data: 7.770e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.801e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14529, It: 0, Loss Data: 9.078e-02, Loss Eqns: 2.427e+00, Loss Aux: 4.090e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14530, It: 0, Loss Data: 8.272e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.528e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 14531, It: 0, Loss Data: 9.211e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.430e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14532, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.277e+00, Loss Aux: 5.289e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14533, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.380e+00, Loss Aux: 4.362e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14534, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.631e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14535, It: 0, Loss Data: 9.365e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.021e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14536, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.741e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14537, It: 0, Loss Data: 7.755e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.940e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14538, It: 0, Loss Data: 7.331e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.955e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14539, It: 0, Loss Data: 8.109e-02, Loss Eqns: 2.264e+00, Loss Aux: 5.058e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14540, It: 0, Loss Data: 8.849e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.376e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14541, It: 0, Loss Data: 7.790e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.901e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14542, It: 0, Loss Data: 8.226e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.245e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14543, It: 0, Loss Data: 8.789e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.799e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 14544, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.277e+00, Loss Aux: 5.082e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14545, It: 0, Loss Data: 8.000e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.677e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14546, It: 0, Loss Data: 8.228e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.844e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14547, It: 0, Loss Data: 8.672e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.290e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14548, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.684e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14549, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.161e+00, Loss Aux: 4.493e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14550, It: 0, Loss Data: 8.246e-02, Loss Eqns: 2.197e+00, Loss Aux: 5.157e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14551, It: 0, Loss Data: 8.028e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.327e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14552, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.221e+00, Loss Aux: 5.550e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14553, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.230e+00, Loss Aux: 5.131e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14554, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.279e+00, Loss Aux: 4.083e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14555, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.327e+00, Loss Aux: 3.864e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14556, It: 0, Loss Data: 7.775e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.190e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14557, It: 0, Loss Data: 7.975e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.518e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14558, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.720e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 14559, It: 0, Loss Data: 8.680e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.804e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 14560, It: 0, Loss Data: 8.155e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.415e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14561, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.441e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14562, It: 0, Loss Data: 8.779e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.538e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14563, It: 0, Loss Data: 9.364e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.737e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14564, It: 0, Loss Data: 8.516e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.009e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14565, It: 0, Loss Data: 7.030e-02, Loss Eqns: 2.245e+00, Loss Aux: 5.259e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14566, It: 0, Loss Data: 8.779e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.772e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14567, It: 0, Loss Data: 8.408e-02, Loss Eqns: 2.301e+00, Loss Aux: 3.833e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14568, It: 0, Loss Data: 9.070e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.835e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14569, It: 0, Loss Data: 8.719e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.662e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14570, It: 0, Loss Data: 8.134e-02, Loss Eqns: 2.313e+00, Loss Aux: 5.289e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14571, It: 0, Loss Data: 9.192e-02, Loss Eqns: 2.480e+00, Loss Aux: 4.189e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14572, It: 0, Loss Data: 1.126e-01, Loss Eqns: 2.625e+00, Loss Aux: 5.406e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14573, It: 0, Loss Data: 8.358e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.681e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14574, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.524e+00, Loss Aux: 3.796e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14575, It: 0, Loss Data: 8.937e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.214e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14576, It: 0, Loss Data: 8.880e-02, Loss Eqns: 2.570e+00, Loss Aux: 4.463e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14577, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.720e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14578, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.486e+00, Loss Aux: 4.186e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 14579, It: 0, Loss Data: 8.826e-02, Loss Eqns: 2.444e+00, Loss Aux: 5.631e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14580, It: 0, Loss Data: 1.000e-01, Loss Eqns: 2.407e+00, Loss Aux: 3.656e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14581, It: 0, Loss Data: 7.975e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.538e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14582, It: 0, Loss Data: 1.282e-01, Loss Eqns: 3.010e+00, Loss Aux: 7.472e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14583, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.719e+00, Loss Aux: 4.747e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14584, It: 0, Loss Data: 1.173e-01, Loss Eqns: 2.914e+00, Loss Aux: 3.476e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14585, It: 0, Loss Data: 8.414e-02, Loss Eqns: 2.406e+00, Loss Aux: 4.695e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14586, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.805e+00, Loss Aux: 4.634e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14587, It: 0, Loss Data: 9.644e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.154e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14588, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.485e+00, Loss Aux: 3.848e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14589, It: 0, Loss Data: 9.653e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.992e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14590, It: 0, Loss Data: 9.665e-02, Loss Eqns: 2.339e+00, Loss Aux: 5.778e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14591, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.340e+00, Loss Aux: 4.082e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14592, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.244e+00, Loss Aux: 4.169e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14593, It: 0, Loss Data: 9.381e-02, Loss Eqns: 2.265e+00, Loss Aux: 6.055e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 14594, It: 0, Loss Data: 1.083e-01, Loss Eqns: 2.300e+00, Loss Aux: 4.702e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14595, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.367e+00, Loss Aux: 3.028e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14596, It: 0, Loss Data: 9.865e-02, Loss Eqns: 2.207e+00, Loss Aux: 3.539e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14597, It: 0, Loss Data: 9.071e-02, Loss Eqns: 2.303e+00, Loss Aux: 5.370e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14598, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.137e+00, Loss Aux: 5.654e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14599, It: 0, Loss Data: 1.029e-01, Loss Eqns: 2.342e+00, Loss Aux: 4.458e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14600, It: 0, Loss Data: 9.099e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.060e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14601, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.892e+00, Loss Aux: 5.798e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14602, It: 0, Loss Data: 1.137e-01, Loss Eqns: 2.452e+00, Loss Aux: 5.288e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14603, It: 0, Loss Data: 1.218e-01, Loss Eqns: 2.594e+00, Loss Aux: 5.447e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 14604, It: 0, Loss Data: 9.888e-02, Loss Eqns: 2.442e+00, Loss Aux: 6.208e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14605, It: 0, Loss Data: 1.134e-01, Loss Eqns: 2.781e+00, Loss Aux: 5.530e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14606, It: 0, Loss Data: 1.002e-01, Loss Eqns: 2.327e+00, Loss Aux: 3.226e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14607, It: 0, Loss Data: 1.084e-01, Loss Eqns: 2.625e+00, Loss Aux: 3.079e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14608, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.265e+00, Loss Aux: 5.231e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14609, It: 0, Loss Data: 9.660e-02, Loss Eqns: 2.447e+00, Loss Aux: 5.612e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14610, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.021e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14611, It: 0, Loss Data: 1.025e-01, Loss Eqns: 2.325e+00, Loss Aux: 3.717e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14612, It: 0, Loss Data: 9.533e-02, Loss Eqns: 2.479e+00, Loss Aux: 5.125e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14613, It: 0, Loss Data: 1.016e-01, Loss Eqns: 2.516e+00, Loss Aux: 5.876e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14614, It: 0, Loss Data: 1.112e-01, Loss Eqns: 2.481e+00, Loss Aux: 4.809e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14615, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.410e+00, Loss Aux: 5.127e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14616, It: 0, Loss Data: 9.038e-02, Loss Eqns: 2.487e+00, Loss Aux: 6.579e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14617, It: 0, Loss Data: 1.047e-01, Loss Eqns: 2.437e+00, Loss Aux: 6.881e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14618, It: 0, Loss Data: 9.253e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.250e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14619, It: 0, Loss Data: 9.382e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.563e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14620, It: 0, Loss Data: 9.402e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.514e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14621, It: 0, Loss Data: 8.644e-02, Loss Eqns: 2.134e+00, Loss Aux: 4.151e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14622, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.967e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 14623, It: 0, Loss Data: 9.518e-02, Loss Eqns: 2.242e+00, Loss Aux: 5.309e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14624, It: 0, Loss Data: 7.676e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.815e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14625, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.648e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14626, It: 0, Loss Data: 7.715e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.923e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14627, It: 0, Loss Data: 9.580e-02, Loss Eqns: 2.189e+00, Loss Aux: 5.153e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14628, It: 0, Loss Data: 9.228e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.885e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14629, It: 0, Loss Data: 8.699e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.473e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 14630, It: 0, Loss Data: 8.124e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.408e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14631, It: 0, Loss Data: 7.786e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.594e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14632, It: 0, Loss Data: 9.837e-02, Loss Eqns: 2.452e+00, Loss Aux: 3.958e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14633, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.587e+00, Loss Aux: 5.271e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14634, It: 0, Loss Data: 1.497e-01, Loss Eqns: 3.382e+00, Loss Aux: 6.377e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14635, It: 0, Loss Data: 1.696e-01, Loss Eqns: 3.327e+00, Loss Aux: 4.054e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14636, It: 0, Loss Data: 1.868e-01, Loss Eqns: 3.600e+00, Loss Aux: 4.437e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14637, It: 0, Loss Data: 1.172e-01, Loss Eqns: 2.519e+00, Loss Aux: 7.351e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14638, It: 0, Loss Data: 1.651e-01, Loss Eqns: 3.128e+00, Loss Aux: 6.296e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14639, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.367e+00, Loss Aux: 3.000e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14640, It: 0, Loss Data: 1.462e-01, Loss Eqns: 2.792e+00, Loss Aux: 2.522e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14641, It: 0, Loss Data: 1.102e-01, Loss Eqns: 2.640e+00, Loss Aux: 5.603e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14642, It: 0, Loss Data: 1.548e-01, Loss Eqns: 2.617e+00, Loss Aux: 1.303e-01, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14643, It: 0, Loss Data: 1.040e-01, Loss Eqns: 2.293e+00, Loss Aux: 1.051e-01, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14644, It: 0, Loss Data: 1.425e-01, Loss Eqns: 2.289e+00, Loss Aux: 7.352e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14645, It: 0, Loss Data: 1.211e-01, Loss Eqns: 2.275e+00, Loss Aux: 5.566e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14646, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.446e+00, Loss Aux: 5.423e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14647, It: 0, Loss Data: 1.396e-01, Loss Eqns: 2.358e+00, Loss Aux: 6.342e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14648, It: 0, Loss Data: 1.124e-01, Loss Eqns: 2.267e+00, Loss Aux: 4.949e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14649, It: 0, Loss Data: 1.510e-01, Loss Eqns: 2.312e+00, Loss Aux: 4.300e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14650, It: 0, Loss Data: 1.069e-01, Loss Eqns: 2.393e+00, Loss Aux: 4.699e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14651, It: 0, Loss Data: 1.169e-01, Loss Eqns: 2.538e+00, Loss Aux: 6.002e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14652, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.312e+00, Loss Aux: 5.562e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14653, It: 0, Loss Data: 9.954e-02, Loss Eqns: 2.463e+00, Loss Aux: 4.070e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14654, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.720e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14655, It: 0, Loss Data: 8.251e-02, Loss Eqns: 2.522e+00, Loss Aux: 5.244e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14656, It: 0, Loss Data: 9.429e-02, Loss Eqns: 2.456e+00, Loss Aux: 7.552e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14657, It: 0, Loss Data: 1.048e-01, Loss Eqns: 2.307e+00, Loss Aux: 7.671e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14658, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.406e+00, Loss Aux: 6.264e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14659, It: 0, Loss Data: 9.568e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.158e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14660, It: 0, Loss Data: 9.616e-02, Loss Eqns: 2.466e+00, Loss Aux: 4.453e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14661, It: 0, Loss Data: 9.402e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.154e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14662, It: 0, Loss Data: 9.466e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.982e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14663, It: 0, Loss Data: 9.506e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.094e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14664, It: 0, Loss Data: 8.318e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.562e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14665, It: 0, Loss Data: 8.017e-02, Loss Eqns: 2.390e+00, Loss Aux: 5.008e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14666, It: 0, Loss Data: 7.406e-02, Loss Eqns: 2.354e+00, Loss Aux: 5.057e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14667, It: 0, Loss Data: 9.244e-02, Loss Eqns: 2.346e+00, Loss Aux: 5.611e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14668, It: 0, Loss Data: 9.076e-02, Loss Eqns: 2.365e+00, Loss Aux: 6.050e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14669, It: 0, Loss Data: 9.387e-02, Loss Eqns: 2.372e+00, Loss Aux: 6.386e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14670, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.293e+00, Loss Aux: 5.491e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14671, It: 0, Loss Data: 9.569e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.455e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14672, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.289e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 14673, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.847e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14674, It: 0, Loss Data: 8.924e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.825e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14675, It: 0, Loss Data: 8.788e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.351e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14676, It: 0, Loss Data: 9.705e-02, Loss Eqns: 2.338e+00, Loss Aux: 4.334e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14677, It: 0, Loss Data: 7.963e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.719e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14678, It: 0, Loss Data: 8.006e-02, Loss Eqns: 2.407e+00, Loss Aux: 5.359e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14679, It: 0, Loss Data: 8.052e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.822e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14680, It: 0, Loss Data: 9.207e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.205e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14681, It: 0, Loss Data: 8.012e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.221e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14682, It: 0, Loss Data: 8.879e-02, Loss Eqns: 2.426e+00, Loss Aux: 4.689e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14683, It: 0, Loss Data: 9.712e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.979e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 14684, It: 0, Loss Data: 8.339e-02, Loss Eqns: 2.226e+00, Loss Aux: 5.254e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14685, It: 0, Loss Data: 8.629e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.457e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14686, It: 0, Loss Data: 8.205e-02, Loss Eqns: 2.302e+00, Loss Aux: 5.574e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14687, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.359e+00, Loss Aux: 5.180e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14688, It: 0, Loss Data: 7.623e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.647e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14689, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.289e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14690, It: 0, Loss Data: 7.416e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.123e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14691, It: 0, Loss Data: 9.601e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.999e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14692, It: 0, Loss Data: 8.309e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.018e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14693, It: 0, Loss Data: 7.795e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.687e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14694, It: 0, Loss Data: 9.367e-02, Loss Eqns: 2.165e+00, Loss Aux: 5.747e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14695, It: 0, Loss Data: 8.216e-02, Loss Eqns: 2.300e+00, Loss Aux: 5.755e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14696, It: 0, Loss Data: 8.146e-02, Loss Eqns: 2.358e+00, Loss Aux: 5.195e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14697, It: 0, Loss Data: 9.400e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.958e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14698, It: 0, Loss Data: 9.548e-02, Loss Eqns: 2.229e+00, Loss Aux: 4.952e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14699, It: 0, Loss Data: 7.228e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.698e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14700, It: 0, Loss Data: 8.716e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.247e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14701, It: 0, Loss Data: 8.588e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.046e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14702, It: 0, Loss Data: 9.937e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.245e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14703, It: 0, Loss Data: 8.381e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.614e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 14704, It: 0, Loss Data: 7.869e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.767e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14705, It: 0, Loss Data: 1.058e-01, Loss Eqns: 2.280e+00, Loss Aux: 4.546e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14706, It: 0, Loss Data: 9.204e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.680e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14707, It: 0, Loss Data: 8.248e-02, Loss Eqns: 2.299e+00, Loss Aux: 5.133e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14708, It: 0, Loss Data: 7.992e-02, Loss Eqns: 2.249e+00, Loss Aux: 5.461e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 14709, It: 0, Loss Data: 9.554e-02, Loss Eqns: 2.319e+00, Loss Aux: 5.176e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14710, It: 0, Loss Data: 8.595e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.690e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14711, It: 0, Loss Data: 8.369e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.724e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14712, It: 0, Loss Data: 6.552e-02, Loss Eqns: 2.344e+00, Loss Aux: 5.349e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14713, It: 0, Loss Data: 7.809e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.918e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14714, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.433e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14715, It: 0, Loss Data: 8.113e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.658e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14716, It: 0, Loss Data: 8.369e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.270e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14717, It: 0, Loss Data: 9.546e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.936e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14718, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.339e+00, Loss Aux: 3.878e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14719, It: 0, Loss Data: 9.371e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.243e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14720, It: 0, Loss Data: 8.372e-02, Loss Eqns: 2.352e+00, Loss Aux: 5.132e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14721, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.321e+00, Loss Aux: 5.104e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14722, It: 0, Loss Data: 9.241e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.750e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 14723, It: 0, Loss Data: 9.094e-02, Loss Eqns: 2.206e+00, Loss Aux: 4.781e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14724, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.763e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14725, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.470e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14726, It: 0, Loss Data: 8.075e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.622e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14727, It: 0, Loss Data: 8.061e-02, Loss Eqns: 2.306e+00, Loss Aux: 5.078e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14728, It: 0, Loss Data: 8.211e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.309e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 14729, It: 0, Loss Data: 8.067e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.752e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14730, It: 0, Loss Data: 8.541e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.119e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14731, It: 0, Loss Data: 9.202e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.888e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14732, It: 0, Loss Data: 8.409e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.489e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14733, It: 0, Loss Data: 7.373e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.842e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14734, It: 0, Loss Data: 9.476e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.622e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 14735, It: 0, Loss Data: 9.932e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.462e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14736, It: 0, Loss Data: 8.159e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.552e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14737, It: 0, Loss Data: 7.746e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.755e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 14738, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.865e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14739, It: 0, Loss Data: 7.682e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.701e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14740, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.836e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14741, It: 0, Loss Data: 7.934e-02, Loss Eqns: 2.222e+00, Loss Aux: 5.027e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14742, It: 0, Loss Data: 8.972e-02, Loss Eqns: 2.305e+00, Loss Aux: 5.035e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 14743, It: 0, Loss Data: 8.374e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.728e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14744, It: 0, Loss Data: 8.220e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.367e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14745, It: 0, Loss Data: 6.461e-02, Loss Eqns: 2.253e+00, Loss Aux: 3.871e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14746, It: 0, Loss Data: 6.989e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.861e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14747, It: 0, Loss Data: 8.615e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.225e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14748, It: 0, Loss Data: 8.879e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.274e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14749, It: 0, Loss Data: 9.389e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.375e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14750, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.837e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14751, It: 0, Loss Data: 7.251e-02, Loss Eqns: 2.312e+00, Loss Aux: 5.508e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14752, It: 0, Loss Data: 6.192e-02, Loss Eqns: 2.217e+00, Loss Aux: 5.389e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14753, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.725e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14754, It: 0, Loss Data: 9.645e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.084e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14755, It: 0, Loss Data: 9.761e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.086e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14756, It: 0, Loss Data: 8.419e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.010e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14757, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.757e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14758, It: 0, Loss Data: 7.821e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.803e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 14759, It: 0, Loss Data: 9.196e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.504e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14760, It: 0, Loss Data: 8.348e-02, Loss Eqns: 2.355e+00, Loss Aux: 5.243e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14761, It: 0, Loss Data: 9.245e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.958e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14762, It: 0, Loss Data: 8.155e-02, Loss Eqns: 2.358e+00, Loss Aux: 5.973e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14763, It: 0, Loss Data: 8.347e-02, Loss Eqns: 2.314e+00, Loss Aux: 5.082e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14764, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.200e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14765, It: 0, Loss Data: 8.705e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.296e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14766, It: 0, Loss Data: 9.238e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.431e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14767, It: 0, Loss Data: 8.299e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.441e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14768, It: 0, Loss Data: 8.519e-02, Loss Eqns: 2.385e+00, Loss Aux: 3.955e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14769, It: 0, Loss Data: 7.109e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.546e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14770, It: 0, Loss Data: 8.987e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.635e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14771, It: 0, Loss Data: 7.813e-02, Loss Eqns: 2.270e+00, Loss Aux: 3.854e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14772, It: 0, Loss Data: 7.312e-02, Loss Eqns: 2.308e+00, Loss Aux: 3.961e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14773, It: 0, Loss Data: 8.718e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.139e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14774, It: 0, Loss Data: 8.578e-02, Loss Eqns: 2.299e+00, Loss Aux: 5.032e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 14775, It: 0, Loss Data: 7.571e-02, Loss Eqns: 2.192e+00, Loss Aux: 5.655e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14776, It: 0, Loss Data: 7.755e-02, Loss Eqns: 2.117e+00, Loss Aux: 5.628e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14777, It: 0, Loss Data: 9.242e-02, Loss Eqns: 2.186e+00, Loss Aux: 4.883e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14778, It: 0, Loss Data: 7.794e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.265e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14779, It: 0, Loss Data: 8.861e-02, Loss Eqns: 2.240e+00, Loss Aux: 4.330e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14780, It: 0, Loss Data: 8.743e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.402e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14781, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.227e+00, Loss Aux: 3.971e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 14782, It: 0, Loss Data: 6.340e-02, Loss Eqns: 2.243e+00, Loss Aux: 3.953e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14783, It: 0, Loss Data: 8.265e-02, Loss Eqns: 2.230e+00, Loss Aux: 4.271e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14784, It: 0, Loss Data: 8.352e-02, Loss Eqns: 2.212e+00, Loss Aux: 4.546e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14785, It: 0, Loss Data: 9.190e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.818e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14786, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.205e+00, Loss Aux: 4.400e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14787, It: 0, Loss Data: 7.718e-02, Loss Eqns: 2.195e+00, Loss Aux: 3.745e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14788, It: 0, Loss Data: 8.703e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.589e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14789, It: 0, Loss Data: 8.108e-02, Loss Eqns: 2.333e+00, Loss Aux: 4.121e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14790, It: 0, Loss Data: 9.999e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.627e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14791, It: 0, Loss Data: 8.902e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.635e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14792, It: 0, Loss Data: 8.507e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.959e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14793, It: 0, Loss Data: 8.167e-02, Loss Eqns: 2.283e+00, Loss Aux: 3.890e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14794, It: 0, Loss Data: 9.177e-02, Loss Eqns: 2.361e+00, Loss Aux: 4.184e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14795, It: 0, Loss Data: 8.142e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.885e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14796, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.241e+00, Loss Aux: 5.141e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14797, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.204e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14798, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.245e+00, Loss Aux: 3.639e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14799, It: 0, Loss Data: 8.372e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.125e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14800, It: 0, Loss Data: 9.565e-02, Loss Eqns: 2.255e+00, Loss Aux: 5.058e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14801, It: 0, Loss Data: 8.775e-02, Loss Eqns: 2.249e+00, Loss Aux: 5.005e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14802, It: 0, Loss Data: 8.375e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.962e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14803, It: 0, Loss Data: 8.106e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.355e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14804, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.367e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14805, It: 0, Loss Data: 9.869e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.159e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14806, It: 0, Loss Data: 9.755e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.390e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14807, It: 0, Loss Data: 8.200e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.080e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14808, It: 0, Loss Data: 9.282e-02, Loss Eqns: 2.511e+00, Loss Aux: 4.041e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14809, It: 0, Loss Data: 7.548e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.498e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14810, It: 0, Loss Data: 7.732e-02, Loss Eqns: 2.418e+00, Loss Aux: 4.781e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 14811, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.371e+00, Loss Aux: 4.212e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14812, It: 0, Loss Data: 7.702e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.852e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14813, It: 0, Loss Data: 9.372e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.163e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14814, It: 0, Loss Data: 7.991e-02, Loss Eqns: 2.352e+00, Loss Aux: 5.377e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14815, It: 0, Loss Data: 8.273e-02, Loss Eqns: 2.278e+00, Loss Aux: 6.219e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14816, It: 0, Loss Data: 7.120e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.481e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14817, It: 0, Loss Data: 6.913e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.308e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 14818, It: 0, Loss Data: 8.327e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.860e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14819, It: 0, Loss Data: 7.768e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.582e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14820, It: 0, Loss Data: 8.868e-02, Loss Eqns: 2.188e+00, Loss Aux: 4.389e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14821, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.239e+00, Loss Aux: 3.862e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14822, It: 0, Loss Data: 8.899e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.819e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14823, It: 0, Loss Data: 8.094e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.616e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14824, It: 0, Loss Data: 9.924e-02, Loss Eqns: 2.296e+00, Loss Aux: 5.891e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14825, It: 0, Loss Data: 9.039e-02, Loss Eqns: 2.237e+00, Loss Aux: 5.878e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14826, It: 0, Loss Data: 8.717e-02, Loss Eqns: 2.167e+00, Loss Aux: 4.991e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14827, It: 0, Loss Data: 7.938e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.139e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14828, It: 0, Loss Data: 1.053e-01, Loss Eqns: 2.340e+00, Loss Aux: 3.808e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14829, It: 0, Loss Data: 8.591e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.266e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14830, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.315e+00, Loss Aux: 4.889e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14831, It: 0, Loss Data: 8.767e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.492e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14832, It: 0, Loss Data: 7.806e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.087e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 14833, It: 0, Loss Data: 8.498e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.352e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14834, It: 0, Loss Data: 7.658e-02, Loss Eqns: 2.360e+00, Loss Aux: 4.713e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14835, It: 0, Loss Data: 7.567e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.407e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14836, It: 0, Loss Data: 8.820e-02, Loss Eqns: 2.346e+00, Loss Aux: 3.943e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 14837, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.032e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 14838, It: 0, Loss Data: 9.412e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.563e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14839, It: 0, Loss Data: 8.271e-02, Loss Eqns: 2.258e+00, Loss Aux: 5.020e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14840, It: 0, Loss Data: 8.632e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.712e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14841, It: 0, Loss Data: 8.075e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.323e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14842, It: 0, Loss Data: 7.572e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.843e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14843, It: 0, Loss Data: 9.083e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.781e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 14844, It: 0, Loss Data: 8.841e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.675e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14845, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.291e+00, Loss Aux: 5.723e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14846, It: 0, Loss Data: 8.534e-02, Loss Eqns: 2.248e+00, Loss Aux: 5.557e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14847, It: 0, Loss Data: 8.455e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.751e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14848, It: 0, Loss Data: 7.821e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.269e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14849, It: 0, Loss Data: 8.120e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.342e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 14850, It: 0, Loss Data: 8.113e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.595e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14851, It: 0, Loss Data: 9.019e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.473e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14852, It: 0, Loss Data: 8.678e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.261e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14853, It: 0, Loss Data: 7.118e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.133e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14854, It: 0, Loss Data: 7.833e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.314e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14855, It: 0, Loss Data: 7.958e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.366e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 14856, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.153e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14857, It: 0, Loss Data: 7.744e-02, Loss Eqns: 2.347e+00, Loss Aux: 3.800e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14858, It: 0, Loss Data: 7.689e-02, Loss Eqns: 2.178e+00, Loss Aux: 3.910e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14859, It: 0, Loss Data: 7.976e-02, Loss Eqns: 2.166e+00, Loss Aux: 4.600e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14860, It: 0, Loss Data: 9.394e-02, Loss Eqns: 2.204e+00, Loss Aux: 5.662e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14861, It: 0, Loss Data: 8.714e-02, Loss Eqns: 2.239e+00, Loss Aux: 5.223e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14862, It: 0, Loss Data: 8.729e-02, Loss Eqns: 2.099e+00, Loss Aux: 4.166e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14863, It: 0, Loss Data: 9.458e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.558e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14864, It: 0, Loss Data: 8.404e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.820e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 14865, It: 0, Loss Data: 8.937e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.710e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14866, It: 0, Loss Data: 8.397e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.988e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14867, It: 0, Loss Data: 7.500e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.784e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14868, It: 0, Loss Data: 9.632e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.202e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14869, It: 0, Loss Data: 7.724e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.121e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 14870, It: 0, Loss Data: 7.820e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.835e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14871, It: 0, Loss Data: 7.989e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.105e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14872, It: 0, Loss Data: 8.886e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.771e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14873, It: 0, Loss Data: 8.242e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.811e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14874, It: 0, Loss Data: 9.145e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.527e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14875, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.232e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14876, It: 0, Loss Data: 8.925e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.948e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14877, It: 0, Loss Data: 7.661e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.001e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14878, It: 0, Loss Data: 9.028e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.497e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14879, It: 0, Loss Data: 8.434e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.931e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 14880, It: 0, Loss Data: 7.282e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.916e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14881, It: 0, Loss Data: 8.195e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.643e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14882, It: 0, Loss Data: 8.806e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.722e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14883, It: 0, Loss Data: 7.926e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.976e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14884, It: 0, Loss Data: 7.904e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.587e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 14885, It: 0, Loss Data: 7.001e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.481e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 14886, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.666e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14887, It: 0, Loss Data: 8.315e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.568e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14888, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.225e+00, Loss Aux: 3.909e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14889, It: 0, Loss Data: 9.463e-02, Loss Eqns: 2.237e+00, Loss Aux: 3.702e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14890, It: 0, Loss Data: 8.186e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.242e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 14891, It: 0, Loss Data: 8.036e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.727e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 14892, It: 0, Loss Data: 8.538e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.707e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14893, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.795e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14894, It: 0, Loss Data: 9.728e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.377e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14895, It: 0, Loss Data: 9.685e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.174e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 14896, It: 0, Loss Data: 8.193e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.385e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14897, It: 0, Loss Data: 8.172e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.111e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14898, It: 0, Loss Data: 8.452e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.890e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14899, It: 0, Loss Data: 7.987e-02, Loss Eqns: 2.373e+00, Loss Aux: 4.562e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14900, It: 0, Loss Data: 7.702e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.117e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14901, It: 0, Loss Data: 7.714e-02, Loss Eqns: 2.360e+00, Loss Aux: 3.568e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14902, It: 0, Loss Data: 8.243e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.447e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14903, It: 0, Loss Data: 8.625e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.763e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14904, It: 0, Loss Data: 7.594e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.993e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14905, It: 0, Loss Data: 7.911e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.341e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14906, It: 0, Loss Data: 9.605e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.665e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14907, It: 0, Loss Data: 7.846e-02, Loss Eqns: 2.257e+00, Loss Aux: 5.189e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 14908, It: 0, Loss Data: 8.425e-02, Loss Eqns: 2.284e+00, Loss Aux: 5.204e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14909, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.587e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14910, It: 0, Loss Data: 8.549e-02, Loss Eqns: 2.240e+00, Loss Aux: 4.240e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14911, It: 0, Loss Data: 7.995e-02, Loss Eqns: 2.340e+00, Loss Aux: 3.809e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14912, It: 0, Loss Data: 8.901e-02, Loss Eqns: 2.303e+00, Loss Aux: 3.597e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14913, It: 0, Loss Data: 9.170e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.632e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14914, It: 0, Loss Data: 8.662e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.031e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14915, It: 0, Loss Data: 8.491e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.899e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14916, It: 0, Loss Data: 7.986e-02, Loss Eqns: 2.314e+00, Loss Aux: 5.002e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14917, It: 0, Loss Data: 7.774e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.551e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 14918, It: 0, Loss Data: 8.884e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.357e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 14919, It: 0, Loss Data: 7.260e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.092e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14920, It: 0, Loss Data: 8.871e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.026e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14921, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.752e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14922, It: 0, Loss Data: 8.026e-02, Loss Eqns: 2.351e+00, Loss Aux: 5.234e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14923, It: 0, Loss Data: 8.205e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.918e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14924, It: 0, Loss Data: 9.265e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.532e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14925, It: 0, Loss Data: 8.424e-02, Loss Eqns: 2.388e+00, Loss Aux: 4.370e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14926, It: 0, Loss Data: 9.571e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.126e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14927, It: 0, Loss Data: 8.144e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.840e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14928, It: 0, Loss Data: 7.258e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.195e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 14929, It: 0, Loss Data: 7.062e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.610e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14930, It: 0, Loss Data: 8.029e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.784e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14931, It: 0, Loss Data: 8.677e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.767e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14932, It: 0, Loss Data: 9.640e-02, Loss Eqns: 2.231e+00, Loss Aux: 4.555e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 14933, It: 0, Loss Data: 7.942e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.447e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 14934, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.431e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14935, It: 0, Loss Data: 8.953e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.654e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 14936, It: 0, Loss Data: 7.773e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.689e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 14937, It: 0, Loss Data: 9.026e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.241e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 14938, It: 0, Loss Data: 8.223e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.868e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14939, It: 0, Loss Data: 8.864e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.029e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14940, It: 0, Loss Data: 8.515e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.627e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14941, It: 0, Loss Data: 7.738e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.899e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14942, It: 0, Loss Data: 7.155e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.298e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 14943, It: 0, Loss Data: 9.472e-02, Loss Eqns: 2.299e+00, Loss Aux: 3.914e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 14944, It: 0, Loss Data: 7.792e-02, Loss Eqns: 2.223e+00, Loss Aux: 3.923e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14945, It: 0, Loss Data: 9.137e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.456e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14946, It: 0, Loss Data: 7.943e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.848e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 14947, It: 0, Loss Data: 8.793e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.692e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 14948, It: 0, Loss Data: 6.854e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.444e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14949, It: 0, Loss Data: 8.658e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.468e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14950, It: 0, Loss Data: 8.038e-02, Loss Eqns: 2.186e+00, Loss Aux: 4.674e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14951, It: 0, Loss Data: 7.761e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.080e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 14952, It: 0, Loss Data: 7.268e-02, Loss Eqns: 2.248e+00, Loss Aux: 3.523e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14953, It: 0, Loss Data: 8.421e-02, Loss Eqns: 2.212e+00, Loss Aux: 4.324e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 14954, It: 0, Loss Data: 1.023e-01, Loss Eqns: 2.210e+00, Loss Aux: 5.437e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 14955, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.224e+00, Loss Aux: 5.558e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14956, It: 0, Loss Data: 7.359e-02, Loss Eqns: 2.169e+00, Loss Aux: 4.169e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 14957, It: 0, Loss Data: 7.544e-02, Loss Eqns: 2.175e+00, Loss Aux: 3.289e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14958, It: 0, Loss Data: 8.476e-02, Loss Eqns: 2.239e+00, Loss Aux: 3.558e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 14959, It: 0, Loss Data: 9.047e-02, Loss Eqns: 2.182e+00, Loss Aux: 5.024e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14960, It: 0, Loss Data: 9.987e-02, Loss Eqns: 2.182e+00, Loss Aux: 5.727e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14961, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.192e+00, Loss Aux: 4.763e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14962, It: 0, Loss Data: 8.379e-02, Loss Eqns: 2.272e+00, Loss Aux: 3.960e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 14963, It: 0, Loss Data: 9.204e-02, Loss Eqns: 2.209e+00, Loss Aux: 3.905e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 14964, It: 0, Loss Data: 9.753e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.823e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14965, It: 0, Loss Data: 9.498e-02, Loss Eqns: 2.230e+00, Loss Aux: 4.644e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 14966, It: 0, Loss Data: 8.850e-02, Loss Eqns: 2.247e+00, Loss Aux: 3.371e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14967, It: 0, Loss Data: 9.174e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.143e-02, Time: 0.145, Learning Rate: 1.0e-03\n",
      "Epoch: 14968, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.879e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 14969, It: 0, Loss Data: 8.406e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.792e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14970, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.382e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 14971, It: 0, Loss Data: 8.234e-02, Loss Eqns: 2.361e+00, Loss Aux: 3.919e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 14972, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.305e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 14973, It: 0, Loss Data: 6.729e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.838e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 14974, It: 0, Loss Data: 9.959e-02, Loss Eqns: 2.262e+00, Loss Aux: 5.343e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 14975, It: 0, Loss Data: 7.804e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.704e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14976, It: 0, Loss Data: 8.628e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.422e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 14977, It: 0, Loss Data: 9.867e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.384e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14978, It: 0, Loss Data: 8.020e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.693e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 14979, It: 0, Loss Data: 8.797e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.486e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14980, It: 0, Loss Data: 9.007e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.661e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 14981, It: 0, Loss Data: 8.349e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.606e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14982, It: 0, Loss Data: 8.276e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.561e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14983, It: 0, Loss Data: 7.926e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.530e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14984, It: 0, Loss Data: 8.649e-02, Loss Eqns: 2.335e+00, Loss Aux: 5.345e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 14985, It: 0, Loss Data: 7.995e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.352e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14986, It: 0, Loss Data: 9.251e-02, Loss Eqns: 2.403e+00, Loss Aux: 3.921e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 14987, It: 0, Loss Data: 8.600e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.026e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 14988, It: 0, Loss Data: 9.701e-02, Loss Eqns: 2.367e+00, Loss Aux: 4.549e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 14989, It: 0, Loss Data: 9.284e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.790e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 14990, It: 0, Loss Data: 7.120e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.245e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 14991, It: 0, Loss Data: 8.051e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.938e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 14992, It: 0, Loss Data: 7.216e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.262e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 14993, It: 0, Loss Data: 6.980e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.472e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 14994, It: 0, Loss Data: 7.806e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.726e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 14995, It: 0, Loss Data: 7.685e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.998e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 14996, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.272e+00, Loss Aux: 5.335e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 14997, It: 0, Loss Data: 8.996e-02, Loss Eqns: 2.247e+00, Loss Aux: 5.337e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 14998, It: 0, Loss Data: 6.777e-02, Loss Eqns: 2.259e+00, Loss Aux: 5.089e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 14999, It: 0, Loss Data: 8.398e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.290e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15000, It: 0, Loss Data: 8.369e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.982e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15001, It: 0, Loss Data: 8.474e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.837e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15002, It: 0, Loss Data: 8.601e-02, Loss Eqns: 2.232e+00, Loss Aux: 3.478e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15003, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.364e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 15004, It: 0, Loss Data: 9.481e-02, Loss Eqns: 2.223e+00, Loss Aux: 3.897e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15005, It: 0, Loss Data: 7.808e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.408e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 15006, It: 0, Loss Data: 7.375e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.441e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15007, It: 0, Loss Data: 7.508e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.254e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15008, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.712e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15009, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.192e+00, Loss Aux: 5.086e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15010, It: 0, Loss Data: 7.575e-02, Loss Eqns: 2.244e+00, Loss Aux: 5.148e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15011, It: 0, Loss Data: 8.104e-02, Loss Eqns: 2.242e+00, Loss Aux: 5.249e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15012, It: 0, Loss Data: 8.054e-02, Loss Eqns: 2.174e+00, Loss Aux: 4.854e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15013, It: 0, Loss Data: 8.764e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.500e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15014, It: 0, Loss Data: 9.848e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.015e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15015, It: 0, Loss Data: 7.982e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.690e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15016, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.459e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15017, It: 0, Loss Data: 8.529e-02, Loss Eqns: 2.263e+00, Loss Aux: 3.512e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15018, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.261e+00, Loss Aux: 3.969e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15019, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.788e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15020, It: 0, Loss Data: 7.247e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.900e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15021, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.765e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 15022, It: 0, Loss Data: 8.709e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.710e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15023, It: 0, Loss Data: 7.408e-02, Loss Eqns: 2.292e+00, Loss Aux: 5.456e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15024, It: 0, Loss Data: 7.210e-02, Loss Eqns: 2.189e+00, Loss Aux: 5.614e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15025, It: 0, Loss Data: 8.135e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.639e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15026, It: 0, Loss Data: 8.718e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.691e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15027, It: 0, Loss Data: 8.897e-02, Loss Eqns: 2.267e+00, Loss Aux: 3.736e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15028, It: 0, Loss Data: 8.910e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.456e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15029, It: 0, Loss Data: 8.471e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.260e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15030, It: 0, Loss Data: 9.378e-02, Loss Eqns: 2.261e+00, Loss Aux: 3.783e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15031, It: 0, Loss Data: 8.691e-02, Loss Eqns: 2.260e+00, Loss Aux: 3.492e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 15032, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.693e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 15033, It: 0, Loss Data: 8.476e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.276e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15034, It: 0, Loss Data: 7.933e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.741e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15035, It: 0, Loss Data: 8.059e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.923e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15036, It: 0, Loss Data: 7.995e-02, Loss Eqns: 2.317e+00, Loss Aux: 5.092e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15037, It: 0, Loss Data: 9.034e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.811e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15038, It: 0, Loss Data: 7.728e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.499e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15039, It: 0, Loss Data: 7.884e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.240e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15040, It: 0, Loss Data: 8.644e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.061e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15041, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.438e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15042, It: 0, Loss Data: 8.376e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.705e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15043, It: 0, Loss Data: 7.252e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.244e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15044, It: 0, Loss Data: 8.787e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.806e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15045, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.022e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15046, It: 0, Loss Data: 8.016e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.375e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15047, It: 0, Loss Data: 7.440e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.724e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15048, It: 0, Loss Data: 8.252e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.258e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15049, It: 0, Loss Data: 8.871e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.155e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15050, It: 0, Loss Data: 7.837e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.376e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15051, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.956e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 15052, It: 0, Loss Data: 8.187e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.624e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15053, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.896e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15054, It: 0, Loss Data: 7.608e-02, Loss Eqns: 2.218e+00, Loss Aux: 3.880e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15055, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.194e+00, Loss Aux: 4.435e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15056, It: 0, Loss Data: 7.960e-02, Loss Eqns: 2.200e+00, Loss Aux: 4.807e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15057, It: 0, Loss Data: 7.932e-02, Loss Eqns: 2.208e+00, Loss Aux: 4.505e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15058, It: 0, Loss Data: 9.357e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.645e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15059, It: 0, Loss Data: 9.372e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.732e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15060, It: 0, Loss Data: 7.084e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.568e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15061, It: 0, Loss Data: 8.875e-02, Loss Eqns: 2.267e+00, Loss Aux: 5.588e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15062, It: 0, Loss Data: 8.078e-02, Loss Eqns: 2.307e+00, Loss Aux: 5.360e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15063, It: 0, Loss Data: 9.109e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.129e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15064, It: 0, Loss Data: 9.307e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.616e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15065, It: 0, Loss Data: 7.883e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.085e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15066, It: 0, Loss Data: 9.103e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.808e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15067, It: 0, Loss Data: 9.044e-02, Loss Eqns: 2.194e+00, Loss Aux: 4.756e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15068, It: 0, Loss Data: 8.099e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.097e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15069, It: 0, Loss Data: 8.828e-02, Loss Eqns: 2.242e+00, Loss Aux: 3.600e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15070, It: 0, Loss Data: 9.874e-02, Loss Eqns: 2.253e+00, Loss Aux: 3.790e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15071, It: 0, Loss Data: 7.652e-02, Loss Eqns: 2.326e+00, Loss Aux: 3.871e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15072, It: 0, Loss Data: 9.279e-02, Loss Eqns: 2.202e+00, Loss Aux: 4.023e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15073, It: 0, Loss Data: 8.231e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.241e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15074, It: 0, Loss Data: 7.638e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.620e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15075, It: 0, Loss Data: 8.328e-02, Loss Eqns: 2.340e+00, Loss Aux: 5.498e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15076, It: 0, Loss Data: 8.490e-02, Loss Eqns: 2.288e+00, Loss Aux: 5.948e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15077, It: 0, Loss Data: 7.414e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.950e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15078, It: 0, Loss Data: 9.192e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.959e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15079, It: 0, Loss Data: 8.150e-02, Loss Eqns: 2.381e+00, Loss Aux: 3.841e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15080, It: 0, Loss Data: 7.247e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.183e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15081, It: 0, Loss Data: 8.242e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.712e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15082, It: 0, Loss Data: 8.519e-02, Loss Eqns: 2.358e+00, Loss Aux: 5.166e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15083, It: 0, Loss Data: 9.201e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.783e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15084, It: 0, Loss Data: 8.444e-02, Loss Eqns: 2.373e+00, Loss Aux: 3.865e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15085, It: 0, Loss Data: 7.544e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.632e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15086, It: 0, Loss Data: 8.538e-02, Loss Eqns: 2.375e+00, Loss Aux: 3.855e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15087, It: 0, Loss Data: 9.089e-02, Loss Eqns: 2.297e+00, Loss Aux: 3.795e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15088, It: 0, Loss Data: 6.217e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.963e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15089, It: 0, Loss Data: 7.541e-02, Loss Eqns: 2.402e+00, Loss Aux: 4.291e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 15090, It: 0, Loss Data: 8.126e-02, Loss Eqns: 2.233e+00, Loss Aux: 3.816e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 15091, It: 0, Loss Data: 9.513e-02, Loss Eqns: 2.217e+00, Loss Aux: 3.932e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15092, It: 0, Loss Data: 8.486e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.045e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15093, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.152e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15094, It: 0, Loss Data: 7.731e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.683e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15095, It: 0, Loss Data: 8.822e-02, Loss Eqns: 2.350e+00, Loss Aux: 5.046e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15096, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.385e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15097, It: 0, Loss Data: 7.663e-02, Loss Eqns: 2.228e+00, Loss Aux: 3.542e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15098, It: 0, Loss Data: 9.334e-02, Loss Eqns: 2.281e+00, Loss Aux: 3.245e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15099, It: 0, Loss Data: 8.748e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.295e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15100, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.130e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15101, It: 0, Loss Data: 8.594e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.944e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15102, It: 0, Loss Data: 9.029e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.945e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15103, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.433e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15104, It: 0, Loss Data: 7.826e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.217e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15105, It: 0, Loss Data: 9.696e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.290e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15106, It: 0, Loss Data: 8.388e-02, Loss Eqns: 2.543e+00, Loss Aux: 3.205e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15107, It: 0, Loss Data: 9.778e-02, Loss Eqns: 2.497e+00, Loss Aux: 4.920e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15108, It: 0, Loss Data: 8.702e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.446e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15109, It: 0, Loss Data: 8.697e-02, Loss Eqns: 2.486e+00, Loss Aux: 3.755e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15110, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.450e+00, Loss Aux: 4.183e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15111, It: 0, Loss Data: 7.804e-02, Loss Eqns: 2.460e+00, Loss Aux: 4.442e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15112, It: 0, Loss Data: 9.700e-02, Loss Eqns: 2.491e+00, Loss Aux: 4.253e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15113, It: 0, Loss Data: 7.909e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.899e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15114, It: 0, Loss Data: 9.537e-02, Loss Eqns: 2.489e+00, Loss Aux: 4.740e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15115, It: 0, Loss Data: 9.344e-02, Loss Eqns: 2.457e+00, Loss Aux: 4.159e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15116, It: 0, Loss Data: 9.971e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.564e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15117, It: 0, Loss Data: 8.963e-02, Loss Eqns: 2.635e+00, Loss Aux: 5.003e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15118, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.335e+00, Loss Aux: 3.849e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15119, It: 0, Loss Data: 9.786e-02, Loss Eqns: 2.298e+00, Loss Aux: 3.681e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15120, It: 0, Loss Data: 9.215e-02, Loss Eqns: 2.448e+00, Loss Aux: 4.391e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15121, It: 0, Loss Data: 7.653e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.214e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15122, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.372e+00, Loss Aux: 4.508e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15123, It: 0, Loss Data: 9.303e-02, Loss Eqns: 2.423e+00, Loss Aux: 5.145e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15124, It: 0, Loss Data: 8.747e-02, Loss Eqns: 2.435e+00, Loss Aux: 5.496e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15125, It: 0, Loss Data: 8.892e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.766e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15126, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.638e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15127, It: 0, Loss Data: 9.702e-02, Loss Eqns: 2.453e+00, Loss Aux: 4.921e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15128, It: 0, Loss Data: 8.934e-02, Loss Eqns: 2.469e+00, Loss Aux: 5.839e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15129, It: 0, Loss Data: 1.179e-01, Loss Eqns: 2.953e+00, Loss Aux: 3.731e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15130, It: 0, Loss Data: 8.760e-02, Loss Eqns: 2.401e+00, Loss Aux: 3.805e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15131, It: 0, Loss Data: 9.119e-02, Loss Eqns: 3.224e+00, Loss Aux: 4.808e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15132, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.167e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15133, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.637e+00, Loss Aux: 3.760e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15134, It: 0, Loss Data: 1.562e-01, Loss Eqns: 4.005e+00, Loss Aux: 7.382e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15135, It: 0, Loss Data: 2.303e-01, Loss Eqns: 4.669e+00, Loss Aux: 3.518e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15136, It: 0, Loss Data: 1.421e-01, Loss Eqns: 3.747e+00, Loss Aux: 5.122e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15137, It: 0, Loss Data: 1.908e-01, Loss Eqns: 3.472e+00, Loss Aux: 1.098e-01, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15138, It: 0, Loss Data: 2.373e-01, Loss Eqns: 3.732e+00, Loss Aux: 1.017e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15139, It: 0, Loss Data: 2.061e-01, Loss Eqns: 4.121e+00, Loss Aux: 2.716e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15140, It: 0, Loss Data: 2.714e-01, Loss Eqns: 4.896e+00, Loss Aux: 2.718e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15141, It: 0, Loss Data: 1.297e-01, Loss Eqns: 2.512e+00, Loss Aux: 6.328e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 15142, It: 0, Loss Data: 3.001e-01, Loss Eqns: 5.250e+00, Loss Aux: 1.130e-01, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15143, It: 0, Loss Data: 1.317e-01, Loss Eqns: 2.615e+00, Loss Aux: 6.212e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 15144, It: 0, Loss Data: 2.231e-01, Loss Eqns: 3.899e+00, Loss Aux: 3.029e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15145, It: 0, Loss Data: 1.722e-01, Loss Eqns: 3.463e+00, Loss Aux: 3.061e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15146, It: 0, Loss Data: 1.052e-01, Loss Eqns: 2.479e+00, Loss Aux: 6.171e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 15147, It: 0, Loss Data: 1.769e-01, Loss Eqns: 3.667e+00, Loss Aux: 8.706e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15148, It: 0, Loss Data: 1.374e-01, Loss Eqns: 2.611e+00, Loss Aux: 7.267e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15149, It: 0, Loss Data: 1.674e-01, Loss Eqns: 2.644e+00, Loss Aux: 5.090e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 15150, It: 0, Loss Data: 1.694e-01, Loss Eqns: 2.894e+00, Loss Aux: 4.359e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15151, It: 0, Loss Data: 1.180e-01, Loss Eqns: 2.375e+00, Loss Aux: 5.458e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15152, It: 0, Loss Data: 2.323e-01, Loss Eqns: 3.366e+00, Loss Aux: 8.746e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15153, It: 0, Loss Data: 1.192e-01, Loss Eqns: 2.464e+00, Loss Aux: 6.845e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15154, It: 0, Loss Data: 1.871e-01, Loss Eqns: 2.720e+00, Loss Aux: 4.388e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15155, It: 0, Loss Data: 1.853e-01, Loss Eqns: 3.079e+00, Loss Aux: 3.905e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15156, It: 0, Loss Data: 1.377e-01, Loss Eqns: 2.394e+00, Loss Aux: 7.373e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15157, It: 0, Loss Data: 1.452e-01, Loss Eqns: 2.662e+00, Loss Aux: 1.077e-01, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15158, It: 0, Loss Data: 1.243e-01, Loss Eqns: 2.931e+00, Loss Aux: 9.480e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15159, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.337e+00, Loss Aux: 6.372e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15160, It: 0, Loss Data: 1.247e-01, Loss Eqns: 2.852e+00, Loss Aux: 4.685e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15161, It: 0, Loss Data: 1.332e-01, Loss Eqns: 2.621e+00, Loss Aux: 4.879e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15162, It: 0, Loss Data: 1.155e-01, Loss Eqns: 2.460e+00, Loss Aux: 5.935e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15163, It: 0, Loss Data: 1.221e-01, Loss Eqns: 2.831e+00, Loss Aux: 5.241e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15164, It: 0, Loss Data: 1.108e-01, Loss Eqns: 2.456e+00, Loss Aux: 4.290e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15165, It: 0, Loss Data: 1.128e-01, Loss Eqns: 2.535e+00, Loss Aux: 4.411e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15166, It: 0, Loss Data: 1.099e-01, Loss Eqns: 2.550e+00, Loss Aux: 5.263e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15167, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.364e+00, Loss Aux: 7.164e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15168, It: 0, Loss Data: 9.898e-02, Loss Eqns: 2.574e+00, Loss Aux: 7.511e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15169, It: 0, Loss Data: 9.238e-02, Loss Eqns: 2.426e+00, Loss Aux: 6.759e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15170, It: 0, Loss Data: 1.063e-01, Loss Eqns: 2.409e+00, Loss Aux: 5.709e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15171, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.486e+00, Loss Aux: 5.759e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15172, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.315e+00, Loss Aux: 6.217e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15173, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.465e+00, Loss Aux: 5.891e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15174, It: 0, Loss Data: 9.740e-02, Loss Eqns: 2.438e+00, Loss Aux: 4.854e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15175, It: 0, Loss Data: 9.996e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.062e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15176, It: 0, Loss Data: 1.334e-01, Loss Eqns: 2.509e+00, Loss Aux: 3.145e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15177, It: 0, Loss Data: 8.500e-02, Loss Eqns: 2.404e+00, Loss Aux: 5.659e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15178, It: 0, Loss Data: 1.237e-01, Loss Eqns: 2.477e+00, Loss Aux: 7.979e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15179, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.493e+00, Loss Aux: 7.652e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15180, It: 0, Loss Data: 9.488e-02, Loss Eqns: 2.360e+00, Loss Aux: 5.960e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15181, It: 0, Loss Data: 1.055e-01, Loss Eqns: 2.416e+00, Loss Aux: 5.973e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15182, It: 0, Loss Data: 9.965e-02, Loss Eqns: 2.385e+00, Loss Aux: 7.221e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15183, It: 0, Loss Data: 9.451e-02, Loss Eqns: 2.378e+00, Loss Aux: 7.082e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15184, It: 0, Loss Data: 9.031e-02, Loss Eqns: 2.496e+00, Loss Aux: 4.724e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15185, It: 0, Loss Data: 1.100e-01, Loss Eqns: 2.427e+00, Loss Aux: 3.572e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15186, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.917e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15187, It: 0, Loss Data: 9.269e-02, Loss Eqns: 2.446e+00, Loss Aux: 5.912e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15188, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.304e+00, Loss Aux: 7.126e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15189, It: 0, Loss Data: 8.243e-02, Loss Eqns: 2.450e+00, Loss Aux: 6.252e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15190, It: 0, Loss Data: 9.322e-02, Loss Eqns: 2.345e+00, Loss Aux: 5.451e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15191, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.492e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15192, It: 0, Loss Data: 8.943e-02, Loss Eqns: 2.423e+00, Loss Aux: 6.444e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15193, It: 0, Loss Data: 9.710e-02, Loss Eqns: 2.251e+00, Loss Aux: 6.180e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15194, It: 0, Loss Data: 8.674e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.986e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15195, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.317e+00, Loss Aux: 5.253e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15196, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.330e+00, Loss Aux: 5.459e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15197, It: 0, Loss Data: 9.297e-02, Loss Eqns: 2.335e+00, Loss Aux: 5.720e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15198, It: 0, Loss Data: 9.383e-02, Loss Eqns: 2.272e+00, Loss Aux: 5.782e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15199, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.307e+00, Loss Aux: 5.029e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15200, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.202e+00, Loss Aux: 4.697e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15201, It: 0, Loss Data: 9.600e-02, Loss Eqns: 2.227e+00, Loss Aux: 5.183e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15202, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.376e+00, Loss Aux: 5.555e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15203, It: 0, Loss Data: 9.166e-02, Loss Eqns: 2.271e+00, Loss Aux: 5.328e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15204, It: 0, Loss Data: 7.427e-02, Loss Eqns: 2.215e+00, Loss Aux: 5.150e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15205, It: 0, Loss Data: 9.485e-02, Loss Eqns: 2.295e+00, Loss Aux: 5.497e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 15206, It: 0, Loss Data: 7.582e-02, Loss Eqns: 2.255e+00, Loss Aux: 5.731e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15207, It: 0, Loss Data: 8.580e-02, Loss Eqns: 2.311e+00, Loss Aux: 5.509e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15208, It: 0, Loss Data: 8.057e-02, Loss Eqns: 2.218e+00, Loss Aux: 5.005e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15209, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.238e+00, Loss Aux: 4.789e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15210, It: 0, Loss Data: 9.742e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.859e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15211, It: 0, Loss Data: 9.811e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.639e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15212, It: 0, Loss Data: 8.833e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.506e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15213, It: 0, Loss Data: 9.155e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.836e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15214, It: 0, Loss Data: 9.233e-02, Loss Eqns: 2.286e+00, Loss Aux: 5.175e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15215, It: 0, Loss Data: 8.004e-02, Loss Eqns: 2.276e+00, Loss Aux: 5.282e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15216, It: 0, Loss Data: 8.451e-02, Loss Eqns: 2.275e+00, Loss Aux: 5.107e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15217, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.737e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15218, It: 0, Loss Data: 8.358e-02, Loss Eqns: 2.392e+00, Loss Aux: 4.839e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15219, It: 0, Loss Data: 9.771e-02, Loss Eqns: 2.366e+00, Loss Aux: 5.387e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15220, It: 0, Loss Data: 7.603e-02, Loss Eqns: 2.311e+00, Loss Aux: 5.813e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15221, It: 0, Loss Data: 7.534e-02, Loss Eqns: 2.255e+00, Loss Aux: 5.623e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15222, It: 0, Loss Data: 8.232e-02, Loss Eqns: 2.366e+00, Loss Aux: 5.031e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15223, It: 0, Loss Data: 8.048e-02, Loss Eqns: 2.453e+00, Loss Aux: 4.585e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15224, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.694e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15225, It: 0, Loss Data: 7.961e-02, Loss Eqns: 2.333e+00, Loss Aux: 5.572e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15226, It: 0, Loss Data: 8.164e-02, Loss Eqns: 2.256e+00, Loss Aux: 6.105e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15227, It: 0, Loss Data: 9.037e-02, Loss Eqns: 2.336e+00, Loss Aux: 5.306e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15228, It: 0, Loss Data: 9.147e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.453e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15229, It: 0, Loss Data: 9.622e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.338e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15230, It: 0, Loss Data: 6.259e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.400e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15231, It: 0, Loss Data: 7.635e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.248e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15232, It: 0, Loss Data: 8.900e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.079e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15233, It: 0, Loss Data: 9.428e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.191e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15234, It: 0, Loss Data: 6.820e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.759e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15235, It: 0, Loss Data: 9.793e-02, Loss Eqns: 2.329e+00, Loss Aux: 5.234e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15236, It: 0, Loss Data: 8.902e-02, Loss Eqns: 2.228e+00, Loss Aux: 5.213e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15237, It: 0, Loss Data: 7.572e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.179e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15238, It: 0, Loss Data: 8.751e-02, Loss Eqns: 2.292e+00, Loss Aux: 5.221e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15239, It: 0, Loss Data: 8.403e-02, Loss Eqns: 2.291e+00, Loss Aux: 5.395e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15240, It: 0, Loss Data: 8.855e-02, Loss Eqns: 2.395e+00, Loss Aux: 5.805e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 15241, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.256e+00, Loss Aux: 5.311e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15242, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.481e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15243, It: 0, Loss Data: 9.186e-02, Loss Eqns: 2.397e+00, Loss Aux: 4.410e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15244, It: 0, Loss Data: 8.617e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.814e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15245, It: 0, Loss Data: 7.624e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.909e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15246, It: 0, Loss Data: 8.384e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.808e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15247, It: 0, Loss Data: 8.277e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.647e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15248, It: 0, Loss Data: 8.699e-02, Loss Eqns: 2.401e+00, Loss Aux: 4.731e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15249, It: 0, Loss Data: 8.947e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.833e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15250, It: 0, Loss Data: 7.660e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.887e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15251, It: 0, Loss Data: 9.900e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.865e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15252, It: 0, Loss Data: 8.586e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.420e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15253, It: 0, Loss Data: 7.966e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.158e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15254, It: 0, Loss Data: 7.718e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.361e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15255, It: 0, Loss Data: 9.755e-02, Loss Eqns: 2.355e+00, Loss Aux: 5.128e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15256, It: 0, Loss Data: 8.938e-02, Loss Eqns: 2.293e+00, Loss Aux: 6.312e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15257, It: 0, Loss Data: 9.647e-02, Loss Eqns: 2.268e+00, Loss Aux: 6.497e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15258, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.284e+00, Loss Aux: 5.564e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15259, It: 0, Loss Data: 9.033e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.207e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15260, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.338e+00, Loss Aux: 3.863e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 15261, It: 0, Loss Data: 7.193e-02, Loss Eqns: 2.301e+00, Loss Aux: 4.336e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15262, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.286e+00, Loss Aux: 5.232e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15263, It: 0, Loss Data: 9.693e-02, Loss Eqns: 2.314e+00, Loss Aux: 5.119e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15264, It: 0, Loss Data: 8.667e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.869e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15265, It: 0, Loss Data: 1.433e-01, Loss Eqns: 3.028e+00, Loss Aux: 7.587e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15266, It: 0, Loss Data: 1.170e-01, Loss Eqns: 2.826e+00, Loss Aux: 4.685e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15267, It: 0, Loss Data: 1.469e-01, Loss Eqns: 3.300e+00, Loss Aux: 4.135e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15268, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.515e+00, Loss Aux: 4.232e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15269, It: 0, Loss Data: 1.218e-01, Loss Eqns: 3.151e+00, Loss Aux: 6.074e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15270, It: 0, Loss Data: 1.209e-01, Loss Eqns: 2.605e+00, Loss Aux: 5.922e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15271, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.658e+00, Loss Aux: 4.264e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15272, It: 0, Loss Data: 1.256e-01, Loss Eqns: 2.905e+00, Loss Aux: 3.821e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15273, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.901e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15274, It: 0, Loss Data: 1.199e-01, Loss Eqns: 2.884e+00, Loss Aux: 5.928e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15275, It: 0, Loss Data: 9.727e-02, Loss Eqns: 2.356e+00, Loss Aux: 5.141e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15276, It: 0, Loss Data: 1.018e-01, Loss Eqns: 2.500e+00, Loss Aux: 3.696e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15277, It: 0, Loss Data: 9.910e-02, Loss Eqns: 2.504e+00, Loss Aux: 3.312e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15278, It: 0, Loss Data: 9.452e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.531e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15279, It: 0, Loss Data: 1.107e-01, Loss Eqns: 2.532e+00, Loss Aux: 5.526e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15280, It: 0, Loss Data: 9.342e-02, Loss Eqns: 2.352e+00, Loss Aux: 5.126e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15281, It: 0, Loss Data: 1.061e-01, Loss Eqns: 2.335e+00, Loss Aux: 5.012e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15282, It: 0, Loss Data: 9.047e-02, Loss Eqns: 2.226e+00, Loss Aux: 5.222e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15283, It: 0, Loss Data: 8.463e-02, Loss Eqns: 2.353e+00, Loss Aux: 6.293e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15284, It: 0, Loss Data: 9.905e-02, Loss Eqns: 2.438e+00, Loss Aux: 6.166e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15285, It: 0, Loss Data: 9.031e-02, Loss Eqns: 2.252e+00, Loss Aux: 5.053e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15286, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.357e+00, Loss Aux: 3.931e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15287, It: 0, Loss Data: 9.940e-02, Loss Eqns: 2.220e+00, Loss Aux: 3.853e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15288, It: 0, Loss Data: 9.000e-02, Loss Eqns: 2.272e+00, Loss Aux: 5.022e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15289, It: 0, Loss Data: 9.555e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.630e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15290, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.979e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15291, It: 0, Loss Data: 9.345e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.314e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15292, It: 0, Loss Data: 7.809e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.059e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15293, It: 0, Loss Data: 8.194e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.544e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15294, It: 0, Loss Data: 9.832e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.848e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15295, It: 0, Loss Data: 7.905e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.601e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15296, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.827e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 15297, It: 0, Loss Data: 8.102e-02, Loss Eqns: 2.262e+00, Loss Aux: 5.349e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15298, It: 0, Loss Data: 8.230e-02, Loss Eqns: 2.256e+00, Loss Aux: 5.920e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15299, It: 0, Loss Data: 8.247e-02, Loss Eqns: 2.208e+00, Loss Aux: 5.679e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15300, It: 0, Loss Data: 9.059e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.545e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15301, It: 0, Loss Data: 8.889e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.056e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15302, It: 0, Loss Data: 9.693e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.115e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15303, It: 0, Loss Data: 9.714e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.587e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15304, It: 0, Loss Data: 9.358e-02, Loss Eqns: 2.229e+00, Loss Aux: 4.659e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15305, It: 0, Loss Data: 8.724e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.344e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15306, It: 0, Loss Data: 9.762e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.342e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15307, It: 0, Loss Data: 8.952e-02, Loss Eqns: 2.309e+00, Loss Aux: 4.782e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15308, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.422e+00, Loss Aux: 5.236e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15309, It: 0, Loss Data: 8.700e-02, Loss Eqns: 2.388e+00, Loss Aux: 5.567e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15310, It: 0, Loss Data: 8.415e-02, Loss Eqns: 2.333e+00, Loss Aux: 5.219e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15311, It: 0, Loss Data: 7.433e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.864e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15312, It: 0, Loss Data: 7.826e-02, Loss Eqns: 2.314e+00, Loss Aux: 5.359e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15313, It: 0, Loss Data: 7.897e-02, Loss Eqns: 2.297e+00, Loss Aux: 5.857e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15314, It: 0, Loss Data: 8.119e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.680e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15315, It: 0, Loss Data: 8.485e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.878e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15316, It: 0, Loss Data: 8.963e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.697e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15317, It: 0, Loss Data: 9.154e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.838e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15318, It: 0, Loss Data: 7.584e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.817e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15319, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.339e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15320, It: 0, Loss Data: 7.816e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.902e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15321, It: 0, Loss Data: 7.945e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.838e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15322, It: 0, Loss Data: 7.681e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.154e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15323, It: 0, Loss Data: 7.669e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.464e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15324, It: 0, Loss Data: 7.722e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.694e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15325, It: 0, Loss Data: 8.717e-02, Loss Eqns: 2.235e+00, Loss Aux: 5.119e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15326, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.202e+00, Loss Aux: 5.600e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15327, It: 0, Loss Data: 7.201e-02, Loss Eqns: 2.276e+00, Loss Aux: 5.486e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 15328, It: 0, Loss Data: 8.186e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.727e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15329, It: 0, Loss Data: 8.897e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.344e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15330, It: 0, Loss Data: 8.581e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.539e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15331, It: 0, Loss Data: 8.161e-02, Loss Eqns: 2.234e+00, Loss Aux: 4.692e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 15332, It: 0, Loss Data: 8.256e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.326e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15333, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.155e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15334, It: 0, Loss Data: 9.208e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.472e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15335, It: 0, Loss Data: 7.612e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.893e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15336, It: 0, Loss Data: 8.228e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.383e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15337, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.141e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15338, It: 0, Loss Data: 9.112e-02, Loss Eqns: 2.396e+00, Loss Aux: 4.341e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15339, It: 0, Loss Data: 7.628e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.977e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15340, It: 0, Loss Data: 7.523e-02, Loss Eqns: 2.287e+00, Loss Aux: 5.457e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15341, It: 0, Loss Data: 8.761e-02, Loss Eqns: 2.378e+00, Loss Aux: 5.221e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15342, It: 0, Loss Data: 7.648e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.908e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15343, It: 0, Loss Data: 9.528e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.773e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15344, It: 0, Loss Data: 8.967e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.985e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 15345, It: 0, Loss Data: 8.527e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.971e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15346, It: 0, Loss Data: 8.616e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.814e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15347, It: 0, Loss Data: 8.256e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.705e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15348, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.553e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15349, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.591e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15350, It: 0, Loss Data: 7.134e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.751e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15351, It: 0, Loss Data: 8.386e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.942e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15352, It: 0, Loss Data: 7.387e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.782e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15353, It: 0, Loss Data: 7.135e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.334e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 15354, It: 0, Loss Data: 7.915e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.036e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15355, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.203e+00, Loss Aux: 4.245e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15356, It: 0, Loss Data: 8.698e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.392e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15357, It: 0, Loss Data: 8.827e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.420e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15358, It: 0, Loss Data: 8.492e-02, Loss Eqns: 2.204e+00, Loss Aux: 4.098e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15359, It: 0, Loss Data: 8.678e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.826e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15360, It: 0, Loss Data: 8.080e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.855e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15361, It: 0, Loss Data: 8.579e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.141e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15362, It: 0, Loss Data: 8.074e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.594e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15363, It: 0, Loss Data: 7.932e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.953e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15364, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.775e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15365, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.362e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15366, It: 0, Loss Data: 7.234e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.535e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15367, It: 0, Loss Data: 9.125e-02, Loss Eqns: 2.326e+00, Loss Aux: 5.481e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15368, It: 0, Loss Data: 9.395e-02, Loss Eqns: 2.327e+00, Loss Aux: 6.173e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15369, It: 0, Loss Data: 8.296e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.160e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 15370, It: 0, Loss Data: 8.560e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.942e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15371, It: 0, Loss Data: 8.327e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.577e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15372, It: 0, Loss Data: 8.488e-02, Loss Eqns: 2.237e+00, Loss Aux: 3.872e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15373, It: 0, Loss Data: 7.779e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.776e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15374, It: 0, Loss Data: 6.914e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.816e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 15375, It: 0, Loss Data: 8.979e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.927e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15376, It: 0, Loss Data: 8.270e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.651e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15377, It: 0, Loss Data: 8.118e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.497e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15378, It: 0, Loss Data: 8.785e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.673e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15379, It: 0, Loss Data: 7.714e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.646e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15380, It: 0, Loss Data: 9.360e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.360e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15381, It: 0, Loss Data: 8.318e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.283e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 15382, It: 0, Loss Data: 8.589e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.578e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15383, It: 0, Loss Data: 8.121e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.764e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15384, It: 0, Loss Data: 8.021e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.683e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15385, It: 0, Loss Data: 7.185e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.137e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15386, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.028e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15387, It: 0, Loss Data: 8.610e-02, Loss Eqns: 2.255e+00, Loss Aux: 4.267e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15388, It: 0, Loss Data: 8.228e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.641e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15389, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.608e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15390, It: 0, Loss Data: 8.401e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.579e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15391, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.832e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15392, It: 0, Loss Data: 7.922e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.949e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15393, It: 0, Loss Data: 8.225e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.971e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15394, It: 0, Loss Data: 9.294e-02, Loss Eqns: 2.203e+00, Loss Aux: 4.492e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15395, It: 0, Loss Data: 1.004e-01, Loss Eqns: 2.317e+00, Loss Aux: 4.067e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 15396, It: 0, Loss Data: 8.567e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.351e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15397, It: 0, Loss Data: 8.931e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.869e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15398, It: 0, Loss Data: 7.437e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.851e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15399, It: 0, Loss Data: 8.345e-02, Loss Eqns: 2.343e+00, Loss Aux: 4.348e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15400, It: 0, Loss Data: 8.457e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.973e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15401, It: 0, Loss Data: 7.526e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.262e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15402, It: 0, Loss Data: 8.398e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.893e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15403, It: 0, Loss Data: 8.450e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.866e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15404, It: 0, Loss Data: 8.315e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.718e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 15405, It: 0, Loss Data: 8.628e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.896e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15406, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.349e+00, Loss Aux: 5.383e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15407, It: 0, Loss Data: 7.966e-02, Loss Eqns: 2.309e+00, Loss Aux: 5.209e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15408, It: 0, Loss Data: 7.101e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.591e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15409, It: 0, Loss Data: 9.251e-02, Loss Eqns: 2.267e+00, Loss Aux: 3.674e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15410, It: 0, Loss Data: 7.666e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.454e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15411, It: 0, Loss Data: 7.786e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.837e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15412, It: 0, Loss Data: 7.280e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.563e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15413, It: 0, Loss Data: 7.877e-02, Loss Eqns: 2.263e+00, Loss Aux: 5.362e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15414, It: 0, Loss Data: 8.448e-02, Loss Eqns: 2.302e+00, Loss Aux: 5.780e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15415, It: 0, Loss Data: 7.910e-02, Loss Eqns: 2.282e+00, Loss Aux: 5.359e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15416, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.870e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15417, It: 0, Loss Data: 7.829e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.682e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15418, It: 0, Loss Data: 8.316e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.757e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15419, It: 0, Loss Data: 7.698e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.630e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15420, It: 0, Loss Data: 8.484e-02, Loss Eqns: 2.219e+00, Loss Aux: 4.475e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15421, It: 0, Loss Data: 8.840e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.353e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15422, It: 0, Loss Data: 9.000e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.087e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15423, It: 0, Loss Data: 7.462e-02, Loss Eqns: 2.185e+00, Loss Aux: 4.024e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15424, It: 0, Loss Data: 8.354e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.276e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15425, It: 0, Loss Data: 7.869e-02, Loss Eqns: 2.181e+00, Loss Aux: 4.730e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15426, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.818e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15427, It: 0, Loss Data: 9.654e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.028e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15428, It: 0, Loss Data: 9.250e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.920e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15429, It: 0, Loss Data: 9.094e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.341e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15430, It: 0, Loss Data: 7.829e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.234e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15431, It: 0, Loss Data: 8.711e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.428e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15432, It: 0, Loss Data: 7.946e-02, Loss Eqns: 2.277e+00, Loss Aux: 5.037e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15433, It: 0, Loss Data: 7.782e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.915e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15434, It: 0, Loss Data: 7.656e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.684e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15435, It: 0, Loss Data: 8.448e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.422e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15436, It: 0, Loss Data: 8.453e-02, Loss Eqns: 2.418e+00, Loss Aux: 4.114e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15437, It: 0, Loss Data: 7.857e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.232e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15438, It: 0, Loss Data: 8.604e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.547e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 15439, It: 0, Loss Data: 8.566e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.828e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15440, It: 0, Loss Data: 8.688e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.676e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15441, It: 0, Loss Data: 8.402e-02, Loss Eqns: 2.200e+00, Loss Aux: 4.425e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15442, It: 0, Loss Data: 9.063e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.160e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15443, It: 0, Loss Data: 9.111e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.014e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15444, It: 0, Loss Data: 9.590e-02, Loss Eqns: 2.188e+00, Loss Aux: 3.869e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15445, It: 0, Loss Data: 8.133e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.377e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15446, It: 0, Loss Data: 7.967e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.248e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15447, It: 0, Loss Data: 8.302e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.105e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15448, It: 0, Loss Data: 7.345e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.089e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15449, It: 0, Loss Data: 8.878e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.278e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15450, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.550e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15451, It: 0, Loss Data: 8.530e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.158e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 15452, It: 0, Loss Data: 8.222e-02, Loss Eqns: 2.324e+00, Loss Aux: 3.710e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15453, It: 0, Loss Data: 8.380e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.426e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15454, It: 0, Loss Data: 9.424e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.142e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15455, It: 0, Loss Data: 8.060e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.943e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15456, It: 0, Loss Data: 8.320e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.103e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 15457, It: 0, Loss Data: 7.620e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.445e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15458, It: 0, Loss Data: 8.577e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.844e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15459, It: 0, Loss Data: 7.347e-02, Loss Eqns: 2.327e+00, Loss Aux: 5.388e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15460, It: 0, Loss Data: 8.001e-02, Loss Eqns: 2.302e+00, Loss Aux: 5.431e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15461, It: 0, Loss Data: 8.702e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.710e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15462, It: 0, Loss Data: 7.819e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.343e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15463, It: 0, Loss Data: 9.051e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.709e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15464, It: 0, Loss Data: 7.782e-02, Loss Eqns: 2.230e+00, Loss Aux: 5.141e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15465, It: 0, Loss Data: 8.899e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.891e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15466, It: 0, Loss Data: 1.027e-01, Loss Eqns: 2.564e+00, Loss Aux: 5.222e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15467, It: 0, Loss Data: 9.913e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.532e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15468, It: 0, Loss Data: 9.763e-02, Loss Eqns: 2.506e+00, Loss Aux: 3.278e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15469, It: 0, Loss Data: 9.871e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.576e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15470, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.593e+00, Loss Aux: 5.354e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15471, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.423e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15472, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.379e+00, Loss Aux: 3.709e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15473, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.284e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15474, It: 0, Loss Data: 8.112e-02, Loss Eqns: 2.428e+00, Loss Aux: 5.416e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15475, It: 0, Loss Data: 9.023e-02, Loss Eqns: 2.283e+00, Loss Aux: 5.297e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15476, It: 0, Loss Data: 1.008e-01, Loss Eqns: 2.390e+00, Loss Aux: 4.030e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15477, It: 0, Loss Data: 7.762e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.692e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15478, It: 0, Loss Data: 7.472e-02, Loss Eqns: 2.527e+00, Loss Aux: 4.599e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15479, It: 0, Loss Data: 7.465e-02, Loss Eqns: 2.306e+00, Loss Aux: 5.100e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15480, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.402e+00, Loss Aux: 5.058e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15481, It: 0, Loss Data: 6.938e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.746e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15482, It: 0, Loss Data: 7.635e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.215e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15483, It: 0, Loss Data: 8.506e-02, Loss Eqns: 2.328e+00, Loss Aux: 3.424e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 15484, It: 0, Loss Data: 8.052e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.149e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15485, It: 0, Loss Data: 8.858e-02, Loss Eqns: 2.219e+00, Loss Aux: 3.710e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15486, It: 0, Loss Data: 8.511e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.243e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15487, It: 0, Loss Data: 9.128e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.626e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15488, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.349e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15489, It: 0, Loss Data: 8.845e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.618e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15490, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.711e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15491, It: 0, Loss Data: 7.777e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.508e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15492, It: 0, Loss Data: 7.939e-02, Loss Eqns: 2.159e+00, Loss Aux: 4.415e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15493, It: 0, Loss Data: 9.781e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.790e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15494, It: 0, Loss Data: 9.177e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.841e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15495, It: 0, Loss Data: 9.216e-02, Loss Eqns: 2.200e+00, Loss Aux: 4.888e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15496, It: 0, Loss Data: 8.358e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.569e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15497, It: 0, Loss Data: 7.602e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.203e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15498, It: 0, Loss Data: 8.399e-02, Loss Eqns: 2.234e+00, Loss Aux: 4.080e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15499, It: 0, Loss Data: 8.085e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.068e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15500, It: 0, Loss Data: 8.853e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.087e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15501, It: 0, Loss Data: 8.592e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.073e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15502, It: 0, Loss Data: 8.313e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.075e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15503, It: 0, Loss Data: 8.814e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.120e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 15504, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.217e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15505, It: 0, Loss Data: 9.040e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.990e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15506, It: 0, Loss Data: 8.669e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.121e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15507, It: 0, Loss Data: 8.755e-02, Loss Eqns: 2.217e+00, Loss Aux: 4.256e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15508, It: 0, Loss Data: 8.253e-02, Loss Eqns: 2.375e+00, Loss Aux: 4.542e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15509, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.420e+00, Loss Aux: 5.105e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15510, It: 0, Loss Data: 7.593e-02, Loss Eqns: 2.367e+00, Loss Aux: 5.658e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15511, It: 0, Loss Data: 7.977e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.994e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15512, It: 0, Loss Data: 8.814e-02, Loss Eqns: 2.382e+00, Loss Aux: 3.717e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15513, It: 0, Loss Data: 9.077e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.305e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15514, It: 0, Loss Data: 7.855e-02, Loss Eqns: 2.433e+00, Loss Aux: 3.621e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15515, It: 0, Loss Data: 7.815e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.055e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15516, It: 0, Loss Data: 7.286e-02, Loss Eqns: 2.362e+00, Loss Aux: 3.869e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15517, It: 0, Loss Data: 8.003e-02, Loss Eqns: 2.316e+00, Loss Aux: 3.999e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15518, It: 0, Loss Data: 7.811e-02, Loss Eqns: 2.442e+00, Loss Aux: 4.379e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15519, It: 0, Loss Data: 7.994e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.857e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15520, It: 0, Loss Data: 7.576e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.818e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 15521, It: 0, Loss Data: 8.510e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.177e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15522, It: 0, Loss Data: 9.372e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.816e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15523, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.946e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15524, It: 0, Loss Data: 7.382e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.479e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15525, It: 0, Loss Data: 9.114e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.710e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15526, It: 0, Loss Data: 8.556e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.512e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15527, It: 0, Loss Data: 9.197e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.193e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15528, It: 0, Loss Data: 1.028e-01, Loss Eqns: 2.227e+00, Loss Aux: 3.845e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15529, It: 0, Loss Data: 8.483e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.897e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 15530, It: 0, Loss Data: 7.509e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.155e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15531, It: 0, Loss Data: 8.666e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.669e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 15532, It: 0, Loss Data: 8.281e-02, Loss Eqns: 2.247e+00, Loss Aux: 5.134e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15533, It: 0, Loss Data: 8.326e-02, Loss Eqns: 2.210e+00, Loss Aux: 5.041e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15534, It: 0, Loss Data: 7.978e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.427e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 15535, It: 0, Loss Data: 8.900e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.003e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15536, It: 0, Loss Data: 8.097e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.269e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15537, It: 0, Loss Data: 8.159e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.768e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15538, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.196e+00, Loss Aux: 4.469e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15539, It: 0, Loss Data: 7.891e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.839e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15540, It: 0, Loss Data: 9.479e-02, Loss Eqns: 2.247e+00, Loss Aux: 3.677e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15541, It: 0, Loss Data: 7.641e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.159e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15542, It: 0, Loss Data: 8.144e-02, Loss Eqns: 2.211e+00, Loss Aux: 4.745e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15543, It: 0, Loss Data: 8.676e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.834e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15544, It: 0, Loss Data: 8.865e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.683e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15545, It: 0, Loss Data: 9.473e-02, Loss Eqns: 2.178e+00, Loss Aux: 4.283e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15546, It: 0, Loss Data: 7.543e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.185e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15547, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.313e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15548, It: 0, Loss Data: 7.472e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.375e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15549, It: 0, Loss Data: 8.387e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.168e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15550, It: 0, Loss Data: 9.388e-02, Loss Eqns: 2.329e+00, Loss Aux: 3.677e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15551, It: 0, Loss Data: 6.402e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.868e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15552, It: 0, Loss Data: 8.574e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.518e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15553, It: 0, Loss Data: 9.320e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.826e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 15554, It: 0, Loss Data: 8.599e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.482e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15555, It: 0, Loss Data: 7.919e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.897e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15556, It: 0, Loss Data: 7.760e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.745e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15557, It: 0, Loss Data: 7.702e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.016e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15558, It: 0, Loss Data: 8.801e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.547e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15559, It: 0, Loss Data: 7.071e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.506e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15560, It: 0, Loss Data: 8.333e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.528e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15561, It: 0, Loss Data: 9.609e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.964e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15562, It: 0, Loss Data: 9.219e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.908e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15563, It: 0, Loss Data: 8.554e-02, Loss Eqns: 2.271e+00, Loss Aux: 4.711e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15564, It: 0, Loss Data: 8.841e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.534e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15565, It: 0, Loss Data: 7.887e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.458e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15566, It: 0, Loss Data: 7.560e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.040e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15567, It: 0, Loss Data: 8.536e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.851e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15568, It: 0, Loss Data: 7.146e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.747e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15569, It: 0, Loss Data: 7.911e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.855e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15570, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.154e+00, Loss Aux: 3.821e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15571, It: 0, Loss Data: 7.464e-02, Loss Eqns: 2.387e+00, Loss Aux: 3.927e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15572, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.436e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15573, It: 0, Loss Data: 7.449e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.530e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15574, It: 0, Loss Data: 8.754e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.275e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15575, It: 0, Loss Data: 7.306e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.344e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15576, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.351e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15577, It: 0, Loss Data: 9.708e-02, Loss Eqns: 2.291e+00, Loss Aux: 4.416e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15578, It: 0, Loss Data: 8.777e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.193e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15579, It: 0, Loss Data: 8.957e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.008e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15580, It: 0, Loss Data: 8.533e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.100e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15581, It: 0, Loss Data: 6.946e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.082e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15582, It: 0, Loss Data: 7.924e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.099e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15583, It: 0, Loss Data: 8.204e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.206e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15584, It: 0, Loss Data: 7.961e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.570e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15585, It: 0, Loss Data: 7.430e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.895e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15586, It: 0, Loss Data: 8.867e-02, Loss Eqns: 2.235e+00, Loss Aux: 5.201e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15587, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.959e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15588, It: 0, Loss Data: 8.449e-02, Loss Eqns: 2.229e+00, Loss Aux: 4.519e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15589, It: 0, Loss Data: 8.837e-02, Loss Eqns: 2.206e+00, Loss Aux: 4.006e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15590, It: 0, Loss Data: 8.821e-02, Loss Eqns: 2.224e+00, Loss Aux: 3.832e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15591, It: 0, Loss Data: 8.728e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.278e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15592, It: 0, Loss Data: 8.363e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.624e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15593, It: 0, Loss Data: 7.980e-02, Loss Eqns: 2.277e+00, Loss Aux: 4.325e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15594, It: 0, Loss Data: 8.062e-02, Loss Eqns: 2.353e+00, Loss Aux: 3.878e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15595, It: 0, Loss Data: 8.055e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.038e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15596, It: 0, Loss Data: 7.858e-02, Loss Eqns: 2.297e+00, Loss Aux: 4.564e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15597, It: 0, Loss Data: 8.332e-02, Loss Eqns: 2.304e+00, Loss Aux: 5.391e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15598, It: 0, Loss Data: 9.191e-02, Loss Eqns: 2.354e+00, Loss Aux: 5.358e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15599, It: 0, Loss Data: 8.605e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.486e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15600, It: 0, Loss Data: 9.421e-02, Loss Eqns: 2.302e+00, Loss Aux: 3.815e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15601, It: 0, Loss Data: 7.155e-02, Loss Eqns: 2.406e+00, Loss Aux: 3.665e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 15602, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.377e+00, Loss Aux: 3.703e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15603, It: 0, Loss Data: 6.402e-02, Loss Eqns: 2.352e+00, Loss Aux: 3.577e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15604, It: 0, Loss Data: 8.802e-02, Loss Eqns: 2.410e+00, Loss Aux: 3.664e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15605, It: 0, Loss Data: 8.454e-02, Loss Eqns: 2.383e+00, Loss Aux: 4.371e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15606, It: 0, Loss Data: 8.115e-02, Loss Eqns: 2.288e+00, Loss Aux: 5.173e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15607, It: 0, Loss Data: 8.333e-02, Loss Eqns: 2.267e+00, Loss Aux: 5.608e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 15608, It: 0, Loss Data: 8.317e-02, Loss Eqns: 2.315e+00, Loss Aux: 5.038e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15609, It: 0, Loss Data: 8.980e-02, Loss Eqns: 2.331e+00, Loss Aux: 4.284e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 15610, It: 0, Loss Data: 7.604e-02, Loss Eqns: 2.228e+00, Loss Aux: 3.680e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15611, It: 0, Loss Data: 8.412e-02, Loss Eqns: 2.273e+00, Loss Aux: 3.742e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15612, It: 0, Loss Data: 8.513e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.282e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15613, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.731e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15614, It: 0, Loss Data: 8.351e-02, Loss Eqns: 2.219e+00, Loss Aux: 4.315e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15615, It: 0, Loss Data: 9.150e-02, Loss Eqns: 2.292e+00, Loss Aux: 3.554e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15616, It: 0, Loss Data: 9.157e-02, Loss Eqns: 2.296e+00, Loss Aux: 3.215e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15617, It: 0, Loss Data: 7.525e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.680e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15618, It: 0, Loss Data: 8.691e-02, Loss Eqns: 2.679e+00, Loss Aux: 3.584e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15619, It: 0, Loss Data: 8.455e-02, Loss Eqns: 2.551e+00, Loss Aux: 5.777e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15620, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.348e+00, Loss Aux: 6.886e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15621, It: 0, Loss Data: 8.765e-02, Loss Eqns: 2.466e+00, Loss Aux: 4.671e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15622, It: 0, Loss Data: 8.133e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.570e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15623, It: 0, Loss Data: 8.714e-02, Loss Eqns: 2.282e+00, Loss Aux: 3.429e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15624, It: 0, Loss Data: 8.175e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.409e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15625, It: 0, Loss Data: 8.409e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.566e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15626, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.201e+00, Loss Aux: 4.580e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15627, It: 0, Loss Data: 7.738e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.129e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15628, It: 0, Loss Data: 9.152e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.344e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15629, It: 0, Loss Data: 7.391e-02, Loss Eqns: 2.265e+00, Loss Aux: 5.135e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15630, It: 0, Loss Data: 9.037e-02, Loss Eqns: 2.274e+00, Loss Aux: 5.172e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 15631, It: 0, Loss Data: 8.190e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.413e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15632, It: 0, Loss Data: 8.922e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.289e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15633, It: 0, Loss Data: 9.236e-02, Loss Eqns: 2.216e+00, Loss Aux: 4.968e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15634, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.233e+00, Loss Aux: 5.008e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15635, It: 0, Loss Data: 8.576e-02, Loss Eqns: 2.240e+00, Loss Aux: 5.067e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15636, It: 0, Loss Data: 7.484e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.915e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15637, It: 0, Loss Data: 9.579e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.385e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15638, It: 0, Loss Data: 7.923e-02, Loss Eqns: 2.232e+00, Loss Aux: 3.789e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15639, It: 0, Loss Data: 8.263e-02, Loss Eqns: 2.336e+00, Loss Aux: 3.547e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15640, It: 0, Loss Data: 8.145e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.196e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15641, It: 0, Loss Data: 8.250e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.449e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15642, It: 0, Loss Data: 8.581e-02, Loss Eqns: 2.376e+00, Loss Aux: 3.812e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15643, It: 0, Loss Data: 8.500e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.542e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15644, It: 0, Loss Data: 7.954e-02, Loss Eqns: 2.358e+00, Loss Aux: 3.781e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15645, It: 0, Loss Data: 9.643e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.371e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 15646, It: 0, Loss Data: 8.618e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.242e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15647, It: 0, Loss Data: 8.268e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.199e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15648, It: 0, Loss Data: 7.903e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.317e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15649, It: 0, Loss Data: 8.645e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.381e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15650, It: 0, Loss Data: 7.817e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.759e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15651, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.938e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15652, It: 0, Loss Data: 6.359e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.578e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15653, It: 0, Loss Data: 8.192e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.297e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15654, It: 0, Loss Data: 8.298e-02, Loss Eqns: 2.206e+00, Loss Aux: 4.467e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15655, It: 0, Loss Data: 9.420e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.371e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15656, It: 0, Loss Data: 6.847e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.163e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15657, It: 0, Loss Data: 7.037e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.047e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15658, It: 0, Loss Data: 8.048e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.615e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15659, It: 0, Loss Data: 9.757e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.496e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15660, It: 0, Loss Data: 8.237e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.180e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15661, It: 0, Loss Data: 8.463e-02, Loss Eqns: 2.253e+00, Loss Aux: 5.160e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15662, It: 0, Loss Data: 9.653e-02, Loss Eqns: 2.150e+00, Loss Aux: 5.352e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15663, It: 0, Loss Data: 8.255e-02, Loss Eqns: 2.219e+00, Loss Aux: 5.053e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15664, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.746e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15665, It: 0, Loss Data: 7.828e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.419e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15666, It: 0, Loss Data: 9.203e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.953e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15667, It: 0, Loss Data: 7.540e-02, Loss Eqns: 2.290e+00, Loss Aux: 3.749e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 15668, It: 0, Loss Data: 7.309e-02, Loss Eqns: 2.264e+00, Loss Aux: 3.853e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 15669, It: 0, Loss Data: 7.988e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.423e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15670, It: 0, Loss Data: 8.750e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.830e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15671, It: 0, Loss Data: 7.236e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.372e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15672, It: 0, Loss Data: 8.043e-02, Loss Eqns: 2.249e+00, Loss Aux: 3.879e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15673, It: 0, Loss Data: 8.244e-02, Loss Eqns: 2.230e+00, Loss Aux: 3.713e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15674, It: 0, Loss Data: 9.859e-02, Loss Eqns: 2.184e+00, Loss Aux: 4.473e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15675, It: 0, Loss Data: 9.552e-02, Loss Eqns: 2.267e+00, Loss Aux: 5.369e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15676, It: 0, Loss Data: 9.292e-02, Loss Eqns: 2.222e+00, Loss Aux: 4.677e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15677, It: 0, Loss Data: 8.511e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.854e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15678, It: 0, Loss Data: 9.347e-02, Loss Eqns: 2.404e+00, Loss Aux: 3.814e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15679, It: 0, Loss Data: 8.274e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.329e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15680, It: 0, Loss Data: 9.299e-02, Loss Eqns: 2.397e+00, Loss Aux: 5.269e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15681, It: 0, Loss Data: 7.364e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.488e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15682, It: 0, Loss Data: 9.008e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.572e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15683, It: 0, Loss Data: 8.077e-02, Loss Eqns: 2.259e+00, Loss Aux: 3.972e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15684, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.322e+00, Loss Aux: 3.961e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15685, It: 0, Loss Data: 7.639e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.247e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15686, It: 0, Loss Data: 7.117e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.315e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15687, It: 0, Loss Data: 7.124e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.672e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 15688, It: 0, Loss Data: 7.823e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.381e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15689, It: 0, Loss Data: 8.074e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.065e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15690, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.634e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15691, It: 0, Loss Data: 9.221e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.662e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15692, It: 0, Loss Data: 8.969e-02, Loss Eqns: 2.177e+00, Loss Aux: 4.321e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15693, It: 0, Loss Data: 9.243e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.093e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15694, It: 0, Loss Data: 9.226e-02, Loss Eqns: 2.353e+00, Loss Aux: 4.416e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15695, It: 0, Loss Data: 7.932e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.112e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15696, It: 0, Loss Data: 8.027e-02, Loss Eqns: 2.287e+00, Loss Aux: 5.146e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15697, It: 0, Loss Data: 8.112e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.795e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 15698, It: 0, Loss Data: 8.112e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.538e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15699, It: 0, Loss Data: 7.856e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.457e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15700, It: 0, Loss Data: 7.044e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.497e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15701, It: 0, Loss Data: 7.912e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.444e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15702, It: 0, Loss Data: 7.135e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.114e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15703, It: 0, Loss Data: 8.795e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.610e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 15704, It: 0, Loss Data: 8.467e-02, Loss Eqns: 2.318e+00, Loss Aux: 3.464e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15705, It: 0, Loss Data: 8.397e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.787e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15706, It: 0, Loss Data: 7.319e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.044e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15707, It: 0, Loss Data: 7.440e-02, Loss Eqns: 2.211e+00, Loss Aux: 3.861e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15708, It: 0, Loss Data: 7.209e-02, Loss Eqns: 2.371e+00, Loss Aux: 3.878e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15709, It: 0, Loss Data: 8.294e-02, Loss Eqns: 2.245e+00, Loss Aux: 3.893e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15710, It: 0, Loss Data: 8.274e-02, Loss Eqns: 2.196e+00, Loss Aux: 4.245e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15711, It: 0, Loss Data: 7.929e-02, Loss Eqns: 2.218e+00, Loss Aux: 4.486e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15712, It: 0, Loss Data: 8.055e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.540e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15713, It: 0, Loss Data: 9.460e-02, Loss Eqns: 2.240e+00, Loss Aux: 4.729e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15714, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.274e+00, Loss Aux: 5.186e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 15715, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.252e+00, Loss Aux: 5.282e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 15716, It: 0, Loss Data: 8.619e-02, Loss Eqns: 2.299e+00, Loss Aux: 4.443e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15717, It: 0, Loss Data: 9.763e-02, Loss Eqns: 2.286e+00, Loss Aux: 3.756e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15718, It: 0, Loss Data: 8.951e-02, Loss Eqns: 2.217e+00, Loss Aux: 3.649e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15719, It: 0, Loss Data: 8.573e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.795e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15720, It: 0, Loss Data: 7.546e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.248e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15721, It: 0, Loss Data: 7.857e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.622e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15722, It: 0, Loss Data: 8.242e-02, Loss Eqns: 2.356e+00, Loss Aux: 4.752e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15723, It: 0, Loss Data: 7.176e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.733e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15724, It: 0, Loss Data: 7.407e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.495e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15725, It: 0, Loss Data: 7.278e-02, Loss Eqns: 2.327e+00, Loss Aux: 4.127e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15726, It: 0, Loss Data: 8.426e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.001e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15727, It: 0, Loss Data: 7.414e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.590e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15728, It: 0, Loss Data: 9.275e-02, Loss Eqns: 2.278e+00, Loss Aux: 5.146e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15729, It: 0, Loss Data: 9.422e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.929e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15730, It: 0, Loss Data: 8.103e-02, Loss Eqns: 2.281e+00, Loss Aux: 4.135e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15731, It: 0, Loss Data: 7.153e-02, Loss Eqns: 2.249e+00, Loss Aux: 3.738e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15732, It: 0, Loss Data: 8.585e-02, Loss Eqns: 2.325e+00, Loss Aux: 3.706e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15733, It: 0, Loss Data: 7.692e-02, Loss Eqns: 2.252e+00, Loss Aux: 3.502e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15734, It: 0, Loss Data: 7.999e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.742e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15735, It: 0, Loss Data: 8.150e-02, Loss Eqns: 2.230e+00, Loss Aux: 4.090e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15736, It: 0, Loss Data: 8.281e-02, Loss Eqns: 2.339e+00, Loss Aux: 4.434e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15737, It: 0, Loss Data: 8.914e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.311e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15738, It: 0, Loss Data: 8.366e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.650e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15739, It: 0, Loss Data: 8.079e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.549e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15740, It: 0, Loss Data: 8.859e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.486e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15741, It: 0, Loss Data: 8.584e-02, Loss Eqns: 2.164e+00, Loss Aux: 4.681e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15742, It: 0, Loss Data: 9.305e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.662e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15743, It: 0, Loss Data: 8.074e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.573e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15744, It: 0, Loss Data: 8.437e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.503e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15745, It: 0, Loss Data: 7.821e-02, Loss Eqns: 2.272e+00, Loss Aux: 3.965e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15746, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.306e+00, Loss Aux: 3.429e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15747, It: 0, Loss Data: 7.217e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.603e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15748, It: 0, Loss Data: 7.768e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.012e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15749, It: 0, Loss Data: 7.975e-02, Loss Eqns: 2.229e+00, Loss Aux: 4.341e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15750, It: 0, Loss Data: 8.068e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.634e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15751, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.562e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15752, It: 0, Loss Data: 9.005e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.789e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 15753, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.643e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15754, It: 0, Loss Data: 8.156e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.256e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15755, It: 0, Loss Data: 8.560e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.989e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15756, It: 0, Loss Data: 8.537e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.302e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15757, It: 0, Loss Data: 8.130e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.772e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15758, It: 0, Loss Data: 7.971e-02, Loss Eqns: 2.205e+00, Loss Aux: 4.389e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15759, It: 0, Loss Data: 8.234e-02, Loss Eqns: 2.300e+00, Loss Aux: 3.872e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15760, It: 0, Loss Data: 7.509e-02, Loss Eqns: 2.359e+00, Loss Aux: 3.718e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 15761, It: 0, Loss Data: 9.319e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.774e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15762, It: 0, Loss Data: 7.131e-02, Loss Eqns: 2.300e+00, Loss Aux: 5.151e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15763, It: 0, Loss Data: 7.893e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.398e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15764, It: 0, Loss Data: 7.837e-02, Loss Eqns: 2.255e+00, Loss Aux: 3.724e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15765, It: 0, Loss Data: 7.676e-02, Loss Eqns: 2.317e+00, Loss Aux: 3.992e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15766, It: 0, Loss Data: 7.824e-02, Loss Eqns: 2.281e+00, Loss Aux: 5.043e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15767, It: 0, Loss Data: 7.704e-02, Loss Eqns: 2.260e+00, Loss Aux: 5.210e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 15768, It: 0, Loss Data: 8.891e-02, Loss Eqns: 2.187e+00, Loss Aux: 4.430e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15769, It: 0, Loss Data: 7.827e-02, Loss Eqns: 2.230e+00, Loss Aux: 3.768e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15770, It: 0, Loss Data: 8.338e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.067e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15771, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.219e+00, Loss Aux: 4.442e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15772, It: 0, Loss Data: 9.889e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.713e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15773, It: 0, Loss Data: 8.383e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.379e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 15774, It: 0, Loss Data: 8.337e-02, Loss Eqns: 2.258e+00, Loss Aux: 3.899e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15775, It: 0, Loss Data: 9.218e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.583e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15776, It: 0, Loss Data: 8.670e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.038e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15777, It: 0, Loss Data: 8.132e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.971e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15778, It: 0, Loss Data: 8.417e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.414e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15779, It: 0, Loss Data: 7.602e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.922e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15780, It: 0, Loss Data: 8.879e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.653e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15781, It: 0, Loss Data: 7.563e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.442e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15782, It: 0, Loss Data: 8.042e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.284e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15783, It: 0, Loss Data: 8.863e-02, Loss Eqns: 2.315e+00, Loss Aux: 3.123e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15784, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.224e+00, Loss Aux: 3.957e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15785, It: 0, Loss Data: 7.845e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.958e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15786, It: 0, Loss Data: 9.114e-02, Loss Eqns: 2.196e+00, Loss Aux: 5.475e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15787, It: 0, Loss Data: 7.374e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.903e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 15788, It: 0, Loss Data: 7.256e-02, Loss Eqns: 2.269e+00, Loss Aux: 3.873e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15789, It: 0, Loss Data: 9.828e-02, Loss Eqns: 2.239e+00, Loss Aux: 3.914e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15790, It: 0, Loss Data: 9.057e-02, Loss Eqns: 2.202e+00, Loss Aux: 4.877e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15791, It: 0, Loss Data: 8.637e-02, Loss Eqns: 2.157e+00, Loss Aux: 4.887e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15792, It: 0, Loss Data: 8.096e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.032e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15793, It: 0, Loss Data: 7.227e-02, Loss Eqns: 2.190e+00, Loss Aux: 3.384e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15794, It: 0, Loss Data: 8.634e-02, Loss Eqns: 2.195e+00, Loss Aux: 3.755e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15795, It: 0, Loss Data: 9.592e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.748e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15796, It: 0, Loss Data: 7.892e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.719e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15797, It: 0, Loss Data: 7.164e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.128e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15798, It: 0, Loss Data: 8.225e-02, Loss Eqns: 2.201e+00, Loss Aux: 4.003e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15799, It: 0, Loss Data: 8.462e-02, Loss Eqns: 2.153e+00, Loss Aux: 4.153e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15800, It: 0, Loss Data: 9.314e-02, Loss Eqns: 2.147e+00, Loss Aux: 4.811e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15801, It: 0, Loss Data: 9.321e-02, Loss Eqns: 2.238e+00, Loss Aux: 4.597e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15802, It: 0, Loss Data: 7.649e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.663e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15803, It: 0, Loss Data: 7.646e-02, Loss Eqns: 2.263e+00, Loss Aux: 3.216e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15804, It: 0, Loss Data: 8.000e-02, Loss Eqns: 2.305e+00, Loss Aux: 3.751e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15805, It: 0, Loss Data: 9.015e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.883e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15806, It: 0, Loss Data: 9.593e-02, Loss Eqns: 2.184e+00, Loss Aux: 5.551e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 15807, It: 0, Loss Data: 9.184e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.723e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15808, It: 0, Loss Data: 8.339e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.749e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15809, It: 0, Loss Data: 8.881e-02, Loss Eqns: 2.228e+00, Loss Aux: 3.618e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15810, It: 0, Loss Data: 8.683e-02, Loss Eqns: 2.267e+00, Loss Aux: 3.983e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15811, It: 0, Loss Data: 8.666e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.379e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15812, It: 0, Loss Data: 8.272e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.197e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15813, It: 0, Loss Data: 7.305e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.212e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15814, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.342e+00, Loss Aux: 4.342e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15815, It: 0, Loss Data: 7.202e-02, Loss Eqns: 2.316e+00, Loss Aux: 4.314e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15816, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.167e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15817, It: 0, Loss Data: 8.206e-02, Loss Eqns: 2.345e+00, Loss Aux: 3.639e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15818, It: 0, Loss Data: 7.770e-02, Loss Eqns: 2.265e+00, Loss Aux: 3.580e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15819, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.321e+00, Loss Aux: 3.910e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15820, It: 0, Loss Data: 8.079e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.728e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15821, It: 0, Loss Data: 7.840e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.459e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15822, It: 0, Loss Data: 8.873e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.054e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15823, It: 0, Loss Data: 7.115e-02, Loss Eqns: 2.262e+00, Loss Aux: 3.973e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15824, It: 0, Loss Data: 8.923e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.329e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15825, It: 0, Loss Data: 8.631e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.869e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15826, It: 0, Loss Data: 9.123e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.742e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 15827, It: 0, Loss Data: 9.075e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.455e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 15828, It: 0, Loss Data: 7.996e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.061e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15829, It: 0, Loss Data: 7.777e-02, Loss Eqns: 2.275e+00, Loss Aux: 3.930e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15830, It: 0, Loss Data: 7.292e-02, Loss Eqns: 2.248e+00, Loss Aux: 3.837e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15831, It: 0, Loss Data: 8.366e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.658e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15832, It: 0, Loss Data: 8.648e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.707e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15833, It: 0, Loss Data: 9.143e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.375e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15834, It: 0, Loss Data: 7.688e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.689e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15835, It: 0, Loss Data: 8.070e-02, Loss Eqns: 2.322e+00, Loss Aux: 4.354e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15836, It: 0, Loss Data: 9.104e-02, Loss Eqns: 2.198e+00, Loss Aux: 3.689e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15837, It: 0, Loss Data: 8.830e-02, Loss Eqns: 2.267e+00, Loss Aux: 3.527e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15838, It: 0, Loss Data: 7.341e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.598e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15839, It: 0, Loss Data: 8.825e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.050e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15840, It: 0, Loss Data: 7.895e-02, Loss Eqns: 2.216e+00, Loss Aux: 4.824e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15841, It: 0, Loss Data: 8.236e-02, Loss Eqns: 2.315e+00, Loss Aux: 5.318e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15842, It: 0, Loss Data: 8.045e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.763e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15843, It: 0, Loss Data: 9.988e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.198e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15844, It: 0, Loss Data: 7.913e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.752e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15845, It: 0, Loss Data: 8.063e-02, Loss Eqns: 2.216e+00, Loss Aux: 3.612e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15846, It: 0, Loss Data: 8.259e-02, Loss Eqns: 2.214e+00, Loss Aux: 3.955e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15847, It: 0, Loss Data: 1.044e-01, Loss Eqns: 2.281e+00, Loss Aux: 4.031e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15848, It: 0, Loss Data: 8.829e-02, Loss Eqns: 2.213e+00, Loss Aux: 3.857e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15849, It: 0, Loss Data: 9.329e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.659e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15850, It: 0, Loss Data: 7.477e-02, Loss Eqns: 2.323e+00, Loss Aux: 4.435e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15851, It: 0, Loss Data: 8.792e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.939e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15852, It: 0, Loss Data: 7.825e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.840e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15853, It: 0, Loss Data: 8.055e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.282e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15854, It: 0, Loss Data: 8.573e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.092e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15855, It: 0, Loss Data: 9.009e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.438e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15856, It: 0, Loss Data: 8.147e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.838e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15857, It: 0, Loss Data: 8.494e-02, Loss Eqns: 2.295e+00, Loss Aux: 5.012e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15858, It: 0, Loss Data: 8.091e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.457e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15859, It: 0, Loss Data: 6.321e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.904e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15860, It: 0, Loss Data: 9.324e-02, Loss Eqns: 2.342e+00, Loss Aux: 3.543e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15861, It: 0, Loss Data: 8.399e-02, Loss Eqns: 2.277e+00, Loss Aux: 3.758e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15862, It: 0, Loss Data: 9.427e-02, Loss Eqns: 2.280e+00, Loss Aux: 4.081e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15863, It: 0, Loss Data: 7.960e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.149e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 15864, It: 0, Loss Data: 8.114e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.261e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15865, It: 0, Loss Data: 7.881e-02, Loss Eqns: 2.362e+00, Loss Aux: 4.541e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15866, It: 0, Loss Data: 9.598e-02, Loss Eqns: 2.289e+00, Loss Aux: 4.422e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15867, It: 0, Loss Data: 8.695e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.284e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15868, It: 0, Loss Data: 7.074e-02, Loss Eqns: 2.318e+00, Loss Aux: 4.418e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15869, It: 0, Loss Data: 7.688e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.521e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15870, It: 0, Loss Data: 9.046e-02, Loss Eqns: 2.226e+00, Loss Aux: 3.969e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15871, It: 0, Loss Data: 7.597e-02, Loss Eqns: 2.280e+00, Loss Aux: 3.638e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 15872, It: 0, Loss Data: 9.775e-02, Loss Eqns: 2.274e+00, Loss Aux: 3.971e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15873, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.356e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15874, It: 0, Loss Data: 8.388e-02, Loss Eqns: 2.312e+00, Loss Aux: 4.568e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15875, It: 0, Loss Data: 8.659e-02, Loss Eqns: 2.266e+00, Loss Aux: 4.293e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15876, It: 0, Loss Data: 8.485e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.180e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15877, It: 0, Loss Data: 9.782e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.135e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15878, It: 0, Loss Data: 8.080e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.121e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15879, It: 0, Loss Data: 9.216e-02, Loss Eqns: 2.309e+00, Loss Aux: 3.757e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15880, It: 0, Loss Data: 7.457e-02, Loss Eqns: 2.333e+00, Loss Aux: 3.996e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15881, It: 0, Loss Data: 8.207e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.667e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15882, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.279e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15883, It: 0, Loss Data: 8.140e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.509e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15884, It: 0, Loss Data: 7.730e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.839e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15885, It: 0, Loss Data: 7.907e-02, Loss Eqns: 2.343e+00, Loss Aux: 3.742e-02, Time: 0.218, Learning Rate: 1.0e-03\n",
      "Epoch: 15886, It: 0, Loss Data: 8.284e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.236e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15887, It: 0, Loss Data: 7.366e-02, Loss Eqns: 2.335e+00, Loss Aux: 5.055e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15888, It: 0, Loss Data: 8.008e-02, Loss Eqns: 2.343e+00, Loss Aux: 5.089e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15889, It: 0, Loss Data: 8.158e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.447e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15890, It: 0, Loss Data: 9.455e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.944e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15891, It: 0, Loss Data: 9.425e-02, Loss Eqns: 2.394e+00, Loss Aux: 3.788e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15892, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.354e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 15893, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.229e+00, Loss Aux: 4.522e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15894, It: 0, Loss Data: 9.145e-02, Loss Eqns: 2.288e+00, Loss Aux: 3.939e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15895, It: 0, Loss Data: 8.144e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.588e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15896, It: 0, Loss Data: 8.701e-02, Loss Eqns: 2.313e+00, Loss Aux: 3.701e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15897, It: 0, Loss Data: 8.023e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.273e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15898, It: 0, Loss Data: 7.721e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.554e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15899, It: 0, Loss Data: 7.394e-02, Loss Eqns: 2.386e+00, Loss Aux: 4.569e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15900, It: 0, Loss Data: 7.755e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.923e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15901, It: 0, Loss Data: 7.513e-02, Loss Eqns: 2.300e+00, Loss Aux: 5.906e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15902, It: 0, Loss Data: 7.992e-02, Loss Eqns: 2.267e+00, Loss Aux: 6.075e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15903, It: 0, Loss Data: 7.739e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.101e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15904, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.314e+00, Loss Aux: 3.210e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15905, It: 0, Loss Data: 7.189e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.288e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15906, It: 0, Loss Data: 8.600e-02, Loss Eqns: 2.294e+00, Loss Aux: 3.768e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15907, It: 0, Loss Data: 8.090e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.135e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 15908, It: 0, Loss Data: 8.295e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.347e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15909, It: 0, Loss Data: 8.714e-02, Loss Eqns: 2.278e+00, Loss Aux: 4.626e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15910, It: 0, Loss Data: 9.035e-02, Loss Eqns: 2.120e+00, Loss Aux: 4.965e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15911, It: 0, Loss Data: 9.332e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.829e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 15912, It: 0, Loss Data: 1.010e-01, Loss Eqns: 2.297e+00, Loss Aux: 4.111e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15913, It: 0, Loss Data: 8.403e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.273e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15914, It: 0, Loss Data: 7.716e-02, Loss Eqns: 2.192e+00, Loss Aux: 4.917e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15915, It: 0, Loss Data: 8.999e-02, Loss Eqns: 2.269e+00, Loss Aux: 5.105e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15916, It: 0, Loss Data: 8.290e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.441e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15917, It: 0, Loss Data: 7.914e-02, Loss Eqns: 2.330e+00, Loss Aux: 3.836e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 15918, It: 0, Loss Data: 8.455e-02, Loss Eqns: 2.444e+00, Loss Aux: 3.581e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 15919, It: 0, Loss Data: 7.574e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.310e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15920, It: 0, Loss Data: 8.492e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.687e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15921, It: 0, Loss Data: 8.937e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.439e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15922, It: 0, Loss Data: 7.670e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.105e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15923, It: 0, Loss Data: 7.746e-02, Loss Eqns: 2.411e+00, Loss Aux: 3.893e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15924, It: 0, Loss Data: 7.799e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.958e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15925, It: 0, Loss Data: 7.753e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.586e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15926, It: 0, Loss Data: 8.423e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.326e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15927, It: 0, Loss Data: 8.373e-02, Loss Eqns: 2.283e+00, Loss Aux: 3.611e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 15928, It: 0, Loss Data: 7.066e-02, Loss Eqns: 2.224e+00, Loss Aux: 3.635e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 15929, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.254e+00, Loss Aux: 3.743e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15930, It: 0, Loss Data: 7.798e-02, Loss Eqns: 2.304e+00, Loss Aux: 3.735e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15931, It: 0, Loss Data: 8.504e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.872e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15932, It: 0, Loss Data: 8.307e-02, Loss Eqns: 2.211e+00, Loss Aux: 4.318e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15933, It: 0, Loss Data: 1.057e-01, Loss Eqns: 2.240e+00, Loss Aux: 4.496e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15934, It: 0, Loss Data: 7.732e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.871e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15935, It: 0, Loss Data: 8.922e-02, Loss Eqns: 2.299e+00, Loss Aux: 5.672e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15936, It: 0, Loss Data: 9.723e-02, Loss Eqns: 2.363e+00, Loss Aux: 5.686e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15937, It: 0, Loss Data: 8.816e-02, Loss Eqns: 2.239e+00, Loss Aux: 4.322e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 15938, It: 0, Loss Data: 8.877e-02, Loss Eqns: 2.363e+00, Loss Aux: 3.560e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 15939, It: 0, Loss Data: 8.995e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.416e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15940, It: 0, Loss Data: 9.783e-02, Loss Eqns: 2.315e+00, Loss Aux: 4.026e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 15941, It: 0, Loss Data: 8.126e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.792e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 15942, It: 0, Loss Data: 9.252e-02, Loss Eqns: 2.340e+00, Loss Aux: 4.128e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15943, It: 0, Loss Data: 7.815e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.632e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15944, It: 0, Loss Data: 7.717e-02, Loss Eqns: 2.526e+00, Loss Aux: 3.774e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 15945, It: 0, Loss Data: 8.041e-02, Loss Eqns: 2.438e+00, Loss Aux: 4.115e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15946, It: 0, Loss Data: 9.063e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.418e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15947, It: 0, Loss Data: 8.484e-02, Loss Eqns: 2.496e+00, Loss Aux: 4.492e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15948, It: 0, Loss Data: 8.144e-02, Loss Eqns: 2.393e+00, Loss Aux: 3.961e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 15949, It: 0, Loss Data: 8.565e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.302e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 15950, It: 0, Loss Data: 8.321e-02, Loss Eqns: 2.464e+00, Loss Aux: 4.877e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 15951, It: 0, Loss Data: 8.028e-02, Loss Eqns: 2.437e+00, Loss Aux: 4.621e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 15952, It: 0, Loss Data: 6.891e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.250e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 15953, It: 0, Loss Data: 8.491e-02, Loss Eqns: 2.662e+00, Loss Aux: 4.426e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 15954, It: 0, Loss Data: 8.061e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.314e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 15955, It: 0, Loss Data: 9.982e-02, Loss Eqns: 2.490e+00, Loss Aux: 4.592e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 15956, It: 0, Loss Data: 9.711e-02, Loss Eqns: 2.572e+00, Loss Aux: 4.168e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 15957, It: 0, Loss Data: 8.766e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.818e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15958, It: 0, Loss Data: 8.760e-02, Loss Eqns: 2.472e+00, Loss Aux: 4.377e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15959, It: 0, Loss Data: 7.915e-02, Loss Eqns: 2.298e+00, Loss Aux: 5.148e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 15960, It: 0, Loss Data: 7.969e-02, Loss Eqns: 2.390e+00, Loss Aux: 4.693e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 15961, It: 0, Loss Data: 9.359e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.889e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 15962, It: 0, Loss Data: 6.941e-02, Loss Eqns: 2.337e+00, Loss Aux: 3.843e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15963, It: 0, Loss Data: 8.665e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.306e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15964, It: 0, Loss Data: 9.679e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.355e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 15965, It: 0, Loss Data: 8.454e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.560e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15966, It: 0, Loss Data: 7.604e-02, Loss Eqns: 2.359e+00, Loss Aux: 4.497e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 15967, It: 0, Loss Data: 7.723e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.987e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15968, It: 0, Loss Data: 9.575e-02, Loss Eqns: 2.310e+00, Loss Aux: 3.643e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15969, It: 0, Loss Data: 7.383e-02, Loss Eqns: 2.300e+00, Loss Aux: 4.139e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15970, It: 0, Loss Data: 7.566e-02, Loss Eqns: 2.368e+00, Loss Aux: 4.533e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 15971, It: 0, Loss Data: 7.363e-02, Loss Eqns: 2.225e+00, Loss Aux: 4.525e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15972, It: 0, Loss Data: 9.317e-02, Loss Eqns: 2.185e+00, Loss Aux: 3.961e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 15973, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.268e+00, Loss Aux: 3.602e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15974, It: 0, Loss Data: 8.081e-02, Loss Eqns: 2.284e+00, Loss Aux: 3.823e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 15975, It: 0, Loss Data: 8.948e-02, Loss Eqns: 2.294e+00, Loss Aux: 4.637e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 15976, It: 0, Loss Data: 7.965e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.708e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 15977, It: 0, Loss Data: 7.998e-02, Loss Eqns: 2.306e+00, Loss Aux: 4.101e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 15978, It: 0, Loss Data: 7.584e-02, Loss Eqns: 2.235e+00, Loss Aux: 3.728e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 15979, It: 0, Loss Data: 9.097e-02, Loss Eqns: 2.273e+00, Loss Aux: 4.048e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 15980, It: 0, Loss Data: 8.196e-02, Loss Eqns: 2.216e+00, Loss Aux: 4.912e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 15981, It: 0, Loss Data: 8.096e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.502e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 15982, It: 0, Loss Data: 8.695e-02, Loss Eqns: 2.224e+00, Loss Aux: 4.017e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 15983, It: 0, Loss Data: 9.277e-02, Loss Eqns: 2.183e+00, Loss Aux: 4.057e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 15984, It: 0, Loss Data: 7.257e-02, Loss Eqns: 2.148e+00, Loss Aux: 4.400e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 15985, It: 0, Loss Data: 7.789e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.652e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 15986, It: 0, Loss Data: 7.716e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.363e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15987, It: 0, Loss Data: 8.998e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.005e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 15988, It: 0, Loss Data: 7.540e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.777e-02, Time: 0.133, Learning Rate: 1.0e-03\n",
      "Epoch: 15989, It: 0, Loss Data: 6.319e-02, Loss Eqns: 2.184e+00, Loss Aux: 4.542e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 15990, It: 0, Loss Data: 7.189e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.335e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15991, It: 0, Loss Data: 9.130e-02, Loss Eqns: 2.211e+00, Loss Aux: 3.907e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 15992, It: 0, Loss Data: 8.662e-02, Loss Eqns: 2.185e+00, Loss Aux: 4.080e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 15993, It: 0, Loss Data: 9.206e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.683e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 15994, It: 0, Loss Data: 7.581e-02, Loss Eqns: 2.167e+00, Loss Aux: 5.085e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 15995, It: 0, Loss Data: 7.810e-02, Loss Eqns: 2.142e+00, Loss Aux: 4.115e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 15996, It: 0, Loss Data: 7.356e-02, Loss Eqns: 2.251e+00, Loss Aux: 3.697e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 15997, It: 0, Loss Data: 8.959e-02, Loss Eqns: 2.184e+00, Loss Aux: 3.856e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 15998, It: 0, Loss Data: 8.804e-02, Loss Eqns: 2.188e+00, Loss Aux: 4.222e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 15999, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.198e+00, Loss Aux: 4.646e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16000, It: 0, Loss Data: 8.956e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.218e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16001, It: 0, Loss Data: 8.224e-02, Loss Eqns: 2.181e+00, Loss Aux: 4.021e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16002, It: 0, Loss Data: 8.235e-02, Loss Eqns: 2.208e+00, Loss Aux: 4.269e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16003, It: 0, Loss Data: 8.407e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.556e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16004, It: 0, Loss Data: 8.986e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.095e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16005, It: 0, Loss Data: 8.221e-02, Loss Eqns: 2.193e+00, Loss Aux: 5.053e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16006, It: 0, Loss Data: 8.721e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.537e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16007, It: 0, Loss Data: 7.804e-02, Loss Eqns: 2.238e+00, Loss Aux: 4.719e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16008, It: 0, Loss Data: 7.949e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.508e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16009, It: 0, Loss Data: 8.387e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.318e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16010, It: 0, Loss Data: 9.530e-02, Loss Eqns: 2.344e+00, Loss Aux: 3.862e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16011, It: 0, Loss Data: 8.449e-02, Loss Eqns: 2.256e+00, Loss Aux: 3.953e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16012, It: 0, Loss Data: 7.434e-02, Loss Eqns: 2.220e+00, Loss Aux: 4.539e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16013, It: 0, Loss Data: 1.046e-01, Loss Eqns: 2.200e+00, Loss Aux: 4.695e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16014, It: 0, Loss Data: 8.163e-02, Loss Eqns: 2.232e+00, Loss Aux: 3.927e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16015, It: 0, Loss Data: 8.108e-02, Loss Eqns: 2.332e+00, Loss Aux: 3.669e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16016, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.261e+00, Loss Aux: 4.175e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16017, It: 0, Loss Data: 7.330e-02, Loss Eqns: 2.289e+00, Loss Aux: 5.363e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16018, It: 0, Loss Data: 1.198e-01, Loss Eqns: 3.026e+00, Loss Aux: 3.991e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16019, It: 0, Loss Data: 1.075e-01, Loss Eqns: 3.340e+00, Loss Aux: 6.457e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16020, It: 0, Loss Data: 7.042e-02, Loss Eqns: 2.574e+00, Loss Aux: 6.355e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 16021, It: 0, Loss Data: 9.552e-02, Loss Eqns: 2.928e+00, Loss Aux: 4.842e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16022, It: 0, Loss Data: 8.713e-02, Loss Eqns: 2.382e+00, Loss Aux: 4.218e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16023, It: 0, Loss Data: 7.446e-02, Loss Eqns: 2.672e+00, Loss Aux: 3.891e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16024, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.604e+00, Loss Aux: 3.817e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 16025, It: 0, Loss Data: 8.015e-02, Loss Eqns: 2.399e+00, Loss Aux: 4.392e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16026, It: 0, Loss Data: 9.288e-02, Loss Eqns: 2.570e+00, Loss Aux: 4.601e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16027, It: 0, Loss Data: 8.762e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.029e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16028, It: 0, Loss Data: 9.324e-02, Loss Eqns: 2.442e+00, Loss Aux: 3.884e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16029, It: 0, Loss Data: 9.088e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.459e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16030, It: 0, Loss Data: 1.335e-01, Loss Eqns: 3.679e+00, Loss Aux: 6.674e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 16031, It: 0, Loss Data: 1.763e-01, Loss Eqns: 5.255e+00, Loss Aux: 4.292e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16032, It: 0, Loss Data: 2.026e-01, Loss Eqns: 4.825e+00, Loss Aux: 4.376e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16033, It: 0, Loss Data: 1.229e-01, Loss Eqns: 3.554e+00, Loss Aux: 6.318e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16034, It: 0, Loss Data: 1.781e-01, Loss Eqns: 4.764e+00, Loss Aux: 5.362e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16035, It: 0, Loss Data: 1.554e-01, Loss Eqns: 3.484e+00, Loss Aux: 2.701e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16036, It: 0, Loss Data: 1.602e-01, Loss Eqns: 4.566e+00, Loss Aux: 3.003e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16037, It: 0, Loss Data: 1.146e-01, Loss Eqns: 3.003e+00, Loss Aux: 5.905e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16038, It: 0, Loss Data: 1.620e-01, Loss Eqns: 3.547e+00, Loss Aux: 8.965e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16039, It: 0, Loss Data: 1.026e-01, Loss Eqns: 2.741e+00, Loss Aux: 7.721e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16040, It: 0, Loss Data: 1.364e-01, Loss Eqns: 2.942e+00, Loss Aux: 5.376e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16041, It: 0, Loss Data: 1.301e-01, Loss Eqns: 2.940e+00, Loss Aux: 4.847e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 16042, It: 0, Loss Data: 1.227e-01, Loss Eqns: 2.784e+00, Loss Aux: 5.249e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16043, It: 0, Loss Data: 1.096e-01, Loss Eqns: 2.861e+00, Loss Aux: 4.884e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16044, It: 0, Loss Data: 1.401e-01, Loss Eqns: 2.656e+00, Loss Aux: 3.985e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 16045, It: 0, Loss Data: 9.767e-02, Loss Eqns: 2.325e+00, Loss Aux: 5.781e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16046, It: 0, Loss Data: 1.316e-01, Loss Eqns: 2.479e+00, Loss Aux: 7.459e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16047, It: 0, Loss Data: 1.064e-01, Loss Eqns: 2.357e+00, Loss Aux: 6.518e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16048, It: 0, Loss Data: 9.252e-02, Loss Eqns: 2.348e+00, Loss Aux: 4.884e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16049, It: 0, Loss Data: 1.005e-01, Loss Eqns: 2.467e+00, Loss Aux: 3.919e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16050, It: 0, Loss Data: 1.042e-01, Loss Eqns: 2.383e+00, Loss Aux: 3.492e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16051, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.425e+00, Loss Aux: 4.260e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16052, It: 0, Loss Data: 9.951e-02, Loss Eqns: 2.334e+00, Loss Aux: 5.816e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16053, It: 0, Loss Data: 1.013e-01, Loss Eqns: 2.345e+00, Loss Aux: 6.806e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16054, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.403e+00, Loss Aux: 6.511e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16055, It: 0, Loss Data: 9.290e-02, Loss Eqns: 2.382e+00, Loss Aux: 5.653e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 16056, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.407e+00, Loss Aux: 4.951e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16057, It: 0, Loss Data: 9.654e-02, Loss Eqns: 2.405e+00, Loss Aux: 4.597e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16058, It: 0, Loss Data: 7.356e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.031e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16059, It: 0, Loss Data: 9.887e-02, Loss Eqns: 2.360e+00, Loss Aux: 5.913e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16060, It: 0, Loss Data: 8.539e-02, Loss Eqns: 2.380e+00, Loss Aux: 6.570e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16061, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.352e+00, Loss Aux: 6.619e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16062, It: 0, Loss Data: 8.739e-02, Loss Eqns: 2.384e+00, Loss Aux: 6.614e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16063, It: 0, Loss Data: 9.079e-02, Loss Eqns: 2.309e+00, Loss Aux: 5.974e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16064, It: 0, Loss Data: 9.663e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.936e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16065, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.242e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16066, It: 0, Loss Data: 8.388e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.185e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16067, It: 0, Loss Data: 8.847e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.792e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16068, It: 0, Loss Data: 8.332e-02, Loss Eqns: 2.296e+00, Loss Aux: 5.530e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16069, It: 0, Loss Data: 7.493e-02, Loss Eqns: 2.355e+00, Loss Aux: 5.531e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16070, It: 0, Loss Data: 8.534e-02, Loss Eqns: 2.343e+00, Loss Aux: 5.248e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16071, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.292e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 16072, It: 0, Loss Data: 9.744e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.519e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16073, It: 0, Loss Data: 8.198e-02, Loss Eqns: 2.299e+00, Loss Aux: 5.675e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16074, It: 0, Loss Data: 7.270e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.430e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16075, It: 0, Loss Data: 8.206e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.831e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16076, It: 0, Loss Data: 7.818e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.341e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16077, It: 0, Loss Data: 8.248e-02, Loss Eqns: 2.400e+00, Loss Aux: 4.436e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16078, It: 0, Loss Data: 8.013e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.014e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16079, It: 0, Loss Data: 8.322e-02, Loss Eqns: 2.395e+00, Loss Aux: 5.062e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16080, It: 0, Loss Data: 8.042e-02, Loss Eqns: 2.359e+00, Loss Aux: 5.074e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16081, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.246e+00, Loss Aux: 5.033e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16082, It: 0, Loss Data: 8.377e-02, Loss Eqns: 2.295e+00, Loss Aux: 5.095e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16083, It: 0, Loss Data: 7.659e-02, Loss Eqns: 2.260e+00, Loss Aux: 5.467e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16084, It: 0, Loss Data: 8.542e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.425e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16085, It: 0, Loss Data: 8.490e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.197e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16086, It: 0, Loss Data: 7.956e-02, Loss Eqns: 2.286e+00, Loss Aux: 4.870e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16087, It: 0, Loss Data: 7.036e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.594e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16088, It: 0, Loss Data: 8.379e-02, Loss Eqns: 2.199e+00, Loss Aux: 4.650e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16089, It: 0, Loss Data: 8.618e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.887e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16090, It: 0, Loss Data: 9.528e-02, Loss Eqns: 2.255e+00, Loss Aux: 5.011e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16091, It: 0, Loss Data: 8.475e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.965e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16092, It: 0, Loss Data: 8.561e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.894e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16093, It: 0, Loss Data: 8.524e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.884e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 16094, It: 0, Loss Data: 8.945e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.964e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 16095, It: 0, Loss Data: 7.438e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.931e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16096, It: 0, Loss Data: 8.842e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.758e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16097, It: 0, Loss Data: 8.334e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.982e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16098, It: 0, Loss Data: 7.637e-02, Loss Eqns: 2.262e+00, Loss Aux: 5.088e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16099, It: 0, Loss Data: 8.948e-02, Loss Eqns: 2.253e+00, Loss Aux: 4.814e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16100, It: 0, Loss Data: 8.043e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.450e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16101, It: 0, Loss Data: 8.246e-02, Loss Eqns: 2.268e+00, Loss Aux: 4.827e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16102, It: 0, Loss Data: 7.262e-02, Loss Eqns: 2.251e+00, Loss Aux: 5.591e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16103, It: 0, Loss Data: 7.362e-02, Loss Eqns: 2.316e+00, Loss Aux: 6.100e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16104, It: 0, Loss Data: 9.293e-02, Loss Eqns: 2.229e+00, Loss Aux: 5.442e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16105, It: 0, Loss Data: 8.116e-02, Loss Eqns: 2.366e+00, Loss Aux: 4.681e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16106, It: 0, Loss Data: 8.666e-02, Loss Eqns: 2.412e+00, Loss Aux: 4.260e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16107, It: 0, Loss Data: 8.666e-02, Loss Eqns: 2.341e+00, Loss Aux: 4.317e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16108, It: 0, Loss Data: 8.465e-02, Loss Eqns: 2.329e+00, Loss Aux: 4.371e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16109, It: 0, Loss Data: 7.802e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.483e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16110, It: 0, Loss Data: 8.432e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.670e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16111, It: 0, Loss Data: 8.502e-02, Loss Eqns: 2.336e+00, Loss Aux: 4.861e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 16112, It: 0, Loss Data: 8.587e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.944e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16113, It: 0, Loss Data: 8.433e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.328e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16114, It: 0, Loss Data: 8.101e-02, Loss Eqns: 2.312e+00, Loss Aux: 5.625e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16115, It: 0, Loss Data: 9.213e-02, Loss Eqns: 2.275e+00, Loss Aux: 5.091e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16116, It: 0, Loss Data: 1.238e-01, Loss Eqns: 2.899e+00, Loss Aux: 6.031e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16117, It: 0, Loss Data: 1.264e-01, Loss Eqns: 3.065e+00, Loss Aux: 4.212e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 16118, It: 0, Loss Data: 1.316e-01, Loss Eqns: 3.264e+00, Loss Aux: 4.226e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16119, It: 0, Loss Data: 9.536e-02, Loss Eqns: 2.454e+00, Loss Aux: 6.504e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16120, It: 0, Loss Data: 1.197e-01, Loss Eqns: 3.501e+00, Loss Aux: 7.360e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16121, It: 0, Loss Data: 8.699e-02, Loss Eqns: 2.416e+00, Loss Aux: 4.499e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16122, It: 0, Loss Data: 1.458e-01, Loss Eqns: 2.970e+00, Loss Aux: 3.661e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16123, It: 0, Loss Data: 1.073e-01, Loss Eqns: 2.460e+00, Loss Aux: 5.843e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16124, It: 0, Loss Data: 1.106e-01, Loss Eqns: 2.729e+00, Loss Aux: 7.190e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16125, It: 0, Loss Data: 1.350e-01, Loss Eqns: 3.511e+00, Loss Aux: 6.988e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16126, It: 0, Loss Data: 1.835e-01, Loss Eqns: 3.306e+00, Loss Aux: 3.620e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16127, It: 0, Loss Data: 1.883e-01, Loss Eqns: 4.107e+00, Loss Aux: 3.367e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16128, It: 0, Loss Data: 1.325e-01, Loss Eqns: 2.904e+00, Loss Aux: 6.452e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16129, It: 0, Loss Data: 1.848e-01, Loss Eqns: 2.822e+00, Loss Aux: 8.327e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16130, It: 0, Loss Data: 1.270e-01, Loss Eqns: 3.113e+00, Loss Aux: 5.948e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16131, It: 0, Loss Data: 1.440e-01, Loss Eqns: 2.552e+00, Loss Aux: 4.164e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16132, It: 0, Loss Data: 1.545e-01, Loss Eqns: 2.831e+00, Loss Aux: 3.912e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16133, It: 0, Loss Data: 1.214e-01, Loss Eqns: 2.771e+00, Loss Aux: 7.356e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16134, It: 0, Loss Data: 1.356e-01, Loss Eqns: 2.505e+00, Loss Aux: 8.558e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16135, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.639e+00, Loss Aux: 5.673e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16136, It: 0, Loss Data: 1.152e-01, Loss Eqns: 2.513e+00, Loss Aux: 4.372e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16137, It: 0, Loss Data: 1.261e-01, Loss Eqns: 2.372e+00, Loss Aux: 3.784e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16138, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.490e+00, Loss Aux: 5.469e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16139, It: 0, Loss Data: 1.311e-01, Loss Eqns: 2.350e+00, Loss Aux: 8.161e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16140, It: 0, Loss Data: 1.089e-01, Loss Eqns: 2.302e+00, Loss Aux: 8.105e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16141, It: 0, Loss Data: 1.253e-01, Loss Eqns: 2.394e+00, Loss Aux: 6.381e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16142, It: 0, Loss Data: 1.202e-01, Loss Eqns: 2.188e+00, Loss Aux: 4.583e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16143, It: 0, Loss Data: 1.425e-01, Loss Eqns: 2.472e+00, Loss Aux: 3.620e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16144, It: 0, Loss Data: 1.156e-01, Loss Eqns: 2.456e+00, Loss Aux: 5.383e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16145, It: 0, Loss Data: 1.800e-01, Loss Eqns: 2.979e+00, Loss Aux: 7.124e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16146, It: 0, Loss Data: 9.618e-02, Loss Eqns: 2.532e+00, Loss Aux: 4.683e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16147, It: 0, Loss Data: 1.694e-01, Loss Eqns: 2.848e+00, Loss Aux: 4.227e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 16148, It: 0, Loss Data: 1.242e-01, Loss Eqns: 2.570e+00, Loss Aux: 4.080e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16149, It: 0, Loss Data: 8.536e-02, Loss Eqns: 2.728e+00, Loss Aux: 7.292e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16150, It: 0, Loss Data: 1.358e-01, Loss Eqns: 2.711e+00, Loss Aux: 9.396e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16151, It: 0, Loss Data: 1.009e-01, Loss Eqns: 2.509e+00, Loss Aux: 6.687e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16152, It: 0, Loss Data: 1.144e-01, Loss Eqns: 2.774e+00, Loss Aux: 4.655e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16153, It: 0, Loss Data: 1.178e-01, Loss Eqns: 2.403e+00, Loss Aux: 4.332e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16154, It: 0, Loss Data: 9.206e-02, Loss Eqns: 2.476e+00, Loss Aux: 6.726e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16155, It: 0, Loss Data: 1.236e-01, Loss Eqns: 2.667e+00, Loss Aux: 8.873e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16156, It: 0, Loss Data: 9.489e-02, Loss Eqns: 2.289e+00, Loss Aux: 6.889e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16157, It: 0, Loss Data: 1.166e-01, Loss Eqns: 2.488e+00, Loss Aux: 4.895e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16158, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.348e+00, Loss Aux: 3.937e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16159, It: 0, Loss Data: 1.001e-01, Loss Eqns: 2.395e+00, Loss Aux: 3.871e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16160, It: 0, Loss Data: 9.938e-02, Loss Eqns: 2.589e+00, Loss Aux: 4.721e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16161, It: 0, Loss Data: 9.605e-02, Loss Eqns: 2.332e+00, Loss Aux: 5.554e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16162, It: 0, Loss Data: 1.074e-01, Loss Eqns: 2.376e+00, Loss Aux: 6.186e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16163, It: 0, Loss Data: 9.261e-02, Loss Eqns: 2.362e+00, Loss Aux: 6.694e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16164, It: 0, Loss Data: 8.771e-02, Loss Eqns: 2.292e+00, Loss Aux: 6.476e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16165, It: 0, Loss Data: 7.509e-02, Loss Eqns: 2.455e+00, Loss Aux: 5.936e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16166, It: 0, Loss Data: 9.676e-02, Loss Eqns: 2.377e+00, Loss Aux: 4.785e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16167, It: 0, Loss Data: 9.966e-02, Loss Eqns: 2.410e+00, Loss Aux: 4.227e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16168, It: 0, Loss Data: 9.813e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.938e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16169, It: 0, Loss Data: 6.906e-02, Loss Eqns: 2.268e+00, Loss Aux: 6.277e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16170, It: 0, Loss Data: 9.502e-02, Loss Eqns: 2.377e+00, Loss Aux: 7.394e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16171, It: 0, Loss Data: 9.901e-02, Loss Eqns: 2.168e+00, Loss Aux: 7.182e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16172, It: 0, Loss Data: 1.036e-01, Loss Eqns: 2.266e+00, Loss Aux: 6.294e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16173, It: 0, Loss Data: 1.033e-01, Loss Eqns: 2.291e+00, Loss Aux: 5.246e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16174, It: 0, Loss Data: 1.030e-01, Loss Eqns: 2.326e+00, Loss Aux: 4.847e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16175, It: 0, Loss Data: 7.570e-02, Loss Eqns: 2.463e+00, Loss Aux: 4.808e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16176, It: 0, Loss Data: 8.532e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.896e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16177, It: 0, Loss Data: 9.020e-02, Loss Eqns: 2.308e+00, Loss Aux: 5.038e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16178, It: 0, Loss Data: 9.566e-02, Loss Eqns: 2.345e+00, Loss Aux: 5.304e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16179, It: 0, Loss Data: 7.073e-02, Loss Eqns: 2.387e+00, Loss Aux: 5.676e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16180, It: 0, Loss Data: 9.010e-02, Loss Eqns: 2.403e+00, Loss Aux: 5.584e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16181, It: 0, Loss Data: 7.672e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.150e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16182, It: 0, Loss Data: 8.318e-02, Loss Eqns: 2.349e+00, Loss Aux: 4.897e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16183, It: 0, Loss Data: 7.733e-02, Loss Eqns: 2.284e+00, Loss Aux: 5.451e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16184, It: 0, Loss Data: 9.120e-02, Loss Eqns: 2.332e+00, Loss Aux: 6.153e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16185, It: 0, Loss Data: 7.255e-02, Loss Eqns: 2.371e+00, Loss Aux: 6.475e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16186, It: 0, Loss Data: 9.254e-02, Loss Eqns: 2.290e+00, Loss Aux: 5.971e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16187, It: 0, Loss Data: 7.890e-02, Loss Eqns: 2.279e+00, Loss Aux: 5.170e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16188, It: 0, Loss Data: 8.685e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.799e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16189, It: 0, Loss Data: 9.769e-02, Loss Eqns: 2.355e+00, Loss Aux: 4.665e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16190, It: 0, Loss Data: 8.147e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.242e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16191, It: 0, Loss Data: 8.810e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.019e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16192, It: 0, Loss Data: 8.857e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.345e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16193, It: 0, Loss Data: 9.242e-02, Loss Eqns: 2.315e+00, Loss Aux: 5.347e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16194, It: 0, Loss Data: 8.496e-02, Loss Eqns: 2.381e+00, Loss Aux: 5.852e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16195, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.353e+00, Loss Aux: 5.523e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16196, It: 0, Loss Data: 9.201e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.596e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16197, It: 0, Loss Data: 8.375e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.184e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16198, It: 0, Loss Data: 8.654e-02, Loss Eqns: 2.314e+00, Loss Aux: 4.586e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16199, It: 0, Loss Data: 8.711e-02, Loss Eqns: 2.360e+00, Loss Aux: 5.378e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16200, It: 0, Loss Data: 8.597e-02, Loss Eqns: 2.385e+00, Loss Aux: 5.630e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16201, It: 0, Loss Data: 8.061e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.272e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16202, It: 0, Loss Data: 7.652e-02, Loss Eqns: 2.380e+00, Loss Aux: 5.190e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 16203, It: 0, Loss Data: 8.424e-02, Loss Eqns: 2.441e+00, Loss Aux: 5.207e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16204, It: 0, Loss Data: 9.205e-02, Loss Eqns: 2.342e+00, Loss Aux: 5.312e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16205, It: 0, Loss Data: 8.441e-02, Loss Eqns: 2.351e+00, Loss Aux: 4.805e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16206, It: 0, Loss Data: 7.775e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.321e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16207, It: 0, Loss Data: 7.888e-02, Loss Eqns: 2.310e+00, Loss Aux: 4.466e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16208, It: 0, Loss Data: 7.647e-02, Loss Eqns: 2.318e+00, Loss Aux: 5.056e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16209, It: 0, Loss Data: 8.309e-02, Loss Eqns: 2.320e+00, Loss Aux: 5.601e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16210, It: 0, Loss Data: 8.784e-02, Loss Eqns: 2.266e+00, Loss Aux: 6.010e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16211, It: 0, Loss Data: 7.848e-02, Loss Eqns: 2.255e+00, Loss Aux: 6.025e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16212, It: 0, Loss Data: 7.817e-02, Loss Eqns: 2.302e+00, Loss Aux: 5.554e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16213, It: 0, Loss Data: 9.032e-02, Loss Eqns: 2.344e+00, Loss Aux: 5.284e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16214, It: 0, Loss Data: 7.535e-02, Loss Eqns: 2.223e+00, Loss Aux: 4.593e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16215, It: 0, Loss Data: 8.102e-02, Loss Eqns: 2.248e+00, Loss Aux: 4.236e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16216, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.307e+00, Loss Aux: 4.351e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16217, It: 0, Loss Data: 8.034e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.281e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16218, It: 0, Loss Data: 6.696e-02, Loss Eqns: 2.370e+00, Loss Aux: 4.300e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16219, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.837e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16220, It: 0, Loss Data: 9.243e-02, Loss Eqns: 2.279e+00, Loss Aux: 5.899e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16221, It: 0, Loss Data: 7.979e-02, Loss Eqns: 2.189e+00, Loss Aux: 6.313e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16222, It: 0, Loss Data: 9.203e-02, Loss Eqns: 2.245e+00, Loss Aux: 5.461e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16223, It: 0, Loss Data: 9.232e-02, Loss Eqns: 2.211e+00, Loss Aux: 4.621e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16224, It: 0, Loss Data: 8.608e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.515e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16225, It: 0, Loss Data: 8.634e-02, Loss Eqns: 2.311e+00, Loss Aux: 5.064e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16226, It: 0, Loss Data: 8.635e-02, Loss Eqns: 2.249e+00, Loss Aux: 5.661e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 16227, It: 0, Loss Data: 8.974e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.111e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16228, It: 0, Loss Data: 9.305e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.298e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16229, It: 0, Loss Data: 7.954e-02, Loss Eqns: 2.328e+00, Loss Aux: 4.136e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16230, It: 0, Loss Data: 8.294e-02, Loss Eqns: 2.283e+00, Loss Aux: 4.757e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16231, It: 0, Loss Data: 8.525e-02, Loss Eqns: 2.293e+00, Loss Aux: 5.279e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16232, It: 0, Loss Data: 9.296e-02, Loss Eqns: 2.376e+00, Loss Aux: 4.839e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16233, It: 0, Loss Data: 8.411e-02, Loss Eqns: 2.348e+00, Loss Aux: 3.964e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16234, It: 0, Loss Data: 7.648e-02, Loss Eqns: 2.331e+00, Loss Aux: 3.629e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16235, It: 0, Loss Data: 8.430e-02, Loss Eqns: 2.369e+00, Loss Aux: 4.121e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16236, It: 0, Loss Data: 7.840e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.659e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16237, It: 0, Loss Data: 8.720e-02, Loss Eqns: 2.350e+00, Loss Aux: 4.890e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16238, It: 0, Loss Data: 9.169e-02, Loss Eqns: 2.352e+00, Loss Aux: 4.916e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 16239, It: 0, Loss Data: 8.496e-02, Loss Eqns: 2.300e+00, Loss Aux: 5.218e-02, Time: 0.230, Learning Rate: 1.0e-03\n",
      "Epoch: 16240, It: 0, Loss Data: 6.854e-02, Loss Eqns: 2.273e+00, Loss Aux: 5.757e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16241, It: 0, Loss Data: 8.443e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.769e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 16242, It: 0, Loss Data: 9.341e-02, Loss Eqns: 2.280e+00, Loss Aux: 5.533e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16243, It: 0, Loss Data: 7.743e-02, Loss Eqns: 2.238e+00, Loss Aux: 5.123e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16244, It: 0, Loss Data: 7.751e-02, Loss Eqns: 2.240e+00, Loss Aux: 4.672e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16245, It: 0, Loss Data: 8.736e-02, Loss Eqns: 2.232e+00, Loss Aux: 4.555e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16246, It: 0, Loss Data: 8.620e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.655e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16247, It: 0, Loss Data: 8.442e-02, Loss Eqns: 2.274e+00, Loss Aux: 4.799e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16248, It: 0, Loss Data: 9.083e-02, Loss Eqns: 2.274e+00, Loss Aux: 5.243e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16249, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.201e+00, Loss Aux: 5.567e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 16250, It: 0, Loss Data: 8.056e-02, Loss Eqns: 2.217e+00, Loss Aux: 5.765e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16251, It: 0, Loss Data: 8.136e-02, Loss Eqns: 2.271e+00, Loss Aux: 5.354e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16252, It: 0, Loss Data: 9.477e-02, Loss Eqns: 2.186e+00, Loss Aux: 4.610e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16253, It: 0, Loss Data: 1.191e-01, Loss Eqns: 2.689e+00, Loss Aux: 5.467e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16254, It: 0, Loss Data: 9.186e-02, Loss Eqns: 2.378e+00, Loss Aux: 3.877e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16255, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.765e+00, Loss Aux: 3.897e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16256, It: 0, Loss Data: 8.285e-02, Loss Eqns: 2.310e+00, Loss Aux: 5.332e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16257, It: 0, Loss Data: 9.095e-02, Loss Eqns: 2.750e+00, Loss Aux: 6.598e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16258, It: 0, Loss Data: 9.492e-02, Loss Eqns: 2.275e+00, Loss Aux: 5.130e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16259, It: 0, Loss Data: 9.185e-02, Loss Eqns: 2.549e+00, Loss Aux: 3.929e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16260, It: 0, Loss Data: 9.619e-02, Loss Eqns: 2.486e+00, Loss Aux: 4.292e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16261, It: 0, Loss Data: 8.725e-02, Loss Eqns: 2.391e+00, Loss Aux: 5.670e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16262, It: 0, Loss Data: 9.919e-02, Loss Eqns: 2.542e+00, Loss Aux: 5.960e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16263, It: 0, Loss Data: 9.944e-02, Loss Eqns: 2.320e+00, Loss Aux: 4.501e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16264, It: 0, Loss Data: 9.247e-02, Loss Eqns: 2.453e+00, Loss Aux: 3.773e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16265, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.289e+00, Loss Aux: 3.953e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16266, It: 0, Loss Data: 9.515e-02, Loss Eqns: 2.416e+00, Loss Aux: 5.081e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16267, It: 0, Loss Data: 7.952e-02, Loss Eqns: 2.418e+00, Loss Aux: 5.618e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16268, It: 0, Loss Data: 8.237e-02, Loss Eqns: 2.331e+00, Loss Aux: 5.024e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16269, It: 0, Loss Data: 9.493e-02, Loss Eqns: 2.337e+00, Loss Aux: 4.781e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16270, It: 0, Loss Data: 9.131e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.958e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16271, It: 0, Loss Data: 9.757e-02, Loss Eqns: 2.337e+00, Loss Aux: 5.980e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 16272, It: 0, Loss Data: 8.606e-02, Loss Eqns: 2.230e+00, Loss Aux: 5.776e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 16273, It: 0, Loss Data: 8.577e-02, Loss Eqns: 2.389e+00, Loss Aux: 4.606e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16274, It: 0, Loss Data: 8.753e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.115e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16275, It: 0, Loss Data: 8.692e-02, Loss Eqns: 2.378e+00, Loss Aux: 4.262e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16276, It: 0, Loss Data: 8.162e-02, Loss Eqns: 2.374e+00, Loss Aux: 4.465e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16277, It: 0, Loss Data: 7.974e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.894e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16278, It: 0, Loss Data: 8.561e-02, Loss Eqns: 2.254e+00, Loss Aux: 5.944e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16279, It: 0, Loss Data: 9.514e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.684e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16280, It: 0, Loss Data: 1.021e-01, Loss Eqns: 2.269e+00, Loss Aux: 4.368e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16281, It: 0, Loss Data: 7.927e-02, Loss Eqns: 2.290e+00, Loss Aux: 5.297e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16282, It: 0, Loss Data: 1.085e-01, Loss Eqns: 2.352e+00, Loss Aux: 7.157e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16283, It: 0, Loss Data: 8.808e-02, Loss Eqns: 2.270e+00, Loss Aux: 7.025e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16284, It: 0, Loss Data: 1.603e-01, Loss Eqns: 3.115e+00, Loss Aux: 4.347e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16285, It: 0, Loss Data: 8.141e-02, Loss Eqns: 2.346e+00, Loss Aux: 4.158e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16286, It: 0, Loss Data: 1.290e-01, Loss Eqns: 3.580e+00, Loss Aux: 5.233e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16287, It: 0, Loss Data: 9.930e-02, Loss Eqns: 2.296e+00, Loss Aux: 5.439e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16288, It: 0, Loss Data: 1.092e-01, Loss Eqns: 2.699e+00, Loss Aux: 4.370e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16289, It: 0, Loss Data: 1.139e-01, Loss Eqns: 2.792e+00, Loss Aux: 4.107e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16290, It: 0, Loss Data: 8.436e-02, Loss Eqns: 2.341e+00, Loss Aux: 5.054e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16291, It: 0, Loss Data: 1.247e-01, Loss Eqns: 3.047e+00, Loss Aux: 6.246e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16292, It: 0, Loss Data: 9.572e-02, Loss Eqns: 2.247e+00, Loss Aux: 5.797e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16293, It: 0, Loss Data: 9.420e-02, Loss Eqns: 2.614e+00, Loss Aux: 4.615e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16294, It: 0, Loss Data: 1.177e-01, Loss Eqns: 2.632e+00, Loss Aux: 4.267e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16295, It: 0, Loss Data: 9.318e-02, Loss Eqns: 2.317e+00, Loss Aux: 4.818e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16296, It: 0, Loss Data: 1.006e-01, Loss Eqns: 2.752e+00, Loss Aux: 5.217e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16297, It: 0, Loss Data: 8.708e-02, Loss Eqns: 2.417e+00, Loss Aux: 4.940e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16298, It: 0, Loss Data: 1.034e-01, Loss Eqns: 2.490e+00, Loss Aux: 4.713e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 16299, It: 0, Loss Data: 7.853e-02, Loss Eqns: 2.476e+00, Loss Aux: 4.994e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16300, It: 0, Loss Data: 8.078e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.915e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16301, It: 0, Loss Data: 1.326e-01, Loss Eqns: 3.053e+00, Loss Aux: 7.839e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16302, It: 0, Loss Data: 9.093e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.258e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16303, It: 0, Loss Data: 1.302e-01, Loss Eqns: 2.820e+00, Loss Aux: 4.049e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16304, It: 0, Loss Data: 9.890e-02, Loss Eqns: 2.529e+00, Loss Aux: 4.074e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 16305, It: 0, Loss Data: 9.774e-02, Loss Eqns: 2.392e+00, Loss Aux: 5.578e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16306, It: 0, Loss Data: 1.153e-01, Loss Eqns: 2.724e+00, Loss Aux: 5.775e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16307, It: 0, Loss Data: 9.309e-02, Loss Eqns: 2.267e+00, Loss Aux: 4.180e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16308, It: 0, Loss Data: 1.090e-01, Loss Eqns: 2.548e+00, Loss Aux: 3.546e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16309, It: 0, Loss Data: 9.561e-02, Loss Eqns: 2.427e+00, Loss Aux: 4.373e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16310, It: 0, Loss Data: 9.976e-02, Loss Eqns: 2.180e+00, Loss Aux: 6.300e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 16311, It: 0, Loss Data: 1.056e-01, Loss Eqns: 2.501e+00, Loss Aux: 7.163e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16312, It: 0, Loss Data: 8.071e-02, Loss Eqns: 2.156e+00, Loss Aux: 5.757e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16313, It: 0, Loss Data: 1.110e-01, Loss Eqns: 2.238e+00, Loss Aux: 4.135e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16314, It: 0, Loss Data: 1.062e-01, Loss Eqns: 2.290e+00, Loss Aux: 3.753e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16315, It: 0, Loss Data: 9.687e-02, Loss Eqns: 2.202e+00, Loss Aux: 5.244e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16316, It: 0, Loss Data: 9.267e-02, Loss Eqns: 2.363e+00, Loss Aux: 7.030e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16317, It: 0, Loss Data: 1.015e-01, Loss Eqns: 2.232e+00, Loss Aux: 6.308e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16318, It: 0, Loss Data: 9.451e-02, Loss Eqns: 2.305e+00, Loss Aux: 4.757e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16319, It: 0, Loss Data: 1.045e-01, Loss Eqns: 2.312e+00, Loss Aux: 4.158e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16320, It: 0, Loss Data: 7.924e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.029e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16321, It: 0, Loss Data: 9.923e-02, Loss Eqns: 2.423e+00, Loss Aux: 4.618e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16322, It: 0, Loss Data: 9.080e-02, Loss Eqns: 2.357e+00, Loss Aux: 5.247e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16323, It: 0, Loss Data: 9.468e-02, Loss Eqns: 2.269e+00, Loss Aux: 5.401e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16324, It: 0, Loss Data: 7.954e-02, Loss Eqns: 2.453e+00, Loss Aux: 5.250e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16325, It: 0, Loss Data: 7.850e-02, Loss Eqns: 2.334e+00, Loss Aux: 5.398e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16326, It: 0, Loss Data: 8.117e-02, Loss Eqns: 2.442e+00, Loss Aux: 5.564e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16327, It: 0, Loss Data: 8.068e-02, Loss Eqns: 2.371e+00, Loss Aux: 5.061e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16328, It: 0, Loss Data: 7.936e-02, Loss Eqns: 2.222e+00, Loss Aux: 4.622e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16329, It: 0, Loss Data: 7.970e-02, Loss Eqns: 2.308e+00, Loss Aux: 4.620e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16330, It: 0, Loss Data: 8.534e-02, Loss Eqns: 2.211e+00, Loss Aux: 5.221e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16331, It: 0, Loss Data: 8.526e-02, Loss Eqns: 2.306e+00, Loss Aux: 5.529e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16332, It: 0, Loss Data: 7.643e-02, Loss Eqns: 2.228e+00, Loss Aux: 5.424e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16333, It: 0, Loss Data: 9.311e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.835e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16334, It: 0, Loss Data: 8.082e-02, Loss Eqns: 2.216e+00, Loss Aux: 4.502e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16335, It: 0, Loss Data: 8.503e-02, Loss Eqns: 2.209e+00, Loss Aux: 4.397e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16336, It: 0, Loss Data: 8.418e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.491e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16337, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.845e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16338, It: 0, Loss Data: 8.813e-02, Loss Eqns: 2.225e+00, Loss Aux: 5.149e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16339, It: 0, Loss Data: 9.283e-02, Loss Eqns: 2.243e+00, Loss Aux: 5.065e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16340, It: 0, Loss Data: 9.224e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.758e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 16341, It: 0, Loss Data: 8.622e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.303e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16342, It: 0, Loss Data: 8.062e-02, Loss Eqns: 2.270e+00, Loss Aux: 4.238e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16343, It: 0, Loss Data: 9.144e-02, Loss Eqns: 2.347e+00, Loss Aux: 4.427e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16344, It: 0, Loss Data: 8.176e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.850e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16345, It: 0, Loss Data: 7.842e-02, Loss Eqns: 2.337e+00, Loss Aux: 5.217e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16346, It: 0, Loss Data: 9.235e-02, Loss Eqns: 2.380e+00, Loss Aux: 5.476e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16347, It: 0, Loss Data: 8.603e-02, Loss Eqns: 2.340e+00, Loss Aux: 5.555e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16348, It: 0, Loss Data: 9.072e-02, Loss Eqns: 2.341e+00, Loss Aux: 5.473e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16349, It: 0, Loss Data: 8.895e-02, Loss Eqns: 2.360e+00, Loss Aux: 5.135e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16350, It: 0, Loss Data: 9.805e-02, Loss Eqns: 2.363e+00, Loss Aux: 4.769e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16351, It: 0, Loss Data: 8.547e-02, Loss Eqns: 2.258e+00, Loss Aux: 4.758e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16352, It: 0, Loss Data: 7.783e-02, Loss Eqns: 2.365e+00, Loss Aux: 4.882e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16353, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.392e+00, Loss Aux: 5.095e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16354, It: 0, Loss Data: 6.989e-02, Loss Eqns: 2.325e+00, Loss Aux: 4.903e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16355, It: 0, Loss Data: 7.662e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.658e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16356, It: 0, Loss Data: 7.844e-02, Loss Eqns: 2.324e+00, Loss Aux: 4.686e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16357, It: 0, Loss Data: 7.099e-02, Loss Eqns: 2.339e+00, Loss Aux: 5.097e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16358, It: 0, Loss Data: 7.607e-02, Loss Eqns: 2.318e+00, Loss Aux: 5.517e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16359, It: 0, Loss Data: 8.752e-02, Loss Eqns: 2.316e+00, Loss Aux: 5.497e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16360, It: 0, Loss Data: 8.182e-02, Loss Eqns: 2.326e+00, Loss Aux: 4.822e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16361, It: 0, Loss Data: 9.444e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.318e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16362, It: 0, Loss Data: 8.944e-02, Loss Eqns: 2.358e+00, Loss Aux: 4.374e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16363, It: 0, Loss Data: 7.999e-02, Loss Eqns: 2.354e+00, Loss Aux: 4.727e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16364, It: 0, Loss Data: 8.466e-02, Loss Eqns: 2.236e+00, Loss Aux: 5.222e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16365, It: 0, Loss Data: 7.641e-02, Loss Eqns: 2.288e+00, Loss Aux: 4.941e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16366, It: 0, Loss Data: 8.766e-02, Loss Eqns: 2.222e+00, Loss Aux: 4.222e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16367, It: 0, Loss Data: 8.507e-02, Loss Eqns: 2.234e+00, Loss Aux: 4.030e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16368, It: 0, Loss Data: 7.520e-02, Loss Eqns: 2.249e+00, Loss Aux: 4.569e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16369, It: 0, Loss Data: 8.696e-02, Loss Eqns: 2.289e+00, Loss Aux: 5.412e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 16370, It: 0, Loss Data: 8.557e-02, Loss Eqns: 2.242e+00, Loss Aux: 5.557e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16371, It: 0, Loss Data: 8.559e-02, Loss Eqns: 2.318e+00, Loss Aux: 5.323e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 16372, It: 0, Loss Data: 8.492e-02, Loss Eqns: 2.337e+00, Loss Aux: 5.077e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16373, It: 0, Loss Data: 9.063e-02, Loss Eqns: 2.289e+00, Loss Aux: 5.260e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16374, It: 0, Loss Data: 7.276e-02, Loss Eqns: 2.274e+00, Loss Aux: 5.437e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16375, It: 0, Loss Data: 7.486e-02, Loss Eqns: 2.260e+00, Loss Aux: 4.886e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16376, It: 0, Loss Data: 8.262e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.199e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16377, It: 0, Loss Data: 8.242e-02, Loss Eqns: 2.271e+00, Loss Aux: 3.899e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16378, It: 0, Loss Data: 7.187e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.116e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16379, It: 0, Loss Data: 9.185e-02, Loss Eqns: 2.180e+00, Loss Aux: 4.687e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16380, It: 0, Loss Data: 8.344e-02, Loss Eqns: 2.209e+00, Loss Aux: 5.088e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16381, It: 0, Loss Data: 8.639e-02, Loss Eqns: 2.200e+00, Loss Aux: 4.722e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16382, It: 0, Loss Data: 9.710e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.465e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16383, It: 0, Loss Data: 6.995e-02, Loss Eqns: 2.276e+00, Loss Aux: 4.531e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16384, It: 0, Loss Data: 9.399e-02, Loss Eqns: 2.186e+00, Loss Aux: 4.468e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16385, It: 0, Loss Data: 8.178e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.318e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16386, It: 0, Loss Data: 8.471e-02, Loss Eqns: 2.279e+00, Loss Aux: 4.290e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16387, It: 0, Loss Data: 7.974e-02, Loss Eqns: 2.247e+00, Loss Aux: 4.845e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16388, It: 0, Loss Data: 8.817e-02, Loss Eqns: 2.271e+00, Loss Aux: 5.340e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16389, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.766e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16390, It: 0, Loss Data: 7.522e-02, Loss Eqns: 2.207e+00, Loss Aux: 5.823e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16391, It: 0, Loss Data: 8.429e-02, Loss Eqns: 2.196e+00, Loss Aux: 5.463e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16392, It: 0, Loss Data: 6.425e-02, Loss Eqns: 2.303e+00, Loss Aux: 4.853e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16393, It: 0, Loss Data: 7.870e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.399e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16394, It: 0, Loss Data: 9.474e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.168e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16395, It: 0, Loss Data: 9.814e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.089e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16396, It: 0, Loss Data: 8.145e-02, Loss Eqns: 2.265e+00, Loss Aux: 4.022e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16397, It: 0, Loss Data: 8.301e-02, Loss Eqns: 2.312e+00, Loss Aux: 3.902e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16398, It: 0, Loss Data: 8.916e-02, Loss Eqns: 2.323e+00, Loss Aux: 3.926e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16399, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.536e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16400, It: 0, Loss Data: 8.077e-02, Loss Eqns: 2.241e+00, Loss Aux: 5.344e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16401, It: 0, Loss Data: 8.180e-02, Loss Eqns: 2.191e+00, Loss Aux: 5.936e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16402, It: 0, Loss Data: 7.202e-02, Loss Eqns: 2.290e+00, Loss Aux: 5.444e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16403, It: 0, Loss Data: 7.735e-02, Loss Eqns: 2.264e+00, Loss Aux: 5.031e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16404, It: 0, Loss Data: 9.519e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.580e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16405, It: 0, Loss Data: 8.302e-02, Loss Eqns: 2.241e+00, Loss Aux: 4.526e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16406, It: 0, Loss Data: 8.279e-02, Loss Eqns: 2.344e+00, Loss Aux: 4.659e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16407, It: 0, Loss Data: 8.885e-02, Loss Eqns: 2.270e+00, Loss Aux: 5.028e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16408, It: 0, Loss Data: 7.857e-02, Loss Eqns: 2.255e+00, Loss Aux: 5.257e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16409, It: 0, Loss Data: 9.065e-02, Loss Eqns: 2.302e+00, Loss Aux: 4.792e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 16410, It: 0, Loss Data: 7.087e-02, Loss Eqns: 2.275e+00, Loss Aux: 4.491e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16411, It: 0, Loss Data: 8.510e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.141e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16412, It: 0, Loss Data: 8.627e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.881e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16413, It: 0, Loss Data: 8.768e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.023e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 16414, It: 0, Loss Data: 7.723e-02, Loss Eqns: 2.175e+00, Loss Aux: 4.476e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16415, It: 0, Loss Data: 7.040e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.588e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16416, It: 0, Loss Data: 7.033e-02, Loss Eqns: 2.293e+00, Loss Aux: 4.679e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16417, It: 0, Loss Data: 7.716e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.774e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16418, It: 0, Loss Data: 7.849e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.650e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16419, It: 0, Loss Data: 9.863e-02, Loss Eqns: 2.304e+00, Loss Aux: 4.323e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16420, It: 0, Loss Data: 7.547e-02, Loss Eqns: 2.285e+00, Loss Aux: 3.932e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16421, It: 0, Loss Data: 8.357e-02, Loss Eqns: 2.319e+00, Loss Aux: 3.859e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16422, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.345e+00, Loss Aux: 4.252e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16423, It: 0, Loss Data: 8.593e-02, Loss Eqns: 2.330e+00, Loss Aux: 4.899e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16424, It: 0, Loss Data: 8.570e-02, Loss Eqns: 2.269e+00, Loss Aux: 4.728e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16425, It: 0, Loss Data: 7.932e-02, Loss Eqns: 2.292e+00, Loss Aux: 4.279e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16426, It: 0, Loss Data: 7.863e-02, Loss Eqns: 2.335e+00, Loss Aux: 4.448e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16427, It: 0, Loss Data: 8.320e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.465e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16428, It: 0, Loss Data: 6.851e-02, Loss Eqns: 2.238e+00, Loss Aux: 4.941e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16429, It: 0, Loss Data: 8.191e-02, Loss Eqns: 2.291e+00, Loss Aux: 5.187e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16430, It: 0, Loss Data: 8.056e-02, Loss Eqns: 2.228e+00, Loss Aux: 5.245e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16431, It: 0, Loss Data: 7.588e-02, Loss Eqns: 2.209e+00, Loss Aux: 5.010e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16432, It: 0, Loss Data: 8.772e-02, Loss Eqns: 2.245e+00, Loss Aux: 4.795e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16433, It: 0, Loss Data: 8.177e-02, Loss Eqns: 2.263e+00, Loss Aux: 4.355e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16434, It: 0, Loss Data: 8.316e-02, Loss Eqns: 2.262e+00, Loss Aux: 4.224e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16435, It: 0, Loss Data: 8.011e-02, Loss Eqns: 2.307e+00, Loss Aux: 3.977e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16436, It: 0, Loss Data: 8.518e-02, Loss Eqns: 2.186e+00, Loss Aux: 3.972e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16437, It: 0, Loss Data: 8.621e-02, Loss Eqns: 2.257e+00, Loss Aux: 4.081e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16438, It: 0, Loss Data: 8.561e-02, Loss Eqns: 2.321e+00, Loss Aux: 4.473e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 16439, It: 0, Loss Data: 7.311e-02, Loss Eqns: 2.244e+00, Loss Aux: 4.536e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16440, It: 0, Loss Data: 7.096e-02, Loss Eqns: 2.228e+00, Loss Aux: 4.613e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16441, It: 0, Loss Data: 7.979e-02, Loss Eqns: 2.282e+00, Loss Aux: 4.486e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16442, It: 0, Loss Data: 7.686e-02, Loss Eqns: 2.226e+00, Loss Aux: 4.558e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16443, It: 0, Loss Data: 8.473e-02, Loss Eqns: 2.233e+00, Loss Aux: 4.370e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16444, It: 0, Loss Data: 7.761e-02, Loss Eqns: 2.295e+00, Loss Aux: 4.203e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16445, It: 0, Loss Data: 9.188e-02, Loss Eqns: 2.243e+00, Loss Aux: 4.290e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16446, It: 0, Loss Data: 8.183e-02, Loss Eqns: 2.211e+00, Loss Aux: 4.485e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16447, It: 0, Loss Data: 8.516e-02, Loss Eqns: 2.287e+00, Loss Aux: 4.661e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16448, It: 0, Loss Data: 7.077e-02, Loss Eqns: 2.332e+00, Loss Aux: 4.699e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16449, It: 0, Loss Data: 7.926e-02, Loss Eqns: 2.190e+00, Loss Aux: 4.614e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16450, It: 0, Loss Data: 9.014e-02, Loss Eqns: 2.298e+00, Loss Aux: 4.263e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16451, It: 0, Loss Data: 7.075e-02, Loss Eqns: 2.320e+00, Loss Aux: 3.732e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16452, It: 0, Loss Data: 7.279e-02, Loss Eqns: 2.209e+00, Loss Aux: 3.590e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16453, It: 0, Loss Data: 8.060e-02, Loss Eqns: 2.293e+00, Loss Aux: 3.690e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16454, It: 0, Loss Data: 7.154e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.059e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16455, It: 0, Loss Data: 8.165e-02, Loss Eqns: 2.185e+00, Loss Aux: 4.531e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16456, It: 0, Loss Data: 8.794e-02, Loss Eqns: 2.225e+00, Loss Aux: 5.103e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16457, It: 0, Loss Data: 9.992e-02, Loss Eqns: 2.160e+00, Loss Aux: 5.386e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16458, It: 0, Loss Data: 8.893e-02, Loss Eqns: 2.179e+00, Loss Aux: 4.976e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16459, It: 0, Loss Data: 8.323e-02, Loss Eqns: 2.198e+00, Loss Aux: 4.567e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16460, It: 0, Loss Data: 8.652e-02, Loss Eqns: 2.285e+00, Loss Aux: 4.244e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16461, It: 0, Loss Data: 8.600e-02, Loss Eqns: 2.139e+00, Loss Aux: 4.282e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16462, It: 0, Loss Data: 8.946e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.601e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16463, It: 0, Loss Data: 8.649e-02, Loss Eqns: 2.193e+00, Loss Aux: 4.629e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16464, It: 0, Loss Data: 7.625e-02, Loss Eqns: 2.251e+00, Loss Aux: 4.427e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16465, It: 0, Loss Data: 9.118e-02, Loss Eqns: 2.205e+00, Loss Aux: 4.506e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16466, It: 0, Loss Data: 8.237e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.492e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16467, It: 0, Loss Data: 8.070e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.469e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16468, It: 0, Loss Data: 8.254e-02, Loss Eqns: 2.296e+00, Loss Aux: 4.271e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16469, It: 0, Loss Data: 7.923e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.343e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16470, It: 0, Loss Data: 9.490e-02, Loss Eqns: 2.272e+00, Loss Aux: 4.085e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16471, It: 0, Loss Data: 7.939e-02, Loss Eqns: 2.244e+00, Loss Aux: 3.956e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16472, It: 0, Loss Data: 9.056e-02, Loss Eqns: 2.291e+00, Loss Aux: 3.994e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16473, It: 0, Loss Data: 8.211e-02, Loss Eqns: 2.284e+00, Loss Aux: 4.214e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16474, It: 0, Loss Data: 6.864e-02, Loss Eqns: 2.334e+00, Loss Aux: 4.730e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16475, It: 0, Loss Data: 7.571e-02, Loss Eqns: 2.238e+00, Loss Aux: 5.313e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16476, It: 0, Loss Data: 7.804e-02, Loss Eqns: 2.267e+00, Loss Aux: 5.317e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16477, It: 0, Loss Data: 7.622e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.829e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16478, It: 0, Loss Data: 7.997e-02, Loss Eqns: 2.246e+00, Loss Aux: 4.393e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16479, It: 0, Loss Data: 8.824e-02, Loss Eqns: 2.201e+00, Loss Aux: 4.216e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16480, It: 0, Loss Data: 9.357e-02, Loss Eqns: 2.252e+00, Loss Aux: 4.495e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16481, It: 0, Loss Data: 8.160e-02, Loss Eqns: 2.221e+00, Loss Aux: 4.661e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16482, It: 0, Loss Data: 7.458e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.429e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16483, It: 0, Loss Data: 7.691e-02, Loss Eqns: 2.256e+00, Loss Aux: 4.080e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16484, It: 0, Loss Data: 7.423e-02, Loss Eqns: 2.313e+00, Loss Aux: 4.114e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16485, It: 0, Loss Data: 8.361e-02, Loss Eqns: 2.170e+00, Loss Aux: 4.404e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16486, It: 0, Loss Data: 8.420e-02, Loss Eqns: 2.188e+00, Loss Aux: 4.447e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16487, It: 0, Loss Data: 7.864e-02, Loss Eqns: 2.186e+00, Loss Aux: 4.263e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16488, It: 0, Loss Data: 8.310e-02, Loss Eqns: 2.196e+00, Loss Aux: 3.877e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16489, It: 0, Loss Data: 8.456e-02, Loss Eqns: 2.150e+00, Loss Aux: 4.107e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16490, It: 0, Loss Data: 6.947e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.727e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16491, It: 0, Loss Data: 8.710e-02, Loss Eqns: 2.215e+00, Loss Aux: 5.043e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16492, It: 0, Loss Data: 7.239e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.799e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16493, It: 0, Loss Data: 8.647e-02, Loss Eqns: 2.242e+00, Loss Aux: 4.574e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16494, It: 0, Loss Data: 7.283e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.501e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16495, It: 0, Loss Data: 7.626e-02, Loss Eqns: 2.199e+00, Loss Aux: 4.412e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16496, It: 0, Loss Data: 9.003e-02, Loss Eqns: 2.218e+00, Loss Aux: 4.160e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16497, It: 0, Loss Data: 8.572e-02, Loss Eqns: 2.227e+00, Loss Aux: 3.637e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16498, It: 0, Loss Data: 8.023e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.313e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16499, It: 0, Loss Data: 9.140e-02, Loss Eqns: 2.192e+00, Loss Aux: 3.354e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16500, It: 0, Loss Data: 9.431e-02, Loss Eqns: 2.168e+00, Loss Aux: 3.611e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 16501, It: 0, Loss Data: 8.439e-02, Loss Eqns: 2.203e+00, Loss Aux: 4.122e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16502, It: 0, Loss Data: 9.051e-02, Loss Eqns: 2.208e+00, Loss Aux: 4.617e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 16503, It: 0, Loss Data: 8.470e-02, Loss Eqns: 2.264e+00, Loss Aux: 4.510e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16504, It: 0, Loss Data: 8.005e-02, Loss Eqns: 2.217e+00, Loss Aux: 4.099e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16505, It: 0, Loss Data: 8.499e-02, Loss Eqns: 2.265e+00, Loss Aux: 3.905e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16506, It: 0, Loss Data: 7.504e-02, Loss Eqns: 2.227e+00, Loss Aux: 4.419e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16507, It: 0, Loss Data: 8.598e-02, Loss Eqns: 2.313e+00, Loss Aux: 5.392e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16508, It: 0, Loss Data: 7.542e-02, Loss Eqns: 2.313e+00, Loss Aux: 5.821e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16509, It: 0, Loss Data: 7.321e-02, Loss Eqns: 2.226e+00, Loss Aux: 5.314e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16510, It: 0, Loss Data: 7.260e-02, Loss Eqns: 2.319e+00, Loss Aux: 4.567e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16511, It: 0, Loss Data: 7.699e-02, Loss Eqns: 2.364e+00, Loss Aux: 4.163e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16512, It: 0, Loss Data: 7.539e-02, Loss Eqns: 2.290e+00, Loss Aux: 4.113e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16513, It: 0, Loss Data: 7.524e-02, Loss Eqns: 2.311e+00, Loss Aux: 4.154e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16514, It: 0, Loss Data: 7.969e-02, Loss Eqns: 2.259e+00, Loss Aux: 4.094e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16515, It: 0, Loss Data: 8.067e-02, Loss Eqns: 2.278e+00, Loss Aux: 3.780e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16516, It: 0, Loss Data: 6.937e-02, Loss Eqns: 2.246e+00, Loss Aux: 3.387e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16517, It: 0, Loss Data: 8.179e-02, Loss Eqns: 2.189e+00, Loss Aux: 4.033e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16518, It: 0, Loss Data: 7.463e-02, Loss Eqns: 2.235e+00, Loss Aux: 4.942e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16519, It: 0, Loss Data: 7.735e-02, Loss Eqns: 2.278e+00, Loss Aux: 5.014e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16520, It: 0, Loss Data: 7.937e-02, Loss Eqns: 2.237e+00, Loss Aux: 4.470e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16521, It: 0, Loss Data: 7.625e-02, Loss Eqns: 2.120e+00, Loss Aux: 3.917e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16522, It: 0, Loss Data: 8.585e-02, Loss Eqns: 2.259e+00, Loss Aux: 3.663e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16523, It: 0, Loss Data: 8.101e-02, Loss Eqns: 2.287e+00, Loss Aux: 3.865e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16524, It: 0, Loss Data: 7.999e-02, Loss Eqns: 2.201e+00, Loss Aux: 4.165e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16525, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.215e+00, Loss Aux: 4.353e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16526, It: 0, Loss Data: 7.508e-02, Loss Eqns: 2.195e+00, Loss Aux: 4.239e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16527, It: 0, Loss Data: 7.632e-02, Loss Eqns: 2.155e+00, Loss Aux: 4.023e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16528, It: 0, Loss Data: 8.445e-02, Loss Eqns: 2.156e+00, Loss Aux: 4.503e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16529, It: 0, Loss Data: 7.891e-02, Loss Eqns: 2.254e+00, Loss Aux: 4.566e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16530, It: 0, Loss Data: 8.600e-02, Loss Eqns: 2.210e+00, Loss Aux: 3.980e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16531, It: 0, Loss Data: 8.848e-02, Loss Eqns: 2.193e+00, Loss Aux: 3.483e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16532, It: 0, Loss Data: 7.671e-02, Loss Eqns: 2.182e+00, Loss Aux: 3.558e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16533, It: 0, Loss Data: 6.919e-02, Loss Eqns: 2.149e+00, Loss Aux: 4.308e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16534, It: 0, Loss Data: 7.936e-02, Loss Eqns: 2.187e+00, Loss Aux: 4.804e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16535, It: 0, Loss Data: 7.668e-02, Loss Eqns: 2.147e+00, Loss Aux: 4.668e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16536, It: 0, Loss Data: 8.106e-02, Loss Eqns: 2.250e+00, Loss Aux: 4.351e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 16537, It: 0, Loss Data: 7.708e-02, Loss Eqns: 2.152e+00, Loss Aux: 4.195e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16538, It: 0, Loss Data: 8.782e-02, Loss Eqns: 2.150e+00, Loss Aux: 4.594e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16539, It: 0, Loss Data: 8.252e-02, Loss Eqns: 2.211e+00, Loss Aux: 4.631e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16540, It: 0, Loss Data: 8.866e-02, Loss Eqns: 2.066e+00, Loss Aux: 4.156e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16541, It: 0, Loss Data: 8.795e-02, Loss Eqns: 2.171e+00, Loss Aux: 3.914e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16542, It: 0, Loss Data: 8.086e-02, Loss Eqns: 2.065e+00, Loss Aux: 3.801e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16543, It: 0, Loss Data: 9.108e-02, Loss Eqns: 2.147e+00, Loss Aux: 3.876e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16544, It: 0, Loss Data: 8.102e-02, Loss Eqns: 2.151e+00, Loss Aux: 3.971e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16545, It: 0, Loss Data: 8.127e-02, Loss Eqns: 2.144e+00, Loss Aux: 3.872e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16546, It: 0, Loss Data: 7.521e-02, Loss Eqns: 2.213e+00, Loss Aux: 3.772e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16547, It: 0, Loss Data: 7.886e-02, Loss Eqns: 2.175e+00, Loss Aux: 3.828e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16548, It: 0, Loss Data: 8.258e-02, Loss Eqns: 2.117e+00, Loss Aux: 4.533e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16549, It: 0, Loss Data: 8.080e-02, Loss Eqns: 2.198e+00, Loss Aux: 5.300e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16550, It: 0, Loss Data: 9.230e-02, Loss Eqns: 2.113e+00, Loss Aux: 5.093e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16551, It: 0, Loss Data: 7.681e-02, Loss Eqns: 2.175e+00, Loss Aux: 3.810e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16552, It: 0, Loss Data: 8.332e-02, Loss Eqns: 2.187e+00, Loss Aux: 3.256e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16553, It: 0, Loss Data: 7.628e-02, Loss Eqns: 2.185e+00, Loss Aux: 3.716e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16554, It: 0, Loss Data: 7.248e-02, Loss Eqns: 2.168e+00, Loss Aux: 4.599e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16555, It: 0, Loss Data: 9.283e-02, Loss Eqns: 2.206e+00, Loss Aux: 4.407e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16556, It: 0, Loss Data: 8.319e-02, Loss Eqns: 2.203e+00, Loss Aux: 3.978e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16557, It: 0, Loss Data: 7.795e-02, Loss Eqns: 2.133e+00, Loss Aux: 3.676e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16558, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.236e+00, Loss Aux: 4.029e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 16559, It: 0, Loss Data: 6.968e-02, Loss Eqns: 2.210e+00, Loss Aux: 4.891e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16560, It: 0, Loss Data: 9.520e-02, Loss Eqns: 2.185e+00, Loss Aux: 5.326e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16561, It: 0, Loss Data: 7.510e-02, Loss Eqns: 2.218e+00, Loss Aux: 4.948e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16562, It: 0, Loss Data: 8.719e-02, Loss Eqns: 2.200e+00, Loss Aux: 4.110e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16563, It: 0, Loss Data: 8.239e-02, Loss Eqns: 2.192e+00, Loss Aux: 3.951e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16564, It: 0, Loss Data: 6.943e-02, Loss Eqns: 2.164e+00, Loss Aux: 4.025e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16565, It: 0, Loss Data: 9.305e-02, Loss Eqns: 2.202e+00, Loss Aux: 4.184e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16566, It: 0, Loss Data: 8.155e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.242e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16567, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.199e+00, Loss Aux: 4.311e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16568, It: 0, Loss Data: 7.521e-02, Loss Eqns: 2.185e+00, Loss Aux: 4.327e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16569, It: 0, Loss Data: 7.955e-02, Loss Eqns: 2.213e+00, Loss Aux: 4.521e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16570, It: 0, Loss Data: 7.503e-02, Loss Eqns: 2.106e+00, Loss Aux: 4.271e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16571, It: 0, Loss Data: 8.143e-02, Loss Eqns: 2.207e+00, Loss Aux: 3.858e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16572, It: 0, Loss Data: 7.781e-02, Loss Eqns: 2.207e+00, Loss Aux: 3.551e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16573, It: 0, Loss Data: 7.527e-02, Loss Eqns: 2.188e+00, Loss Aux: 3.438e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16574, It: 0, Loss Data: 7.540e-02, Loss Eqns: 2.146e+00, Loss Aux: 3.537e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16575, It: 0, Loss Data: 8.146e-02, Loss Eqns: 2.193e+00, Loss Aux: 3.757e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16576, It: 0, Loss Data: 7.447e-02, Loss Eqns: 2.185e+00, Loss Aux: 4.032e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16577, It: 0, Loss Data: 9.161e-02, Loss Eqns: 2.213e+00, Loss Aux: 4.280e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16578, It: 0, Loss Data: 7.072e-02, Loss Eqns: 2.214e+00, Loss Aux: 4.471e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16579, It: 0, Loss Data: 7.245e-02, Loss Eqns: 2.125e+00, Loss Aux: 4.547e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16580, It: 0, Loss Data: 7.975e-02, Loss Eqns: 2.084e+00, Loss Aux: 4.444e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16581, It: 0, Loss Data: 7.200e-02, Loss Eqns: 2.071e+00, Loss Aux: 3.965e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16582, It: 0, Loss Data: 7.754e-02, Loss Eqns: 2.101e+00, Loss Aux: 3.747e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16583, It: 0, Loss Data: 8.641e-02, Loss Eqns: 2.115e+00, Loss Aux: 3.710e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16584, It: 0, Loss Data: 7.527e-02, Loss Eqns: 2.089e+00, Loss Aux: 3.611e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16585, It: 0, Loss Data: 8.744e-02, Loss Eqns: 2.089e+00, Loss Aux: 3.826e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16586, It: 0, Loss Data: 8.356e-02, Loss Eqns: 2.120e+00, Loss Aux: 3.847e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16587, It: 0, Loss Data: 7.799e-02, Loss Eqns: 2.076e+00, Loss Aux: 3.892e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16588, It: 0, Loss Data: 7.959e-02, Loss Eqns: 2.082e+00, Loss Aux: 3.739e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16589, It: 0, Loss Data: 8.327e-02, Loss Eqns: 2.147e+00, Loss Aux: 4.067e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 16590, It: 0, Loss Data: 8.155e-02, Loss Eqns: 2.158e+00, Loss Aux: 4.408e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16591, It: 0, Loss Data: 7.426e-02, Loss Eqns: 2.162e+00, Loss Aux: 4.253e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16592, It: 0, Loss Data: 7.438e-02, Loss Eqns: 2.074e+00, Loss Aux: 3.995e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16593, It: 0, Loss Data: 7.274e-02, Loss Eqns: 2.166e+00, Loss Aux: 3.809e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16594, It: 0, Loss Data: 7.350e-02, Loss Eqns: 2.141e+00, Loss Aux: 3.994e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16595, It: 0, Loss Data: 7.944e-02, Loss Eqns: 2.097e+00, Loss Aux: 4.132e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16596, It: 0, Loss Data: 7.612e-02, Loss Eqns: 2.098e+00, Loss Aux: 4.270e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16597, It: 0, Loss Data: 8.727e-02, Loss Eqns: 2.099e+00, Loss Aux: 4.201e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16598, It: 0, Loss Data: 7.842e-02, Loss Eqns: 2.081e+00, Loss Aux: 4.006e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16599, It: 0, Loss Data: 7.851e-02, Loss Eqns: 2.109e+00, Loss Aux: 3.814e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16600, It: 0, Loss Data: 8.168e-02, Loss Eqns: 2.129e+00, Loss Aux: 3.756e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16601, It: 0, Loss Data: 7.272e-02, Loss Eqns: 2.109e+00, Loss Aux: 3.674e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16602, It: 0, Loss Data: 7.427e-02, Loss Eqns: 2.107e+00, Loss Aux: 3.501e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16603, It: 0, Loss Data: 7.916e-02, Loss Eqns: 2.046e+00, Loss Aux: 3.534e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16604, It: 0, Loss Data: 8.068e-02, Loss Eqns: 2.126e+00, Loss Aux: 3.921e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16605, It: 0, Loss Data: 6.937e-02, Loss Eqns: 2.106e+00, Loss Aux: 4.251e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16606, It: 0, Loss Data: 8.569e-02, Loss Eqns: 2.074e+00, Loss Aux: 4.553e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 16607, It: 0, Loss Data: 8.741e-02, Loss Eqns: 2.089e+00, Loss Aux: 4.545e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16608, It: 0, Loss Data: 8.508e-02, Loss Eqns: 2.129e+00, Loss Aux: 4.278e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16609, It: 0, Loss Data: 7.667e-02, Loss Eqns: 2.132e+00, Loss Aux: 4.013e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16610, It: 0, Loss Data: 7.151e-02, Loss Eqns: 2.085e+00, Loss Aux: 4.137e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16611, It: 0, Loss Data: 8.103e-02, Loss Eqns: 2.053e+00, Loss Aux: 4.329e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16612, It: 0, Loss Data: 8.001e-02, Loss Eqns: 2.055e+00, Loss Aux: 4.290e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16613, It: 0, Loss Data: 7.949e-02, Loss Eqns: 2.196e+00, Loss Aux: 3.711e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16614, It: 0, Loss Data: 8.478e-02, Loss Eqns: 2.114e+00, Loss Aux: 3.299e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16615, It: 0, Loss Data: 8.527e-02, Loss Eqns: 2.054e+00, Loss Aux: 3.436e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16616, It: 0, Loss Data: 7.742e-02, Loss Eqns: 2.049e+00, Loss Aux: 3.676e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16617, It: 0, Loss Data: 7.080e-02, Loss Eqns: 2.046e+00, Loss Aux: 3.567e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16618, It: 0, Loss Data: 8.313e-02, Loss Eqns: 2.118e+00, Loss Aux: 3.677e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16619, It: 0, Loss Data: 6.735e-02, Loss Eqns: 2.081e+00, Loss Aux: 4.139e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16620, It: 0, Loss Data: 6.614e-02, Loss Eqns: 2.069e+00, Loss Aux: 4.780e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16621, It: 0, Loss Data: 7.450e-02, Loss Eqns: 2.154e+00, Loss Aux: 5.127e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16622, It: 0, Loss Data: 8.704e-02, Loss Eqns: 2.069e+00, Loss Aux: 4.849e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16623, It: 0, Loss Data: 8.568e-02, Loss Eqns: 2.079e+00, Loss Aux: 4.475e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16624, It: 0, Loss Data: 7.846e-02, Loss Eqns: 2.139e+00, Loss Aux: 4.093e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16625, It: 0, Loss Data: 6.406e-02, Loss Eqns: 2.098e+00, Loss Aux: 3.913e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16626, It: 0, Loss Data: 6.862e-02, Loss Eqns: 2.115e+00, Loss Aux: 3.573e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16627, It: 0, Loss Data: 8.169e-02, Loss Eqns: 2.024e+00, Loss Aux: 3.324e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16628, It: 0, Loss Data: 8.985e-02, Loss Eqns: 2.087e+00, Loss Aux: 3.524e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16629, It: 0, Loss Data: 7.403e-02, Loss Eqns: 1.964e+00, Loss Aux: 4.072e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16630, It: 0, Loss Data: 7.863e-02, Loss Eqns: 1.967e+00, Loss Aux: 4.226e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16631, It: 0, Loss Data: 6.846e-02, Loss Eqns: 2.002e+00, Loss Aux: 4.014e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16632, It: 0, Loss Data: 7.057e-02, Loss Eqns: 2.117e+00, Loss Aux: 3.721e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 16633, It: 0, Loss Data: 7.364e-02, Loss Eqns: 2.095e+00, Loss Aux: 3.679e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 16634, It: 0, Loss Data: 7.303e-02, Loss Eqns: 2.065e+00, Loss Aux: 4.157e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16635, It: 0, Loss Data: 8.127e-02, Loss Eqns: 2.077e+00, Loss Aux: 4.254e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16636, It: 0, Loss Data: 8.205e-02, Loss Eqns: 2.025e+00, Loss Aux: 4.162e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16637, It: 0, Loss Data: 7.691e-02, Loss Eqns: 2.025e+00, Loss Aux: 3.799e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16638, It: 0, Loss Data: 7.812e-02, Loss Eqns: 1.998e+00, Loss Aux: 3.493e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16639, It: 0, Loss Data: 7.292e-02, Loss Eqns: 2.068e+00, Loss Aux: 3.431e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16640, It: 0, Loss Data: 8.590e-02, Loss Eqns: 2.073e+00, Loss Aux: 3.567e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16641, It: 0, Loss Data: 7.709e-02, Loss Eqns: 2.047e+00, Loss Aux: 3.768e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16642, It: 0, Loss Data: 8.014e-02, Loss Eqns: 1.970e+00, Loss Aux: 4.082e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16643, It: 0, Loss Data: 8.308e-02, Loss Eqns: 2.019e+00, Loss Aux: 4.319e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16644, It: 0, Loss Data: 7.417e-02, Loss Eqns: 2.080e+00, Loss Aux: 4.127e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16645, It: 0, Loss Data: 6.963e-02, Loss Eqns: 2.054e+00, Loss Aux: 3.737e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16646, It: 0, Loss Data: 6.898e-02, Loss Eqns: 2.019e+00, Loss Aux: 3.529e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16647, It: 0, Loss Data: 8.054e-02, Loss Eqns: 2.009e+00, Loss Aux: 3.712e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16648, It: 0, Loss Data: 7.995e-02, Loss Eqns: 1.986e+00, Loss Aux: 4.105e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16649, It: 0, Loss Data: 8.406e-02, Loss Eqns: 1.977e+00, Loss Aux: 4.288e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 16650, It: 0, Loss Data: 7.840e-02, Loss Eqns: 1.990e+00, Loss Aux: 3.943e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16651, It: 0, Loss Data: 7.501e-02, Loss Eqns: 2.011e+00, Loss Aux: 3.807e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16652, It: 0, Loss Data: 7.373e-02, Loss Eqns: 2.007e+00, Loss Aux: 3.963e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16653, It: 0, Loss Data: 7.200e-02, Loss Eqns: 2.022e+00, Loss Aux: 3.976e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16654, It: 0, Loss Data: 7.051e-02, Loss Eqns: 2.033e+00, Loss Aux: 3.777e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16655, It: 0, Loss Data: 8.750e-02, Loss Eqns: 1.992e+00, Loss Aux: 3.627e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16656, It: 0, Loss Data: 7.395e-02, Loss Eqns: 1.954e+00, Loss Aux: 3.887e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16657, It: 0, Loss Data: 7.668e-02, Loss Eqns: 1.985e+00, Loss Aux: 3.850e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16658, It: 0, Loss Data: 6.456e-02, Loss Eqns: 1.968e+00, Loss Aux: 3.914e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16659, It: 0, Loss Data: 7.597e-02, Loss Eqns: 1.977e+00, Loss Aux: 4.050e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16660, It: 0, Loss Data: 7.459e-02, Loss Eqns: 1.924e+00, Loss Aux: 4.078e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16661, It: 0, Loss Data: 8.430e-02, Loss Eqns: 1.986e+00, Loss Aux: 4.000e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16662, It: 0, Loss Data: 6.886e-02, Loss Eqns: 1.925e+00, Loss Aux: 3.965e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16663, It: 0, Loss Data: 7.876e-02, Loss Eqns: 1.993e+00, Loss Aux: 3.761e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16664, It: 0, Loss Data: 6.876e-02, Loss Eqns: 1.992e+00, Loss Aux: 3.836e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16665, It: 0, Loss Data: 6.527e-02, Loss Eqns: 1.967e+00, Loss Aux: 3.678e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16666, It: 0, Loss Data: 7.485e-02, Loss Eqns: 1.984e+00, Loss Aux: 3.929e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16667, It: 0, Loss Data: 7.651e-02, Loss Eqns: 2.057e+00, Loss Aux: 3.748e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16668, It: 0, Loss Data: 8.397e-02, Loss Eqns: 1.968e+00, Loss Aux: 3.721e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16669, It: 0, Loss Data: 7.634e-02, Loss Eqns: 1.945e+00, Loss Aux: 3.871e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16670, It: 0, Loss Data: 6.351e-02, Loss Eqns: 1.939e+00, Loss Aux: 4.166e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16671, It: 0, Loss Data: 7.756e-02, Loss Eqns: 1.922e+00, Loss Aux: 3.941e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16672, It: 0, Loss Data: 7.861e-02, Loss Eqns: 1.938e+00, Loss Aux: 3.476e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16673, It: 0, Loss Data: 8.282e-02, Loss Eqns: 1.922e+00, Loss Aux: 3.276e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16674, It: 0, Loss Data: 9.605e-02, Loss Eqns: 1.937e+00, Loss Aux: 3.356e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16675, It: 0, Loss Data: 7.261e-02, Loss Eqns: 1.921e+00, Loss Aux: 3.732e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16676, It: 0, Loss Data: 7.294e-02, Loss Eqns: 2.012e+00, Loss Aux: 3.995e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16677, It: 0, Loss Data: 6.572e-02, Loss Eqns: 1.946e+00, Loss Aux: 4.040e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16678, It: 0, Loss Data: 8.145e-02, Loss Eqns: 1.991e+00, Loss Aux: 3.767e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16679, It: 0, Loss Data: 6.138e-02, Loss Eqns: 1.992e+00, Loss Aux: 3.692e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16680, It: 0, Loss Data: 7.990e-02, Loss Eqns: 1.999e+00, Loss Aux: 3.849e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16681, It: 0, Loss Data: 8.403e-02, Loss Eqns: 1.995e+00, Loss Aux: 3.800e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16682, It: 0, Loss Data: 6.595e-02, Loss Eqns: 1.997e+00, Loss Aux: 3.692e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16683, It: 0, Loss Data: 6.342e-02, Loss Eqns: 1.942e+00, Loss Aux: 3.579e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16684, It: 0, Loss Data: 7.475e-02, Loss Eqns: 1.897e+00, Loss Aux: 3.589e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 16685, It: 0, Loss Data: 7.213e-02, Loss Eqns: 1.890e+00, Loss Aux: 4.057e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16686, It: 0, Loss Data: 7.662e-02, Loss Eqns: 1.936e+00, Loss Aux: 4.211e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16687, It: 0, Loss Data: 8.002e-02, Loss Eqns: 1.943e+00, Loss Aux: 4.001e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16688, It: 0, Loss Data: 6.731e-02, Loss Eqns: 1.926e+00, Loss Aux: 3.774e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16689, It: 0, Loss Data: 7.397e-02, Loss Eqns: 1.947e+00, Loss Aux: 3.982e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16690, It: 0, Loss Data: 8.098e-02, Loss Eqns: 1.840e+00, Loss Aux: 4.515e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16691, It: 0, Loss Data: 7.441e-02, Loss Eqns: 1.933e+00, Loss Aux: 4.254e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16692, It: 0, Loss Data: 9.541e-02, Loss Eqns: 1.921e+00, Loss Aux: 3.253e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 16693, It: 0, Loss Data: 8.065e-02, Loss Eqns: 1.939e+00, Loss Aux: 2.822e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16694, It: 0, Loss Data: 6.704e-02, Loss Eqns: 1.966e+00, Loss Aux: 3.363e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16695, It: 0, Loss Data: 8.440e-02, Loss Eqns: 1.906e+00, Loss Aux: 4.151e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16696, It: 0, Loss Data: 9.008e-02, Loss Eqns: 1.886e+00, Loss Aux: 4.374e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16697, It: 0, Loss Data: 6.928e-02, Loss Eqns: 1.941e+00, Loss Aux: 4.203e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16698, It: 0, Loss Data: 7.831e-02, Loss Eqns: 1.870e+00, Loss Aux: 4.308e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16699, It: 0, Loss Data: 7.609e-02, Loss Eqns: 1.916e+00, Loss Aux: 4.265e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16700, It: 0, Loss Data: 7.618e-02, Loss Eqns: 1.894e+00, Loss Aux: 3.676e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16701, It: 0, Loss Data: 6.801e-02, Loss Eqns: 1.913e+00, Loss Aux: 3.167e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 16702, It: 0, Loss Data: 8.070e-02, Loss Eqns: 1.863e+00, Loss Aux: 3.410e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16703, It: 0, Loss Data: 7.757e-02, Loss Eqns: 1.907e+00, Loss Aux: 3.875e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16704, It: 0, Loss Data: 7.360e-02, Loss Eqns: 1.884e+00, Loss Aux: 4.270e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 16705, It: 0, Loss Data: 9.737e-02, Loss Eqns: 1.894e+00, Loss Aux: 4.115e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16706, It: 0, Loss Data: 8.625e-02, Loss Eqns: 1.916e+00, Loss Aux: 3.852e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16707, It: 0, Loss Data: 8.190e-02, Loss Eqns: 1.947e+00, Loss Aux: 3.812e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16708, It: 0, Loss Data: 8.165e-02, Loss Eqns: 1.865e+00, Loss Aux: 4.017e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16709, It: 0, Loss Data: 7.780e-02, Loss Eqns: 1.885e+00, Loss Aux: 4.087e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16710, It: 0, Loss Data: 8.189e-02, Loss Eqns: 2.040e+00, Loss Aux: 3.886e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16711, It: 0, Loss Data: 7.625e-02, Loss Eqns: 1.930e+00, Loss Aux: 3.798e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16712, It: 0, Loss Data: 6.903e-02, Loss Eqns: 1.900e+00, Loss Aux: 4.094e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16713, It: 0, Loss Data: 7.870e-02, Loss Eqns: 1.902e+00, Loss Aux: 4.342e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16714, It: 0, Loss Data: 7.885e-02, Loss Eqns: 1.950e+00, Loss Aux: 4.042e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16715, It: 0, Loss Data: 7.490e-02, Loss Eqns: 1.921e+00, Loss Aux: 3.371e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16716, It: 0, Loss Data: 7.712e-02, Loss Eqns: 1.951e+00, Loss Aux: 3.289e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16717, It: 0, Loss Data: 7.675e-02, Loss Eqns: 1.913e+00, Loss Aux: 4.209e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16718, It: 0, Loss Data: 7.930e-02, Loss Eqns: 1.974e+00, Loss Aux: 4.864e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16719, It: 0, Loss Data: 7.960e-02, Loss Eqns: 1.844e+00, Loss Aux: 4.824e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16720, It: 0, Loss Data: 7.834e-02, Loss Eqns: 2.084e+00, Loss Aux: 3.823e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16721, It: 0, Loss Data: 7.594e-02, Loss Eqns: 1.944e+00, Loss Aux: 3.521e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16722, It: 0, Loss Data: 7.501e-02, Loss Eqns: 1.935e+00, Loss Aux: 3.659e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16723, It: 0, Loss Data: 7.685e-02, Loss Eqns: 1.923e+00, Loss Aux: 3.970e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 16724, It: 0, Loss Data: 8.189e-02, Loss Eqns: 1.878e+00, Loss Aux: 3.678e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16725, It: 0, Loss Data: 7.626e-02, Loss Eqns: 1.844e+00, Loss Aux: 3.192e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16726, It: 0, Loss Data: 7.704e-02, Loss Eqns: 1.862e+00, Loss Aux: 3.421e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16727, It: 0, Loss Data: 8.116e-02, Loss Eqns: 1.836e+00, Loss Aux: 4.077e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16728, It: 0, Loss Data: 6.933e-02, Loss Eqns: 1.923e+00, Loss Aux: 4.600e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16729, It: 0, Loss Data: 7.532e-02, Loss Eqns: 1.913e+00, Loss Aux: 4.599e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16730, It: 0, Loss Data: 7.513e-02, Loss Eqns: 1.969e+00, Loss Aux: 3.618e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16731, It: 0, Loss Data: 8.152e-02, Loss Eqns: 1.933e+00, Loss Aux: 2.943e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16732, It: 0, Loss Data: 6.384e-02, Loss Eqns: 1.849e+00, Loss Aux: 3.124e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16733, It: 0, Loss Data: 6.941e-02, Loss Eqns: 1.877e+00, Loss Aux: 4.030e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16734, It: 0, Loss Data: 8.653e-02, Loss Eqns: 1.890e+00, Loss Aux: 4.985e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16735, It: 0, Loss Data: 6.548e-02, Loss Eqns: 1.863e+00, Loss Aux: 5.018e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16736, It: 0, Loss Data: 8.311e-02, Loss Eqns: 1.852e+00, Loss Aux: 4.609e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16737, It: 0, Loss Data: 8.837e-02, Loss Eqns: 1.770e+00, Loss Aux: 4.243e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16738, It: 0, Loss Data: 8.112e-02, Loss Eqns: 1.804e+00, Loss Aux: 3.815e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16739, It: 0, Loss Data: 7.490e-02, Loss Eqns: 1.810e+00, Loss Aux: 3.657e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16740, It: 0, Loss Data: 7.519e-02, Loss Eqns: 1.906e+00, Loss Aux: 3.655e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16741, It: 0, Loss Data: 8.397e-02, Loss Eqns: 1.820e+00, Loss Aux: 3.720e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16742, It: 0, Loss Data: 7.880e-02, Loss Eqns: 1.906e+00, Loss Aux: 4.073e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 16743, It: 0, Loss Data: 7.316e-02, Loss Eqns: 1.821e+00, Loss Aux: 4.469e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16744, It: 0, Loss Data: 6.947e-02, Loss Eqns: 1.873e+00, Loss Aux: 4.502e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16745, It: 0, Loss Data: 8.143e-02, Loss Eqns: 1.825e+00, Loss Aux: 3.968e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16746, It: 0, Loss Data: 7.619e-02, Loss Eqns: 1.867e+00, Loss Aux: 3.044e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16747, It: 0, Loss Data: 8.000e-02, Loss Eqns: 1.861e+00, Loss Aux: 3.001e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16748, It: 0, Loss Data: 6.814e-02, Loss Eqns: 1.851e+00, Loss Aux: 3.553e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16749, It: 0, Loss Data: 7.184e-02, Loss Eqns: 1.881e+00, Loss Aux: 4.452e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16750, It: 0, Loss Data: 7.960e-02, Loss Eqns: 1.860e+00, Loss Aux: 4.540e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16751, It: 0, Loss Data: 7.728e-02, Loss Eqns: 1.824e+00, Loss Aux: 4.098e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16752, It: 0, Loss Data: 6.684e-02, Loss Eqns: 1.791e+00, Loss Aux: 3.724e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16753, It: 0, Loss Data: 7.514e-02, Loss Eqns: 1.779e+00, Loss Aux: 3.909e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16754, It: 0, Loss Data: 9.086e-02, Loss Eqns: 1.899e+00, Loss Aux: 4.235e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16755, It: 0, Loss Data: 6.431e-02, Loss Eqns: 1.801e+00, Loss Aux: 4.061e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16756, It: 0, Loss Data: 7.964e-02, Loss Eqns: 1.829e+00, Loss Aux: 3.664e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16757, It: 0, Loss Data: 8.101e-02, Loss Eqns: 1.886e+00, Loss Aux: 3.646e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16758, It: 0, Loss Data: 8.624e-02, Loss Eqns: 1.843e+00, Loss Aux: 4.044e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16759, It: 0, Loss Data: 7.731e-02, Loss Eqns: 1.795e+00, Loss Aux: 4.636e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16760, It: 0, Loss Data: 8.386e-02, Loss Eqns: 1.825e+00, Loss Aux: 4.364e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16761, It: 0, Loss Data: 7.759e-02, Loss Eqns: 1.771e+00, Loss Aux: 3.692e-02, Time: 0.228, Learning Rate: 1.0e-03\n",
      "Epoch: 16762, It: 0, Loss Data: 8.533e-02, Loss Eqns: 1.825e+00, Loss Aux: 3.562e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16763, It: 0, Loss Data: 7.016e-02, Loss Eqns: 1.847e+00, Loss Aux: 3.646e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16764, It: 0, Loss Data: 7.734e-02, Loss Eqns: 1.753e+00, Loss Aux: 3.953e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16765, It: 0, Loss Data: 6.621e-02, Loss Eqns: 1.904e+00, Loss Aux: 4.171e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16766, It: 0, Loss Data: 8.030e-02, Loss Eqns: 1.854e+00, Loss Aux: 3.969e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16767, It: 0, Loss Data: 5.985e-02, Loss Eqns: 1.808e+00, Loss Aux: 3.684e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16768, It: 0, Loss Data: 6.830e-02, Loss Eqns: 1.878e+00, Loss Aux: 3.730e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16769, It: 0, Loss Data: 7.443e-02, Loss Eqns: 1.832e+00, Loss Aux: 3.987e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16770, It: 0, Loss Data: 7.549e-02, Loss Eqns: 1.825e+00, Loss Aux: 4.245e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16771, It: 0, Loss Data: 7.455e-02, Loss Eqns: 1.809e+00, Loss Aux: 3.939e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16772, It: 0, Loss Data: 8.340e-02, Loss Eqns: 1.841e+00, Loss Aux: 3.558e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16773, It: 0, Loss Data: 7.037e-02, Loss Eqns: 1.799e+00, Loss Aux: 3.579e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16774, It: 0, Loss Data: 7.058e-02, Loss Eqns: 1.819e+00, Loss Aux: 3.934e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16775, It: 0, Loss Data: 7.839e-02, Loss Eqns: 1.774e+00, Loss Aux: 3.991e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 16776, It: 0, Loss Data: 7.397e-02, Loss Eqns: 1.820e+00, Loss Aux: 3.756e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16777, It: 0, Loss Data: 7.436e-02, Loss Eqns: 1.744e+00, Loss Aux: 3.583e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16778, It: 0, Loss Data: 8.528e-02, Loss Eqns: 1.832e+00, Loss Aux: 3.803e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16779, It: 0, Loss Data: 7.163e-02, Loss Eqns: 1.799e+00, Loss Aux: 4.051e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16780, It: 0, Loss Data: 6.553e-02, Loss Eqns: 1.784e+00, Loss Aux: 3.689e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16781, It: 0, Loss Data: 7.180e-02, Loss Eqns: 1.839e+00, Loss Aux: 3.470e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16782, It: 0, Loss Data: 6.802e-02, Loss Eqns: 1.750e+00, Loss Aux: 3.799e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16783, It: 0, Loss Data: 7.571e-02, Loss Eqns: 1.751e+00, Loss Aux: 4.399e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 16784, It: 0, Loss Data: 7.060e-02, Loss Eqns: 1.709e+00, Loss Aux: 4.449e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16785, It: 0, Loss Data: 8.349e-02, Loss Eqns: 1.687e+00, Loss Aux: 4.092e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16786, It: 0, Loss Data: 8.573e-02, Loss Eqns: 1.789e+00, Loss Aux: 3.553e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16787, It: 0, Loss Data: 6.888e-02, Loss Eqns: 1.767e+00, Loss Aux: 3.118e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16788, It: 0, Loss Data: 7.649e-02, Loss Eqns: 1.793e+00, Loss Aux: 3.352e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16789, It: 0, Loss Data: 6.759e-02, Loss Eqns: 1.715e+00, Loss Aux: 3.890e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16790, It: 0, Loss Data: 8.245e-02, Loss Eqns: 1.814e+00, Loss Aux: 4.532e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16791, It: 0, Loss Data: 7.245e-02, Loss Eqns: 1.800e+00, Loss Aux: 4.661e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16792, It: 0, Loss Data: 7.326e-02, Loss Eqns: 1.768e+00, Loss Aux: 4.360e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16793, It: 0, Loss Data: 7.202e-02, Loss Eqns: 1.749e+00, Loss Aux: 3.806e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16794, It: 0, Loss Data: 7.940e-02, Loss Eqns: 1.789e+00, Loss Aux: 3.261e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16795, It: 0, Loss Data: 6.890e-02, Loss Eqns: 1.819e+00, Loss Aux: 2.762e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16796, It: 0, Loss Data: 6.822e-02, Loss Eqns: 1.743e+00, Loss Aux: 3.243e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16797, It: 0, Loss Data: 6.879e-02, Loss Eqns: 1.786e+00, Loss Aux: 4.027e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16798, It: 0, Loss Data: 7.063e-02, Loss Eqns: 1.726e+00, Loss Aux: 4.832e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16799, It: 0, Loss Data: 6.752e-02, Loss Eqns: 1.771e+00, Loss Aux: 5.174e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16800, It: 0, Loss Data: 8.532e-02, Loss Eqns: 1.771e+00, Loss Aux: 4.584e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16801, It: 0, Loss Data: 6.653e-02, Loss Eqns: 1.769e+00, Loss Aux: 3.867e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16802, It: 0, Loss Data: 7.222e-02, Loss Eqns: 1.744e+00, Loss Aux: 4.061e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16803, It: 0, Loss Data: 7.433e-02, Loss Eqns: 1.779e+00, Loss Aux: 4.121e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16804, It: 0, Loss Data: 7.264e-02, Loss Eqns: 1.753e+00, Loss Aux: 3.972e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16805, It: 0, Loss Data: 8.191e-02, Loss Eqns: 1.793e+00, Loss Aux: 3.881e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16806, It: 0, Loss Data: 8.634e-02, Loss Eqns: 1.771e+00, Loss Aux: 4.073e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16807, It: 0, Loss Data: 6.916e-02, Loss Eqns: 1.753e+00, Loss Aux: 3.810e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16808, It: 0, Loss Data: 6.903e-02, Loss Eqns: 1.732e+00, Loss Aux: 3.496e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16809, It: 0, Loss Data: 6.960e-02, Loss Eqns: 1.713e+00, Loss Aux: 3.407e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16810, It: 0, Loss Data: 7.875e-02, Loss Eqns: 1.771e+00, Loss Aux: 3.522e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16811, It: 0, Loss Data: 6.362e-02, Loss Eqns: 1.769e+00, Loss Aux: 3.760e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16812, It: 0, Loss Data: 8.343e-02, Loss Eqns: 1.819e+00, Loss Aux: 4.022e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16813, It: 0, Loss Data: 5.574e-02, Loss Eqns: 1.754e+00, Loss Aux: 4.229e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16814, It: 0, Loss Data: 6.492e-02, Loss Eqns: 1.776e+00, Loss Aux: 4.492e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16815, It: 0, Loss Data: 7.843e-02, Loss Eqns: 1.710e+00, Loss Aux: 4.438e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16816, It: 0, Loss Data: 7.110e-02, Loss Eqns: 1.672e+00, Loss Aux: 3.871e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16817, It: 0, Loss Data: 7.493e-02, Loss Eqns: 1.720e+00, Loss Aux: 3.461e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16818, It: 0, Loss Data: 7.747e-02, Loss Eqns: 1.724e+00, Loss Aux: 4.039e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16819, It: 0, Loss Data: 7.336e-02, Loss Eqns: 1.676e+00, Loss Aux: 4.522e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16820, It: 0, Loss Data: 8.201e-02, Loss Eqns: 1.746e+00, Loss Aux: 3.995e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16821, It: 0, Loss Data: 7.376e-02, Loss Eqns: 1.761e+00, Loss Aux: 3.595e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16822, It: 0, Loss Data: 6.438e-02, Loss Eqns: 1.715e+00, Loss Aux: 3.836e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16823, It: 0, Loss Data: 7.368e-02, Loss Eqns: 1.805e+00, Loss Aux: 4.308e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16824, It: 0, Loss Data: 7.787e-02, Loss Eqns: 1.704e+00, Loss Aux: 4.266e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16825, It: 0, Loss Data: 7.149e-02, Loss Eqns: 1.682e+00, Loss Aux: 3.954e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16826, It: 0, Loss Data: 8.864e-02, Loss Eqns: 1.683e+00, Loss Aux: 3.972e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16827, It: 0, Loss Data: 7.664e-02, Loss Eqns: 1.644e+00, Loss Aux: 4.214e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16828, It: 0, Loss Data: 7.585e-02, Loss Eqns: 1.809e+00, Loss Aux: 4.369e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16829, It: 0, Loss Data: 5.904e-02, Loss Eqns: 1.693e+00, Loss Aux: 4.027e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16830, It: 0, Loss Data: 6.613e-02, Loss Eqns: 1.651e+00, Loss Aux: 3.765e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16831, It: 0, Loss Data: 7.080e-02, Loss Eqns: 1.714e+00, Loss Aux: 3.743e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16832, It: 0, Loss Data: 7.930e-02, Loss Eqns: 1.690e+00, Loss Aux: 3.692e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16833, It: 0, Loss Data: 7.997e-02, Loss Eqns: 1.689e+00, Loss Aux: 3.971e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16834, It: 0, Loss Data: 7.787e-02, Loss Eqns: 1.619e+00, Loss Aux: 3.817e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16835, It: 0, Loss Data: 7.615e-02, Loss Eqns: 1.615e+00, Loss Aux: 3.842e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16836, It: 0, Loss Data: 7.928e-02, Loss Eqns: 1.740e+00, Loss Aux: 3.614e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 16837, It: 0, Loss Data: 7.659e-02, Loss Eqns: 1.724e+00, Loss Aux: 3.759e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16838, It: 0, Loss Data: 7.112e-02, Loss Eqns: 1.696e+00, Loss Aux: 4.000e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16839, It: 0, Loss Data: 8.109e-02, Loss Eqns: 1.715e+00, Loss Aux: 4.149e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16840, It: 0, Loss Data: 8.271e-02, Loss Eqns: 1.755e+00, Loss Aux: 3.955e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16841, It: 0, Loss Data: 6.792e-02, Loss Eqns: 1.765e+00, Loss Aux: 3.629e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16842, It: 0, Loss Data: 7.446e-02, Loss Eqns: 1.749e+00, Loss Aux: 3.681e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16843, It: 0, Loss Data: 5.961e-02, Loss Eqns: 1.759e+00, Loss Aux: 4.202e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 16844, It: 0, Loss Data: 7.663e-02, Loss Eqns: 1.748e+00, Loss Aux: 4.595e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16845, It: 0, Loss Data: 6.799e-02, Loss Eqns: 1.632e+00, Loss Aux: 4.488e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16846, It: 0, Loss Data: 7.901e-02, Loss Eqns: 1.739e+00, Loss Aux: 4.074e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16847, It: 0, Loss Data: 7.095e-02, Loss Eqns: 1.723e+00, Loss Aux: 3.710e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16848, It: 0, Loss Data: 7.015e-02, Loss Eqns: 1.672e+00, Loss Aux: 3.350e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16849, It: 0, Loss Data: 6.892e-02, Loss Eqns: 1.754e+00, Loss Aux: 3.348e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 16850, It: 0, Loss Data: 7.820e-02, Loss Eqns: 1.715e+00, Loss Aux: 3.528e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16851, It: 0, Loss Data: 7.309e-02, Loss Eqns: 1.643e+00, Loss Aux: 3.538e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16852, It: 0, Loss Data: 7.609e-02, Loss Eqns: 1.657e+00, Loss Aux: 3.189e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16853, It: 0, Loss Data: 7.236e-02, Loss Eqns: 1.603e+00, Loss Aux: 3.183e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16854, It: 0, Loss Data: 7.683e-02, Loss Eqns: 1.671e+00, Loss Aux: 3.486e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16855, It: 0, Loss Data: 6.942e-02, Loss Eqns: 1.719e+00, Loss Aux: 3.865e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 16856, It: 0, Loss Data: 8.300e-02, Loss Eqns: 1.602e+00, Loss Aux: 4.579e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16857, It: 0, Loss Data: 6.248e-02, Loss Eqns: 1.657e+00, Loss Aux: 5.159e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16858, It: 0, Loss Data: 8.471e-02, Loss Eqns: 1.698e+00, Loss Aux: 4.566e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16859, It: 0, Loss Data: 6.636e-02, Loss Eqns: 1.750e+00, Loss Aux: 4.137e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16860, It: 0, Loss Data: 7.489e-02, Loss Eqns: 1.669e+00, Loss Aux: 3.819e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16861, It: 0, Loss Data: 6.633e-02, Loss Eqns: 1.718e+00, Loss Aux: 3.221e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16862, It: 0, Loss Data: 6.585e-02, Loss Eqns: 1.751e+00, Loss Aux: 3.379e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16863, It: 0, Loss Data: 8.498e-02, Loss Eqns: 1.628e+00, Loss Aux: 3.648e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 16864, It: 0, Loss Data: 8.169e-02, Loss Eqns: 1.658e+00, Loss Aux: 3.965e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16865, It: 0, Loss Data: 8.122e-02, Loss Eqns: 1.737e+00, Loss Aux: 3.853e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16866, It: 0, Loss Data: 7.331e-02, Loss Eqns: 1.680e+00, Loss Aux: 3.545e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16867, It: 0, Loss Data: 7.273e-02, Loss Eqns: 1.638e+00, Loss Aux: 3.616e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16868, It: 0, Loss Data: 7.272e-02, Loss Eqns: 1.711e+00, Loss Aux: 3.794e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16869, It: 0, Loss Data: 7.277e-02, Loss Eqns: 1.720e+00, Loss Aux: 3.972e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16870, It: 0, Loss Data: 8.426e-02, Loss Eqns: 1.674e+00, Loss Aux: 3.961e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16871, It: 0, Loss Data: 6.477e-02, Loss Eqns: 1.710e+00, Loss Aux: 4.268e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16872, It: 0, Loss Data: 7.724e-02, Loss Eqns: 1.815e+00, Loss Aux: 4.319e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16873, It: 0, Loss Data: 6.974e-02, Loss Eqns: 1.628e+00, Loss Aux: 4.309e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16874, It: 0, Loss Data: 7.206e-02, Loss Eqns: 1.716e+00, Loss Aux: 3.650e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16875, It: 0, Loss Data: 7.218e-02, Loss Eqns: 1.793e+00, Loss Aux: 3.081e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16876, It: 0, Loss Data: 8.532e-02, Loss Eqns: 1.682e+00, Loss Aux: 3.142e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 16877, It: 0, Loss Data: 8.384e-02, Loss Eqns: 1.849e+00, Loss Aux: 3.851e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16878, It: 0, Loss Data: 7.412e-02, Loss Eqns: 1.799e+00, Loss Aux: 4.071e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16879, It: 0, Loss Data: 6.881e-02, Loss Eqns: 1.676e+00, Loss Aux: 3.627e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16880, It: 0, Loss Data: 7.252e-02, Loss Eqns: 1.984e+00, Loss Aux: 3.274e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16881, It: 0, Loss Data: 6.990e-02, Loss Eqns: 1.704e+00, Loss Aux: 3.625e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 16882, It: 0, Loss Data: 7.183e-02, Loss Eqns: 1.752e+00, Loss Aux: 4.529e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 16883, It: 0, Loss Data: 7.784e-02, Loss Eqns: 2.004e+00, Loss Aux: 5.259e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 16884, It: 0, Loss Data: 8.030e-02, Loss Eqns: 2.050e+00, Loss Aux: 4.801e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16885, It: 0, Loss Data: 7.564e-02, Loss Eqns: 1.873e+00, Loss Aux: 4.221e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16886, It: 0, Loss Data: 6.744e-02, Loss Eqns: 1.944e+00, Loss Aux: 4.043e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 16887, It: 0, Loss Data: 7.370e-02, Loss Eqns: 1.760e+00, Loss Aux: 3.794e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16888, It: 0, Loss Data: 9.022e-02, Loss Eqns: 2.049e+00, Loss Aux: 3.564e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16889, It: 0, Loss Data: 8.144e-02, Loss Eqns: 1.740e+00, Loss Aux: 4.193e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 16890, It: 0, Loss Data: 7.856e-02, Loss Eqns: 2.044e+00, Loss Aux: 4.365e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16891, It: 0, Loss Data: 6.919e-02, Loss Eqns: 1.856e+00, Loss Aux: 3.342e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 16892, It: 0, Loss Data: 8.942e-02, Loss Eqns: 1.811e+00, Loss Aux: 2.984e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16893, It: 0, Loss Data: 7.384e-02, Loss Eqns: 1.980e+00, Loss Aux: 3.619e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16894, It: 0, Loss Data: 7.513e-02, Loss Eqns: 1.644e+00, Loss Aux: 4.050e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16895, It: 0, Loss Data: 7.676e-02, Loss Eqns: 1.702e+00, Loss Aux: 4.308e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16896, It: 0, Loss Data: 6.027e-02, Loss Eqns: 1.706e+00, Loss Aux: 4.497e-02, Time: 0.142, Learning Rate: 1.0e-03\n",
      "Epoch: 16897, It: 0, Loss Data: 7.003e-02, Loss Eqns: 1.588e+00, Loss Aux: 4.024e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16898, It: 0, Loss Data: 8.597e-02, Loss Eqns: 1.705e+00, Loss Aux: 3.338e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16899, It: 0, Loss Data: 7.979e-02, Loss Eqns: 1.591e+00, Loss Aux: 3.514e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 16900, It: 0, Loss Data: 8.093e-02, Loss Eqns: 1.770e+00, Loss Aux: 3.874e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 16901, It: 0, Loss Data: 7.453e-02, Loss Eqns: 1.691e+00, Loss Aux: 3.992e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16902, It: 0, Loss Data: 7.547e-02, Loss Eqns: 1.665e+00, Loss Aux: 4.269e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16903, It: 0, Loss Data: 8.078e-02, Loss Eqns: 1.720e+00, Loss Aux: 3.989e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 16904, It: 0, Loss Data: 7.953e-02, Loss Eqns: 1.594e+00, Loss Aux: 3.687e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 16905, It: 0, Loss Data: 8.143e-02, Loss Eqns: 1.649e+00, Loss Aux: 3.905e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16906, It: 0, Loss Data: 8.099e-02, Loss Eqns: 1.646e+00, Loss Aux: 4.424e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16907, It: 0, Loss Data: 6.195e-02, Loss Eqns: 1.667e+00, Loss Aux: 4.244e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16908, It: 0, Loss Data: 6.827e-02, Loss Eqns: 1.604e+00, Loss Aux: 4.460e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16909, It: 0, Loss Data: 8.146e-02, Loss Eqns: 1.627e+00, Loss Aux: 4.259e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16910, It: 0, Loss Data: 8.001e-02, Loss Eqns: 1.712e+00, Loss Aux: 4.063e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16911, It: 0, Loss Data: 8.056e-02, Loss Eqns: 1.549e+00, Loss Aux: 3.371e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 16912, It: 0, Loss Data: 6.260e-02, Loss Eqns: 1.621e+00, Loss Aux: 2.604e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16913, It: 0, Loss Data: 6.453e-02, Loss Eqns: 1.593e+00, Loss Aux: 2.851e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 16914, It: 0, Loss Data: 6.784e-02, Loss Eqns: 1.694e+00, Loss Aux: 4.149e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16915, It: 0, Loss Data: 6.705e-02, Loss Eqns: 1.604e+00, Loss Aux: 5.171e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16916, It: 0, Loss Data: 8.073e-02, Loss Eqns: 1.617e+00, Loss Aux: 6.008e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16917, It: 0, Loss Data: 6.990e-02, Loss Eqns: 1.671e+00, Loss Aux: 5.733e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16918, It: 0, Loss Data: 6.552e-02, Loss Eqns: 1.628e+00, Loss Aux: 4.368e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16919, It: 0, Loss Data: 5.923e-02, Loss Eqns: 1.627e+00, Loss Aux: 3.609e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16920, It: 0, Loss Data: 7.024e-02, Loss Eqns: 1.640e+00, Loss Aux: 3.839e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 16921, It: 0, Loss Data: 6.752e-02, Loss Eqns: 1.583e+00, Loss Aux: 4.443e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16922, It: 0, Loss Data: 7.030e-02, Loss Eqns: 1.538e+00, Loss Aux: 4.619e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 16923, It: 0, Loss Data: 7.854e-02, Loss Eqns: 1.625e+00, Loss Aux: 4.287e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16924, It: 0, Loss Data: 7.129e-02, Loss Eqns: 1.568e+00, Loss Aux: 4.028e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16925, It: 0, Loss Data: 6.983e-02, Loss Eqns: 1.597e+00, Loss Aux: 4.070e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 16926, It: 0, Loss Data: 8.017e-02, Loss Eqns: 1.549e+00, Loss Aux: 3.961e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16927, It: 0, Loss Data: 7.396e-02, Loss Eqns: 1.545e+00, Loss Aux: 3.633e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16928, It: 0, Loss Data: 7.610e-02, Loss Eqns: 1.584e+00, Loss Aux: 3.530e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16929, It: 0, Loss Data: 6.844e-02, Loss Eqns: 1.636e+00, Loss Aux: 3.689e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 16930, It: 0, Loss Data: 6.922e-02, Loss Eqns: 1.520e+00, Loss Aux: 4.536e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16931, It: 0, Loss Data: 6.618e-02, Loss Eqns: 1.565e+00, Loss Aux: 5.049e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16932, It: 0, Loss Data: 6.776e-02, Loss Eqns: 1.605e+00, Loss Aux: 4.606e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16933, It: 0, Loss Data: 6.217e-02, Loss Eqns: 1.538e+00, Loss Aux: 3.695e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16934, It: 0, Loss Data: 7.931e-02, Loss Eqns: 1.534e+00, Loss Aux: 3.768e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 16935, It: 0, Loss Data: 7.063e-02, Loss Eqns: 1.578e+00, Loss Aux: 4.012e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16936, It: 0, Loss Data: 7.262e-02, Loss Eqns: 1.579e+00, Loss Aux: 3.782e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16937, It: 0, Loss Data: 6.887e-02, Loss Eqns: 1.563e+00, Loss Aux: 3.726e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16938, It: 0, Loss Data: 7.171e-02, Loss Eqns: 1.548e+00, Loss Aux: 3.715e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16939, It: 0, Loss Data: 7.544e-02, Loss Eqns: 1.558e+00, Loss Aux: 4.447e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16940, It: 0, Loss Data: 7.086e-02, Loss Eqns: 1.508e+00, Loss Aux: 4.939e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16941, It: 0, Loss Data: 7.659e-02, Loss Eqns: 1.560e+00, Loss Aux: 4.736e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16942, It: 0, Loss Data: 7.048e-02, Loss Eqns: 1.583e+00, Loss Aux: 3.863e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16943, It: 0, Loss Data: 7.194e-02, Loss Eqns: 1.564e+00, Loss Aux: 3.244e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16944, It: 0, Loss Data: 6.044e-02, Loss Eqns: 1.600e+00, Loss Aux: 3.252e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16945, It: 0, Loss Data: 7.052e-02, Loss Eqns: 1.538e+00, Loss Aux: 3.620e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 16946, It: 0, Loss Data: 7.777e-02, Loss Eqns: 1.600e+00, Loss Aux: 4.045e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16947, It: 0, Loss Data: 6.925e-02, Loss Eqns: 1.519e+00, Loss Aux: 4.142e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16948, It: 0, Loss Data: 7.104e-02, Loss Eqns: 1.526e+00, Loss Aux: 3.747e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16949, It: 0, Loss Data: 6.880e-02, Loss Eqns: 1.523e+00, Loss Aux: 3.546e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16950, It: 0, Loss Data: 8.135e-02, Loss Eqns: 1.606e+00, Loss Aux: 3.627e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16951, It: 0, Loss Data: 7.223e-02, Loss Eqns: 1.562e+00, Loss Aux: 4.238e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16952, It: 0, Loss Data: 6.424e-02, Loss Eqns: 1.520e+00, Loss Aux: 4.737e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16953, It: 0, Loss Data: 7.036e-02, Loss Eqns: 1.521e+00, Loss Aux: 5.404e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16954, It: 0, Loss Data: 7.197e-02, Loss Eqns: 1.546e+00, Loss Aux: 5.055e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 16955, It: 0, Loss Data: 7.050e-02, Loss Eqns: 1.476e+00, Loss Aux: 3.985e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16956, It: 0, Loss Data: 7.380e-02, Loss Eqns: 1.580e+00, Loss Aux: 3.131e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 16957, It: 0, Loss Data: 7.138e-02, Loss Eqns: 1.520e+00, Loss Aux: 2.833e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 16958, It: 0, Loss Data: 7.113e-02, Loss Eqns: 1.554e+00, Loss Aux: 3.083e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 16959, It: 0, Loss Data: 7.174e-02, Loss Eqns: 1.511e+00, Loss Aux: 3.729e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 16960, It: 0, Loss Data: 7.207e-02, Loss Eqns: 1.502e+00, Loss Aux: 4.697e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16961, It: 0, Loss Data: 6.240e-02, Loss Eqns: 1.525e+00, Loss Aux: 4.686e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 16962, It: 0, Loss Data: 7.392e-02, Loss Eqns: 1.513e+00, Loss Aux: 4.389e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 16963, It: 0, Loss Data: 6.566e-02, Loss Eqns: 1.482e+00, Loss Aux: 3.712e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16964, It: 0, Loss Data: 7.638e-02, Loss Eqns: 1.553e+00, Loss Aux: 3.391e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16965, It: 0, Loss Data: 6.054e-02, Loss Eqns: 1.469e+00, Loss Aux: 3.272e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 16966, It: 0, Loss Data: 6.752e-02, Loss Eqns: 1.492e+00, Loss Aux: 3.425e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 16967, It: 0, Loss Data: 7.781e-02, Loss Eqns: 1.436e+00, Loss Aux: 4.023e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16968, It: 0, Loss Data: 6.396e-02, Loss Eqns: 1.502e+00, Loss Aux: 4.181e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 16969, It: 0, Loss Data: 6.737e-02, Loss Eqns: 1.486e+00, Loss Aux: 4.052e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 16970, It: 0, Loss Data: 7.431e-02, Loss Eqns: 1.533e+00, Loss Aux: 4.150e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 16971, It: 0, Loss Data: 8.331e-02, Loss Eqns: 1.459e+00, Loss Aux: 4.658e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 16972, It: 0, Loss Data: 6.986e-02, Loss Eqns: 1.482e+00, Loss Aux: 4.590e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 16973, It: 0, Loss Data: 6.746e-02, Loss Eqns: 1.466e+00, Loss Aux: 3.666e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16974, It: 0, Loss Data: 6.711e-02, Loss Eqns: 1.520e+00, Loss Aux: 3.166e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 16975, It: 0, Loss Data: 6.222e-02, Loss Eqns: 1.544e+00, Loss Aux: 3.609e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 16976, It: 0, Loss Data: 7.330e-02, Loss Eqns: 1.559e+00, Loss Aux: 4.020e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16977, It: 0, Loss Data: 6.606e-02, Loss Eqns: 1.497e+00, Loss Aux: 4.103e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 16978, It: 0, Loss Data: 6.412e-02, Loss Eqns: 1.498e+00, Loss Aux: 3.657e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 16979, It: 0, Loss Data: 6.543e-02, Loss Eqns: 1.564e+00, Loss Aux: 3.669e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 16980, It: 0, Loss Data: 5.979e-02, Loss Eqns: 1.482e+00, Loss Aux: 4.437e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16981, It: 0, Loss Data: 6.925e-02, Loss Eqns: 1.469e+00, Loss Aux: 4.702e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 16982, It: 0, Loss Data: 6.234e-02, Loss Eqns: 1.501e+00, Loss Aux: 3.950e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 16983, It: 0, Loss Data: 7.425e-02, Loss Eqns: 1.505e+00, Loss Aux: 3.152e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 16984, It: 0, Loss Data: 6.867e-02, Loss Eqns: 1.493e+00, Loss Aux: 3.237e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 16985, It: 0, Loss Data: 7.951e-02, Loss Eqns: 1.510e+00, Loss Aux: 4.256e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 16986, It: 0, Loss Data: 7.820e-02, Loss Eqns: 1.406e+00, Loss Aux: 4.896e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16987, It: 0, Loss Data: 5.950e-02, Loss Eqns: 1.427e+00, Loss Aux: 4.636e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16988, It: 0, Loss Data: 8.209e-02, Loss Eqns: 1.454e+00, Loss Aux: 3.761e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 16989, It: 0, Loss Data: 7.178e-02, Loss Eqns: 1.435e+00, Loss Aux: 3.758e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16990, It: 0, Loss Data: 8.410e-02, Loss Eqns: 1.440e+00, Loss Aux: 3.946e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 16991, It: 0, Loss Data: 7.060e-02, Loss Eqns: 1.512e+00, Loss Aux: 3.524e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 16992, It: 0, Loss Data: 6.926e-02, Loss Eqns: 1.479e+00, Loss Aux: 3.218e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 16993, It: 0, Loss Data: 6.905e-02, Loss Eqns: 1.489e+00, Loss Aux: 3.635e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 16994, It: 0, Loss Data: 6.757e-02, Loss Eqns: 1.466e+00, Loss Aux: 4.506e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 16995, It: 0, Loss Data: 8.069e-02, Loss Eqns: 1.486e+00, Loss Aux: 4.777e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 16996, It: 0, Loss Data: 6.977e-02, Loss Eqns: 1.485e+00, Loss Aux: 4.038e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 16997, It: 0, Loss Data: 6.121e-02, Loss Eqns: 1.479e+00, Loss Aux: 2.996e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 16998, It: 0, Loss Data: 6.765e-02, Loss Eqns: 1.487e+00, Loss Aux: 3.030e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 16999, It: 0, Loss Data: 6.794e-02, Loss Eqns: 1.491e+00, Loss Aux: 4.273e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17000, It: 0, Loss Data: 7.935e-02, Loss Eqns: 1.391e+00, Loss Aux: 5.657e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17001, It: 0, Loss Data: 5.799e-02, Loss Eqns: 1.440e+00, Loss Aux: 5.061e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17002, It: 0, Loss Data: 6.989e-02, Loss Eqns: 1.420e+00, Loss Aux: 3.839e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17003, It: 0, Loss Data: 8.149e-02, Loss Eqns: 1.423e+00, Loss Aux: 3.384e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17004, It: 0, Loss Data: 7.703e-02, Loss Eqns: 1.539e+00, Loss Aux: 3.346e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17005, It: 0, Loss Data: 7.625e-02, Loss Eqns: 1.461e+00, Loss Aux: 3.453e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17006, It: 0, Loss Data: 7.686e-02, Loss Eqns: 1.510e+00, Loss Aux: 3.551e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17007, It: 0, Loss Data: 6.848e-02, Loss Eqns: 1.563e+00, Loss Aux: 4.007e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17008, It: 0, Loss Data: 6.293e-02, Loss Eqns: 1.432e+00, Loss Aux: 4.566e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17009, It: 0, Loss Data: 7.444e-02, Loss Eqns: 1.502e+00, Loss Aux: 4.400e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17010, It: 0, Loss Data: 7.046e-02, Loss Eqns: 1.617e+00, Loss Aux: 3.970e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17011, It: 0, Loss Data: 6.716e-02, Loss Eqns: 1.515e+00, Loss Aux: 4.332e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17012, It: 0, Loss Data: 6.317e-02, Loss Eqns: 1.505e+00, Loss Aux: 4.718e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17013, It: 0, Loss Data: 7.746e-02, Loss Eqns: 1.440e+00, Loss Aux: 4.013e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17014, It: 0, Loss Data: 6.594e-02, Loss Eqns: 1.489e+00, Loss Aux: 3.752e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17015, It: 0, Loss Data: 8.118e-02, Loss Eqns: 1.555e+00, Loss Aux: 3.659e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17016, It: 0, Loss Data: 7.395e-02, Loss Eqns: 1.452e+00, Loss Aux: 4.128e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17017, It: 0, Loss Data: 8.514e-02, Loss Eqns: 1.444e+00, Loss Aux: 4.223e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17018, It: 0, Loss Data: 6.646e-02, Loss Eqns: 1.491e+00, Loss Aux: 3.367e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17019, It: 0, Loss Data: 6.060e-02, Loss Eqns: 1.504e+00, Loss Aux: 3.150e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17020, It: 0, Loss Data: 6.495e-02, Loss Eqns: 1.428e+00, Loss Aux: 3.749e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17021, It: 0, Loss Data: 7.237e-02, Loss Eqns: 1.396e+00, Loss Aux: 4.837e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17022, It: 0, Loss Data: 7.527e-02, Loss Eqns: 1.484e+00, Loss Aux: 4.682e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17023, It: 0, Loss Data: 6.861e-02, Loss Eqns: 1.465e+00, Loss Aux: 3.835e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17024, It: 0, Loss Data: 6.793e-02, Loss Eqns: 1.479e+00, Loss Aux: 3.850e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17025, It: 0, Loss Data: 6.958e-02, Loss Eqns: 1.420e+00, Loss Aux: 4.400e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17026, It: 0, Loss Data: 6.370e-02, Loss Eqns: 1.401e+00, Loss Aux: 4.387e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17027, It: 0, Loss Data: 7.163e-02, Loss Eqns: 1.362e+00, Loss Aux: 3.787e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17028, It: 0, Loss Data: 6.135e-02, Loss Eqns: 1.506e+00, Loss Aux: 3.422e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17029, It: 0, Loss Data: 6.260e-02, Loss Eqns: 1.442e+00, Loss Aux: 3.266e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17030, It: 0, Loss Data: 6.695e-02, Loss Eqns: 1.426e+00, Loss Aux: 3.909e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17031, It: 0, Loss Data: 6.233e-02, Loss Eqns: 1.429e+00, Loss Aux: 4.734e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17032, It: 0, Loss Data: 7.697e-02, Loss Eqns: 1.423e+00, Loss Aux: 4.955e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17033, It: 0, Loss Data: 7.229e-02, Loss Eqns: 1.403e+00, Loss Aux: 4.343e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17034, It: 0, Loss Data: 7.600e-02, Loss Eqns: 1.396e+00, Loss Aux: 3.599e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 17035, It: 0, Loss Data: 7.331e-02, Loss Eqns: 1.443e+00, Loss Aux: 3.158e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17036, It: 0, Loss Data: 8.449e-02, Loss Eqns: 1.462e+00, Loss Aux: 3.813e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17037, It: 0, Loss Data: 5.778e-02, Loss Eqns: 1.437e+00, Loss Aux: 4.332e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17038, It: 0, Loss Data: 6.472e-02, Loss Eqns: 1.394e+00, Loss Aux: 4.118e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17039, It: 0, Loss Data: 7.903e-02, Loss Eqns: 1.433e+00, Loss Aux: 4.016e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17040, It: 0, Loss Data: 6.671e-02, Loss Eqns: 1.434e+00, Loss Aux: 4.802e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17041, It: 0, Loss Data: 8.612e-02, Loss Eqns: 1.396e+00, Loss Aux: 5.618e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17042, It: 0, Loss Data: 6.374e-02, Loss Eqns: 1.408e+00, Loss Aux: 4.246e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17043, It: 0, Loss Data: 7.574e-02, Loss Eqns: 1.437e+00, Loss Aux: 3.156e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17044, It: 0, Loss Data: 6.054e-02, Loss Eqns: 1.440e+00, Loss Aux: 2.964e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17045, It: 0, Loss Data: 6.511e-02, Loss Eqns: 1.422e+00, Loss Aux: 3.736e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17046, It: 0, Loss Data: 6.569e-02, Loss Eqns: 1.398e+00, Loss Aux: 4.496e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17047, It: 0, Loss Data: 6.920e-02, Loss Eqns: 1.383e+00, Loss Aux: 3.938e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17048, It: 0, Loss Data: 6.773e-02, Loss Eqns: 1.368e+00, Loss Aux: 3.477e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17049, It: 0, Loss Data: 7.013e-02, Loss Eqns: 1.385e+00, Loss Aux: 4.161e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17050, It: 0, Loss Data: 6.508e-02, Loss Eqns: 1.455e+00, Loss Aux: 4.314e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17051, It: 0, Loss Data: 5.903e-02, Loss Eqns: 1.474e+00, Loss Aux: 3.856e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17052, It: 0, Loss Data: 7.696e-02, Loss Eqns: 1.406e+00, Loss Aux: 3.715e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17053, It: 0, Loss Data: 6.504e-02, Loss Eqns: 1.389e+00, Loss Aux: 4.426e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17054, It: 0, Loss Data: 7.707e-02, Loss Eqns: 1.400e+00, Loss Aux: 5.085e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17055, It: 0, Loss Data: 7.324e-02, Loss Eqns: 1.392e+00, Loss Aux: 4.103e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17056, It: 0, Loss Data: 5.969e-02, Loss Eqns: 1.466e+00, Loss Aux: 3.293e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17057, It: 0, Loss Data: 6.605e-02, Loss Eqns: 1.336e+00, Loss Aux: 2.926e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17058, It: 0, Loss Data: 7.084e-02, Loss Eqns: 1.368e+00, Loss Aux: 3.182e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17059, It: 0, Loss Data: 6.296e-02, Loss Eqns: 1.420e+00, Loss Aux: 4.049e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17060, It: 0, Loss Data: 6.349e-02, Loss Eqns: 1.432e+00, Loss Aux: 4.764e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17061, It: 0, Loss Data: 6.581e-02, Loss Eqns: 1.346e+00, Loss Aux: 5.315e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17062, It: 0, Loss Data: 7.498e-02, Loss Eqns: 1.394e+00, Loss Aux: 4.627e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17063, It: 0, Loss Data: 5.745e-02, Loss Eqns: 1.393e+00, Loss Aux: 4.115e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17064, It: 0, Loss Data: 6.042e-02, Loss Eqns: 1.415e+00, Loss Aux: 3.868e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17065, It: 0, Loss Data: 6.891e-02, Loss Eqns: 1.405e+00, Loss Aux: 4.301e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17066, It: 0, Loss Data: 7.665e-02, Loss Eqns: 1.302e+00, Loss Aux: 4.287e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17067, It: 0, Loss Data: 7.581e-02, Loss Eqns: 1.363e+00, Loss Aux: 3.826e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17068, It: 0, Loss Data: 7.476e-02, Loss Eqns: 1.355e+00, Loss Aux: 3.720e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17069, It: 0, Loss Data: 6.349e-02, Loss Eqns: 1.303e+00, Loss Aux: 3.952e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17070, It: 0, Loss Data: 6.352e-02, Loss Eqns: 1.351e+00, Loss Aux: 4.043e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17071, It: 0, Loss Data: 7.176e-02, Loss Eqns: 1.344e+00, Loss Aux: 3.764e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17072, It: 0, Loss Data: 6.582e-02, Loss Eqns: 1.374e+00, Loss Aux: 4.116e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17073, It: 0, Loss Data: 6.419e-02, Loss Eqns: 1.292e+00, Loss Aux: 4.432e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17074, It: 0, Loss Data: 7.057e-02, Loss Eqns: 1.318e+00, Loss Aux: 4.202e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17075, It: 0, Loss Data: 7.203e-02, Loss Eqns: 1.383e+00, Loss Aux: 3.428e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17076, It: 0, Loss Data: 6.554e-02, Loss Eqns: 1.393e+00, Loss Aux: 3.032e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17077, It: 0, Loss Data: 6.695e-02, Loss Eqns: 1.334e+00, Loss Aux: 3.601e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17078, It: 0, Loss Data: 7.490e-02, Loss Eqns: 1.371e+00, Loss Aux: 3.913e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17079, It: 0, Loss Data: 6.687e-02, Loss Eqns: 1.416e+00, Loss Aux: 4.432e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17080, It: 0, Loss Data: 7.665e-02, Loss Eqns: 1.385e+00, Loss Aux: 4.221e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17081, It: 0, Loss Data: 6.491e-02, Loss Eqns: 1.350e+00, Loss Aux: 3.755e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17082, It: 0, Loss Data: 5.892e-02, Loss Eqns: 1.396e+00, Loss Aux: 3.623e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17083, It: 0, Loss Data: 7.083e-02, Loss Eqns: 1.378e+00, Loss Aux: 4.391e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17084, It: 0, Loss Data: 6.369e-02, Loss Eqns: 1.398e+00, Loss Aux: 4.435e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17085, It: 0, Loss Data: 7.391e-02, Loss Eqns: 1.324e+00, Loss Aux: 4.611e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17086, It: 0, Loss Data: 7.118e-02, Loss Eqns: 1.333e+00, Loss Aux: 4.349e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 17087, It: 0, Loss Data: 6.952e-02, Loss Eqns: 1.308e+00, Loss Aux: 3.352e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17088, It: 0, Loss Data: 7.879e-02, Loss Eqns: 1.397e+00, Loss Aux: 3.198e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17089, It: 0, Loss Data: 6.458e-02, Loss Eqns: 1.387e+00, Loss Aux: 3.453e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17090, It: 0, Loss Data: 6.791e-02, Loss Eqns: 1.354e+00, Loss Aux: 4.280e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17091, It: 0, Loss Data: 7.252e-02, Loss Eqns: 1.355e+00, Loss Aux: 4.957e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17092, It: 0, Loss Data: 7.214e-02, Loss Eqns: 1.362e+00, Loss Aux: 4.864e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17093, It: 0, Loss Data: 7.228e-02, Loss Eqns: 1.355e+00, Loss Aux: 4.589e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17094, It: 0, Loss Data: 7.834e-02, Loss Eqns: 1.371e+00, Loss Aux: 3.777e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17095, It: 0, Loss Data: 5.623e-02, Loss Eqns: 1.416e+00, Loss Aux: 3.662e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17096, It: 0, Loss Data: 7.615e-02, Loss Eqns: 1.411e+00, Loss Aux: 4.451e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17097, It: 0, Loss Data: 6.011e-02, Loss Eqns: 1.358e+00, Loss Aux: 4.402e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17098, It: 0, Loss Data: 6.514e-02, Loss Eqns: 1.385e+00, Loss Aux: 4.020e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17099, It: 0, Loss Data: 6.892e-02, Loss Eqns: 1.330e+00, Loss Aux: 3.117e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17100, It: 0, Loss Data: 6.877e-02, Loss Eqns: 1.447e+00, Loss Aux: 2.556e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 17101, It: 0, Loss Data: 6.520e-02, Loss Eqns: 1.435e+00, Loss Aux: 3.068e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17102, It: 0, Loss Data: 6.570e-02, Loss Eqns: 1.370e+00, Loss Aux: 3.966e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17103, It: 0, Loss Data: 6.430e-02, Loss Eqns: 1.361e+00, Loss Aux: 4.499e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17104, It: 0, Loss Data: 6.543e-02, Loss Eqns: 1.403e+00, Loss Aux: 4.568e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17105, It: 0, Loss Data: 6.884e-02, Loss Eqns: 1.372e+00, Loss Aux: 4.747e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17106, It: 0, Loss Data: 6.543e-02, Loss Eqns: 1.337e+00, Loss Aux: 4.504e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17107, It: 0, Loss Data: 5.827e-02, Loss Eqns: 1.338e+00, Loss Aux: 3.608e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17108, It: 0, Loss Data: 7.181e-02, Loss Eqns: 1.348e+00, Loss Aux: 3.178e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17109, It: 0, Loss Data: 6.691e-02, Loss Eqns: 1.332e+00, Loss Aux: 4.141e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17110, It: 0, Loss Data: 7.053e-02, Loss Eqns: 1.380e+00, Loss Aux: 5.563e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17111, It: 0, Loss Data: 6.303e-02, Loss Eqns: 1.329e+00, Loss Aux: 5.188e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17112, It: 0, Loss Data: 6.636e-02, Loss Eqns: 1.363e+00, Loss Aux: 4.055e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17113, It: 0, Loss Data: 5.881e-02, Loss Eqns: 1.440e+00, Loss Aux: 3.468e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17114, It: 0, Loss Data: 6.689e-02, Loss Eqns: 1.347e+00, Loss Aux: 3.331e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17115, It: 0, Loss Data: 7.056e-02, Loss Eqns: 1.301e+00, Loss Aux: 3.475e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17116, It: 0, Loss Data: 6.114e-02, Loss Eqns: 1.345e+00, Loss Aux: 3.574e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17117, It: 0, Loss Data: 6.694e-02, Loss Eqns: 1.355e+00, Loss Aux: 3.717e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 17118, It: 0, Loss Data: 6.589e-02, Loss Eqns: 1.291e+00, Loss Aux: 3.897e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17119, It: 0, Loss Data: 6.303e-02, Loss Eqns: 1.341e+00, Loss Aux: 4.043e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17120, It: 0, Loss Data: 8.018e-02, Loss Eqns: 1.267e+00, Loss Aux: 4.296e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17121, It: 0, Loss Data: 6.698e-02, Loss Eqns: 1.308e+00, Loss Aux: 4.881e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17122, It: 0, Loss Data: 7.122e-02, Loss Eqns: 1.367e+00, Loss Aux: 5.067e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17123, It: 0, Loss Data: 6.696e-02, Loss Eqns: 1.368e+00, Loss Aux: 3.948e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17124, It: 0, Loss Data: 6.608e-02, Loss Eqns: 1.289e+00, Loss Aux: 3.283e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17125, It: 0, Loss Data: 6.433e-02, Loss Eqns: 1.325e+00, Loss Aux: 3.844e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17126, It: 0, Loss Data: 6.408e-02, Loss Eqns: 1.386e+00, Loss Aux: 4.471e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17127, It: 0, Loss Data: 6.725e-02, Loss Eqns: 1.324e+00, Loss Aux: 4.589e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17128, It: 0, Loss Data: 6.558e-02, Loss Eqns: 1.344e+00, Loss Aux: 4.070e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17129, It: 0, Loss Data: 7.154e-02, Loss Eqns: 1.333e+00, Loss Aux: 4.247e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17130, It: 0, Loss Data: 6.502e-02, Loss Eqns: 1.339e+00, Loss Aux: 4.472e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17131, It: 0, Loss Data: 5.979e-02, Loss Eqns: 1.341e+00, Loss Aux: 3.684e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17132, It: 0, Loss Data: 6.222e-02, Loss Eqns: 1.362e+00, Loss Aux: 3.135e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17133, It: 0, Loss Data: 6.399e-02, Loss Eqns: 1.369e+00, Loss Aux: 3.422e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17134, It: 0, Loss Data: 7.027e-02, Loss Eqns: 1.262e+00, Loss Aux: 5.326e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17135, It: 0, Loss Data: 6.887e-02, Loss Eqns: 1.274e+00, Loss Aux: 6.093e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 17136, It: 0, Loss Data: 6.522e-02, Loss Eqns: 1.310e+00, Loss Aux: 4.354e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17137, It: 0, Loss Data: 6.373e-02, Loss Eqns: 1.337e+00, Loss Aux: 3.119e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17138, It: 0, Loss Data: 6.961e-02, Loss Eqns: 1.394e+00, Loss Aux: 3.113e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17139, It: 0, Loss Data: 6.442e-02, Loss Eqns: 1.312e+00, Loss Aux: 4.095e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17140, It: 0, Loss Data: 6.662e-02, Loss Eqns: 1.279e+00, Loss Aux: 4.627e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17141, It: 0, Loss Data: 7.570e-02, Loss Eqns: 1.370e+00, Loss Aux: 4.525e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17142, It: 0, Loss Data: 7.204e-02, Loss Eqns: 1.307e+00, Loss Aux: 4.670e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17143, It: 0, Loss Data: 6.295e-02, Loss Eqns: 1.338e+00, Loss Aux: 4.294e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17144, It: 0, Loss Data: 6.557e-02, Loss Eqns: 1.398e+00, Loss Aux: 3.336e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17145, It: 0, Loss Data: 5.584e-02, Loss Eqns: 1.345e+00, Loss Aux: 3.287e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17146, It: 0, Loss Data: 6.402e-02, Loss Eqns: 1.322e+00, Loss Aux: 4.057e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17147, It: 0, Loss Data: 6.277e-02, Loss Eqns: 1.300e+00, Loss Aux: 4.941e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17148, It: 0, Loss Data: 7.079e-02, Loss Eqns: 1.263e+00, Loss Aux: 4.915e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17149, It: 0, Loss Data: 5.733e-02, Loss Eqns: 1.335e+00, Loss Aux: 4.076e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17150, It: 0, Loss Data: 7.368e-02, Loss Eqns: 1.290e+00, Loss Aux: 3.682e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17151, It: 0, Loss Data: 5.655e-02, Loss Eqns: 1.268e+00, Loss Aux: 3.616e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17152, It: 0, Loss Data: 6.435e-02, Loss Eqns: 1.243e+00, Loss Aux: 3.573e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17153, It: 0, Loss Data: 7.094e-02, Loss Eqns: 1.206e+00, Loss Aux: 3.881e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17154, It: 0, Loss Data: 6.924e-02, Loss Eqns: 1.239e+00, Loss Aux: 4.583e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17155, It: 0, Loss Data: 6.531e-02, Loss Eqns: 1.235e+00, Loss Aux: 5.217e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17156, It: 0, Loss Data: 6.799e-02, Loss Eqns: 1.240e+00, Loss Aux: 4.478e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17157, It: 0, Loss Data: 5.663e-02, Loss Eqns: 1.276e+00, Loss Aux: 3.542e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17158, It: 0, Loss Data: 5.729e-02, Loss Eqns: 1.320e+00, Loss Aux: 2.995e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17159, It: 0, Loss Data: 7.471e-02, Loss Eqns: 1.283e+00, Loss Aux: 3.643e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17160, It: 0, Loss Data: 6.465e-02, Loss Eqns: 1.277e+00, Loss Aux: 4.496e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17161, It: 0, Loss Data: 6.145e-02, Loss Eqns: 1.210e+00, Loss Aux: 4.831e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17162, It: 0, Loss Data: 6.281e-02, Loss Eqns: 1.234e+00, Loss Aux: 3.969e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17163, It: 0, Loss Data: 6.505e-02, Loss Eqns: 1.323e+00, Loss Aux: 3.395e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17164, It: 0, Loss Data: 7.952e-02, Loss Eqns: 1.309e+00, Loss Aux: 4.167e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17165, It: 0, Loss Data: 8.107e-02, Loss Eqns: 1.270e+00, Loss Aux: 4.360e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17166, It: 0, Loss Data: 6.522e-02, Loss Eqns: 1.226e+00, Loss Aux: 4.298e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17167, It: 0, Loss Data: 5.516e-02, Loss Eqns: 1.273e+00, Loss Aux: 3.924e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17168, It: 0, Loss Data: 6.677e-02, Loss Eqns: 1.284e+00, Loss Aux: 3.586e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17169, It: 0, Loss Data: 6.019e-02, Loss Eqns: 1.270e+00, Loss Aux: 3.931e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17170, It: 0, Loss Data: 5.954e-02, Loss Eqns: 1.256e+00, Loss Aux: 3.844e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17171, It: 0, Loss Data: 6.764e-02, Loss Eqns: 1.197e+00, Loss Aux: 3.985e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17172, It: 0, Loss Data: 6.354e-02, Loss Eqns: 1.282e+00, Loss Aux: 3.329e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 17173, It: 0, Loss Data: 6.711e-02, Loss Eqns: 1.228e+00, Loss Aux: 3.524e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17174, It: 0, Loss Data: 5.966e-02, Loss Eqns: 1.229e+00, Loss Aux: 4.470e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17175, It: 0, Loss Data: 7.398e-02, Loss Eqns: 1.251e+00, Loss Aux: 4.989e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17176, It: 0, Loss Data: 5.873e-02, Loss Eqns: 1.183e+00, Loss Aux: 4.274e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17177, It: 0, Loss Data: 5.910e-02, Loss Eqns: 1.297e+00, Loss Aux: 3.165e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17178, It: 0, Loss Data: 6.575e-02, Loss Eqns: 1.264e+00, Loss Aux: 3.483e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17179, It: 0, Loss Data: 6.729e-02, Loss Eqns: 1.252e+00, Loss Aux: 4.180e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17180, It: 0, Loss Data: 5.448e-02, Loss Eqns: 1.227e+00, Loss Aux: 3.898e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17181, It: 0, Loss Data: 6.746e-02, Loss Eqns: 1.255e+00, Loss Aux: 3.481e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17182, It: 0, Loss Data: 7.206e-02, Loss Eqns: 1.214e+00, Loss Aux: 3.972e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17183, It: 0, Loss Data: 6.770e-02, Loss Eqns: 1.179e+00, Loss Aux: 4.550e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 17184, It: 0, Loss Data: 7.965e-02, Loss Eqns: 1.239e+00, Loss Aux: 4.308e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17185, It: 0, Loss Data: 6.267e-02, Loss Eqns: 1.252e+00, Loss Aux: 3.167e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17186, It: 0, Loss Data: 6.350e-02, Loss Eqns: 1.216e+00, Loss Aux: 3.045e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17187, It: 0, Loss Data: 6.967e-02, Loss Eqns: 1.232e+00, Loss Aux: 4.517e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17188, It: 0, Loss Data: 7.255e-02, Loss Eqns: 1.193e+00, Loss Aux: 5.118e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17189, It: 0, Loss Data: 6.306e-02, Loss Eqns: 1.192e+00, Loss Aux: 3.973e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17190, It: 0, Loss Data: 6.707e-02, Loss Eqns: 1.311e+00, Loss Aux: 3.721e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17191, It: 0, Loss Data: 6.352e-02, Loss Eqns: 1.269e+00, Loss Aux: 4.142e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17192, It: 0, Loss Data: 6.606e-02, Loss Eqns: 1.299e+00, Loss Aux: 4.288e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 17193, It: 0, Loss Data: 7.444e-02, Loss Eqns: 1.296e+00, Loss Aux: 3.383e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17194, It: 0, Loss Data: 5.898e-02, Loss Eqns: 1.306e+00, Loss Aux: 3.087e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 17195, It: 0, Loss Data: 6.601e-02, Loss Eqns: 1.293e+00, Loss Aux: 4.202e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17196, It: 0, Loss Data: 6.472e-02, Loss Eqns: 1.317e+00, Loss Aux: 5.845e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 17197, It: 0, Loss Data: 7.078e-02, Loss Eqns: 1.232e+00, Loss Aux: 5.858e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17198, It: 0, Loss Data: 6.073e-02, Loss Eqns: 1.311e+00, Loss Aux: 3.650e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17199, It: 0, Loss Data: 6.167e-02, Loss Eqns: 1.353e+00, Loss Aux: 2.519e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17200, It: 0, Loss Data: 6.720e-02, Loss Eqns: 1.337e+00, Loss Aux: 2.933e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17201, It: 0, Loss Data: 5.254e-02, Loss Eqns: 1.273e+00, Loss Aux: 4.760e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17202, It: 0, Loss Data: 7.376e-02, Loss Eqns: 1.197e+00, Loss Aux: 6.308e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17203, It: 0, Loss Data: 6.994e-02, Loss Eqns: 1.353e+00, Loss Aux: 5.624e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17204, It: 0, Loss Data: 6.946e-02, Loss Eqns: 1.279e+00, Loss Aux: 4.350e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17205, It: 0, Loss Data: 6.631e-02, Loss Eqns: 1.241e+00, Loss Aux: 4.143e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17206, It: 0, Loss Data: 6.044e-02, Loss Eqns: 1.235e+00, Loss Aux: 4.136e-02, Time: 0.217, Learning Rate: 1.0e-03\n",
      "Epoch: 17207, It: 0, Loss Data: 6.505e-02, Loss Eqns: 1.280e+00, Loss Aux: 3.927e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17208, It: 0, Loss Data: 5.739e-02, Loss Eqns: 1.183e+00, Loss Aux: 3.870e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17209, It: 0, Loss Data: 5.494e-02, Loss Eqns: 1.259e+00, Loss Aux: 3.999e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17210, It: 0, Loss Data: 6.796e-02, Loss Eqns: 1.247e+00, Loss Aux: 4.399e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17211, It: 0, Loss Data: 6.880e-02, Loss Eqns: 1.274e+00, Loss Aux: 5.121e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17212, It: 0, Loss Data: 7.672e-02, Loss Eqns: 1.204e+00, Loss Aux: 4.697e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17213, It: 0, Loss Data: 6.897e-02, Loss Eqns: 1.248e+00, Loss Aux: 3.958e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17214, It: 0, Loss Data: 6.357e-02, Loss Eqns: 1.280e+00, Loss Aux: 3.635e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17215, It: 0, Loss Data: 6.134e-02, Loss Eqns: 1.297e+00, Loss Aux: 3.491e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17216, It: 0, Loss Data: 6.852e-02, Loss Eqns: 1.221e+00, Loss Aux: 4.205e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17217, It: 0, Loss Data: 5.577e-02, Loss Eqns: 1.244e+00, Loss Aux: 4.465e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17218, It: 0, Loss Data: 6.578e-02, Loss Eqns: 1.218e+00, Loss Aux: 3.537e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17219, It: 0, Loss Data: 5.787e-02, Loss Eqns: 1.203e+00, Loss Aux: 3.514e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17220, It: 0, Loss Data: 7.229e-02, Loss Eqns: 1.236e+00, Loss Aux: 4.422e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17221, It: 0, Loss Data: 6.510e-02, Loss Eqns: 1.211e+00, Loss Aux: 5.224e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17222, It: 0, Loss Data: 6.191e-02, Loss Eqns: 1.251e+00, Loss Aux: 4.436e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 17223, It: 0, Loss Data: 6.230e-02, Loss Eqns: 1.252e+00, Loss Aux: 3.948e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17224, It: 0, Loss Data: 5.735e-02, Loss Eqns: 1.261e+00, Loss Aux: 3.859e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17225, It: 0, Loss Data: 7.420e-02, Loss Eqns: 1.219e+00, Loss Aux: 4.015e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17226, It: 0, Loss Data: 6.288e-02, Loss Eqns: 1.237e+00, Loss Aux: 3.727e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17227, It: 0, Loss Data: 6.619e-02, Loss Eqns: 1.195e+00, Loss Aux: 3.526e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17228, It: 0, Loss Data: 6.847e-02, Loss Eqns: 1.197e+00, Loss Aux: 3.870e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17229, It: 0, Loss Data: 6.722e-02, Loss Eqns: 1.231e+00, Loss Aux: 4.656e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 17230, It: 0, Loss Data: 6.343e-02, Loss Eqns: 1.206e+00, Loss Aux: 5.220e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 17231, It: 0, Loss Data: 7.330e-02, Loss Eqns: 1.246e+00, Loss Aux: 4.248e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17232, It: 0, Loss Data: 6.575e-02, Loss Eqns: 1.231e+00, Loss Aux: 3.427e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17233, It: 0, Loss Data: 5.918e-02, Loss Eqns: 1.204e+00, Loss Aux: 3.706e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17234, It: 0, Loss Data: 6.794e-02, Loss Eqns: 1.278e+00, Loss Aux: 4.266e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17235, It: 0, Loss Data: 5.999e-02, Loss Eqns: 1.219e+00, Loss Aux: 4.503e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17236, It: 0, Loss Data: 5.290e-02, Loss Eqns: 1.216e+00, Loss Aux: 4.432e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17237, It: 0, Loss Data: 7.123e-02, Loss Eqns: 1.217e+00, Loss Aux: 4.367e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17238, It: 0, Loss Data: 6.451e-02, Loss Eqns: 1.214e+00, Loss Aux: 4.111e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17239, It: 0, Loss Data: 6.974e-02, Loss Eqns: 1.212e+00, Loss Aux: 3.568e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17240, It: 0, Loss Data: 7.268e-02, Loss Eqns: 1.208e+00, Loss Aux: 3.218e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17241, It: 0, Loss Data: 5.967e-02, Loss Eqns: 1.180e+00, Loss Aux: 3.176e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17242, It: 0, Loss Data: 6.331e-02, Loss Eqns: 1.195e+00, Loss Aux: 3.670e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17243, It: 0, Loss Data: 5.528e-02, Loss Eqns: 1.188e+00, Loss Aux: 4.743e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17244, It: 0, Loss Data: 5.224e-02, Loss Eqns: 1.187e+00, Loss Aux: 4.588e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17245, It: 0, Loss Data: 5.986e-02, Loss Eqns: 1.149e+00, Loss Aux: 3.807e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17246, It: 0, Loss Data: 6.353e-02, Loss Eqns: 1.202e+00, Loss Aux: 4.214e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17247, It: 0, Loss Data: 5.714e-02, Loss Eqns: 1.170e+00, Loss Aux: 4.163e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17248, It: 0, Loss Data: 6.823e-02, Loss Eqns: 1.118e+00, Loss Aux: 3.495e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17249, It: 0, Loss Data: 5.155e-02, Loss Eqns: 1.218e+00, Loss Aux: 3.049e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17250, It: 0, Loss Data: 6.779e-02, Loss Eqns: 1.170e+00, Loss Aux: 3.779e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17251, It: 0, Loss Data: 6.354e-02, Loss Eqns: 1.192e+00, Loss Aux: 4.601e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17252, It: 0, Loss Data: 6.024e-02, Loss Eqns: 1.203e+00, Loss Aux: 4.061e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17253, It: 0, Loss Data: 5.707e-02, Loss Eqns: 1.184e+00, Loss Aux: 3.870e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17254, It: 0, Loss Data: 6.566e-02, Loss Eqns: 1.118e+00, Loss Aux: 4.313e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17255, It: 0, Loss Data: 5.901e-02, Loss Eqns: 1.111e+00, Loss Aux: 4.723e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17256, It: 0, Loss Data: 6.044e-02, Loss Eqns: 1.098e+00, Loss Aux: 3.904e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17257, It: 0, Loss Data: 6.055e-02, Loss Eqns: 1.127e+00, Loss Aux: 3.242e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17258, It: 0, Loss Data: 6.023e-02, Loss Eqns: 1.115e+00, Loss Aux: 3.886e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17259, It: 0, Loss Data: 6.264e-02, Loss Eqns: 1.133e+00, Loss Aux: 5.078e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17260, It: 0, Loss Data: 6.075e-02, Loss Eqns: 1.154e+00, Loss Aux: 4.567e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17261, It: 0, Loss Data: 7.680e-02, Loss Eqns: 1.253e+00, Loss Aux: 3.805e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17262, It: 0, Loss Data: 6.208e-02, Loss Eqns: 1.204e+00, Loss Aux: 3.492e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17263, It: 0, Loss Data: 6.264e-02, Loss Eqns: 1.096e+00, Loss Aux: 4.108e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17264, It: 0, Loss Data: 6.228e-02, Loss Eqns: 1.200e+00, Loss Aux: 4.706e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17265, It: 0, Loss Data: 6.540e-02, Loss Eqns: 1.304e+00, Loss Aux: 3.827e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17266, It: 0, Loss Data: 6.615e-02, Loss Eqns: 1.259e+00, Loss Aux: 3.917e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17267, It: 0, Loss Data: 6.122e-02, Loss Eqns: 1.174e+00, Loss Aux: 4.332e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17268, It: 0, Loss Data: 5.313e-02, Loss Eqns: 1.210e+00, Loss Aux: 4.241e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17269, It: 0, Loss Data: 5.995e-02, Loss Eqns: 1.170e+00, Loss Aux: 3.741e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17270, It: 0, Loss Data: 6.935e-02, Loss Eqns: 1.113e+00, Loss Aux: 3.612e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17271, It: 0, Loss Data: 6.966e-02, Loss Eqns: 1.203e+00, Loss Aux: 3.892e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17272, It: 0, Loss Data: 7.114e-02, Loss Eqns: 1.200e+00, Loss Aux: 4.310e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17273, It: 0, Loss Data: 6.448e-02, Loss Eqns: 1.178e+00, Loss Aux: 4.149e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17274, It: 0, Loss Data: 6.897e-02, Loss Eqns: 1.197e+00, Loss Aux: 3.697e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17275, It: 0, Loss Data: 5.637e-02, Loss Eqns: 1.263e+00, Loss Aux: 3.950e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17276, It: 0, Loss Data: 6.633e-02, Loss Eqns: 1.141e+00, Loss Aux: 4.371e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17277, It: 0, Loss Data: 5.295e-02, Loss Eqns: 1.173e+00, Loss Aux: 4.330e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17278, It: 0, Loss Data: 5.262e-02, Loss Eqns: 1.236e+00, Loss Aux: 4.529e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17279, It: 0, Loss Data: 5.956e-02, Loss Eqns: 1.281e+00, Loss Aux: 4.243e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17280, It: 0, Loss Data: 5.484e-02, Loss Eqns: 1.163e+00, Loss Aux: 3.819e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17281, It: 0, Loss Data: 6.418e-02, Loss Eqns: 1.238e+00, Loss Aux: 3.694e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17282, It: 0, Loss Data: 6.083e-02, Loss Eqns: 1.378e+00, Loss Aux: 3.700e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17283, It: 0, Loss Data: 6.398e-02, Loss Eqns: 1.173e+00, Loss Aux: 4.690e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17284, It: 0, Loss Data: 6.420e-02, Loss Eqns: 1.279e+00, Loss Aux: 4.477e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17285, It: 0, Loss Data: 7.077e-02, Loss Eqns: 1.618e+00, Loss Aux: 3.655e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17286, It: 0, Loss Data: 6.129e-02, Loss Eqns: 1.320e+00, Loss Aux: 3.725e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17287, It: 0, Loss Data: 6.517e-02, Loss Eqns: 1.855e+00, Loss Aux: 4.726e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17288, It: 0, Loss Data: 8.450e-02, Loss Eqns: 2.000e+00, Loss Aux: 4.008e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17289, It: 0, Loss Data: 6.390e-02, Loss Eqns: 1.333e+00, Loss Aux: 3.759e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17290, It: 0, Loss Data: 6.617e-02, Loss Eqns: 2.081e+00, Loss Aux: 3.768e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17291, It: 0, Loss Data: 6.473e-02, Loss Eqns: 1.753e+00, Loss Aux: 3.564e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17292, It: 0, Loss Data: 6.940e-02, Loss Eqns: 1.560e+00, Loss Aux: 4.907e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17293, It: 0, Loss Data: 7.686e-02, Loss Eqns: 1.808e+00, Loss Aux: 5.935e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17294, It: 0, Loss Data: 6.300e-02, Loss Eqns: 1.229e+00, Loss Aux: 3.758e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17295, It: 0, Loss Data: 7.113e-02, Loss Eqns: 1.661e+00, Loss Aux: 2.984e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17296, It: 0, Loss Data: 5.937e-02, Loss Eqns: 1.270e+00, Loss Aux: 3.991e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17297, It: 0, Loss Data: 6.491e-02, Loss Eqns: 1.471e+00, Loss Aux: 5.278e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 17298, It: 0, Loss Data: 6.706e-02, Loss Eqns: 1.350e+00, Loss Aux: 4.515e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17299, It: 0, Loss Data: 5.774e-02, Loss Eqns: 1.217e+00, Loss Aux: 3.933e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17300, It: 0, Loss Data: 6.909e-02, Loss Eqns: 1.420e+00, Loss Aux: 4.171e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17301, It: 0, Loss Data: 6.015e-02, Loss Eqns: 1.158e+00, Loss Aux: 3.649e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17302, It: 0, Loss Data: 7.206e-02, Loss Eqns: 1.263e+00, Loss Aux: 3.510e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17303, It: 0, Loss Data: 6.148e-02, Loss Eqns: 1.176e+00, Loss Aux: 4.042e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 17304, It: 0, Loss Data: 5.847e-02, Loss Eqns: 1.221e+00, Loss Aux: 4.503e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17305, It: 0, Loss Data: 5.572e-02, Loss Eqns: 1.305e+00, Loss Aux: 3.688e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17306, It: 0, Loss Data: 6.252e-02, Loss Eqns: 1.220e+00, Loss Aux: 3.885e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17307, It: 0, Loss Data: 5.690e-02, Loss Eqns: 1.431e+00, Loss Aux: 4.179e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17308, It: 0, Loss Data: 6.947e-02, Loss Eqns: 1.197e+00, Loss Aux: 3.857e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17309, It: 0, Loss Data: 6.459e-02, Loss Eqns: 1.165e+00, Loss Aux: 3.906e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17310, It: 0, Loss Data: 5.717e-02, Loss Eqns: 1.424e+00, Loss Aux: 5.076e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17311, It: 0, Loss Data: 1.570e-01, Loss Eqns: 2.244e+00, Loss Aux: 3.487e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17312, It: 0, Loss Data: 1.044e-01, Loss Eqns: 1.281e+00, Loss Aux: 2.823e-01, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17313, It: 0, Loss Data: 1.531e-01, Loss Eqns: 1.932e+00, Loss Aux: 4.125e-01, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17314, It: 0, Loss Data: 1.012e-01, Loss Eqns: 1.770e+00, Loss Aux: 1.797e-01, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17315, It: 0, Loss Data: 1.240e-01, Loss Eqns: 2.000e+00, Loss Aux: 5.382e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17316, It: 0, Loss Data: 8.557e-02, Loss Eqns: 1.575e+00, Loss Aux: 4.013e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 17317, It: 0, Loss Data: 2.687e-01, Loss Eqns: 6.344e+00, Loss Aux: 5.188e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17318, It: 0, Loss Data: 2.172e-01, Loss Eqns: 6.949e+00, Loss Aux: 5.400e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17319, It: 0, Loss Data: 4.360e-01, Loss Eqns: 8.311e+00, Loss Aux: 5.331e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17320, It: 0, Loss Data: 3.833e-01, Loss Eqns: 5.818e+00, Loss Aux: 6.032e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17321, It: 0, Loss Data: 3.634e-01, Loss Eqns: 6.023e+00, Loss Aux: 1.517e-01, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17322, It: 0, Loss Data: 3.015e-01, Loss Eqns: 5.188e+00, Loss Aux: 1.436e-01, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 17323, It: 0, Loss Data: 2.036e-01, Loss Eqns: 3.885e+00, Loss Aux: 6.337e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17324, It: 0, Loss Data: 2.262e-01, Loss Eqns: 3.694e+00, Loss Aux: 5.483e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17325, It: 0, Loss Data: 1.741e-01, Loss Eqns: 3.712e+00, Loss Aux: 6.053e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17326, It: 0, Loss Data: 1.516e-01, Loss Eqns: 3.042e+00, Loss Aux: 5.016e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17327, It: 0, Loss Data: 1.972e-01, Loss Eqns: 2.244e+00, Loss Aux: 5.591e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17328, It: 0, Loss Data: 1.835e-01, Loss Eqns: 2.069e+00, Loss Aux: 5.767e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17329, It: 0, Loss Data: 1.875e-01, Loss Eqns: 1.802e+00, Loss Aux: 6.030e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17330, It: 0, Loss Data: 1.732e-01, Loss Eqns: 1.835e+00, Loss Aux: 7.890e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17331, It: 0, Loss Data: 1.798e-01, Loss Eqns: 1.855e+00, Loss Aux: 9.647e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17332, It: 0, Loss Data: 1.495e-01, Loss Eqns: 1.727e+00, Loss Aux: 9.528e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17333, It: 0, Loss Data: 1.673e-01, Loss Eqns: 1.750e+00, Loss Aux: 6.989e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17334, It: 0, Loss Data: 1.560e-01, Loss Eqns: 1.783e+00, Loss Aux: 4.855e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17335, It: 0, Loss Data: 1.442e-01, Loss Eqns: 1.738e+00, Loss Aux: 4.133e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 17336, It: 0, Loss Data: 1.295e-01, Loss Eqns: 1.503e+00, Loss Aux: 4.708e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17337, It: 0, Loss Data: 1.418e-01, Loss Eqns: 1.658e+00, Loss Aux: 5.017e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17338, It: 0, Loss Data: 1.228e-01, Loss Eqns: 1.632e+00, Loss Aux: 4.774e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17339, It: 0, Loss Data: 1.242e-01, Loss Eqns: 1.480e+00, Loss Aux: 4.360e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 17340, It: 0, Loss Data: 1.010e-01, Loss Eqns: 1.488e+00, Loss Aux: 4.861e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17341, It: 0, Loss Data: 1.049e-01, Loss Eqns: 1.525e+00, Loss Aux: 6.512e-02, Time: 0.204, Learning Rate: 1.0e-03\n",
      "Epoch: 17342, It: 0, Loss Data: 9.621e-02, Loss Eqns: 1.507e+00, Loss Aux: 6.940e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17343, It: 0, Loss Data: 9.832e-02, Loss Eqns: 1.475e+00, Loss Aux: 6.114e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17344, It: 0, Loss Data: 9.894e-02, Loss Eqns: 1.449e+00, Loss Aux: 5.443e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17345, It: 0, Loss Data: 8.835e-02, Loss Eqns: 1.445e+00, Loss Aux: 5.710e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17346, It: 0, Loss Data: 8.244e-02, Loss Eqns: 1.391e+00, Loss Aux: 6.293e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17347, It: 0, Loss Data: 8.119e-02, Loss Eqns: 1.351e+00, Loss Aux: 5.836e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17348, It: 0, Loss Data: 9.005e-02, Loss Eqns: 1.343e+00, Loss Aux: 4.971e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17349, It: 0, Loss Data: 1.044e-01, Loss Eqns: 1.361e+00, Loss Aux: 5.719e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17350, It: 0, Loss Data: 8.014e-02, Loss Eqns: 1.377e+00, Loss Aux: 6.889e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17351, It: 0, Loss Data: 8.213e-02, Loss Eqns: 1.338e+00, Loss Aux: 6.462e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 17352, It: 0, Loss Data: 7.728e-02, Loss Eqns: 1.348e+00, Loss Aux: 5.397e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17353, It: 0, Loss Data: 9.121e-02, Loss Eqns: 1.335e+00, Loss Aux: 4.844e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17354, It: 0, Loss Data: 7.501e-02, Loss Eqns: 1.366e+00, Loss Aux: 5.242e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17355, It: 0, Loss Data: 7.274e-02, Loss Eqns: 1.326e+00, Loss Aux: 5.559e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17356, It: 0, Loss Data: 7.206e-02, Loss Eqns: 1.322e+00, Loss Aux: 4.784e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17357, It: 0, Loss Data: 7.939e-02, Loss Eqns: 1.243e+00, Loss Aux: 4.457e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17358, It: 0, Loss Data: 7.979e-02, Loss Eqns: 1.272e+00, Loss Aux: 5.088e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17359, It: 0, Loss Data: 7.397e-02, Loss Eqns: 1.218e+00, Loss Aux: 5.657e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17360, It: 0, Loss Data: 7.392e-02, Loss Eqns: 1.252e+00, Loss Aux: 5.447e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17361, It: 0, Loss Data: 7.812e-02, Loss Eqns: 1.286e+00, Loss Aux: 5.219e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17362, It: 0, Loss Data: 6.824e-02, Loss Eqns: 1.239e+00, Loss Aux: 5.316e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17363, It: 0, Loss Data: 6.796e-02, Loss Eqns: 1.263e+00, Loss Aux: 5.297e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17364, It: 0, Loss Data: 8.129e-02, Loss Eqns: 1.270e+00, Loss Aux: 5.202e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17365, It: 0, Loss Data: 7.187e-02, Loss Eqns: 1.229e+00, Loss Aux: 5.523e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17366, It: 0, Loss Data: 6.422e-02, Loss Eqns: 1.254e+00, Loss Aux: 5.970e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17367, It: 0, Loss Data: 6.692e-02, Loss Eqns: 1.189e+00, Loss Aux: 6.230e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17368, It: 0, Loss Data: 7.079e-02, Loss Eqns: 1.230e+00, Loss Aux: 5.392e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17369, It: 0, Loss Data: 6.209e-02, Loss Eqns: 1.232e+00, Loss Aux: 4.977e-02, Time: 0.239, Learning Rate: 1.0e-03\n",
      "Epoch: 17370, It: 0, Loss Data: 6.968e-02, Loss Eqns: 1.185e+00, Loss Aux: 5.353e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17371, It: 0, Loss Data: 7.066e-02, Loss Eqns: 1.229e+00, Loss Aux: 6.153e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17372, It: 0, Loss Data: 7.669e-02, Loss Eqns: 1.171e+00, Loss Aux: 6.008e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17373, It: 0, Loss Data: 6.538e-02, Loss Eqns: 1.194e+00, Loss Aux: 5.190e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17374, It: 0, Loss Data: 7.747e-02, Loss Eqns: 1.223e+00, Loss Aux: 4.746e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17375, It: 0, Loss Data: 6.430e-02, Loss Eqns: 1.168e+00, Loss Aux: 4.813e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17376, It: 0, Loss Data: 6.652e-02, Loss Eqns: 1.168e+00, Loss Aux: 5.541e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17377, It: 0, Loss Data: 7.169e-02, Loss Eqns: 1.177e+00, Loss Aux: 6.557e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17378, It: 0, Loss Data: 6.448e-02, Loss Eqns: 1.130e+00, Loss Aux: 6.498e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17379, It: 0, Loss Data: 7.858e-02, Loss Eqns: 1.135e+00, Loss Aux: 5.345e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17380, It: 0, Loss Data: 6.935e-02, Loss Eqns: 1.204e+00, Loss Aux: 4.932e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17381, It: 0, Loss Data: 6.649e-02, Loss Eqns: 1.178e+00, Loss Aux: 5.099e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17382, It: 0, Loss Data: 5.562e-02, Loss Eqns: 1.181e+00, Loss Aux: 5.550e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17383, It: 0, Loss Data: 6.993e-02, Loss Eqns: 1.159e+00, Loss Aux: 5.580e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17384, It: 0, Loss Data: 6.055e-02, Loss Eqns: 1.145e+00, Loss Aux: 5.352e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17385, It: 0, Loss Data: 6.488e-02, Loss Eqns: 1.138e+00, Loss Aux: 5.016e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17386, It: 0, Loss Data: 6.145e-02, Loss Eqns: 1.145e+00, Loss Aux: 5.277e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17387, It: 0, Loss Data: 6.669e-02, Loss Eqns: 1.164e+00, Loss Aux: 5.136e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17388, It: 0, Loss Data: 6.725e-02, Loss Eqns: 1.135e+00, Loss Aux: 4.918e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 17389, It: 0, Loss Data: 6.462e-02, Loss Eqns: 1.116e+00, Loss Aux: 5.105e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17390, It: 0, Loss Data: 6.937e-02, Loss Eqns: 1.180e+00, Loss Aux: 5.618e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17391, It: 0, Loss Data: 6.277e-02, Loss Eqns: 1.146e+00, Loss Aux: 5.861e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17392, It: 0, Loss Data: 6.420e-02, Loss Eqns: 1.191e+00, Loss Aux: 5.411e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17393, It: 0, Loss Data: 6.315e-02, Loss Eqns: 1.187e+00, Loss Aux: 5.213e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17394, It: 0, Loss Data: 6.292e-02, Loss Eqns: 1.148e+00, Loss Aux: 5.310e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17395, It: 0, Loss Data: 6.235e-02, Loss Eqns: 1.152e+00, Loss Aux: 5.435e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17396, It: 0, Loss Data: 6.467e-02, Loss Eqns: 1.129e+00, Loss Aux: 5.090e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17397, It: 0, Loss Data: 6.944e-02, Loss Eqns: 1.123e+00, Loss Aux: 4.643e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17398, It: 0, Loss Data: 6.099e-02, Loss Eqns: 1.134e+00, Loss Aux: 4.662e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17399, It: 0, Loss Data: 6.089e-02, Loss Eqns: 1.166e+00, Loss Aux: 5.078e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17400, It: 0, Loss Data: 7.230e-02, Loss Eqns: 1.139e+00, Loss Aux: 5.670e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17401, It: 0, Loss Data: 5.943e-02, Loss Eqns: 1.166e+00, Loss Aux: 5.391e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17402, It: 0, Loss Data: 6.662e-02, Loss Eqns: 1.108e+00, Loss Aux: 5.104e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17403, It: 0, Loss Data: 6.167e-02, Loss Eqns: 1.107e+00, Loss Aux: 5.774e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17404, It: 0, Loss Data: 6.295e-02, Loss Eqns: 1.125e+00, Loss Aux: 6.332e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17405, It: 0, Loss Data: 5.469e-02, Loss Eqns: 1.111e+00, Loss Aux: 5.053e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17406, It: 0, Loss Data: 6.969e-02, Loss Eqns: 1.110e+00, Loss Aux: 4.747e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 17407, It: 0, Loss Data: 6.489e-02, Loss Eqns: 1.101e+00, Loss Aux: 5.104e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17408, It: 0, Loss Data: 6.114e-02, Loss Eqns: 1.117e+00, Loss Aux: 5.540e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 17409, It: 0, Loss Data: 5.570e-02, Loss Eqns: 1.116e+00, Loss Aux: 5.112e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17410, It: 0, Loss Data: 6.080e-02, Loss Eqns: 1.086e+00, Loss Aux: 5.087e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17411, It: 0, Loss Data: 6.324e-02, Loss Eqns: 1.087e+00, Loss Aux: 5.690e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17412, It: 0, Loss Data: 7.200e-02, Loss Eqns: 1.068e+00, Loss Aux: 6.638e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17413, It: 0, Loss Data: 6.223e-02, Loss Eqns: 1.116e+00, Loss Aux: 5.387e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17414, It: 0, Loss Data: 6.569e-02, Loss Eqns: 1.107e+00, Loss Aux: 4.604e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17415, It: 0, Loss Data: 7.490e-02, Loss Eqns: 1.116e+00, Loss Aux: 4.890e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17416, It: 0, Loss Data: 7.376e-02, Loss Eqns: 1.090e+00, Loss Aux: 5.756e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17417, It: 0, Loss Data: 6.372e-02, Loss Eqns: 1.080e+00, Loss Aux: 5.489e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17418, It: 0, Loss Data: 6.650e-02, Loss Eqns: 1.126e+00, Loss Aux: 4.766e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17419, It: 0, Loss Data: 5.788e-02, Loss Eqns: 1.113e+00, Loss Aux: 4.878e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17420, It: 0, Loss Data: 6.060e-02, Loss Eqns: 1.092e+00, Loss Aux: 5.973e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17421, It: 0, Loss Data: 6.742e-02, Loss Eqns: 1.086e+00, Loss Aux: 6.504e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17422, It: 0, Loss Data: 6.144e-02, Loss Eqns: 1.103e+00, Loss Aux: 4.986e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 17423, It: 0, Loss Data: 6.973e-02, Loss Eqns: 1.113e+00, Loss Aux: 4.383e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17424, It: 0, Loss Data: 6.126e-02, Loss Eqns: 1.127e+00, Loss Aux: 4.703e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 17425, It: 0, Loss Data: 6.047e-02, Loss Eqns: 1.111e+00, Loss Aux: 5.797e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17426, It: 0, Loss Data: 6.986e-02, Loss Eqns: 1.104e+00, Loss Aux: 6.598e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17427, It: 0, Loss Data: 6.664e-02, Loss Eqns: 1.092e+00, Loss Aux: 6.210e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 17428, It: 0, Loss Data: 6.597e-02, Loss Eqns: 1.051e+00, Loss Aux: 5.114e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17429, It: 0, Loss Data: 6.494e-02, Loss Eqns: 1.120e+00, Loss Aux: 5.006e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17430, It: 0, Loss Data: 6.296e-02, Loss Eqns: 1.112e+00, Loss Aux: 4.908e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17431, It: 0, Loss Data: 7.231e-02, Loss Eqns: 1.107e+00, Loss Aux: 5.284e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17432, It: 0, Loss Data: 6.217e-02, Loss Eqns: 1.122e+00, Loss Aux: 5.607e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17433, It: 0, Loss Data: 5.947e-02, Loss Eqns: 1.123e+00, Loss Aux: 5.375e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17434, It: 0, Loss Data: 5.384e-02, Loss Eqns: 1.091e+00, Loss Aux: 5.018e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17435, It: 0, Loss Data: 6.288e-02, Loss Eqns: 1.081e+00, Loss Aux: 5.151e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17436, It: 0, Loss Data: 5.397e-02, Loss Eqns: 1.070e+00, Loss Aux: 5.301e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17437, It: 0, Loss Data: 6.396e-02, Loss Eqns: 1.085e+00, Loss Aux: 5.177e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17438, It: 0, Loss Data: 6.190e-02, Loss Eqns: 1.060e+00, Loss Aux: 4.699e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17439, It: 0, Loss Data: 7.004e-02, Loss Eqns: 1.094e+00, Loss Aux: 4.599e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17440, It: 0, Loss Data: 6.237e-02, Loss Eqns: 1.080e+00, Loss Aux: 5.040e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17441, It: 0, Loss Data: 6.747e-02, Loss Eqns: 1.084e+00, Loss Aux: 6.011e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17442, It: 0, Loss Data: 7.124e-02, Loss Eqns: 1.062e+00, Loss Aux: 6.328e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17443, It: 0, Loss Data: 6.624e-02, Loss Eqns: 1.073e+00, Loss Aux: 5.486e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17444, It: 0, Loss Data: 6.250e-02, Loss Eqns: 1.099e+00, Loss Aux: 4.800e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17445, It: 0, Loss Data: 7.027e-02, Loss Eqns: 1.082e+00, Loss Aux: 4.998e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17446, It: 0, Loss Data: 6.172e-02, Loss Eqns: 1.112e+00, Loss Aux: 5.395e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17447, It: 0, Loss Data: 5.888e-02, Loss Eqns: 1.098e+00, Loss Aux: 5.789e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17448, It: 0, Loss Data: 6.238e-02, Loss Eqns: 1.087e+00, Loss Aux: 5.061e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17449, It: 0, Loss Data: 6.496e-02, Loss Eqns: 1.097e+00, Loss Aux: 4.871e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17450, It: 0, Loss Data: 6.324e-02, Loss Eqns: 1.073e+00, Loss Aux: 5.197e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17451, It: 0, Loss Data: 6.385e-02, Loss Eqns: 1.104e+00, Loss Aux: 4.884e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17452, It: 0, Loss Data: 5.961e-02, Loss Eqns: 1.101e+00, Loss Aux: 4.769e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17453, It: 0, Loss Data: 6.701e-02, Loss Eqns: 1.072e+00, Loss Aux: 5.102e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17454, It: 0, Loss Data: 6.358e-02, Loss Eqns: 1.079e+00, Loss Aux: 5.301e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17455, It: 0, Loss Data: 7.645e-02, Loss Eqns: 1.112e+00, Loss Aux: 4.814e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17456, It: 0, Loss Data: 5.912e-02, Loss Eqns: 1.113e+00, Loss Aux: 4.619e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17457, It: 0, Loss Data: 6.621e-02, Loss Eqns: 1.120e+00, Loss Aux: 4.931e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17458, It: 0, Loss Data: 6.190e-02, Loss Eqns: 1.089e+00, Loss Aux: 5.159e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17459, It: 0, Loss Data: 6.001e-02, Loss Eqns: 1.095e+00, Loss Aux: 4.732e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17460, It: 0, Loss Data: 6.707e-02, Loss Eqns: 1.043e+00, Loss Aux: 4.867e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17461, It: 0, Loss Data: 5.617e-02, Loss Eqns: 1.103e+00, Loss Aux: 5.300e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17462, It: 0, Loss Data: 5.426e-02, Loss Eqns: 1.056e+00, Loss Aux: 5.707e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17463, It: 0, Loss Data: 6.017e-02, Loss Eqns: 1.078e+00, Loss Aux: 5.390e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17464, It: 0, Loss Data: 6.602e-02, Loss Eqns: 1.069e+00, Loss Aux: 5.118e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 17465, It: 0, Loss Data: 5.773e-02, Loss Eqns: 1.079e+00, Loss Aux: 5.200e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17466, It: 0, Loss Data: 6.591e-02, Loss Eqns: 1.090e+00, Loss Aux: 5.163e-02, Time: 0.213, Learning Rate: 1.0e-03\n",
      "Epoch: 17467, It: 0, Loss Data: 5.711e-02, Loss Eqns: 1.079e+00, Loss Aux: 4.508e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17468, It: 0, Loss Data: 7.023e-02, Loss Eqns: 1.084e+00, Loss Aux: 4.371e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17469, It: 0, Loss Data: 5.766e-02, Loss Eqns: 1.054e+00, Loss Aux: 4.703e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17470, It: 0, Loss Data: 6.208e-02, Loss Eqns: 1.018e+00, Loss Aux: 5.224e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17471, It: 0, Loss Data: 6.713e-02, Loss Eqns: 1.094e+00, Loss Aux: 5.238e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17472, It: 0, Loss Data: 6.080e-02, Loss Eqns: 1.069e+00, Loss Aux: 5.073e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17473, It: 0, Loss Data: 6.254e-02, Loss Eqns: 1.075e+00, Loss Aux: 5.453e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 17474, It: 0, Loss Data: 6.520e-02, Loss Eqns: 1.029e+00, Loss Aux: 5.763e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17475, It: 0, Loss Data: 6.567e-02, Loss Eqns: 1.081e+00, Loss Aux: 5.388e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17476, It: 0, Loss Data: 5.569e-02, Loss Eqns: 1.072e+00, Loss Aux: 4.757e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17477, It: 0, Loss Data: 5.673e-02, Loss Eqns: 1.115e+00, Loss Aux: 4.515e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17478, It: 0, Loss Data: 7.140e-02, Loss Eqns: 1.113e+00, Loss Aux: 4.353e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17479, It: 0, Loss Data: 6.164e-02, Loss Eqns: 1.114e+00, Loss Aux: 5.451e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17480, It: 0, Loss Data: 5.910e-02, Loss Eqns: 1.067e+00, Loss Aux: 6.238e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17481, It: 0, Loss Data: 5.604e-02, Loss Eqns: 1.073e+00, Loss Aux: 5.443e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17482, It: 0, Loss Data: 5.635e-02, Loss Eqns: 1.064e+00, Loss Aux: 4.917e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17483, It: 0, Loss Data: 5.272e-02, Loss Eqns: 1.096e+00, Loss Aux: 4.845e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17484, It: 0, Loss Data: 6.291e-02, Loss Eqns: 1.078e+00, Loss Aux: 4.694e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17485, It: 0, Loss Data: 6.207e-02, Loss Eqns: 1.051e+00, Loss Aux: 4.818e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17486, It: 0, Loss Data: 6.208e-02, Loss Eqns: 1.046e+00, Loss Aux: 5.596e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17487, It: 0, Loss Data: 7.079e-02, Loss Eqns: 1.046e+00, Loss Aux: 5.612e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17488, It: 0, Loss Data: 6.869e-02, Loss Eqns: 1.037e+00, Loss Aux: 4.912e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17489, It: 0, Loss Data: 6.328e-02, Loss Eqns: 1.060e+00, Loss Aux: 4.781e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17490, It: 0, Loss Data: 5.659e-02, Loss Eqns: 1.043e+00, Loss Aux: 5.411e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17491, It: 0, Loss Data: 6.836e-02, Loss Eqns: 1.050e+00, Loss Aux: 5.430e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17492, It: 0, Loss Data: 5.490e-02, Loss Eqns: 1.058e+00, Loss Aux: 4.587e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17493, It: 0, Loss Data: 6.548e-02, Loss Eqns: 1.090e+00, Loss Aux: 4.566e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 17494, It: 0, Loss Data: 6.203e-02, Loss Eqns: 1.055e+00, Loss Aux: 4.972e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17495, It: 0, Loss Data: 6.552e-02, Loss Eqns: 1.061e+00, Loss Aux: 5.830e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17496, It: 0, Loss Data: 6.708e-02, Loss Eqns: 1.033e+00, Loss Aux: 5.721e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17497, It: 0, Loss Data: 6.741e-02, Loss Eqns: 1.052e+00, Loss Aux: 5.027e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17498, It: 0, Loss Data: 6.397e-02, Loss Eqns: 1.041e+00, Loss Aux: 4.620e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17499, It: 0, Loss Data: 6.957e-02, Loss Eqns: 1.032e+00, Loss Aux: 4.834e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17500, It: 0, Loss Data: 6.306e-02, Loss Eqns: 1.074e+00, Loss Aux: 5.263e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17501, It: 0, Loss Data: 5.728e-02, Loss Eqns: 1.066e+00, Loss Aux: 4.976e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17502, It: 0, Loss Data: 6.194e-02, Loss Eqns: 1.074e+00, Loss Aux: 5.061e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17503, It: 0, Loss Data: 6.337e-02, Loss Eqns: 1.079e+00, Loss Aux: 5.067e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17504, It: 0, Loss Data: 5.303e-02, Loss Eqns: 1.063e+00, Loss Aux: 5.031e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17505, It: 0, Loss Data: 6.276e-02, Loss Eqns: 1.053e+00, Loss Aux: 5.344e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17506, It: 0, Loss Data: 6.301e-02, Loss Eqns: 1.039e+00, Loss Aux: 5.111e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17507, It: 0, Loss Data: 5.732e-02, Loss Eqns: 1.078e+00, Loss Aux: 4.596e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17508, It: 0, Loss Data: 7.393e-02, Loss Eqns: 1.062e+00, Loss Aux: 4.567e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17509, It: 0, Loss Data: 5.444e-02, Loss Eqns: 1.054e+00, Loss Aux: 4.911e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 17510, It: 0, Loss Data: 6.860e-02, Loss Eqns: 1.052e+00, Loss Aux: 5.747e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17511, It: 0, Loss Data: 5.404e-02, Loss Eqns: 1.032e+00, Loss Aux: 6.324e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17512, It: 0, Loss Data: 6.544e-02, Loss Eqns: 1.029e+00, Loss Aux: 5.377e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17513, It: 0, Loss Data: 5.583e-02, Loss Eqns: 1.060e+00, Loss Aux: 4.531e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17514, It: 0, Loss Data: 6.048e-02, Loss Eqns: 1.065e+00, Loss Aux: 4.478e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17515, It: 0, Loss Data: 4.902e-02, Loss Eqns: 1.043e+00, Loss Aux: 5.232e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17516, It: 0, Loss Data: 6.580e-02, Loss Eqns: 1.015e+00, Loss Aux: 6.251e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17517, It: 0, Loss Data: 5.858e-02, Loss Eqns: 1.061e+00, Loss Aux: 5.484e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17518, It: 0, Loss Data: 6.055e-02, Loss Eqns: 1.026e+00, Loss Aux: 4.787e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 17519, It: 0, Loss Data: 5.457e-02, Loss Eqns: 1.032e+00, Loss Aux: 4.721e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17520, It: 0, Loss Data: 6.674e-02, Loss Eqns: 1.036e+00, Loss Aux: 5.085e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17521, It: 0, Loss Data: 6.803e-02, Loss Eqns: 1.062e+00, Loss Aux: 5.721e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17522, It: 0, Loss Data: 5.645e-02, Loss Eqns: 9.996e-01, Loss Aux: 4.919e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17523, It: 0, Loss Data: 6.108e-02, Loss Eqns: 1.025e+00, Loss Aux: 4.634e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17524, It: 0, Loss Data: 5.835e-02, Loss Eqns: 1.042e+00, Loss Aux: 5.259e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17525, It: 0, Loss Data: 6.347e-02, Loss Eqns: 1.027e+00, Loss Aux: 5.967e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17526, It: 0, Loss Data: 5.974e-02, Loss Eqns: 1.023e+00, Loss Aux: 5.747e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17527, It: 0, Loss Data: 5.326e-02, Loss Eqns: 1.020e+00, Loss Aux: 5.103e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17528, It: 0, Loss Data: 5.869e-02, Loss Eqns: 1.086e+00, Loss Aux: 4.812e-02, Time: 0.222, Learning Rate: 1.0e-03\n",
      "Epoch: 17529, It: 0, Loss Data: 6.723e-02, Loss Eqns: 1.047e+00, Loss Aux: 4.818e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17530, It: 0, Loss Data: 6.734e-02, Loss Eqns: 1.062e+00, Loss Aux: 4.840e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17531, It: 0, Loss Data: 6.097e-02, Loss Eqns: 1.063e+00, Loss Aux: 4.833e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17532, It: 0, Loss Data: 4.894e-02, Loss Eqns: 1.057e+00, Loss Aux: 4.269e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17533, It: 0, Loss Data: 6.154e-02, Loss Eqns: 1.040e+00, Loss Aux: 4.676e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17534, It: 0, Loss Data: 5.626e-02, Loss Eqns: 1.002e+00, Loss Aux: 6.208e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 17535, It: 0, Loss Data: 5.716e-02, Loss Eqns: 9.872e-01, Loss Aux: 6.642e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17536, It: 0, Loss Data: 6.685e-02, Loss Eqns: 9.731e-01, Loss Aux: 5.631e-02, Time: 0.210, Learning Rate: 1.0e-03\n",
      "Epoch: 17537, It: 0, Loss Data: 6.154e-02, Loss Eqns: 1.028e+00, Loss Aux: 5.379e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17538, It: 0, Loss Data: 6.369e-02, Loss Eqns: 1.029e+00, Loss Aux: 5.074e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17539, It: 0, Loss Data: 6.033e-02, Loss Eqns: 1.084e+00, Loss Aux: 4.702e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17540, It: 0, Loss Data: 5.865e-02, Loss Eqns: 1.088e+00, Loss Aux: 4.539e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 17541, It: 0, Loss Data: 5.249e-02, Loss Eqns: 1.074e+00, Loss Aux: 4.884e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17542, It: 0, Loss Data: 5.681e-02, Loss Eqns: 1.022e+00, Loss Aux: 5.035e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17543, It: 0, Loss Data: 4.541e-02, Loss Eqns: 1.022e+00, Loss Aux: 5.409e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17544, It: 0, Loss Data: 5.562e-02, Loss Eqns: 1.038e+00, Loss Aux: 5.931e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17545, It: 0, Loss Data: 5.691e-02, Loss Eqns: 1.013e+00, Loss Aux: 5.643e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17546, It: 0, Loss Data: 5.817e-02, Loss Eqns: 1.038e+00, Loss Aux: 4.953e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17547, It: 0, Loss Data: 6.606e-02, Loss Eqns: 9.787e-01, Loss Aux: 5.106e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17548, It: 0, Loss Data: 6.413e-02, Loss Eqns: 9.908e-01, Loss Aux: 5.667e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17549, It: 0, Loss Data: 6.264e-02, Loss Eqns: 1.006e+00, Loss Aux: 4.961e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17550, It: 0, Loss Data: 5.784e-02, Loss Eqns: 1.041e+00, Loss Aux: 4.686e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17551, It: 0, Loss Data: 6.123e-02, Loss Eqns: 1.005e+00, Loss Aux: 5.097e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17552, It: 0, Loss Data: 6.778e-02, Loss Eqns: 1.055e+00, Loss Aux: 5.052e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17553, It: 0, Loss Data: 6.179e-02, Loss Eqns: 1.003e+00, Loss Aux: 4.440e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17554, It: 0, Loss Data: 6.432e-02, Loss Eqns: 1.012e+00, Loss Aux: 4.207e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17555, It: 0, Loss Data: 5.447e-02, Loss Eqns: 9.917e-01, Loss Aux: 5.437e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 17556, It: 0, Loss Data: 5.191e-02, Loss Eqns: 1.053e+00, Loss Aux: 7.228e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17557, It: 0, Loss Data: 6.581e-02, Loss Eqns: 1.050e+00, Loss Aux: 7.558e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17558, It: 0, Loss Data: 5.723e-02, Loss Eqns: 1.008e+00, Loss Aux: 5.947e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17559, It: 0, Loss Data: 5.755e-02, Loss Eqns: 1.042e+00, Loss Aux: 4.742e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17560, It: 0, Loss Data: 6.603e-02, Loss Eqns: 1.034e+00, Loss Aux: 4.780e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17561, It: 0, Loss Data: 5.800e-02, Loss Eqns: 1.003e+00, Loss Aux: 4.867e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17562, It: 0, Loss Data: 5.684e-02, Loss Eqns: 1.047e+00, Loss Aux: 4.868e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17563, It: 0, Loss Data: 6.132e-02, Loss Eqns: 1.020e+00, Loss Aux: 5.029e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17564, It: 0, Loss Data: 5.848e-02, Loss Eqns: 1.039e+00, Loss Aux: 5.074e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 17565, It: 0, Loss Data: 6.676e-02, Loss Eqns: 1.001e+00, Loss Aux: 5.266e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17566, It: 0, Loss Data: 5.764e-02, Loss Eqns: 1.040e+00, Loss Aux: 5.415e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 17567, It: 0, Loss Data: 5.999e-02, Loss Eqns: 9.935e-01, Loss Aux: 4.921e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17568, It: 0, Loss Data: 5.667e-02, Loss Eqns: 1.038e+00, Loss Aux: 4.966e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17569, It: 0, Loss Data: 6.051e-02, Loss Eqns: 1.002e+00, Loss Aux: 4.997e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17570, It: 0, Loss Data: 5.850e-02, Loss Eqns: 1.041e+00, Loss Aux: 4.733e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17571, It: 0, Loss Data: 6.628e-02, Loss Eqns: 9.928e-01, Loss Aux: 4.870e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17572, It: 0, Loss Data: 5.154e-02, Loss Eqns: 1.028e+00, Loss Aux: 5.476e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17573, It: 0, Loss Data: 6.299e-02, Loss Eqns: 9.855e-01, Loss Aux: 5.250e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 17574, It: 0, Loss Data: 5.947e-02, Loss Eqns: 1.031e+00, Loss Aux: 4.824e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17575, It: 0, Loss Data: 5.835e-02, Loss Eqns: 1.024e+00, Loss Aux: 5.073e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17576, It: 0, Loss Data: 5.985e-02, Loss Eqns: 1.005e+00, Loss Aux: 5.880e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17577, It: 0, Loss Data: 6.060e-02, Loss Eqns: 1.015e+00, Loss Aux: 6.014e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17578, It: 0, Loss Data: 5.866e-02, Loss Eqns: 1.047e+00, Loss Aux: 4.937e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17579, It: 0, Loss Data: 5.257e-02, Loss Eqns: 1.025e+00, Loss Aux: 4.373e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17580, It: 0, Loss Data: 5.743e-02, Loss Eqns: 9.857e-01, Loss Aux: 4.647e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17581, It: 0, Loss Data: 5.618e-02, Loss Eqns: 9.995e-01, Loss Aux: 5.033e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17582, It: 0, Loss Data: 6.009e-02, Loss Eqns: 1.023e+00, Loss Aux: 5.110e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17583, It: 0, Loss Data: 6.002e-02, Loss Eqns: 9.873e-01, Loss Aux: 4.789e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17584, It: 0, Loss Data: 6.338e-02, Loss Eqns: 1.024e+00, Loss Aux: 4.652e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17585, It: 0, Loss Data: 5.810e-02, Loss Eqns: 1.030e+00, Loss Aux: 4.772e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17586, It: 0, Loss Data: 6.119e-02, Loss Eqns: 1.018e+00, Loss Aux: 4.892e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17587, It: 0, Loss Data: 5.861e-02, Loss Eqns: 1.015e+00, Loss Aux: 4.919e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17588, It: 0, Loss Data: 5.626e-02, Loss Eqns: 1.013e+00, Loss Aux: 5.638e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17589, It: 0, Loss Data: 6.173e-02, Loss Eqns: 1.008e+00, Loss Aux: 5.437e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17590, It: 0, Loss Data: 5.887e-02, Loss Eqns: 1.068e+00, Loss Aux: 4.575e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17591, It: 0, Loss Data: 5.276e-02, Loss Eqns: 1.026e+00, Loss Aux: 4.220e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17592, It: 0, Loss Data: 5.582e-02, Loss Eqns: 1.067e+00, Loss Aux: 4.670e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 17593, It: 0, Loss Data: 5.714e-02, Loss Eqns: 1.040e+00, Loss Aux: 5.291e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17594, It: 0, Loss Data: 6.649e-02, Loss Eqns: 1.047e+00, Loss Aux: 5.158e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17595, It: 0, Loss Data: 5.911e-02, Loss Eqns: 1.079e+00, Loss Aux: 5.279e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17596, It: 0, Loss Data: 6.342e-02, Loss Eqns: 1.022e+00, Loss Aux: 5.312e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17597, It: 0, Loss Data: 5.338e-02, Loss Eqns: 1.003e+00, Loss Aux: 5.186e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17598, It: 0, Loss Data: 5.451e-02, Loss Eqns: 1.015e+00, Loss Aux: 5.605e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17599, It: 0, Loss Data: 6.268e-02, Loss Eqns: 1.018e+00, Loss Aux: 5.362e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17600, It: 0, Loss Data: 5.387e-02, Loss Eqns: 1.010e+00, Loss Aux: 4.692e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17601, It: 0, Loss Data: 5.816e-02, Loss Eqns: 9.956e-01, Loss Aux: 4.424e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17602, It: 0, Loss Data: 6.108e-02, Loss Eqns: 1.002e+00, Loss Aux: 4.720e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17603, It: 0, Loss Data: 6.132e-02, Loss Eqns: 9.990e-01, Loss Aux: 4.927e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17604, It: 0, Loss Data: 5.963e-02, Loss Eqns: 1.015e+00, Loss Aux: 5.120e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17605, It: 0, Loss Data: 4.430e-02, Loss Eqns: 1.022e+00, Loss Aux: 5.346e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17606, It: 0, Loss Data: 5.706e-02, Loss Eqns: 9.843e-01, Loss Aux: 5.189e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17607, It: 0, Loss Data: 5.636e-02, Loss Eqns: 9.703e-01, Loss Aux: 5.089e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17608, It: 0, Loss Data: 6.707e-02, Loss Eqns: 9.930e-01, Loss Aux: 5.094e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17609, It: 0, Loss Data: 5.088e-02, Loss Eqns: 9.710e-01, Loss Aux: 4.804e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17610, It: 0, Loss Data: 5.489e-02, Loss Eqns: 9.874e-01, Loss Aux: 4.248e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 17611, It: 0, Loss Data: 6.146e-02, Loss Eqns: 1.011e+00, Loss Aux: 4.609e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17612, It: 0, Loss Data: 6.812e-02, Loss Eqns: 1.016e+00, Loss Aux: 5.276e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17613, It: 0, Loss Data: 6.036e-02, Loss Eqns: 9.775e-01, Loss Aux: 5.497e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 17614, It: 0, Loss Data: 6.056e-02, Loss Eqns: 1.007e+00, Loss Aux: 4.876e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17615, It: 0, Loss Data: 5.746e-02, Loss Eqns: 9.833e-01, Loss Aux: 4.853e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17616, It: 0, Loss Data: 5.787e-02, Loss Eqns: 1.009e+00, Loss Aux: 5.835e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17617, It: 0, Loss Data: 6.229e-02, Loss Eqns: 9.775e-01, Loss Aux: 5.371e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17618, It: 0, Loss Data: 5.538e-02, Loss Eqns: 1.021e+00, Loss Aux: 4.323e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17619, It: 0, Loss Data: 5.703e-02, Loss Eqns: 1.055e+00, Loss Aux: 4.127e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17620, It: 0, Loss Data: 6.397e-02, Loss Eqns: 1.062e+00, Loss Aux: 5.054e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17621, It: 0, Loss Data: 5.252e-02, Loss Eqns: 9.880e-01, Loss Aux: 6.458e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17622, It: 0, Loss Data: 5.781e-02, Loss Eqns: 1.054e+00, Loss Aux: 5.723e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17623, It: 0, Loss Data: 5.782e-02, Loss Eqns: 1.066e+00, Loss Aux: 4.597e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17624, It: 0, Loss Data: 5.953e-02, Loss Eqns: 1.088e+00, Loss Aux: 4.259e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17625, It: 0, Loss Data: 5.350e-02, Loss Eqns: 1.003e+00, Loss Aux: 5.543e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17626, It: 0, Loss Data: 6.007e-02, Loss Eqns: 9.959e-01, Loss Aux: 5.691e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17627, It: 0, Loss Data: 5.885e-02, Loss Eqns: 1.001e+00, Loss Aux: 4.690e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17628, It: 0, Loss Data: 6.354e-02, Loss Eqns: 1.039e+00, Loss Aux: 4.788e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17629, It: 0, Loss Data: 6.530e-02, Loss Eqns: 1.054e+00, Loss Aux: 5.975e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17630, It: 0, Loss Data: 5.081e-02, Loss Eqns: 1.021e+00, Loss Aux: 6.121e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17631, It: 0, Loss Data: 6.112e-02, Loss Eqns: 1.021e+00, Loss Aux: 4.859e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17632, It: 0, Loss Data: 5.226e-02, Loss Eqns: 1.029e+00, Loss Aux: 4.623e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17633, It: 0, Loss Data: 5.270e-02, Loss Eqns: 1.046e+00, Loss Aux: 4.724e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17634, It: 0, Loss Data: 5.142e-02, Loss Eqns: 1.018e+00, Loss Aux: 5.041e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17635, It: 0, Loss Data: 4.774e-02, Loss Eqns: 9.865e-01, Loss Aux: 5.317e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17636, It: 0, Loss Data: 5.390e-02, Loss Eqns: 9.840e-01, Loss Aux: 5.129e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17637, It: 0, Loss Data: 5.299e-02, Loss Eqns: 9.728e-01, Loss Aux: 4.972e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17638, It: 0, Loss Data: 5.873e-02, Loss Eqns: 1.008e+00, Loss Aux: 5.834e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17639, It: 0, Loss Data: 6.055e-02, Loss Eqns: 1.004e+00, Loss Aux: 5.597e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17640, It: 0, Loss Data: 5.412e-02, Loss Eqns: 9.767e-01, Loss Aux: 4.787e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17641, It: 0, Loss Data: 5.579e-02, Loss Eqns: 9.708e-01, Loss Aux: 4.541e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17642, It: 0, Loss Data: 5.398e-02, Loss Eqns: 9.718e-01, Loss Aux: 5.153e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17643, It: 0, Loss Data: 6.653e-02, Loss Eqns: 9.754e-01, Loss Aux: 5.761e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17644, It: 0, Loss Data: 5.725e-02, Loss Eqns: 9.668e-01, Loss Aux: 5.082e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17645, It: 0, Loss Data: 5.772e-02, Loss Eqns: 9.717e-01, Loss Aux: 4.525e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17646, It: 0, Loss Data: 5.586e-02, Loss Eqns: 1.001e+00, Loss Aux: 4.687e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17647, It: 0, Loss Data: 5.697e-02, Loss Eqns: 1.006e+00, Loss Aux: 5.894e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17648, It: 0, Loss Data: 6.169e-02, Loss Eqns: 1.007e+00, Loss Aux: 5.391e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17649, It: 0, Loss Data: 5.640e-02, Loss Eqns: 9.886e-01, Loss Aux: 5.152e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17650, It: 0, Loss Data: 5.152e-02, Loss Eqns: 1.043e+00, Loss Aux: 4.881e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17651, It: 0, Loss Data: 5.235e-02, Loss Eqns: 9.796e-01, Loss Aux: 4.516e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17652, It: 0, Loss Data: 5.634e-02, Loss Eqns: 9.856e-01, Loss Aux: 4.498e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17653, It: 0, Loss Data: 5.601e-02, Loss Eqns: 9.885e-01, Loss Aux: 5.083e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17654, It: 0, Loss Data: 5.083e-02, Loss Eqns: 1.004e+00, Loss Aux: 5.580e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17655, It: 0, Loss Data: 6.306e-02, Loss Eqns: 9.552e-01, Loss Aux: 5.713e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17656, It: 0, Loss Data: 4.931e-02, Loss Eqns: 9.748e-01, Loss Aux: 5.382e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17657, It: 0, Loss Data: 5.454e-02, Loss Eqns: 9.508e-01, Loss Aux: 5.442e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17658, It: 0, Loss Data: 5.931e-02, Loss Eqns: 9.406e-01, Loss Aux: 5.050e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17659, It: 0, Loss Data: 5.985e-02, Loss Eqns: 9.766e-01, Loss Aux: 5.032e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17660, It: 0, Loss Data: 5.996e-02, Loss Eqns: 9.844e-01, Loss Aux: 5.339e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17661, It: 0, Loss Data: 6.310e-02, Loss Eqns: 9.536e-01, Loss Aux: 5.469e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17662, It: 0, Loss Data: 5.909e-02, Loss Eqns: 9.653e-01, Loss Aux: 4.872e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17663, It: 0, Loss Data: 4.916e-02, Loss Eqns: 9.416e-01, Loss Aux: 4.973e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17664, It: 0, Loss Data: 6.090e-02, Loss Eqns: 9.607e-01, Loss Aux: 5.180e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17665, It: 0, Loss Data: 5.523e-02, Loss Eqns: 9.850e-01, Loss Aux: 5.042e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17666, It: 0, Loss Data: 6.240e-02, Loss Eqns: 9.725e-01, Loss Aux: 4.733e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17667, It: 0, Loss Data: 5.719e-02, Loss Eqns: 9.787e-01, Loss Aux: 4.893e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17668, It: 0, Loss Data: 5.395e-02, Loss Eqns: 1.022e+00, Loss Aux: 4.924e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17669, It: 0, Loss Data: 5.295e-02, Loss Eqns: 9.848e-01, Loss Aux: 4.496e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17670, It: 0, Loss Data: 5.349e-02, Loss Eqns: 9.787e-01, Loss Aux: 4.631e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17671, It: 0, Loss Data: 5.201e-02, Loss Eqns: 9.599e-01, Loss Aux: 5.281e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17672, It: 0, Loss Data: 5.353e-02, Loss Eqns: 9.591e-01, Loss Aux: 5.381e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17673, It: 0, Loss Data: 5.476e-02, Loss Eqns: 9.474e-01, Loss Aux: 5.016e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17674, It: 0, Loss Data: 5.608e-02, Loss Eqns: 9.581e-01, Loss Aux: 4.423e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17675, It: 0, Loss Data: 5.296e-02, Loss Eqns: 9.796e-01, Loss Aux: 4.839e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17676, It: 0, Loss Data: 5.725e-02, Loss Eqns: 9.250e-01, Loss Aux: 5.873e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17677, It: 0, Loss Data: 5.197e-02, Loss Eqns: 9.388e-01, Loss Aux: 5.181e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17678, It: 0, Loss Data: 5.754e-02, Loss Eqns: 9.751e-01, Loss Aux: 4.481e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17679, It: 0, Loss Data: 5.557e-02, Loss Eqns: 9.915e-01, Loss Aux: 4.790e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17680, It: 0, Loss Data: 5.258e-02, Loss Eqns: 9.945e-01, Loss Aux: 5.049e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17681, It: 0, Loss Data: 5.700e-02, Loss Eqns: 9.349e-01, Loss Aux: 5.659e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17682, It: 0, Loss Data: 5.805e-02, Loss Eqns: 9.415e-01, Loss Aux: 5.317e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17683, It: 0, Loss Data: 6.267e-02, Loss Eqns: 9.634e-01, Loss Aux: 4.796e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17684, It: 0, Loss Data: 5.166e-02, Loss Eqns: 9.595e-01, Loss Aux: 5.017e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17685, It: 0, Loss Data: 5.478e-02, Loss Eqns: 9.319e-01, Loss Aux: 5.603e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17686, It: 0, Loss Data: 5.827e-02, Loss Eqns: 9.268e-01, Loss Aux: 5.503e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17687, It: 0, Loss Data: 6.006e-02, Loss Eqns: 9.769e-01, Loss Aux: 4.479e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17688, It: 0, Loss Data: 6.578e-02, Loss Eqns: 9.653e-01, Loss Aux: 4.548e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17689, It: 0, Loss Data: 5.425e-02, Loss Eqns: 9.801e-01, Loss Aux: 6.178e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17690, It: 0, Loss Data: 6.130e-02, Loss Eqns: 9.568e-01, Loss Aux: 6.743e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17691, It: 0, Loss Data: 5.877e-02, Loss Eqns: 9.985e-01, Loss Aux: 4.679e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17692, It: 0, Loss Data: 5.146e-02, Loss Eqns: 9.916e-01, Loss Aux: 4.280e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17693, It: 0, Loss Data: 6.182e-02, Loss Eqns: 9.780e-01, Loss Aux: 6.339e-02, Time: 0.248, Learning Rate: 1.0e-03\n",
      "Epoch: 17694, It: 0, Loss Data: 5.895e-02, Loss Eqns: 9.546e-01, Loss Aux: 7.097e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17695, It: 0, Loss Data: 5.795e-02, Loss Eqns: 9.627e-01, Loss Aux: 4.887e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17696, It: 0, Loss Data: 5.073e-02, Loss Eqns: 9.421e-01, Loss Aux: 4.351e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17697, It: 0, Loss Data: 5.893e-02, Loss Eqns: 9.949e-01, Loss Aux: 4.869e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17698, It: 0, Loss Data: 6.454e-02, Loss Eqns: 9.944e-01, Loss Aux: 5.282e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17699, It: 0, Loss Data: 5.626e-02, Loss Eqns: 1.002e+00, Loss Aux: 4.745e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17700, It: 0, Loss Data: 5.089e-02, Loss Eqns: 1.000e+00, Loss Aux: 4.668e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 17701, It: 0, Loss Data: 5.934e-02, Loss Eqns: 9.897e-01, Loss Aux: 4.977e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17702, It: 0, Loss Data: 4.684e-02, Loss Eqns: 1.009e+00, Loss Aux: 5.645e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17703, It: 0, Loss Data: 5.229e-02, Loss Eqns: 9.942e-01, Loss Aux: 6.103e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17704, It: 0, Loss Data: 6.216e-02, Loss Eqns: 9.630e-01, Loss Aux: 5.874e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17705, It: 0, Loss Data: 5.562e-02, Loss Eqns: 1.000e+00, Loss Aux: 4.860e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17706, It: 0, Loss Data: 5.397e-02, Loss Eqns: 1.013e+00, Loss Aux: 4.486e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17707, It: 0, Loss Data: 5.748e-02, Loss Eqns: 1.011e+00, Loss Aux: 4.612e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17708, It: 0, Loss Data: 6.471e-02, Loss Eqns: 1.022e+00, Loss Aux: 4.981e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17709, It: 0, Loss Data: 5.709e-02, Loss Eqns: 9.766e-01, Loss Aux: 5.015e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17710, It: 0, Loss Data: 5.313e-02, Loss Eqns: 9.859e-01, Loss Aux: 5.600e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17711, It: 0, Loss Data: 6.290e-02, Loss Eqns: 9.826e-01, Loss Aux: 6.280e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17712, It: 0, Loss Data: 5.835e-02, Loss Eqns: 9.628e-01, Loss Aux: 5.649e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17713, It: 0, Loss Data: 4.788e-02, Loss Eqns: 1.009e+00, Loss Aux: 4.576e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 17714, It: 0, Loss Data: 4.946e-02, Loss Eqns: 9.998e-01, Loss Aux: 4.152e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17715, It: 0, Loss Data: 5.750e-02, Loss Eqns: 1.028e+00, Loss Aux: 5.383e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17716, It: 0, Loss Data: 5.337e-02, Loss Eqns: 1.038e+00, Loss Aux: 6.078e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17717, It: 0, Loss Data: 5.081e-02, Loss Eqns: 1.032e+00, Loss Aux: 5.739e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17718, It: 0, Loss Data: 5.338e-02, Loss Eqns: 1.011e+00, Loss Aux: 4.705e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17719, It: 0, Loss Data: 5.808e-02, Loss Eqns: 9.645e-01, Loss Aux: 4.527e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17720, It: 0, Loss Data: 6.078e-02, Loss Eqns: 9.228e-01, Loss Aux: 4.709e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17721, It: 0, Loss Data: 6.021e-02, Loss Eqns: 9.338e-01, Loss Aux: 5.681e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17722, It: 0, Loss Data: 5.666e-02, Loss Eqns: 9.624e-01, Loss Aux: 5.346e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17723, It: 0, Loss Data: 4.686e-02, Loss Eqns: 9.956e-01, Loss Aux: 4.505e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17724, It: 0, Loss Data: 5.961e-02, Loss Eqns: 1.040e+00, Loss Aux: 5.441e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17725, It: 0, Loss Data: 5.396e-02, Loss Eqns: 9.677e-01, Loss Aux: 6.355e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17726, It: 0, Loss Data: 6.132e-02, Loss Eqns: 9.780e-01, Loss Aux: 5.419e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17727, It: 0, Loss Data: 6.251e-02, Loss Eqns: 1.006e+00, Loss Aux: 4.243e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17728, It: 0, Loss Data: 5.483e-02, Loss Eqns: 1.021e+00, Loss Aux: 4.578e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17729, It: 0, Loss Data: 5.695e-02, Loss Eqns: 1.045e+00, Loss Aux: 6.979e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17730, It: 0, Loss Data: 5.317e-02, Loss Eqns: 1.040e+00, Loss Aux: 5.945e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17731, It: 0, Loss Data: 5.887e-02, Loss Eqns: 9.768e-01, Loss Aux: 4.454e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17732, It: 0, Loss Data: 5.288e-02, Loss Eqns: 1.029e+00, Loss Aux: 4.536e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 17733, It: 0, Loss Data: 5.508e-02, Loss Eqns: 9.747e-01, Loss Aux: 5.744e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17734, It: 0, Loss Data: 5.555e-02, Loss Eqns: 9.898e-01, Loss Aux: 5.213e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17735, It: 0, Loss Data: 5.346e-02, Loss Eqns: 9.758e-01, Loss Aux: 4.626e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17736, It: 0, Loss Data: 6.087e-02, Loss Eqns: 9.852e-01, Loss Aux: 5.440e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17737, It: 0, Loss Data: 5.614e-02, Loss Eqns: 9.510e-01, Loss Aux: 5.690e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17738, It: 0, Loss Data: 5.519e-02, Loss Eqns: 1.012e+00, Loss Aux: 4.907e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 17739, It: 0, Loss Data: 5.875e-02, Loss Eqns: 9.972e-01, Loss Aux: 4.656e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17740, It: 0, Loss Data: 5.000e-02, Loss Eqns: 1.025e+00, Loss Aux: 4.319e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17741, It: 0, Loss Data: 5.656e-02, Loss Eqns: 9.432e-01, Loss Aux: 4.582e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17742, It: 0, Loss Data: 4.902e-02, Loss Eqns: 9.611e-01, Loss Aux: 5.331e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17743, It: 0, Loss Data: 5.459e-02, Loss Eqns: 9.586e-01, Loss Aux: 5.522e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17744, It: 0, Loss Data: 5.233e-02, Loss Eqns: 9.940e-01, Loss Aux: 5.037e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17745, It: 0, Loss Data: 5.964e-02, Loss Eqns: 9.850e-01, Loss Aux: 4.565e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17746, It: 0, Loss Data: 5.315e-02, Loss Eqns: 9.456e-01, Loss Aux: 5.725e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17747, It: 0, Loss Data: 6.263e-02, Loss Eqns: 9.604e-01, Loss Aux: 6.006e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17748, It: 0, Loss Data: 5.677e-02, Loss Eqns: 9.945e-01, Loss Aux: 4.969e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17749, It: 0, Loss Data: 5.236e-02, Loss Eqns: 9.682e-01, Loss Aux: 5.026e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17750, It: 0, Loss Data: 5.343e-02, Loss Eqns: 9.434e-01, Loss Aux: 5.640e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17751, It: 0, Loss Data: 5.535e-02, Loss Eqns: 9.481e-01, Loss Aux: 5.842e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17752, It: 0, Loss Data: 5.280e-02, Loss Eqns: 9.469e-01, Loss Aux: 5.112e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17753, It: 0, Loss Data: 5.339e-02, Loss Eqns: 9.479e-01, Loss Aux: 4.655e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17754, It: 0, Loss Data: 5.488e-02, Loss Eqns: 9.438e-01, Loss Aux: 5.277e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17755, It: 0, Loss Data: 4.790e-02, Loss Eqns: 9.221e-01, Loss Aux: 5.657e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17756, It: 0, Loss Data: 5.938e-02, Loss Eqns: 9.595e-01, Loss Aux: 4.772e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17757, It: 0, Loss Data: 5.268e-02, Loss Eqns: 9.295e-01, Loss Aux: 4.071e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17758, It: 0, Loss Data: 5.270e-02, Loss Eqns: 9.382e-01, Loss Aux: 4.966e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17759, It: 0, Loss Data: 5.082e-02, Loss Eqns: 9.083e-01, Loss Aux: 6.165e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17760, It: 0, Loss Data: 5.754e-02, Loss Eqns: 9.021e-01, Loss Aux: 5.941e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17761, It: 0, Loss Data: 5.824e-02, Loss Eqns: 9.491e-01, Loss Aux: 5.166e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17762, It: 0, Loss Data: 5.463e-02, Loss Eqns: 9.432e-01, Loss Aux: 4.843e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 17763, It: 0, Loss Data: 5.104e-02, Loss Eqns: 9.286e-01, Loss Aux: 5.129e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17764, It: 0, Loss Data: 5.474e-02, Loss Eqns: 9.169e-01, Loss Aux: 4.870e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17765, It: 0, Loss Data: 4.710e-02, Loss Eqns: 9.063e-01, Loss Aux: 4.799e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17766, It: 0, Loss Data: 4.840e-02, Loss Eqns: 9.110e-01, Loss Aux: 5.279e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17767, It: 0, Loss Data: 5.318e-02, Loss Eqns: 9.257e-01, Loss Aux: 5.526e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17768, It: 0, Loss Data: 5.999e-02, Loss Eqns: 9.098e-01, Loss Aux: 4.982e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17769, It: 0, Loss Data: 5.346e-02, Loss Eqns: 9.136e-01, Loss Aux: 4.614e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17770, It: 0, Loss Data: 5.051e-02, Loss Eqns: 9.167e-01, Loss Aux: 5.045e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17771, It: 0, Loss Data: 5.535e-02, Loss Eqns: 8.973e-01, Loss Aux: 5.808e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17772, It: 0, Loss Data: 5.352e-02, Loss Eqns: 9.270e-01, Loss Aux: 5.308e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17773, It: 0, Loss Data: 5.475e-02, Loss Eqns: 9.527e-01, Loss Aux: 4.450e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17774, It: 0, Loss Data: 5.988e-02, Loss Eqns: 9.368e-01, Loss Aux: 4.605e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17775, It: 0, Loss Data: 5.339e-02, Loss Eqns: 9.138e-01, Loss Aux: 5.599e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17776, It: 0, Loss Data: 5.864e-02, Loss Eqns: 9.303e-01, Loss Aux: 5.322e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17777, It: 0, Loss Data: 5.758e-02, Loss Eqns: 9.292e-01, Loss Aux: 4.846e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17778, It: 0, Loss Data: 5.329e-02, Loss Eqns: 9.475e-01, Loss Aux: 4.907e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17779, It: 0, Loss Data: 5.926e-02, Loss Eqns: 9.387e-01, Loss Aux: 5.983e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17780, It: 0, Loss Data: 5.051e-02, Loss Eqns: 9.293e-01, Loss Aux: 6.018e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 17781, It: 0, Loss Data: 4.979e-02, Loss Eqns: 9.421e-01, Loss Aux: 4.779e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17782, It: 0, Loss Data: 5.336e-02, Loss Eqns: 9.667e-01, Loss Aux: 4.207e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17783, It: 0, Loss Data: 5.270e-02, Loss Eqns: 9.496e-01, Loss Aux: 4.423e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17784, It: 0, Loss Data: 4.612e-02, Loss Eqns: 9.369e-01, Loss Aux: 5.115e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17785, It: 0, Loss Data: 5.290e-02, Loss Eqns: 9.438e-01, Loss Aux: 5.024e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17786, It: 0, Loss Data: 5.423e-02, Loss Eqns: 9.224e-01, Loss Aux: 4.517e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17787, It: 0, Loss Data: 5.596e-02, Loss Eqns: 9.121e-01, Loss Aux: 4.861e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17788, It: 0, Loss Data: 5.342e-02, Loss Eqns: 9.063e-01, Loss Aux: 6.297e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17789, It: 0, Loss Data: 5.518e-02, Loss Eqns: 9.338e-01, Loss Aux: 6.742e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17790, It: 0, Loss Data: 5.204e-02, Loss Eqns: 9.220e-01, Loss Aux: 5.032e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17791, It: 0, Loss Data: 5.449e-02, Loss Eqns: 9.196e-01, Loss Aux: 4.206e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17792, It: 0, Loss Data: 5.929e-02, Loss Eqns: 9.296e-01, Loss Aux: 4.334e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17793, It: 0, Loss Data: 5.167e-02, Loss Eqns: 9.389e-01, Loss Aux: 4.808e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17794, It: 0, Loss Data: 6.066e-02, Loss Eqns: 8.930e-01, Loss Aux: 5.295e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17795, It: 0, Loss Data: 5.939e-02, Loss Eqns: 9.181e-01, Loss Aux: 5.468e-02, Time: 0.215, Learning Rate: 1.0e-03\n",
      "Epoch: 17796, It: 0, Loss Data: 5.417e-02, Loss Eqns: 9.622e-01, Loss Aux: 5.761e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17797, It: 0, Loss Data: 4.623e-02, Loss Eqns: 9.469e-01, Loss Aux: 5.132e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17798, It: 0, Loss Data: 4.833e-02, Loss Eqns: 9.625e-01, Loss Aux: 4.586e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 17799, It: 0, Loss Data: 4.981e-02, Loss Eqns: 9.597e-01, Loss Aux: 4.612e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17800, It: 0, Loss Data: 4.969e-02, Loss Eqns: 9.389e-01, Loss Aux: 5.401e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17801, It: 0, Loss Data: 5.453e-02, Loss Eqns: 9.280e-01, Loss Aux: 5.956e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17802, It: 0, Loss Data: 5.275e-02, Loss Eqns: 9.006e-01, Loss Aux: 5.623e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17803, It: 0, Loss Data: 4.366e-02, Loss Eqns: 8.991e-01, Loss Aux: 4.799e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 17804, It: 0, Loss Data: 5.452e-02, Loss Eqns: 9.453e-01, Loss Aux: 4.816e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17805, It: 0, Loss Data: 5.189e-02, Loss Eqns: 9.066e-01, Loss Aux: 5.037e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17806, It: 0, Loss Data: 5.604e-02, Loss Eqns: 9.141e-01, Loss Aux: 4.837e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17807, It: 0, Loss Data: 5.587e-02, Loss Eqns: 9.333e-01, Loss Aux: 4.884e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17808, It: 0, Loss Data: 5.328e-02, Loss Eqns: 9.419e-01, Loss Aux: 5.526e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17809, It: 0, Loss Data: 5.329e-02, Loss Eqns: 9.303e-01, Loss Aux: 5.661e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17810, It: 0, Loss Data: 5.481e-02, Loss Eqns: 9.316e-01, Loss Aux: 5.006e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17811, It: 0, Loss Data: 5.395e-02, Loss Eqns: 9.134e-01, Loss Aux: 4.802e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17812, It: 0, Loss Data: 5.668e-02, Loss Eqns: 9.037e-01, Loss Aux: 5.055e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17813, It: 0, Loss Data: 5.621e-02, Loss Eqns: 8.916e-01, Loss Aux: 5.300e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17814, It: 0, Loss Data: 5.068e-02, Loss Eqns: 9.553e-01, Loss Aux: 5.531e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17815, It: 0, Loss Data: 4.873e-02, Loss Eqns: 9.205e-01, Loss Aux: 4.903e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17816, It: 0, Loss Data: 5.371e-02, Loss Eqns: 8.842e-01, Loss Aux: 4.440e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17817, It: 0, Loss Data: 5.267e-02, Loss Eqns: 8.695e-01, Loss Aux: 5.110e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17818, It: 0, Loss Data: 4.359e-02, Loss Eqns: 8.828e-01, Loss Aux: 5.940e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17819, It: 0, Loss Data: 6.806e-02, Loss Eqns: 8.934e-01, Loss Aux: 4.706e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17820, It: 0, Loss Data: 5.555e-02, Loss Eqns: 8.905e-01, Loss Aux: 4.138e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17821, It: 0, Loss Data: 5.231e-02, Loss Eqns: 8.898e-01, Loss Aux: 5.240e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17822, It: 0, Loss Data: 5.549e-02, Loss Eqns: 9.344e-01, Loss Aux: 5.777e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17823, It: 0, Loss Data: 5.171e-02, Loss Eqns: 9.079e-01, Loss Aux: 4.534e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17824, It: 0, Loss Data: 5.357e-02, Loss Eqns: 9.485e-01, Loss Aux: 4.370e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17825, It: 0, Loss Data: 4.643e-02, Loss Eqns: 9.067e-01, Loss Aux: 4.846e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17826, It: 0, Loss Data: 4.841e-02, Loss Eqns: 9.180e-01, Loss Aux: 5.717e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17827, It: 0, Loss Data: 5.614e-02, Loss Eqns: 9.188e-01, Loss Aux: 5.779e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17828, It: 0, Loss Data: 5.262e-02, Loss Eqns: 9.311e-01, Loss Aux: 4.592e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17829, It: 0, Loss Data: 5.476e-02, Loss Eqns: 8.878e-01, Loss Aux: 4.322e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17830, It: 0, Loss Data: 5.285e-02, Loss Eqns: 9.352e-01, Loss Aux: 5.106e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17831, It: 0, Loss Data: 5.143e-02, Loss Eqns: 9.429e-01, Loss Aux: 5.111e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17832, It: 0, Loss Data: 5.312e-02, Loss Eqns: 9.488e-01, Loss Aux: 4.475e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17833, It: 0, Loss Data: 4.528e-02, Loss Eqns: 9.472e-01, Loss Aux: 5.013e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17834, It: 0, Loss Data: 5.575e-02, Loss Eqns: 9.073e-01, Loss Aux: 5.994e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17835, It: 0, Loss Data: 5.486e-02, Loss Eqns: 8.967e-01, Loss Aux: 5.372e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17836, It: 0, Loss Data: 5.902e-02, Loss Eqns: 9.255e-01, Loss Aux: 4.603e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17837, It: 0, Loss Data: 5.034e-02, Loss Eqns: 8.993e-01, Loss Aux: 4.957e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17838, It: 0, Loss Data: 5.220e-02, Loss Eqns: 9.218e-01, Loss Aux: 5.155e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17839, It: 0, Loss Data: 5.943e-02, Loss Eqns: 8.818e-01, Loss Aux: 5.081e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17840, It: 0, Loss Data: 5.625e-02, Loss Eqns: 9.149e-01, Loss Aux: 4.940e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17841, It: 0, Loss Data: 4.888e-02, Loss Eqns: 9.131e-01, Loss Aux: 5.050e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 17842, It: 0, Loss Data: 4.744e-02, Loss Eqns: 8.944e-01, Loss Aux: 5.164e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17843, It: 0, Loss Data: 5.239e-02, Loss Eqns: 9.044e-01, Loss Aux: 5.557e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 17844, It: 0, Loss Data: 4.940e-02, Loss Eqns: 9.239e-01, Loss Aux: 5.269e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17845, It: 0, Loss Data: 5.393e-02, Loss Eqns: 9.677e-01, Loss Aux: 4.267e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 17846, It: 0, Loss Data: 4.621e-02, Loss Eqns: 9.656e-01, Loss Aux: 4.382e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17847, It: 0, Loss Data: 4.955e-02, Loss Eqns: 9.188e-01, Loss Aux: 5.543e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17848, It: 0, Loss Data: 5.561e-02, Loss Eqns: 9.145e-01, Loss Aux: 5.295e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17849, It: 0, Loss Data: 5.130e-02, Loss Eqns: 9.011e-01, Loss Aux: 5.131e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 17850, It: 0, Loss Data: 5.477e-02, Loss Eqns: 9.033e-01, Loss Aux: 5.154e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17851, It: 0, Loss Data: 4.809e-02, Loss Eqns: 9.320e-01, Loss Aux: 5.745e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17852, It: 0, Loss Data: 5.129e-02, Loss Eqns: 9.214e-01, Loss Aux: 5.111e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17853, It: 0, Loss Data: 5.135e-02, Loss Eqns: 9.454e-01, Loss Aux: 4.199e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17854, It: 0, Loss Data: 4.362e-02, Loss Eqns: 9.024e-01, Loss Aux: 4.966e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17855, It: 0, Loss Data: 5.460e-02, Loss Eqns: 9.127e-01, Loss Aux: 6.315e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17856, It: 0, Loss Data: 5.407e-02, Loss Eqns: 9.938e-01, Loss Aux: 5.959e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17857, It: 0, Loss Data: 4.747e-02, Loss Eqns: 9.728e-01, Loss Aux: 4.563e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17858, It: 0, Loss Data: 4.885e-02, Loss Eqns: 9.502e-01, Loss Aux: 4.615e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17859, It: 0, Loss Data: 5.359e-02, Loss Eqns: 9.671e-01, Loss Aux: 5.666e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17860, It: 0, Loss Data: 5.167e-02, Loss Eqns: 9.223e-01, Loss Aux: 5.480e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17861, It: 0, Loss Data: 5.838e-02, Loss Eqns: 9.085e-01, Loss Aux: 4.658e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17862, It: 0, Loss Data: 5.408e-02, Loss Eqns: 9.204e-01, Loss Aux: 4.806e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 17863, It: 0, Loss Data: 5.004e-02, Loss Eqns: 9.345e-01, Loss Aux: 5.234e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17864, It: 0, Loss Data: 4.762e-02, Loss Eqns: 9.230e-01, Loss Aux: 5.338e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17865, It: 0, Loss Data: 5.871e-02, Loss Eqns: 9.361e-01, Loss Aux: 4.960e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17866, It: 0, Loss Data: 4.942e-02, Loss Eqns: 9.145e-01, Loss Aux: 4.651e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17867, It: 0, Loss Data: 4.519e-02, Loss Eqns: 8.991e-01, Loss Aux: 4.636e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17868, It: 0, Loss Data: 5.599e-02, Loss Eqns: 8.908e-01, Loss Aux: 5.350e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17869, It: 0, Loss Data: 5.107e-02, Loss Eqns: 9.319e-01, Loss Aux: 5.713e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 17870, It: 0, Loss Data: 5.202e-02, Loss Eqns: 9.364e-01, Loss Aux: 4.995e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17871, It: 0, Loss Data: 5.508e-02, Loss Eqns: 9.472e-01, Loss Aux: 4.928e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17872, It: 0, Loss Data: 4.629e-02, Loss Eqns: 9.357e-01, Loss Aux: 5.090e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17873, It: 0, Loss Data: 4.367e-02, Loss Eqns: 9.176e-01, Loss Aux: 5.199e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17874, It: 0, Loss Data: 4.966e-02, Loss Eqns: 8.974e-01, Loss Aux: 5.289e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17875, It: 0, Loss Data: 5.043e-02, Loss Eqns: 8.987e-01, Loss Aux: 5.225e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17876, It: 0, Loss Data: 5.943e-02, Loss Eqns: 8.815e-01, Loss Aux: 4.942e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 17877, It: 0, Loss Data: 4.509e-02, Loss Eqns: 9.035e-01, Loss Aux: 4.714e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17878, It: 0, Loss Data: 5.837e-02, Loss Eqns: 8.957e-01, Loss Aux: 5.115e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17879, It: 0, Loss Data: 5.712e-02, Loss Eqns: 8.755e-01, Loss Aux: 5.486e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17880, It: 0, Loss Data: 4.658e-02, Loss Eqns: 9.095e-01, Loss Aux: 5.571e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17881, It: 0, Loss Data: 5.461e-02, Loss Eqns: 8.641e-01, Loss Aux: 5.471e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17882, It: 0, Loss Data: 4.614e-02, Loss Eqns: 9.049e-01, Loss Aux: 5.362e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17883, It: 0, Loss Data: 5.336e-02, Loss Eqns: 9.022e-01, Loss Aux: 4.726e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17884, It: 0, Loss Data: 4.187e-02, Loss Eqns: 9.196e-01, Loss Aux: 4.386e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17885, It: 0, Loss Data: 4.883e-02, Loss Eqns: 9.087e-01, Loss Aux: 4.356e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17886, It: 0, Loss Data: 4.831e-02, Loss Eqns: 9.245e-01, Loss Aux: 5.430e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17887, It: 0, Loss Data: 5.468e-02, Loss Eqns: 8.961e-01, Loss Aux: 6.234e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17888, It: 0, Loss Data: 5.475e-02, Loss Eqns: 8.834e-01, Loss Aux: 5.804e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 17889, It: 0, Loss Data: 5.893e-02, Loss Eqns: 9.247e-01, Loss Aux: 5.437e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 17890, It: 0, Loss Data: 4.992e-02, Loss Eqns: 9.049e-01, Loss Aux: 4.741e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17891, It: 0, Loss Data: 5.498e-02, Loss Eqns: 9.258e-01, Loss Aux: 4.397e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 17892, It: 0, Loss Data: 4.781e-02, Loss Eqns: 9.354e-01, Loss Aux: 4.771e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 17893, It: 0, Loss Data: 5.027e-02, Loss Eqns: 9.165e-01, Loss Aux: 4.983e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17894, It: 0, Loss Data: 5.572e-02, Loss Eqns: 9.106e-01, Loss Aux: 5.043e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17895, It: 0, Loss Data: 5.083e-02, Loss Eqns: 9.351e-01, Loss Aux: 4.665e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17896, It: 0, Loss Data: 4.154e-02, Loss Eqns: 8.841e-01, Loss Aux: 5.007e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17897, It: 0, Loss Data: 5.001e-02, Loss Eqns: 9.090e-01, Loss Aux: 5.019e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17898, It: 0, Loss Data: 5.435e-02, Loss Eqns: 9.046e-01, Loss Aux: 5.199e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17899, It: 0, Loss Data: 4.907e-02, Loss Eqns: 8.962e-01, Loss Aux: 5.449e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17900, It: 0, Loss Data: 5.414e-02, Loss Eqns: 9.039e-01, Loss Aux: 5.517e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17901, It: 0, Loss Data: 5.331e-02, Loss Eqns: 9.027e-01, Loss Aux: 4.936e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17902, It: 0, Loss Data: 5.163e-02, Loss Eqns: 8.970e-01, Loss Aux: 4.246e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17903, It: 0, Loss Data: 4.231e-02, Loss Eqns: 8.777e-01, Loss Aux: 4.545e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 17904, It: 0, Loss Data: 5.296e-02, Loss Eqns: 8.948e-01, Loss Aux: 6.194e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17905, It: 0, Loss Data: 4.332e-02, Loss Eqns: 8.782e-01, Loss Aux: 6.122e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17906, It: 0, Loss Data: 4.644e-02, Loss Eqns: 8.832e-01, Loss Aux: 5.119e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17907, It: 0, Loss Data: 5.267e-02, Loss Eqns: 8.654e-01, Loss Aux: 4.591e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17908, It: 0, Loss Data: 4.884e-02, Loss Eqns: 8.763e-01, Loss Aux: 5.231e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17909, It: 0, Loss Data: 5.489e-02, Loss Eqns: 9.008e-01, Loss Aux: 5.105e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 17910, It: 0, Loss Data: 4.933e-02, Loss Eqns: 8.962e-01, Loss Aux: 4.671e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 17911, It: 0, Loss Data: 4.622e-02, Loss Eqns: 9.133e-01, Loss Aux: 4.728e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17912, It: 0, Loss Data: 4.653e-02, Loss Eqns: 8.971e-01, Loss Aux: 5.167e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17913, It: 0, Loss Data: 4.972e-02, Loss Eqns: 8.943e-01, Loss Aux: 5.446e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17914, It: 0, Loss Data: 5.259e-02, Loss Eqns: 8.826e-01, Loss Aux: 5.275e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17915, It: 0, Loss Data: 5.417e-02, Loss Eqns: 9.137e-01, Loss Aux: 5.016e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17916, It: 0, Loss Data: 5.258e-02, Loss Eqns: 9.072e-01, Loss Aux: 4.349e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17917, It: 0, Loss Data: 4.799e-02, Loss Eqns: 9.023e-01, Loss Aux: 4.331e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17918, It: 0, Loss Data: 5.219e-02, Loss Eqns: 8.862e-01, Loss Aux: 5.587e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17919, It: 0, Loss Data: 5.159e-02, Loss Eqns: 9.358e-01, Loss Aux: 5.686e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17920, It: 0, Loss Data: 4.873e-02, Loss Eqns: 9.302e-01, Loss Aux: 4.529e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17921, It: 0, Loss Data: 4.890e-02, Loss Eqns: 9.003e-01, Loss Aux: 4.102e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 17922, It: 0, Loss Data: 5.069e-02, Loss Eqns: 9.040e-01, Loss Aux: 4.836e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17923, It: 0, Loss Data: 4.730e-02, Loss Eqns: 8.563e-01, Loss Aux: 5.465e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17924, It: 0, Loss Data: 5.173e-02, Loss Eqns: 8.007e-01, Loss Aux: 5.219e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 17925, It: 0, Loss Data: 5.101e-02, Loss Eqns: 8.549e-01, Loss Aux: 4.822e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17926, It: 0, Loss Data: 5.145e-02, Loss Eqns: 8.562e-01, Loss Aux: 4.685e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17927, It: 0, Loss Data: 5.193e-02, Loss Eqns: 8.701e-01, Loss Aux: 5.235e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 17928, It: 0, Loss Data: 4.532e-02, Loss Eqns: 8.680e-01, Loss Aux: 5.249e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17929, It: 0, Loss Data: 5.509e-02, Loss Eqns: 8.563e-01, Loss Aux: 5.155e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17930, It: 0, Loss Data: 4.606e-02, Loss Eqns: 8.387e-01, Loss Aux: 5.361e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 17931, It: 0, Loss Data: 5.685e-02, Loss Eqns: 8.952e-01, Loss Aux: 5.273e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17932, It: 0, Loss Data: 4.844e-02, Loss Eqns: 8.547e-01, Loss Aux: 5.618e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 17933, It: 0, Loss Data: 5.166e-02, Loss Eqns: 8.968e-01, Loss Aux: 5.787e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17934, It: 0, Loss Data: 5.228e-02, Loss Eqns: 8.750e-01, Loss Aux: 5.160e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17935, It: 0, Loss Data: 5.239e-02, Loss Eqns: 8.879e-01, Loss Aux: 5.128e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17936, It: 0, Loss Data: 5.206e-02, Loss Eqns: 9.001e-01, Loss Aux: 4.838e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17937, It: 0, Loss Data: 5.449e-02, Loss Eqns: 8.936e-01, Loss Aux: 4.424e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 17938, It: 0, Loss Data: 4.237e-02, Loss Eqns: 9.164e-01, Loss Aux: 5.597e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 17939, It: 0, Loss Data: 5.274e-02, Loss Eqns: 9.047e-01, Loss Aux: 5.937e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17940, It: 0, Loss Data: 4.427e-02, Loss Eqns: 8.882e-01, Loss Aux: 4.911e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 17941, It: 0, Loss Data: 4.976e-02, Loss Eqns: 8.796e-01, Loss Aux: 4.381e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17942, It: 0, Loss Data: 5.058e-02, Loss Eqns: 8.714e-01, Loss Aux: 4.936e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 17943, It: 0, Loss Data: 5.062e-02, Loss Eqns: 8.850e-01, Loss Aux: 5.204e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17944, It: 0, Loss Data: 5.117e-02, Loss Eqns: 9.107e-01, Loss Aux: 4.881e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17945, It: 0, Loss Data: 4.680e-02, Loss Eqns: 8.740e-01, Loss Aux: 4.968e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 17946, It: 0, Loss Data: 5.234e-02, Loss Eqns: 9.075e-01, Loss Aux: 5.868e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17947, It: 0, Loss Data: 4.784e-02, Loss Eqns: 8.983e-01, Loss Aux: 5.736e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 17948, It: 0, Loss Data: 4.132e-02, Loss Eqns: 8.904e-01, Loss Aux: 4.474e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 17949, It: 0, Loss Data: 5.522e-02, Loss Eqns: 8.586e-01, Loss Aux: 4.472e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17950, It: 0, Loss Data: 4.656e-02, Loss Eqns: 8.689e-01, Loss Aux: 5.449e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17951, It: 0, Loss Data: 5.031e-02, Loss Eqns: 8.880e-01, Loss Aux: 5.973e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17952, It: 0, Loss Data: 5.290e-02, Loss Eqns: 9.455e-01, Loss Aux: 5.353e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17953, It: 0, Loss Data: 5.440e-02, Loss Eqns: 9.463e-01, Loss Aux: 5.108e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17954, It: 0, Loss Data: 5.564e-02, Loss Eqns: 9.768e-01, Loss Aux: 5.185e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 17955, It: 0, Loss Data: 4.373e-02, Loss Eqns: 9.394e-01, Loss Aux: 4.470e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17956, It: 0, Loss Data: 4.778e-02, Loss Eqns: 9.497e-01, Loss Aux: 4.346e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17957, It: 0, Loss Data: 5.449e-02, Loss Eqns: 9.238e-01, Loss Aux: 5.357e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 17958, It: 0, Loss Data: 4.863e-02, Loss Eqns: 8.714e-01, Loss Aux: 5.769e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17959, It: 0, Loss Data: 5.182e-02, Loss Eqns: 8.718e-01, Loss Aux: 5.490e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 17960, It: 0, Loss Data: 4.729e-02, Loss Eqns: 9.032e-01, Loss Aux: 4.588e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17961, It: 0, Loss Data: 4.872e-02, Loss Eqns: 9.348e-01, Loss Aux: 4.461e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 17962, It: 0, Loss Data: 5.808e-02, Loss Eqns: 9.389e-01, Loss Aux: 5.647e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 17963, It: 0, Loss Data: 5.320e-02, Loss Eqns: 9.420e-01, Loss Aux: 6.246e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17964, It: 0, Loss Data: 5.104e-02, Loss Eqns: 8.602e-01, Loss Aux: 4.763e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17965, It: 0, Loss Data: 4.764e-02, Loss Eqns: 8.989e-01, Loss Aux: 4.792e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 17966, It: 0, Loss Data: 4.469e-02, Loss Eqns: 8.749e-01, Loss Aux: 5.096e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17967, It: 0, Loss Data: 5.297e-02, Loss Eqns: 9.381e-01, Loss Aux: 4.947e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 17968, It: 0, Loss Data: 4.785e-02, Loss Eqns: 9.052e-01, Loss Aux: 4.802e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17969, It: 0, Loss Data: 4.577e-02, Loss Eqns: 9.293e-01, Loss Aux: 5.165e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17970, It: 0, Loss Data: 4.541e-02, Loss Eqns: 8.808e-01, Loss Aux: 5.386e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17971, It: 0, Loss Data: 4.319e-02, Loss Eqns: 9.182e-01, Loss Aux: 4.656e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 17972, It: 0, Loss Data: 4.480e-02, Loss Eqns: 8.905e-01, Loss Aux: 4.657e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17973, It: 0, Loss Data: 4.865e-02, Loss Eqns: 9.106e-01, Loss Aux: 4.742e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 17974, It: 0, Loss Data: 5.231e-02, Loss Eqns: 9.028e-01, Loss Aux: 4.536e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 17975, It: 0, Loss Data: 4.851e-02, Loss Eqns: 8.598e-01, Loss Aux: 5.334e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17976, It: 0, Loss Data: 4.473e-02, Loss Eqns: 8.287e-01, Loss Aux: 5.592e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 17977, It: 0, Loss Data: 5.129e-02, Loss Eqns: 8.278e-01, Loss Aux: 5.437e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17978, It: 0, Loss Data: 5.712e-02, Loss Eqns: 8.271e-01, Loss Aux: 5.713e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 17979, It: 0, Loss Data: 4.796e-02, Loss Eqns: 8.944e-01, Loss Aux: 5.228e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 17980, It: 0, Loss Data: 4.972e-02, Loss Eqns: 9.103e-01, Loss Aux: 4.729e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17981, It: 0, Loss Data: 5.022e-02, Loss Eqns: 9.178e-01, Loss Aux: 4.701e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17982, It: 0, Loss Data: 4.735e-02, Loss Eqns: 9.092e-01, Loss Aux: 5.143e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 17983, It: 0, Loss Data: 4.972e-02, Loss Eqns: 8.517e-01, Loss Aux: 5.263e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 17984, It: 0, Loss Data: 5.610e-02, Loss Eqns: 8.459e-01, Loss Aux: 6.174e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 17985, It: 0, Loss Data: 5.385e-02, Loss Eqns: 8.602e-01, Loss Aux: 5.556e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17986, It: 0, Loss Data: 5.095e-02, Loss Eqns: 9.111e-01, Loss Aux: 4.745e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17987, It: 0, Loss Data: 5.695e-02, Loss Eqns: 8.850e-01, Loss Aux: 4.483e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17988, It: 0, Loss Data: 4.970e-02, Loss Eqns: 8.700e-01, Loss Aux: 4.912e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17989, It: 0, Loss Data: 5.206e-02, Loss Eqns: 8.952e-01, Loss Aux: 5.201e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 17990, It: 0, Loss Data: 5.408e-02, Loss Eqns: 8.822e-01, Loss Aux: 4.913e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 17991, It: 0, Loss Data: 4.313e-02, Loss Eqns: 8.562e-01, Loss Aux: 4.876e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 17992, It: 0, Loss Data: 4.579e-02, Loss Eqns: 8.950e-01, Loss Aux: 5.573e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 17993, It: 0, Loss Data: 5.135e-02, Loss Eqns: 9.139e-01, Loss Aux: 4.916e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 17994, It: 0, Loss Data: 4.969e-02, Loss Eqns: 8.970e-01, Loss Aux: 4.747e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 17995, It: 0, Loss Data: 4.984e-02, Loss Eqns: 9.041e-01, Loss Aux: 5.439e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 17996, It: 0, Loss Data: 4.852e-02, Loss Eqns: 8.601e-01, Loss Aux: 4.890e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 17997, It: 0, Loss Data: 4.737e-02, Loss Eqns: 8.853e-01, Loss Aux: 4.600e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 17998, It: 0, Loss Data: 4.780e-02, Loss Eqns: 8.933e-01, Loss Aux: 4.938e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 17999, It: 0, Loss Data: 4.548e-02, Loss Eqns: 8.556e-01, Loss Aux: 5.140e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18000, It: 0, Loss Data: 4.657e-02, Loss Eqns: 8.856e-01, Loss Aux: 5.230e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18001, It: 0, Loss Data: 5.350e-02, Loss Eqns: 8.579e-01, Loss Aux: 5.185e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18002, It: 0, Loss Data: 4.647e-02, Loss Eqns: 9.072e-01, Loss Aux: 4.587e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18003, It: 0, Loss Data: 4.529e-02, Loss Eqns: 8.478e-01, Loss Aux: 4.514e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18004, It: 0, Loss Data: 5.615e-02, Loss Eqns: 8.570e-01, Loss Aux: 5.507e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18005, It: 0, Loss Data: 5.143e-02, Loss Eqns: 8.641e-01, Loss Aux: 5.073e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18006, It: 0, Loss Data: 4.923e-02, Loss Eqns: 8.599e-01, Loss Aux: 4.642e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18007, It: 0, Loss Data: 5.678e-02, Loss Eqns: 8.620e-01, Loss Aux: 4.845e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18008, It: 0, Loss Data: 4.992e-02, Loss Eqns: 8.554e-01, Loss Aux: 6.206e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18009, It: 0, Loss Data: 4.588e-02, Loss Eqns: 9.097e-01, Loss Aux: 5.748e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18010, It: 0, Loss Data: 5.248e-02, Loss Eqns: 8.693e-01, Loss Aux: 4.460e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18011, It: 0, Loss Data: 4.408e-02, Loss Eqns: 8.508e-01, Loss Aux: 4.905e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18012, It: 0, Loss Data: 4.853e-02, Loss Eqns: 8.465e-01, Loss Aux: 5.803e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18013, It: 0, Loss Data: 4.585e-02, Loss Eqns: 8.807e-01, Loss Aux: 6.137e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18014, It: 0, Loss Data: 4.294e-02, Loss Eqns: 8.985e-01, Loss Aux: 5.153e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18015, It: 0, Loss Data: 4.674e-02, Loss Eqns: 8.628e-01, Loss Aux: 4.594e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18016, It: 0, Loss Data: 3.910e-02, Loss Eqns: 8.694e-01, Loss Aux: 4.984e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18017, It: 0, Loss Data: 4.886e-02, Loss Eqns: 8.400e-01, Loss Aux: 5.539e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18018, It: 0, Loss Data: 4.512e-02, Loss Eqns: 8.310e-01, Loss Aux: 5.026e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 18019, It: 0, Loss Data: 5.069e-02, Loss Eqns: 8.615e-01, Loss Aux: 4.900e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18020, It: 0, Loss Data: 4.414e-02, Loss Eqns: 8.435e-01, Loss Aux: 4.685e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18021, It: 0, Loss Data: 5.343e-02, Loss Eqns: 8.670e-01, Loss Aux: 4.692e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18022, It: 0, Loss Data: 4.683e-02, Loss Eqns: 8.571e-01, Loss Aux: 4.611e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18023, It: 0, Loss Data: 5.030e-02, Loss Eqns: 8.291e-01, Loss Aux: 5.294e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18024, It: 0, Loss Data: 4.679e-02, Loss Eqns: 8.222e-01, Loss Aux: 6.693e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18025, It: 0, Loss Data: 4.926e-02, Loss Eqns: 8.382e-01, Loss Aux: 7.101e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18026, It: 0, Loss Data: 4.437e-02, Loss Eqns: 8.711e-01, Loss Aux: 4.573e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18027, It: 0, Loss Data: 5.350e-02, Loss Eqns: 8.225e-01, Loss Aux: 4.355e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18028, It: 0, Loss Data: 5.001e-02, Loss Eqns: 8.311e-01, Loss Aux: 5.579e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18029, It: 0, Loss Data: 5.052e-02, Loss Eqns: 8.137e-01, Loss Aux: 5.648e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18030, It: 0, Loss Data: 4.585e-02, Loss Eqns: 8.392e-01, Loss Aux: 4.889e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18031, It: 0, Loss Data: 5.297e-02, Loss Eqns: 8.838e-01, Loss Aux: 4.835e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18032, It: 0, Loss Data: 4.795e-02, Loss Eqns: 8.489e-01, Loss Aux: 4.836e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18033, It: 0, Loss Data: 4.548e-02, Loss Eqns: 8.459e-01, Loss Aux: 4.660e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18034, It: 0, Loss Data: 5.420e-02, Loss Eqns: 8.331e-01, Loss Aux: 5.180e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 18035, It: 0, Loss Data: 5.129e-02, Loss Eqns: 8.517e-01, Loss Aux: 5.501e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18036, It: 0, Loss Data: 5.440e-02, Loss Eqns: 8.344e-01, Loss Aux: 5.318e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18037, It: 0, Loss Data: 4.440e-02, Loss Eqns: 8.579e-01, Loss Aux: 5.493e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18038, It: 0, Loss Data: 5.010e-02, Loss Eqns: 8.875e-01, Loss Aux: 4.983e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18039, It: 0, Loss Data: 4.538e-02, Loss Eqns: 8.758e-01, Loss Aux: 4.283e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18040, It: 0, Loss Data: 3.853e-02, Loss Eqns: 8.942e-01, Loss Aux: 4.545e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18041, It: 0, Loss Data: 5.055e-02, Loss Eqns: 8.428e-01, Loss Aux: 6.539e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18042, It: 0, Loss Data: 4.849e-02, Loss Eqns: 8.400e-01, Loss Aux: 7.053e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18043, It: 0, Loss Data: 5.465e-02, Loss Eqns: 8.394e-01, Loss Aux: 5.073e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18044, It: 0, Loss Data: 5.361e-02, Loss Eqns: 8.793e-01, Loss Aux: 4.772e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18045, It: 0, Loss Data: 5.021e-02, Loss Eqns: 8.695e-01, Loss Aux: 4.746e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18046, It: 0, Loss Data: 4.468e-02, Loss Eqns: 8.880e-01, Loss Aux: 4.480e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 18047, It: 0, Loss Data: 5.183e-02, Loss Eqns: 8.456e-01, Loss Aux: 4.553e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18048, It: 0, Loss Data: 5.189e-02, Loss Eqns: 8.680e-01, Loss Aux: 5.617e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18049, It: 0, Loss Data: 4.915e-02, Loss Eqns: 8.344e-01, Loss Aux: 6.254e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18050, It: 0, Loss Data: 5.293e-02, Loss Eqns: 8.587e-01, Loss Aux: 5.032e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18051, It: 0, Loss Data: 5.137e-02, Loss Eqns: 8.637e-01, Loss Aux: 4.493e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18052, It: 0, Loss Data: 4.896e-02, Loss Eqns: 8.666e-01, Loss Aux: 5.139e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18053, It: 0, Loss Data: 4.319e-02, Loss Eqns: 8.491e-01, Loss Aux: 5.462e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18054, It: 0, Loss Data: 4.914e-02, Loss Eqns: 8.868e-01, Loss Aux: 4.592e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18055, It: 0, Loss Data: 4.212e-02, Loss Eqns: 8.653e-01, Loss Aux: 4.803e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18056, It: 0, Loss Data: 4.874e-02, Loss Eqns: 8.577e-01, Loss Aux: 6.001e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18057, It: 0, Loss Data: 4.881e-02, Loss Eqns: 8.408e-01, Loss Aux: 5.047e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18058, It: 0, Loss Data: 5.244e-02, Loss Eqns: 8.642e-01, Loss Aux: 4.235e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18059, It: 0, Loss Data: 4.645e-02, Loss Eqns: 8.382e-01, Loss Aux: 5.094e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18060, It: 0, Loss Data: 4.382e-02, Loss Eqns: 8.512e-01, Loss Aux: 5.416e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18061, It: 0, Loss Data: 4.590e-02, Loss Eqns: 8.607e-01, Loss Aux: 4.818e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18062, It: 0, Loss Data: 5.276e-02, Loss Eqns: 8.367e-01, Loss Aux: 4.993e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18063, It: 0, Loss Data: 5.562e-02, Loss Eqns: 8.824e-01, Loss Aux: 4.930e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18064, It: 0, Loss Data: 3.924e-02, Loss Eqns: 8.616e-01, Loss Aux: 4.394e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18065, It: 0, Loss Data: 4.851e-02, Loss Eqns: 8.723e-01, Loss Aux: 4.668e-02, Time: 0.214, Learning Rate: 1.0e-03\n",
      "Epoch: 18066, It: 0, Loss Data: 4.365e-02, Loss Eqns: 8.516e-01, Loss Aux: 5.418e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18067, It: 0, Loss Data: 4.732e-02, Loss Eqns: 8.514e-01, Loss Aux: 5.872e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18068, It: 0, Loss Data: 4.346e-02, Loss Eqns: 8.393e-01, Loss Aux: 5.788e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18069, It: 0, Loss Data: 4.931e-02, Loss Eqns: 8.384e-01, Loss Aux: 5.396e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18070, It: 0, Loss Data: 4.765e-02, Loss Eqns: 8.182e-01, Loss Aux: 4.990e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18071, It: 0, Loss Data: 5.088e-02, Loss Eqns: 8.165e-01, Loss Aux: 5.619e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18072, It: 0, Loss Data: 5.349e-02, Loss Eqns: 8.318e-01, Loss Aux: 5.193e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18073, It: 0, Loss Data: 4.744e-02, Loss Eqns: 8.369e-01, Loss Aux: 4.838e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18074, It: 0, Loss Data: 4.489e-02, Loss Eqns: 8.755e-01, Loss Aux: 4.915e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18075, It: 0, Loss Data: 4.707e-02, Loss Eqns: 8.801e-01, Loss Aux: 4.893e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18076, It: 0, Loss Data: 4.584e-02, Loss Eqns: 8.724e-01, Loss Aux: 4.639e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 18077, It: 0, Loss Data: 5.063e-02, Loss Eqns: 8.459e-01, Loss Aux: 4.781e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18078, It: 0, Loss Data: 4.707e-02, Loss Eqns: 8.746e-01, Loss Aux: 5.607e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18079, It: 0, Loss Data: 3.621e-02, Loss Eqns: 8.549e-01, Loss Aux: 5.573e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 18080, It: 0, Loss Data: 4.709e-02, Loss Eqns: 8.326e-01, Loss Aux: 4.917e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18081, It: 0, Loss Data: 4.248e-02, Loss Eqns: 8.497e-01, Loss Aux: 5.384e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18082, It: 0, Loss Data: 5.206e-02, Loss Eqns: 8.950e-01, Loss Aux: 5.692e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18083, It: 0, Loss Data: 4.831e-02, Loss Eqns: 8.406e-01, Loss Aux: 4.520e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18084, It: 0, Loss Data: 5.475e-02, Loss Eqns: 8.401e-01, Loss Aux: 4.283e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18085, It: 0, Loss Data: 5.749e-02, Loss Eqns: 8.676e-01, Loss Aux: 5.307e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18086, It: 0, Loss Data: 5.056e-02, Loss Eqns: 8.492e-01, Loss Aux: 5.499e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18087, It: 0, Loss Data: 5.513e-02, Loss Eqns: 8.932e-01, Loss Aux: 5.072e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18088, It: 0, Loss Data: 5.285e-02, Loss Eqns: 8.632e-01, Loss Aux: 5.601e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18089, It: 0, Loss Data: 4.643e-02, Loss Eqns: 8.873e-01, Loss Aux: 5.149e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18090, It: 0, Loss Data: 4.568e-02, Loss Eqns: 8.598e-01, Loss Aux: 4.117e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18091, It: 0, Loss Data: 4.856e-02, Loss Eqns: 8.697e-01, Loss Aux: 4.272e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18092, It: 0, Loss Data: 4.418e-02, Loss Eqns: 8.676e-01, Loss Aux: 4.830e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18093, It: 0, Loss Data: 5.081e-02, Loss Eqns: 8.435e-01, Loss Aux: 5.223e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18094, It: 0, Loss Data: 5.046e-02, Loss Eqns: 8.619e-01, Loss Aux: 4.666e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18095, It: 0, Loss Data: 5.010e-02, Loss Eqns: 8.799e-01, Loss Aux: 4.958e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18096, It: 0, Loss Data: 4.750e-02, Loss Eqns: 8.739e-01, Loss Aux: 5.704e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18097, It: 0, Loss Data: 4.920e-02, Loss Eqns: 8.323e-01, Loss Aux: 5.343e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18098, It: 0, Loss Data: 4.657e-02, Loss Eqns: 8.777e-01, Loss Aux: 4.408e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18099, It: 0, Loss Data: 4.259e-02, Loss Eqns: 8.650e-01, Loss Aux: 5.079e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 18100, It: 0, Loss Data: 4.668e-02, Loss Eqns: 8.261e-01, Loss Aux: 6.137e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18101, It: 0, Loss Data: 4.744e-02, Loss Eqns: 8.200e-01, Loss Aux: 6.099e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18102, It: 0, Loss Data: 4.525e-02, Loss Eqns: 8.293e-01, Loss Aux: 4.928e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18103, It: 0, Loss Data: 4.835e-02, Loss Eqns: 8.421e-01, Loss Aux: 4.598e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18104, It: 0, Loss Data: 5.100e-02, Loss Eqns: 8.073e-01, Loss Aux: 5.352e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18105, It: 0, Loss Data: 4.945e-02, Loss Eqns: 8.500e-01, Loss Aux: 5.564e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18106, It: 0, Loss Data: 3.992e-02, Loss Eqns: 8.793e-01, Loss Aux: 4.733e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18107, It: 0, Loss Data: 4.326e-02, Loss Eqns: 8.477e-01, Loss Aux: 4.403e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18108, It: 0, Loss Data: 4.647e-02, Loss Eqns: 8.477e-01, Loss Aux: 5.084e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18109, It: 0, Loss Data: 4.951e-02, Loss Eqns: 8.407e-01, Loss Aux: 5.566e-02, Time: 0.216, Learning Rate: 1.0e-03\n",
      "Epoch: 18110, It: 0, Loss Data: 4.427e-02, Loss Eqns: 8.483e-01, Loss Aux: 4.531e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18111, It: 0, Loss Data: 4.820e-02, Loss Eqns: 8.581e-01, Loss Aux: 5.152e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18112, It: 0, Loss Data: 3.663e-02, Loss Eqns: 8.249e-01, Loss Aux: 6.621e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18113, It: 0, Loss Data: 4.115e-02, Loss Eqns: 8.081e-01, Loss Aux: 6.041e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18114, It: 0, Loss Data: 4.365e-02, Loss Eqns: 8.464e-01, Loss Aux: 4.599e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18115, It: 0, Loss Data: 4.471e-02, Loss Eqns: 8.426e-01, Loss Aux: 4.430e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18116, It: 0, Loss Data: 4.902e-02, Loss Eqns: 8.146e-01, Loss Aux: 5.187e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18117, It: 0, Loss Data: 5.119e-02, Loss Eqns: 8.054e-01, Loss Aux: 5.617e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18118, It: 0, Loss Data: 5.097e-02, Loss Eqns: 8.036e-01, Loss Aux: 5.028e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18119, It: 0, Loss Data: 4.730e-02, Loss Eqns: 8.494e-01, Loss Aux: 4.935e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18120, It: 0, Loss Data: 5.027e-02, Loss Eqns: 8.257e-01, Loss Aux: 5.242e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18121, It: 0, Loss Data: 5.137e-02, Loss Eqns: 8.381e-01, Loss Aux: 5.088e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18122, It: 0, Loss Data: 5.144e-02, Loss Eqns: 8.541e-01, Loss Aux: 4.475e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18123, It: 0, Loss Data: 5.072e-02, Loss Eqns: 8.381e-01, Loss Aux: 4.980e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18124, It: 0, Loss Data: 4.944e-02, Loss Eqns: 8.337e-01, Loss Aux: 6.011e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18125, It: 0, Loss Data: 4.867e-02, Loss Eqns: 8.478e-01, Loss Aux: 5.988e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18126, It: 0, Loss Data: 4.584e-02, Loss Eqns: 8.588e-01, Loss Aux: 4.577e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18127, It: 0, Loss Data: 4.951e-02, Loss Eqns: 9.023e-01, Loss Aux: 4.383e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18128, It: 0, Loss Data: 3.678e-02, Loss Eqns: 8.273e-01, Loss Aux: 5.681e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18129, It: 0, Loss Data: 4.424e-02, Loss Eqns: 8.066e-01, Loss Aux: 6.050e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18130, It: 0, Loss Data: 5.548e-02, Loss Eqns: 7.899e-01, Loss Aux: 5.438e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18131, It: 0, Loss Data: 4.877e-02, Loss Eqns: 8.314e-01, Loss Aux: 4.792e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18132, It: 0, Loss Data: 5.244e-02, Loss Eqns: 8.110e-01, Loss Aux: 5.427e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18133, It: 0, Loss Data: 4.502e-02, Loss Eqns: 8.550e-01, Loss Aux: 4.654e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18134, It: 0, Loss Data: 5.004e-02, Loss Eqns: 8.777e-01, Loss Aux: 4.503e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18135, It: 0, Loss Data: 4.963e-02, Loss Eqns: 8.737e-01, Loss Aux: 5.509e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18136, It: 0, Loss Data: 4.175e-02, Loss Eqns: 8.998e-01, Loss Aux: 5.609e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18137, It: 0, Loss Data: 4.623e-02, Loss Eqns: 8.590e-01, Loss Aux: 5.276e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18138, It: 0, Loss Data: 4.927e-02, Loss Eqns: 8.501e-01, Loss Aux: 4.971e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18139, It: 0, Loss Data: 4.614e-02, Loss Eqns: 8.368e-01, Loss Aux: 4.763e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18140, It: 0, Loss Data: 4.850e-02, Loss Eqns: 8.472e-01, Loss Aux: 4.709e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18141, It: 0, Loss Data: 5.886e-02, Loss Eqns: 8.476e-01, Loss Aux: 5.489e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18142, It: 0, Loss Data: 4.262e-02, Loss Eqns: 8.919e-01, Loss Aux: 5.649e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18143, It: 0, Loss Data: 4.692e-02, Loss Eqns: 8.602e-01, Loss Aux: 4.411e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18144, It: 0, Loss Data: 5.158e-02, Loss Eqns: 8.357e-01, Loss Aux: 5.494e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18145, It: 0, Loss Data: 4.941e-02, Loss Eqns: 8.378e-01, Loss Aux: 5.718e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18146, It: 0, Loss Data: 4.624e-02, Loss Eqns: 8.868e-01, Loss Aux: 4.573e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18147, It: 0, Loss Data: 4.526e-02, Loss Eqns: 8.661e-01, Loss Aux: 4.856e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18148, It: 0, Loss Data: 4.777e-02, Loss Eqns: 8.914e-01, Loss Aux: 5.918e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18149, It: 0, Loss Data: 4.281e-02, Loss Eqns: 8.590e-01, Loss Aux: 5.009e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18150, It: 0, Loss Data: 4.420e-02, Loss Eqns: 9.048e-01, Loss Aux: 4.267e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18151, It: 0, Loss Data: 4.187e-02, Loss Eqns: 8.219e-01, Loss Aux: 4.734e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18152, It: 0, Loss Data: 4.728e-02, Loss Eqns: 9.002e-01, Loss Aux: 5.772e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18153, It: 0, Loss Data: 5.183e-02, Loss Eqns: 8.290e-01, Loss Aux: 5.604e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18154, It: 0, Loss Data: 4.240e-02, Loss Eqns: 8.261e-01, Loss Aux: 5.103e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18155, It: 0, Loss Data: 4.618e-02, Loss Eqns: 8.090e-01, Loss Aux: 5.285e-02, Time: 0.207, Learning Rate: 1.0e-03\n",
      "Epoch: 18156, It: 0, Loss Data: 4.465e-02, Loss Eqns: 8.154e-01, Loss Aux: 4.531e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18157, It: 0, Loss Data: 4.736e-02, Loss Eqns: 8.470e-01, Loss Aux: 4.446e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18158, It: 0, Loss Data: 4.801e-02, Loss Eqns: 7.805e-01, Loss Aux: 6.351e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18159, It: 0, Loss Data: 4.364e-02, Loss Eqns: 8.165e-01, Loss Aux: 7.187e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18160, It: 0, Loss Data: 4.372e-02, Loss Eqns: 8.080e-01, Loss Aux: 4.867e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18161, It: 0, Loss Data: 4.963e-02, Loss Eqns: 8.265e-01, Loss Aux: 4.419e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18162, It: 0, Loss Data: 5.093e-02, Loss Eqns: 8.261e-01, Loss Aux: 4.861e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18163, It: 0, Loss Data: 5.349e-02, Loss Eqns: 8.335e-01, Loss Aux: 4.396e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18164, It: 0, Loss Data: 5.333e-02, Loss Eqns: 8.223e-01, Loss Aux: 4.801e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18165, It: 0, Loss Data: 4.776e-02, Loss Eqns: 8.122e-01, Loss Aux: 6.930e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18166, It: 0, Loss Data: 5.351e-02, Loss Eqns: 8.995e-01, Loss Aux: 5.276e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18167, It: 0, Loss Data: 5.111e-02, Loss Eqns: 8.694e-01, Loss Aux: 6.912e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18168, It: 0, Loss Data: 5.155e-02, Loss Eqns: 8.518e-01, Loss Aux: 6.000e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18169, It: 0, Loss Data: 4.965e-02, Loss Eqns: 9.144e-01, Loss Aux: 4.253e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18170, It: 0, Loss Data: 5.010e-02, Loss Eqns: 8.350e-01, Loss Aux: 4.473e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18171, It: 0, Loss Data: 5.020e-02, Loss Eqns: 8.627e-01, Loss Aux: 5.595e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18172, It: 0, Loss Data: 4.552e-02, Loss Eqns: 7.855e-01, Loss Aux: 5.402e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18173, It: 0, Loss Data: 4.380e-02, Loss Eqns: 9.118e-01, Loss Aux: 4.380e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18174, It: 0, Loss Data: 5.022e-02, Loss Eqns: 8.804e-01, Loss Aux: 4.688e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18175, It: 0, Loss Data: 4.506e-02, Loss Eqns: 8.473e-01, Loss Aux: 5.271e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18176, It: 0, Loss Data: 5.236e-02, Loss Eqns: 8.479e-01, Loss Aux: 5.097e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18177, It: 0, Loss Data: 4.691e-02, Loss Eqns: 8.363e-01, Loss Aux: 4.859e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18178, It: 0, Loss Data: 4.533e-02, Loss Eqns: 8.618e-01, Loss Aux: 4.661e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18179, It: 0, Loss Data: 4.552e-02, Loss Eqns: 8.358e-01, Loss Aux: 5.059e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18180, It: 0, Loss Data: 1.302e-01, Loss Eqns: 1.239e+00, Loss Aux: 4.013e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18181, It: 0, Loss Data: 1.021e-01, Loss Eqns: 1.027e+00, Loss Aux: 1.493e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18182, It: 0, Loss Data: 2.532e-01, Loss Eqns: 1.914e+00, Loss Aux: 2.289e-01, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18183, It: 0, Loss Data: 3.930e-01, Loss Eqns: 4.058e+00, Loss Aux: 6.720e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18184, It: 0, Loss Data: 1.703e-01, Loss Eqns: 1.984e+00, Loss Aux: 6.579e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18185, It: 0, Loss Data: 1.014e-01, Loss Eqns: 1.914e+00, Loss Aux: 1.213e-01, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18186, It: 0, Loss Data: 2.453e-01, Loss Eqns: 3.738e+00, Loss Aux: 2.244e-01, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18187, It: 0, Loss Data: 1.005e-01, Loss Eqns: 1.671e+00, Loss Aux: 9.021e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18188, It: 0, Loss Data: 1.712e-01, Loss Eqns: 2.870e+00, Loss Aux: 6.122e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18189, It: 0, Loss Data: 1.424e-01, Loss Eqns: 1.970e+00, Loss Aux: 6.187e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18190, It: 0, Loss Data: 9.586e-02, Loss Eqns: 1.885e+00, Loss Aux: 8.447e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18191, It: 0, Loss Data: 1.614e-01, Loss Eqns: 2.191e+00, Loss Aux: 1.006e-01, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18192, It: 0, Loss Data: 8.120e-02, Loss Eqns: 1.465e+00, Loss Aux: 5.502e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18193, It: 0, Loss Data: 1.487e-01, Loss Eqns: 1.794e+00, Loss Aux: 4.490e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18194, It: 0, Loss Data: 1.123e-01, Loss Eqns: 1.531e+00, Loss Aux: 6.086e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18195, It: 0, Loss Data: 9.808e-02, Loss Eqns: 1.356e+00, Loss Aux: 1.139e-01, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18196, It: 0, Loss Data: 8.883e-02, Loss Eqns: 1.488e+00, Loss Aux: 1.162e-01, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18197, It: 0, Loss Data: 7.397e-02, Loss Eqns: 1.192e+00, Loss Aux: 6.668e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18198, It: 0, Loss Data: 1.009e-01, Loss Eqns: 1.234e+00, Loss Aux: 4.886e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18199, It: 0, Loss Data: 8.223e-02, Loss Eqns: 1.303e+00, Loss Aux: 5.068e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18200, It: 0, Loss Data: 8.122e-02, Loss Eqns: 1.151e+00, Loss Aux: 7.063e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18201, It: 0, Loss Data: 7.617e-02, Loss Eqns: 1.052e+00, Loss Aux: 7.249e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18202, It: 0, Loss Data: 6.056e-02, Loss Eqns: 1.088e+00, Loss Aux: 7.887e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18203, It: 0, Loss Data: 5.413e-02, Loss Eqns: 1.039e+00, Loss Aux: 7.110e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18204, It: 0, Loss Data: 6.101e-02, Loss Eqns: 1.066e+00, Loss Aux: 5.802e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18205, It: 0, Loss Data: 6.208e-02, Loss Eqns: 1.030e+00, Loss Aux: 4.848e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18206, It: 0, Loss Data: 6.141e-02, Loss Eqns: 1.029e+00, Loss Aux: 4.796e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18207, It: 0, Loss Data: 5.655e-02, Loss Eqns: 1.078e+00, Loss Aux: 5.180e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18208, It: 0, Loss Data: 5.423e-02, Loss Eqns: 9.475e-01, Loss Aux: 5.407e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18209, It: 0, Loss Data: 5.138e-02, Loss Eqns: 1.009e+00, Loss Aux: 5.750e-02, Time: 0.229, Learning Rate: 1.0e-03\n",
      "Epoch: 18210, It: 0, Loss Data: 5.026e-02, Loss Eqns: 9.867e-01, Loss Aux: 6.325e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18211, It: 0, Loss Data: 5.615e-02, Loss Eqns: 9.056e-01, Loss Aux: 7.453e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18212, It: 0, Loss Data: 5.107e-02, Loss Eqns: 9.501e-01, Loss Aux: 7.594e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18213, It: 0, Loss Data: 4.451e-02, Loss Eqns: 9.430e-01, Loss Aux: 6.418e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18214, It: 0, Loss Data: 5.530e-02, Loss Eqns: 9.094e-01, Loss Aux: 5.793e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18215, It: 0, Loss Data: 5.423e-02, Loss Eqns: 9.055e-01, Loss Aux: 5.820e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18216, It: 0, Loss Data: 4.647e-02, Loss Eqns: 9.198e-01, Loss Aux: 6.336e-02, Time: 0.212, Learning Rate: 1.0e-03\n",
      "Epoch: 18217, It: 0, Loss Data: 5.316e-02, Loss Eqns: 8.832e-01, Loss Aux: 6.023e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18218, It: 0, Loss Data: 5.454e-02, Loss Eqns: 8.700e-01, Loss Aux: 5.614e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18219, It: 0, Loss Data: 5.128e-02, Loss Eqns: 8.854e-01, Loss Aux: 5.783e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18220, It: 0, Loss Data: 4.956e-02, Loss Eqns: 8.608e-01, Loss Aux: 6.986e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18221, It: 0, Loss Data: 5.069e-02, Loss Eqns: 8.477e-01, Loss Aux: 6.974e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18222, It: 0, Loss Data: 4.836e-02, Loss Eqns: 8.467e-01, Loss Aux: 5.864e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18223, It: 0, Loss Data: 4.596e-02, Loss Eqns: 8.417e-01, Loss Aux: 5.132e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18224, It: 0, Loss Data: 5.036e-02, Loss Eqns: 8.542e-01, Loss Aux: 4.951e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18225, It: 0, Loss Data: 4.674e-02, Loss Eqns: 8.242e-01, Loss Aux: 5.283e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18226, It: 0, Loss Data: 5.089e-02, Loss Eqns: 8.116e-01, Loss Aux: 5.781e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18227, It: 0, Loss Data: 4.254e-02, Loss Eqns: 8.272e-01, Loss Aux: 5.676e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18228, It: 0, Loss Data: 4.985e-02, Loss Eqns: 8.260e-01, Loss Aux: 5.937e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18229, It: 0, Loss Data: 5.814e-02, Loss Eqns: 8.371e-01, Loss Aux: 6.265e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18230, It: 0, Loss Data: 5.350e-02, Loss Eqns: 8.088e-01, Loss Aux: 6.211e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18231, It: 0, Loss Data: 4.539e-02, Loss Eqns: 8.081e-01, Loss Aux: 5.820e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18232, It: 0, Loss Data: 5.106e-02, Loss Eqns: 7.992e-01, Loss Aux: 5.769e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18233, It: 0, Loss Data: 4.574e-02, Loss Eqns: 8.283e-01, Loss Aux: 5.962e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18234, It: 0, Loss Data: 5.265e-02, Loss Eqns: 8.153e-01, Loss Aux: 5.696e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18235, It: 0, Loss Data: 5.180e-02, Loss Eqns: 8.344e-01, Loss Aux: 5.299e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18236, It: 0, Loss Data: 4.338e-02, Loss Eqns: 8.106e-01, Loss Aux: 5.216e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 18237, It: 0, Loss Data: 4.055e-02, Loss Eqns: 8.238e-01, Loss Aux: 5.767e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18238, It: 0, Loss Data: 4.516e-02, Loss Eqns: 8.321e-01, Loss Aux: 6.589e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18239, It: 0, Loss Data: 5.340e-02, Loss Eqns: 8.171e-01, Loss Aux: 6.707e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18240, It: 0, Loss Data: 4.347e-02, Loss Eqns: 8.165e-01, Loss Aux: 5.458e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18241, It: 0, Loss Data: 4.873e-02, Loss Eqns: 8.089e-01, Loss Aux: 4.938e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18242, It: 0, Loss Data: 4.822e-02, Loss Eqns: 8.106e-01, Loss Aux: 5.258e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18243, It: 0, Loss Data: 4.912e-02, Loss Eqns: 7.944e-01, Loss Aux: 5.604e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 18244, It: 0, Loss Data: 4.967e-02, Loss Eqns: 8.024e-01, Loss Aux: 5.385e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18245, It: 0, Loss Data: 5.110e-02, Loss Eqns: 8.298e-01, Loss Aux: 4.988e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18246, It: 0, Loss Data: 5.052e-02, Loss Eqns: 8.197e-01, Loss Aux: 5.150e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18247, It: 0, Loss Data: 4.167e-02, Loss Eqns: 7.855e-01, Loss Aux: 5.781e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18248, It: 0, Loss Data: 5.367e-02, Loss Eqns: 7.905e-01, Loss Aux: 6.564e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18249, It: 0, Loss Data: 4.999e-02, Loss Eqns: 8.055e-01, Loss Aux: 5.952e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18250, It: 0, Loss Data: 5.051e-02, Loss Eqns: 7.959e-01, Loss Aux: 5.386e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18251, It: 0, Loss Data: 4.328e-02, Loss Eqns: 8.031e-01, Loss Aux: 5.726e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18252, It: 0, Loss Data: 4.703e-02, Loss Eqns: 7.841e-01, Loss Aux: 6.422e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18253, It: 0, Loss Data: 4.356e-02, Loss Eqns: 7.942e-01, Loss Aux: 6.086e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18254, It: 0, Loss Data: 4.515e-02, Loss Eqns: 7.968e-01, Loss Aux: 5.407e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18255, It: 0, Loss Data: 4.947e-02, Loss Eqns: 8.045e-01, Loss Aux: 5.517e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18256, It: 0, Loss Data: 4.506e-02, Loss Eqns: 7.745e-01, Loss Aux: 5.934e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18257, It: 0, Loss Data: 4.352e-02, Loss Eqns: 8.061e-01, Loss Aux: 6.198e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18258, It: 0, Loss Data: 5.279e-02, Loss Eqns: 8.099e-01, Loss Aux: 5.831e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 18259, It: 0, Loss Data: 4.397e-02, Loss Eqns: 8.007e-01, Loss Aux: 5.546e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18260, It: 0, Loss Data: 4.933e-02, Loss Eqns: 8.186e-01, Loss Aux: 5.622e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18261, It: 0, Loss Data: 5.441e-02, Loss Eqns: 7.963e-01, Loss Aux: 5.814e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18262, It: 0, Loss Data: 4.187e-02, Loss Eqns: 8.046e-01, Loss Aux: 5.287e-02, Time: 0.219, Learning Rate: 1.0e-03\n",
      "Epoch: 18263, It: 0, Loss Data: 5.211e-02, Loss Eqns: 8.219e-01, Loss Aux: 5.013e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18264, It: 0, Loss Data: 4.387e-02, Loss Eqns: 7.990e-01, Loss Aux: 5.233e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18265, It: 0, Loss Data: 4.596e-02, Loss Eqns: 8.310e-01, Loss Aux: 5.284e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18266, It: 0, Loss Data: 4.548e-02, Loss Eqns: 7.925e-01, Loss Aux: 5.100e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18267, It: 0, Loss Data: 4.576e-02, Loss Eqns: 8.110e-01, Loss Aux: 5.140e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18268, It: 0, Loss Data: 4.210e-02, Loss Eqns: 8.220e-01, Loss Aux: 5.197e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18269, It: 0, Loss Data: 4.332e-02, Loss Eqns: 7.991e-01, Loss Aux: 5.662e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18270, It: 0, Loss Data: 4.454e-02, Loss Eqns: 8.040e-01, Loss Aux: 5.675e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18271, It: 0, Loss Data: 4.624e-02, Loss Eqns: 7.865e-01, Loss Aux: 6.196e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18272, It: 0, Loss Data: 4.151e-02, Loss Eqns: 8.105e-01, Loss Aux: 6.764e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18273, It: 0, Loss Data: 4.920e-02, Loss Eqns: 7.863e-01, Loss Aux: 6.246e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18274, It: 0, Loss Data: 4.043e-02, Loss Eqns: 7.831e-01, Loss Aux: 5.089e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18275, It: 0, Loss Data: 4.216e-02, Loss Eqns: 8.006e-01, Loss Aux: 4.930e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18276, It: 0, Loss Data: 4.471e-02, Loss Eqns: 7.928e-01, Loss Aux: 5.543e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18277, It: 0, Loss Data: 5.352e-02, Loss Eqns: 7.668e-01, Loss Aux: 6.020e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18278, It: 0, Loss Data: 4.953e-02, Loss Eqns: 7.786e-01, Loss Aux: 5.359e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18279, It: 0, Loss Data: 4.661e-02, Loss Eqns: 7.891e-01, Loss Aux: 5.056e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18280, It: 0, Loss Data: 4.547e-02, Loss Eqns: 8.185e-01, Loss Aux: 5.472e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18281, It: 0, Loss Data: 4.888e-02, Loss Eqns: 8.023e-01, Loss Aux: 6.519e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18282, It: 0, Loss Data: 4.258e-02, Loss Eqns: 8.272e-01, Loss Aux: 6.616e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18283, It: 0, Loss Data: 4.906e-02, Loss Eqns: 7.883e-01, Loss Aux: 5.912e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18284, It: 0, Loss Data: 4.626e-02, Loss Eqns: 8.442e-01, Loss Aux: 5.386e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18285, It: 0, Loss Data: 3.841e-02, Loss Eqns: 8.205e-01, Loss Aux: 5.228e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18286, It: 0, Loss Data: 4.772e-02, Loss Eqns: 8.185e-01, Loss Aux: 5.186e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18287, It: 0, Loss Data: 4.463e-02, Loss Eqns: 8.290e-01, Loss Aux: 5.188e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18288, It: 0, Loss Data: 5.299e-02, Loss Eqns: 8.102e-01, Loss Aux: 5.426e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18289, It: 0, Loss Data: 4.565e-02, Loss Eqns: 8.122e-01, Loss Aux: 5.736e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18290, It: 0, Loss Data: 4.070e-02, Loss Eqns: 8.049e-01, Loss Aux: 5.478e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18291, It: 0, Loss Data: 4.022e-02, Loss Eqns: 8.271e-01, Loss Aux: 5.318e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18292, It: 0, Loss Data: 4.748e-02, Loss Eqns: 7.848e-01, Loss Aux: 5.696e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18293, It: 0, Loss Data: 4.796e-02, Loss Eqns: 8.223e-01, Loss Aux: 6.061e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18294, It: 0, Loss Data: 4.824e-02, Loss Eqns: 8.013e-01, Loss Aux: 5.802e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18295, It: 0, Loss Data: 4.034e-02, Loss Eqns: 7.702e-01, Loss Aux: 5.007e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18296, It: 0, Loss Data: 4.587e-02, Loss Eqns: 7.999e-01, Loss Aux: 4.912e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18297, It: 0, Loss Data: 4.688e-02, Loss Eqns: 7.530e-01, Loss Aux: 5.473e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18298, It: 0, Loss Data: 5.214e-02, Loss Eqns: 8.038e-01, Loss Aux: 5.916e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18299, It: 0, Loss Data: 4.631e-02, Loss Eqns: 7.822e-01, Loss Aux: 5.566e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18300, It: 0, Loss Data: 5.953e-02, Loss Eqns: 8.501e-01, Loss Aux: 7.394e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18301, It: 0, Loss Data: 5.786e-02, Loss Eqns: 8.670e-01, Loss Aux: 4.805e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18302, It: 0, Loss Data: 7.645e-02, Loss Eqns: 8.908e-01, Loss Aux: 4.760e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18303, It: 0, Loss Data: 5.101e-02, Loss Eqns: 8.116e-01, Loss Aux: 6.672e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18304, It: 0, Loss Data: 6.277e-02, Loss Eqns: 9.565e-01, Loss Aux: 6.819e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18305, It: 0, Loss Data: 5.209e-02, Loss Eqns: 8.257e-01, Loss Aux: 4.684e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18306, It: 0, Loss Data: 5.946e-02, Loss Eqns: 8.922e-01, Loss Aux: 4.607e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18307, It: 0, Loss Data: 4.234e-02, Loss Eqns: 8.296e-01, Loss Aux: 6.311e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18308, It: 0, Loss Data: 5.895e-02, Loss Eqns: 8.100e-01, Loss Aux: 9.219e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18309, It: 0, Loss Data: 4.887e-02, Loss Eqns: 8.687e-01, Loss Aux: 7.208e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18310, It: 0, Loss Data: 5.110e-02, Loss Eqns: 8.187e-01, Loss Aux: 4.726e-02, Time: 0.225, Learning Rate: 1.0e-03\n",
      "Epoch: 18311, It: 0, Loss Data: 5.066e-02, Loss Eqns: 8.355e-01, Loss Aux: 4.538e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18312, It: 0, Loss Data: 5.710e-02, Loss Eqns: 7.888e-01, Loss Aux: 5.767e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18313, It: 0, Loss Data: 6.110e-02, Loss Eqns: 7.984e-01, Loss Aux: 6.534e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18314, It: 0, Loss Data: 4.895e-02, Loss Eqns: 8.116e-01, Loss Aux: 5.099e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18315, It: 0, Loss Data: 5.666e-02, Loss Eqns: 8.156e-01, Loss Aux: 4.775e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18316, It: 0, Loss Data: 4.848e-02, Loss Eqns: 7.830e-01, Loss Aux: 5.486e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18317, It: 0, Loss Data: 5.330e-02, Loss Eqns: 7.948e-01, Loss Aux: 7.051e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18318, It: 0, Loss Data: 4.646e-02, Loss Eqns: 7.743e-01, Loss Aux: 6.418e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18319, It: 0, Loss Data: 4.966e-02, Loss Eqns: 7.950e-01, Loss Aux: 4.743e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18320, It: 0, Loss Data: 5.733e-02, Loss Eqns: 8.431e-01, Loss Aux: 4.617e-02, Time: 0.208, Learning Rate: 1.0e-03\n",
      "Epoch: 18321, It: 0, Loss Data: 4.591e-02, Loss Eqns: 7.920e-01, Loss Aux: 5.447e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18322, It: 0, Loss Data: 5.430e-02, Loss Eqns: 8.021e-01, Loss Aux: 7.841e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18323, It: 0, Loss Data: 4.706e-02, Loss Eqns: 7.787e-01, Loss Aux: 7.681e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18324, It: 0, Loss Data: 4.640e-02, Loss Eqns: 8.147e-01, Loss Aux: 5.399e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18325, It: 0, Loss Data: 4.784e-02, Loss Eqns: 8.029e-01, Loss Aux: 5.035e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18326, It: 0, Loss Data: 4.481e-02, Loss Eqns: 8.566e-01, Loss Aux: 5.469e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18327, It: 0, Loss Data: 4.798e-02, Loss Eqns: 8.024e-01, Loss Aux: 5.820e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18328, It: 0, Loss Data: 3.997e-02, Loss Eqns: 8.081e-01, Loss Aux: 5.039e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18329, It: 0, Loss Data: 5.029e-02, Loss Eqns: 7.890e-01, Loss Aux: 4.836e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 18330, It: 0, Loss Data: 4.261e-02, Loss Eqns: 7.591e-01, Loss Aux: 5.206e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18331, It: 0, Loss Data: 5.380e-02, Loss Eqns: 8.109e-01, Loss Aux: 6.510e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18332, It: 0, Loss Data: 4.447e-02, Loss Eqns: 7.934e-01, Loss Aux: 6.712e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18333, It: 0, Loss Data: 3.756e-02, Loss Eqns: 8.097e-01, Loss Aux: 5.300e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18334, It: 0, Loss Data: 4.749e-02, Loss Eqns: 7.790e-01, Loss Aux: 4.758e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18335, It: 0, Loss Data: 4.354e-02, Loss Eqns: 8.037e-01, Loss Aux: 4.874e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18336, It: 0, Loss Data: 4.014e-02, Loss Eqns: 7.692e-01, Loss Aux: 5.095e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18337, It: 0, Loss Data: 4.660e-02, Loss Eqns: 8.072e-01, Loss Aux: 5.433e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18338, It: 0, Loss Data: 5.355e-02, Loss Eqns: 7.820e-01, Loss Aux: 6.063e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18339, It: 0, Loss Data: 5.086e-02, Loss Eqns: 7.646e-01, Loss Aux: 5.892e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18340, It: 0, Loss Data: 4.843e-02, Loss Eqns: 7.818e-01, Loss Aux: 5.343e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18341, It: 0, Loss Data: 4.771e-02, Loss Eqns: 8.308e-01, Loss Aux: 5.006e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18342, It: 0, Loss Data: 4.361e-02, Loss Eqns: 8.184e-01, Loss Aux: 5.126e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18343, It: 0, Loss Data: 4.763e-02, Loss Eqns: 8.204e-01, Loss Aux: 6.029e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18344, It: 0, Loss Data: 4.300e-02, Loss Eqns: 7.920e-01, Loss Aux: 6.144e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18345, It: 0, Loss Data: 4.647e-02, Loss Eqns: 8.033e-01, Loss Aux: 5.198e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18346, It: 0, Loss Data: 4.720e-02, Loss Eqns: 7.856e-01, Loss Aux: 4.831e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18347, It: 0, Loss Data: 4.185e-02, Loss Eqns: 7.960e-01, Loss Aux: 5.380e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18348, It: 0, Loss Data: 4.635e-02, Loss Eqns: 7.814e-01, Loss Aux: 6.999e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18349, It: 0, Loss Data: 4.499e-02, Loss Eqns: 7.825e-01, Loss Aux: 6.681e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18350, It: 0, Loss Data: 4.624e-02, Loss Eqns: 8.087e-01, Loss Aux: 5.377e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18351, It: 0, Loss Data: 6.693e-02, Loss Eqns: 9.001e-01, Loss Aux: 6.057e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18352, It: 0, Loss Data: 1.187e-01, Loss Eqns: 1.051e+00, Loss Aux: 5.337e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18353, It: 0, Loss Data: 6.660e-02, Loss Eqns: 8.874e-01, Loss Aux: 5.708e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18354, It: 0, Loss Data: 8.624e-02, Loss Eqns: 9.595e-01, Loss Aux: 1.217e-01, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18355, It: 0, Loss Data: 6.984e-02, Loss Eqns: 9.461e-01, Loss Aux: 6.185e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18356, It: 0, Loss Data: 7.627e-02, Loss Eqns: 8.714e-01, Loss Aux: 4.547e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18357, It: 0, Loss Data: 7.847e-02, Loss Eqns: 1.033e+00, Loss Aux: 4.669e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18358, It: 0, Loss Data: 6.718e-02, Loss Eqns: 7.760e-01, Loss Aux: 8.040e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18359, It: 0, Loss Data: 7.732e-02, Loss Eqns: 9.212e-01, Loss Aux: 8.399e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18360, It: 0, Loss Data: 5.172e-02, Loss Eqns: 8.269e-01, Loss Aux: 5.000e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18361, It: 0, Loss Data: 7.581e-02, Loss Eqns: 8.347e-01, Loss Aux: 4.659e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18362, It: 0, Loss Data: 5.818e-02, Loss Eqns: 8.566e-01, Loss Aux: 6.217e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18363, It: 0, Loss Data: 6.741e-02, Loss Eqns: 7.839e-01, Loss Aux: 9.592e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18364, It: 0, Loss Data: 4.853e-02, Loss Eqns: 8.696e-01, Loss Aux: 7.027e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18365, It: 0, Loss Data: 6.623e-02, Loss Eqns: 7.967e-01, Loss Aux: 4.905e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 18366, It: 0, Loss Data: 6.380e-02, Loss Eqns: 7.857e-01, Loss Aux: 4.730e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18367, It: 0, Loss Data: 5.342e-02, Loss Eqns: 7.781e-01, Loss Aux: 6.730e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18368, It: 0, Loss Data: 7.087e-02, Loss Eqns: 7.451e-01, Loss Aux: 8.653e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18369, It: 0, Loss Data: 4.690e-02, Loss Eqns: 7.512e-01, Loss Aux: 5.829e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18370, It: 0, Loss Data: 6.230e-02, Loss Eqns: 8.076e-01, Loss Aux: 4.794e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18371, It: 0, Loss Data: 5.449e-02, Loss Eqns: 7.502e-01, Loss Aux: 4.826e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18372, It: 0, Loss Data: 5.427e-02, Loss Eqns: 8.114e-01, Loss Aux: 6.556e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18373, It: 0, Loss Data: 6.105e-02, Loss Eqns: 7.763e-01, Loss Aux: 8.191e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18374, It: 0, Loss Data: 4.745e-02, Loss Eqns: 8.003e-01, Loss Aux: 5.654e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18375, It: 0, Loss Data: 6.051e-02, Loss Eqns: 7.901e-01, Loss Aux: 4.809e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18376, It: 0, Loss Data: 4.449e-02, Loss Eqns: 7.922e-01, Loss Aux: 5.148e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18377, It: 0, Loss Data: 5.046e-02, Loss Eqns: 7.973e-01, Loss Aux: 6.201e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18378, It: 0, Loss Data: 4.560e-02, Loss Eqns: 7.930e-01, Loss Aux: 5.353e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18379, It: 0, Loss Data: 4.739e-02, Loss Eqns: 8.125e-01, Loss Aux: 4.744e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18380, It: 0, Loss Data: 4.408e-02, Loss Eqns: 7.652e-01, Loss Aux: 4.857e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18381, It: 0, Loss Data: 4.873e-02, Loss Eqns: 8.389e-01, Loss Aux: 5.945e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18382, It: 0, Loss Data: 4.835e-02, Loss Eqns: 7.822e-01, Loss Aux: 7.045e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18383, It: 0, Loss Data: 4.357e-02, Loss Eqns: 8.079e-01, Loss Aux: 5.981e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18384, It: 0, Loss Data: 4.713e-02, Loss Eqns: 8.098e-01, Loss Aux: 5.001e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18385, It: 0, Loss Data: 4.558e-02, Loss Eqns: 7.578e-01, Loss Aux: 4.937e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18386, It: 0, Loss Data: 4.453e-02, Loss Eqns: 7.984e-01, Loss Aux: 5.243e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18387, It: 0, Loss Data: 4.426e-02, Loss Eqns: 7.791e-01, Loss Aux: 5.252e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18388, It: 0, Loss Data: 4.567e-02, Loss Eqns: 7.504e-01, Loss Aux: 5.181e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18389, It: 0, Loss Data: 4.514e-02, Loss Eqns: 7.999e-01, Loss Aux: 5.254e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18390, It: 0, Loss Data: 4.429e-02, Loss Eqns: 7.656e-01, Loss Aux: 5.583e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18391, It: 0, Loss Data: 4.336e-02, Loss Eqns: 8.243e-01, Loss Aux: 5.399e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18392, It: 0, Loss Data: 4.696e-02, Loss Eqns: 7.671e-01, Loss Aux: 5.198e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18393, It: 0, Loss Data: 4.886e-02, Loss Eqns: 7.545e-01, Loss Aux: 5.531e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18394, It: 0, Loss Data: 4.200e-02, Loss Eqns: 7.609e-01, Loss Aux: 6.219e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18395, It: 0, Loss Data: 4.404e-02, Loss Eqns: 7.534e-01, Loss Aux: 6.589e-02, Time: 0.233, Learning Rate: 1.0e-03\n",
      "Epoch: 18396, It: 0, Loss Data: 4.772e-02, Loss Eqns: 7.866e-01, Loss Aux: 5.367e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18397, It: 0, Loss Data: 4.242e-02, Loss Eqns: 7.843e-01, Loss Aux: 4.970e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18398, It: 0, Loss Data: 4.554e-02, Loss Eqns: 7.960e-01, Loss Aux: 5.040e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18399, It: 0, Loss Data: 4.528e-02, Loss Eqns: 7.739e-01, Loss Aux: 5.373e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18400, It: 0, Loss Data: 4.503e-02, Loss Eqns: 7.769e-01, Loss Aux: 5.670e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18401, It: 0, Loss Data: 4.544e-02, Loss Eqns: 7.920e-01, Loss Aux: 5.812e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18402, It: 0, Loss Data: 5.031e-02, Loss Eqns: 7.998e-01, Loss Aux: 5.917e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18403, It: 0, Loss Data: 4.591e-02, Loss Eqns: 7.798e-01, Loss Aux: 6.109e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18404, It: 0, Loss Data: 4.079e-02, Loss Eqns: 7.816e-01, Loss Aux: 5.763e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18405, It: 0, Loss Data: 4.178e-02, Loss Eqns: 7.802e-01, Loss Aux: 5.035e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18406, It: 0, Loss Data: 3.999e-02, Loss Eqns: 7.737e-01, Loss Aux: 4.895e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18407, It: 0, Loss Data: 4.298e-02, Loss Eqns: 7.817e-01, Loss Aux: 5.221e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18408, It: 0, Loss Data: 4.460e-02, Loss Eqns: 7.691e-01, Loss Aux: 6.439e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18409, It: 0, Loss Data: 4.914e-02, Loss Eqns: 7.760e-01, Loss Aux: 6.400e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18410, It: 0, Loss Data: 4.228e-02, Loss Eqns: 8.021e-01, Loss Aux: 5.302e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18411, It: 0, Loss Data: 4.268e-02, Loss Eqns: 7.963e-01, Loss Aux: 4.954e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18412, It: 0, Loss Data: 4.463e-02, Loss Eqns: 8.143e-01, Loss Aux: 5.333e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18413, It: 0, Loss Data: 5.143e-02, Loss Eqns: 7.628e-01, Loss Aux: 6.128e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18414, It: 0, Loss Data: 4.676e-02, Loss Eqns: 7.454e-01, Loss Aux: 6.150e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18415, It: 0, Loss Data: 4.421e-02, Loss Eqns: 7.682e-01, Loss Aux: 5.496e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18416, It: 0, Loss Data: 4.538e-02, Loss Eqns: 7.878e-01, Loss Aux: 5.481e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18417, It: 0, Loss Data: 4.469e-02, Loss Eqns: 7.628e-01, Loss Aux: 5.672e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18418, It: 0, Loss Data: 3.918e-02, Loss Eqns: 7.685e-01, Loss Aux: 5.659e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18419, It: 0, Loss Data: 4.873e-02, Loss Eqns: 8.203e-01, Loss Aux: 5.150e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18420, It: 0, Loss Data: 3.916e-02, Loss Eqns: 8.002e-01, Loss Aux: 4.936e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 18421, It: 0, Loss Data: 4.307e-02, Loss Eqns: 7.755e-01, Loss Aux: 5.099e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18422, It: 0, Loss Data: 4.557e-02, Loss Eqns: 8.067e-01, Loss Aux: 5.475e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18423, It: 0, Loss Data: 4.284e-02, Loss Eqns: 7.885e-01, Loss Aux: 5.657e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18424, It: 0, Loss Data: 4.300e-02, Loss Eqns: 7.767e-01, Loss Aux: 5.410e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18425, It: 0, Loss Data: 3.583e-02, Loss Eqns: 7.630e-01, Loss Aux: 5.199e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18426, It: 0, Loss Data: 4.581e-02, Loss Eqns: 7.725e-01, Loss Aux: 5.568e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18427, It: 0, Loss Data: 5.026e-02, Loss Eqns: 7.714e-01, Loss Aux: 6.145e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18428, It: 0, Loss Data: 4.363e-02, Loss Eqns: 7.814e-01, Loss Aux: 5.505e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18429, It: 0, Loss Data: 4.609e-02, Loss Eqns: 7.685e-01, Loss Aux: 4.938e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18430, It: 0, Loss Data: 4.291e-02, Loss Eqns: 7.737e-01, Loss Aux: 4.907e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18431, It: 0, Loss Data: 4.736e-02, Loss Eqns: 7.802e-01, Loss Aux: 5.332e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18432, It: 0, Loss Data: 5.042e-02, Loss Eqns: 7.639e-01, Loss Aux: 5.725e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18433, It: 0, Loss Data: 4.619e-02, Loss Eqns: 7.876e-01, Loss Aux: 5.590e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18434, It: 0, Loss Data: 4.269e-02, Loss Eqns: 7.523e-01, Loss Aux: 5.639e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18435, It: 0, Loss Data: 4.952e-02, Loss Eqns: 7.733e-01, Loss Aux: 6.303e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18436, It: 0, Loss Data: 4.851e-02, Loss Eqns: 7.653e-01, Loss Aux: 6.225e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 18437, It: 0, Loss Data: 4.430e-02, Loss Eqns: 7.924e-01, Loss Aux: 5.226e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18438, It: 0, Loss Data: 4.089e-02, Loss Eqns: 8.158e-01, Loss Aux: 4.821e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18439, It: 0, Loss Data: 4.654e-02, Loss Eqns: 8.246e-01, Loss Aux: 4.821e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18440, It: 0, Loss Data: 4.579e-02, Loss Eqns: 8.111e-01, Loss Aux: 4.866e-02, Time: 0.211, Learning Rate: 1.0e-03\n",
      "Epoch: 18441, It: 0, Loss Data: 4.544e-02, Loss Eqns: 8.074e-01, Loss Aux: 5.073e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18442, It: 0, Loss Data: 3.897e-02, Loss Eqns: 7.579e-01, Loss Aux: 5.154e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18443, It: 0, Loss Data: 4.912e-02, Loss Eqns: 7.845e-01, Loss Aux: 5.292e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18444, It: 0, Loss Data: 4.047e-02, Loss Eqns: 7.688e-01, Loss Aux: 5.794e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18445, It: 0, Loss Data: 4.227e-02, Loss Eqns: 8.184e-01, Loss Aux: 5.844e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18446, It: 0, Loss Data: 4.434e-02, Loss Eqns: 7.992e-01, Loss Aux: 5.669e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18447, It: 0, Loss Data: 4.610e-02, Loss Eqns: 7.765e-01, Loss Aux: 5.174e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18448, It: 0, Loss Data: 4.721e-02, Loss Eqns: 7.833e-01, Loss Aux: 5.128e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18449, It: 0, Loss Data: 4.366e-02, Loss Eqns: 7.694e-01, Loss Aux: 5.388e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18450, It: 0, Loss Data: 4.115e-02, Loss Eqns: 7.752e-01, Loss Aux: 5.471e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18451, It: 0, Loss Data: 3.973e-02, Loss Eqns: 7.859e-01, Loss Aux: 5.450e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18452, It: 0, Loss Data: 4.026e-02, Loss Eqns: 7.873e-01, Loss Aux: 5.649e-02, Time: 0.221, Learning Rate: 1.0e-03\n",
      "Epoch: 18453, It: 0, Loss Data: 4.719e-02, Loss Eqns: 7.786e-01, Loss Aux: 6.221e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18454, It: 0, Loss Data: 4.289e-02, Loss Eqns: 7.751e-01, Loss Aux: 6.535e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18455, It: 0, Loss Data: 4.613e-02, Loss Eqns: 7.603e-01, Loss Aux: 5.892e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18456, It: 0, Loss Data: 4.298e-02, Loss Eqns: 7.542e-01, Loss Aux: 5.122e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18457, It: 0, Loss Data: 4.275e-02, Loss Eqns: 7.806e-01, Loss Aux: 4.910e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18458, It: 0, Loss Data: 3.824e-02, Loss Eqns: 7.832e-01, Loss Aux: 5.014e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18459, It: 0, Loss Data: 5.024e-02, Loss Eqns: 7.936e-01, Loss Aux: 5.476e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18460, It: 0, Loss Data: 4.713e-02, Loss Eqns: 7.765e-01, Loss Aux: 5.666e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18461, It: 0, Loss Data: 3.994e-02, Loss Eqns: 7.591e-01, Loss Aux: 5.587e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18462, It: 0, Loss Data: 4.636e-02, Loss Eqns: 7.458e-01, Loss Aux: 5.831e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18463, It: 0, Loss Data: 4.587e-02, Loss Eqns: 7.539e-01, Loss Aux: 5.490e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18464, It: 0, Loss Data: 4.986e-02, Loss Eqns: 8.156e-01, Loss Aux: 5.001e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18465, It: 0, Loss Data: 4.648e-02, Loss Eqns: 7.718e-01, Loss Aux: 4.774e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18466, It: 0, Loss Data: 4.272e-02, Loss Eqns: 8.073e-01, Loss Aux: 5.029e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18467, It: 0, Loss Data: 4.356e-02, Loss Eqns: 7.683e-01, Loss Aux: 6.112e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18468, It: 0, Loss Data: 4.822e-02, Loss Eqns: 7.752e-01, Loss Aux: 6.363e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18469, It: 0, Loss Data: 4.158e-02, Loss Eqns: 7.919e-01, Loss Aux: 5.600e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18470, It: 0, Loss Data: 4.882e-02, Loss Eqns: 8.012e-01, Loss Aux: 5.164e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18471, It: 0, Loss Data: 4.200e-02, Loss Eqns: 7.887e-01, Loss Aux: 5.218e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18472, It: 0, Loss Data: 3.896e-02, Loss Eqns: 7.961e-01, Loss Aux: 5.337e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18473, It: 0, Loss Data: 4.113e-02, Loss Eqns: 8.036e-01, Loss Aux: 4.941e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18474, It: 0, Loss Data: 4.253e-02, Loss Eqns: 7.625e-01, Loss Aux: 4.719e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18475, It: 0, Loss Data: 4.202e-02, Loss Eqns: 7.483e-01, Loss Aux: 4.733e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18476, It: 0, Loss Data: 3.992e-02, Loss Eqns: 7.844e-01, Loss Aux: 5.193e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18477, It: 0, Loss Data: 4.541e-02, Loss Eqns: 7.416e-01, Loss Aux: 5.907e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 18478, It: 0, Loss Data: 4.019e-02, Loss Eqns: 7.391e-01, Loss Aux: 6.217e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18479, It: 0, Loss Data: 4.320e-02, Loss Eqns: 7.754e-01, Loss Aux: 5.744e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18480, It: 0, Loss Data: 4.202e-02, Loss Eqns: 7.449e-01, Loss Aux: 5.178e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18481, It: 0, Loss Data: 4.503e-02, Loss Eqns: 7.369e-01, Loss Aux: 5.342e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18482, It: 0, Loss Data: 4.391e-02, Loss Eqns: 7.360e-01, Loss Aux: 5.788e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18483, It: 0, Loss Data: 4.714e-02, Loss Eqns: 7.440e-01, Loss Aux: 5.483e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18484, It: 0, Loss Data: 4.611e-02, Loss Eqns: 7.729e-01, Loss Aux: 5.237e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18485, It: 0, Loss Data: 4.553e-02, Loss Eqns: 7.780e-01, Loss Aux: 5.207e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18486, It: 0, Loss Data: 3.590e-02, Loss Eqns: 7.717e-01, Loss Aux: 5.402e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18487, It: 0, Loss Data: 4.203e-02, Loss Eqns: 7.734e-01, Loss Aux: 5.857e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18488, It: 0, Loss Data: 4.013e-02, Loss Eqns: 7.769e-01, Loss Aux: 6.175e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18489, It: 0, Loss Data: 4.369e-02, Loss Eqns: 7.723e-01, Loss Aux: 5.680e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18490, It: 0, Loss Data: 4.596e-02, Loss Eqns: 7.625e-01, Loss Aux: 5.757e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18491, It: 0, Loss Data: 4.284e-02, Loss Eqns: 7.596e-01, Loss Aux: 5.527e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18492, It: 0, Loss Data: 4.362e-02, Loss Eqns: 7.854e-01, Loss Aux: 4.881e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18493, It: 0, Loss Data: 4.780e-02, Loss Eqns: 7.869e-01, Loss Aux: 4.724e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18494, It: 0, Loss Data: 4.442e-02, Loss Eqns: 7.746e-01, Loss Aux: 5.339e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18495, It: 0, Loss Data: 4.523e-02, Loss Eqns: 7.843e-01, Loss Aux: 6.594e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18496, It: 0, Loss Data: 3.470e-02, Loss Eqns: 7.550e-01, Loss Aux: 6.370e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18497, It: 0, Loss Data: 3.953e-02, Loss Eqns: 7.376e-01, Loss Aux: 5.391e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18498, It: 0, Loss Data: 4.691e-02, Loss Eqns: 7.605e-01, Loss Aux: 5.161e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18499, It: 0, Loss Data: 4.441e-02, Loss Eqns: 7.538e-01, Loss Aux: 5.074e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18500, It: 0, Loss Data: 4.100e-02, Loss Eqns: 7.644e-01, Loss Aux: 5.007e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18501, It: 0, Loss Data: 4.511e-02, Loss Eqns: 7.520e-01, Loss Aux: 5.012e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18502, It: 0, Loss Data: 4.683e-02, Loss Eqns: 7.643e-01, Loss Aux: 5.352e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18503, It: 0, Loss Data: 4.009e-02, Loss Eqns: 7.616e-01, Loss Aux: 5.501e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18504, It: 0, Loss Data: 4.080e-02, Loss Eqns: 7.608e-01, Loss Aux: 5.160e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18505, It: 0, Loss Data: 3.658e-02, Loss Eqns: 7.843e-01, Loss Aux: 4.749e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18506, It: 0, Loss Data: 4.843e-02, Loss Eqns: 7.758e-01, Loss Aux: 5.129e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18507, It: 0, Loss Data: 3.720e-02, Loss Eqns: 7.974e-01, Loss Aux: 5.319e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18508, It: 0, Loss Data: 5.017e-02, Loss Eqns: 7.559e-01, Loss Aux: 5.351e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18509, It: 0, Loss Data: 4.302e-02, Loss Eqns: 7.850e-01, Loss Aux: 5.264e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18510, It: 0, Loss Data: 4.285e-02, Loss Eqns: 7.494e-01, Loss Aux: 5.269e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18511, It: 0, Loss Data: 4.234e-02, Loss Eqns: 7.799e-01, Loss Aux: 5.348e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18512, It: 0, Loss Data: 4.325e-02, Loss Eqns: 7.609e-01, Loss Aux: 5.267e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18513, It: 0, Loss Data: 4.642e-02, Loss Eqns: 7.603e-01, Loss Aux: 5.194e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18514, It: 0, Loss Data: 4.089e-02, Loss Eqns: 7.678e-01, Loss Aux: 5.496e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18515, It: 0, Loss Data: 4.230e-02, Loss Eqns: 7.329e-01, Loss Aux: 5.630e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18516, It: 0, Loss Data: 4.958e-02, Loss Eqns: 7.717e-01, Loss Aux: 5.286e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18517, It: 0, Loss Data: 3.867e-02, Loss Eqns: 7.487e-01, Loss Aux: 5.090e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18518, It: 0, Loss Data: 5.223e-02, Loss Eqns: 7.431e-01, Loss Aux: 5.260e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18519, It: 0, Loss Data: 4.211e-02, Loss Eqns: 7.523e-01, Loss Aux: 5.546e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18520, It: 0, Loss Data: 4.427e-02, Loss Eqns: 7.695e-01, Loss Aux: 5.608e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18521, It: 0, Loss Data: 4.274e-02, Loss Eqns: 7.410e-01, Loss Aux: 5.342e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18522, It: 0, Loss Data: 4.607e-02, Loss Eqns: 7.824e-01, Loss Aux: 5.273e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18523, It: 0, Loss Data: 4.255e-02, Loss Eqns: 7.552e-01, Loss Aux: 5.422e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18524, It: 0, Loss Data: 4.111e-02, Loss Eqns: 7.828e-01, Loss Aux: 5.373e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18525, It: 0, Loss Data: 4.326e-02, Loss Eqns: 7.918e-01, Loss Aux: 5.091e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18526, It: 0, Loss Data: 4.299e-02, Loss Eqns: 7.765e-01, Loss Aux: 5.187e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18527, It: 0, Loss Data: 4.122e-02, Loss Eqns: 7.526e-01, Loss Aux: 5.637e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18528, It: 0, Loss Data: 3.785e-02, Loss Eqns: 7.425e-01, Loss Aux: 5.807e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18529, It: 0, Loss Data: 4.252e-02, Loss Eqns: 7.635e-01, Loss Aux: 5.555e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18530, It: 0, Loss Data: 4.481e-02, Loss Eqns: 7.633e-01, Loss Aux: 5.314e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18531, It: 0, Loss Data: 4.102e-02, Loss Eqns: 7.543e-01, Loss Aux: 5.441e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18532, It: 0, Loss Data: 4.123e-02, Loss Eqns: 7.758e-01, Loss Aux: 5.319e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18533, It: 0, Loss Data: 4.103e-02, Loss Eqns: 7.577e-01, Loss Aux: 4.954e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18534, It: 0, Loss Data: 3.785e-02, Loss Eqns: 7.480e-01, Loss Aux: 4.984e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18535, It: 0, Loss Data: 3.991e-02, Loss Eqns: 7.358e-01, Loss Aux: 5.192e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18536, It: 0, Loss Data: 4.422e-02, Loss Eqns: 6.976e-01, Loss Aux: 5.613e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18537, It: 0, Loss Data: 4.425e-02, Loss Eqns: 7.282e-01, Loss Aux: 5.332e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18538, It: 0, Loss Data: 3.991e-02, Loss Eqns: 7.548e-01, Loss Aux: 4.825e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18539, It: 0, Loss Data: 4.029e-02, Loss Eqns: 7.655e-01, Loss Aux: 4.915e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18540, It: 0, Loss Data: 4.142e-02, Loss Eqns: 7.379e-01, Loss Aux: 5.017e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18541, It: 0, Loss Data: 4.015e-02, Loss Eqns: 7.451e-01, Loss Aux: 5.425e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18542, It: 0, Loss Data: 4.296e-02, Loss Eqns: 7.386e-01, Loss Aux: 5.688e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18543, It: 0, Loss Data: 4.718e-02, Loss Eqns: 7.489e-01, Loss Aux: 5.298e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18544, It: 0, Loss Data: 4.322e-02, Loss Eqns: 7.484e-01, Loss Aux: 5.222e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18545, It: 0, Loss Data: 4.340e-02, Loss Eqns: 7.390e-01, Loss Aux: 5.283e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18546, It: 0, Loss Data: 3.854e-02, Loss Eqns: 7.722e-01, Loss Aux: 5.862e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18547, It: 0, Loss Data: 4.113e-02, Loss Eqns: 7.469e-01, Loss Aux: 6.122e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18548, It: 0, Loss Data: 4.622e-02, Loss Eqns: 7.357e-01, Loss Aux: 5.971e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18549, It: 0, Loss Data: 4.807e-02, Loss Eqns: 7.492e-01, Loss Aux: 5.632e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18550, It: 0, Loss Data: 4.543e-02, Loss Eqns: 7.699e-01, Loss Aux: 5.363e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 18551, It: 0, Loss Data: 4.679e-02, Loss Eqns: 7.862e-01, Loss Aux: 5.395e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18552, It: 0, Loss Data: 4.518e-02, Loss Eqns: 7.806e-01, Loss Aux: 5.481e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18553, It: 0, Loss Data: 4.824e-02, Loss Eqns: 7.753e-01, Loss Aux: 5.792e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18554, It: 0, Loss Data: 3.969e-02, Loss Eqns: 7.698e-01, Loss Aux: 5.340e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18555, It: 0, Loss Data: 4.374e-02, Loss Eqns: 7.762e-01, Loss Aux: 4.937e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18556, It: 0, Loss Data: 4.320e-02, Loss Eqns: 7.909e-01, Loss Aux: 5.378e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18557, It: 0, Loss Data: 4.162e-02, Loss Eqns: 7.831e-01, Loss Aux: 5.873e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18558, It: 0, Loss Data: 4.015e-02, Loss Eqns: 8.016e-01, Loss Aux: 5.299e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18559, It: 0, Loss Data: 4.502e-02, Loss Eqns: 7.690e-01, Loss Aux: 4.775e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18560, It: 0, Loss Data: 4.589e-02, Loss Eqns: 7.828e-01, Loss Aux: 4.733e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18561, It: 0, Loss Data: 4.153e-02, Loss Eqns: 7.555e-01, Loss Aux: 5.330e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18562, It: 0, Loss Data: 4.438e-02, Loss Eqns: 7.809e-01, Loss Aux: 5.713e-02, Time: 0.205, Learning Rate: 1.0e-03\n",
      "Epoch: 18563, It: 0, Loss Data: 4.206e-02, Loss Eqns: 7.692e-01, Loss Aux: 5.289e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18564, It: 0, Loss Data: 4.379e-02, Loss Eqns: 7.663e-01, Loss Aux: 4.974e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18565, It: 0, Loss Data: 4.457e-02, Loss Eqns: 7.674e-01, Loss Aux: 5.069e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18566, It: 0, Loss Data: 4.289e-02, Loss Eqns: 7.587e-01, Loss Aux: 5.157e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18567, It: 0, Loss Data: 4.231e-02, Loss Eqns: 7.590e-01, Loss Aux: 5.183e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18568, It: 0, Loss Data: 4.031e-02, Loss Eqns: 7.529e-01, Loss Aux: 5.246e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18569, It: 0, Loss Data: 4.564e-02, Loss Eqns: 7.786e-01, Loss Aux: 5.488e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18570, It: 0, Loss Data: 3.879e-02, Loss Eqns: 8.193e-01, Loss Aux: 5.911e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18571, It: 0, Loss Data: 4.305e-02, Loss Eqns: 8.080e-01, Loss Aux: 5.956e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18572, It: 0, Loss Data: 4.166e-02, Loss Eqns: 7.878e-01, Loss Aux: 4.975e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18573, It: 0, Loss Data: 4.141e-02, Loss Eqns: 7.832e-01, Loss Aux: 4.707e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18574, It: 0, Loss Data: 5.050e-02, Loss Eqns: 7.877e-01, Loss Aux: 4.935e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18575, It: 0, Loss Data: 3.982e-02, Loss Eqns: 7.543e-01, Loss Aux: 5.215e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18576, It: 0, Loss Data: 4.296e-02, Loss Eqns: 7.890e-01, Loss Aux: 5.381e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18577, It: 0, Loss Data: 4.340e-02, Loss Eqns: 7.665e-01, Loss Aux: 5.404e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 18578, It: 0, Loss Data: 4.381e-02, Loss Eqns: 7.535e-01, Loss Aux: 5.384e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18579, It: 0, Loss Data: 4.219e-02, Loss Eqns: 7.518e-01, Loss Aux: 5.619e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18580, It: 0, Loss Data: 4.159e-02, Loss Eqns: 7.662e-01, Loss Aux: 5.469e-02, Time: 0.202, Learning Rate: 1.0e-03\n",
      "Epoch: 18581, It: 0, Loss Data: 4.095e-02, Loss Eqns: 7.728e-01, Loss Aux: 5.213e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18582, It: 0, Loss Data: 3.754e-02, Loss Eqns: 7.614e-01, Loss Aux: 5.276e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18583, It: 0, Loss Data: 3.695e-02, Loss Eqns: 7.640e-01, Loss Aux: 5.340e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 18584, It: 0, Loss Data: 4.212e-02, Loss Eqns: 7.453e-01, Loss Aux: 5.406e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18585, It: 0, Loss Data: 4.420e-02, Loss Eqns: 7.544e-01, Loss Aux: 5.535e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18586, It: 0, Loss Data: 4.075e-02, Loss Eqns: 7.678e-01, Loss Aux: 5.400e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18587, It: 0, Loss Data: 4.115e-02, Loss Eqns: 7.358e-01, Loss Aux: 5.232e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18588, It: 0, Loss Data: 4.344e-02, Loss Eqns: 7.644e-01, Loss Aux: 5.078e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18589, It: 0, Loss Data: 4.800e-02, Loss Eqns: 7.652e-01, Loss Aux: 5.218e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18590, It: 0, Loss Data: 4.212e-02, Loss Eqns: 7.546e-01, Loss Aux: 5.799e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18591, It: 0, Loss Data: 4.348e-02, Loss Eqns: 7.754e-01, Loss Aux: 5.961e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18592, It: 0, Loss Data: 4.640e-02, Loss Eqns: 7.423e-01, Loss Aux: 5.408e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18593, It: 0, Loss Data: 4.295e-02, Loss Eqns: 7.627e-01, Loss Aux: 4.941e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18594, It: 0, Loss Data: 4.284e-02, Loss Eqns: 7.576e-01, Loss Aux: 5.085e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18595, It: 0, Loss Data: 4.409e-02, Loss Eqns: 7.494e-01, Loss Aux: 5.658e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18596, It: 0, Loss Data: 4.348e-02, Loss Eqns: 7.578e-01, Loss Aux: 5.522e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18597, It: 0, Loss Data: 4.399e-02, Loss Eqns: 7.549e-01, Loss Aux: 5.261e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18598, It: 0, Loss Data: 4.004e-02, Loss Eqns: 7.815e-01, Loss Aux: 5.082e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18599, It: 0, Loss Data: 4.284e-02, Loss Eqns: 7.612e-01, Loss Aux: 5.131e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18600, It: 0, Loss Data: 4.176e-02, Loss Eqns: 7.750e-01, Loss Aux: 6.060e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18601, It: 0, Loss Data: 4.535e-02, Loss Eqns: 7.375e-01, Loss Aux: 6.303e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18602, It: 0, Loss Data: 4.034e-02, Loss Eqns: 7.445e-01, Loss Aux: 5.401e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 18603, It: 0, Loss Data: 4.467e-02, Loss Eqns: 7.463e-01, Loss Aux: 4.993e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18604, It: 0, Loss Data: 3.912e-02, Loss Eqns: 7.659e-01, Loss Aux: 5.004e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18605, It: 0, Loss Data: 3.922e-02, Loss Eqns: 7.675e-01, Loss Aux: 5.069e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18606, It: 0, Loss Data: 4.159e-02, Loss Eqns: 7.377e-01, Loss Aux: 5.109e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18607, It: 0, Loss Data: 4.230e-02, Loss Eqns: 7.755e-01, Loss Aux: 5.354e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18608, It: 0, Loss Data: 4.263e-02, Loss Eqns: 7.727e-01, Loss Aux: 6.121e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18609, It: 0, Loss Data: 4.083e-02, Loss Eqns: 7.267e-01, Loss Aux: 5.854e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 18610, It: 0, Loss Data: 4.359e-02, Loss Eqns: 7.649e-01, Loss Aux: 5.149e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18611, It: 0, Loss Data: 4.070e-02, Loss Eqns: 7.550e-01, Loss Aux: 4.851e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18612, It: 0, Loss Data: 4.627e-02, Loss Eqns: 7.442e-01, Loss Aux: 5.085e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18613, It: 0, Loss Data: 3.971e-02, Loss Eqns: 7.890e-01, Loss Aux: 5.660e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18614, It: 0, Loss Data: 4.327e-02, Loss Eqns: 7.669e-01, Loss Aux: 6.052e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18615, It: 0, Loss Data: 4.400e-02, Loss Eqns: 7.572e-01, Loss Aux: 5.800e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18616, It: 0, Loss Data: 4.716e-02, Loss Eqns: 7.706e-01, Loss Aux: 5.527e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18617, It: 0, Loss Data: 3.805e-02, Loss Eqns: 7.533e-01, Loss Aux: 5.282e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18618, It: 0, Loss Data: 4.228e-02, Loss Eqns: 7.538e-01, Loss Aux: 5.134e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18619, It: 0, Loss Data: 4.284e-02, Loss Eqns: 7.503e-01, Loss Aux: 5.335e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18620, It: 0, Loss Data: 3.486e-02, Loss Eqns: 7.647e-01, Loss Aux: 5.451e-02, Time: 0.209, Learning Rate: 1.0e-03\n",
      "Epoch: 18621, It: 0, Loss Data: 3.971e-02, Loss Eqns: 7.629e-01, Loss Aux: 5.393e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18622, It: 0, Loss Data: 4.056e-02, Loss Eqns: 7.365e-01, Loss Aux: 5.142e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18623, It: 0, Loss Data: 4.340e-02, Loss Eqns: 7.514e-01, Loss Aux: 5.251e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18624, It: 0, Loss Data: 4.172e-02, Loss Eqns: 7.861e-01, Loss Aux: 4.870e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18625, It: 0, Loss Data: 3.643e-02, Loss Eqns: 7.663e-01, Loss Aux: 4.813e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18626, It: 0, Loss Data: 4.064e-02, Loss Eqns: 7.427e-01, Loss Aux: 5.446e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18627, It: 0, Loss Data: 4.648e-02, Loss Eqns: 7.495e-01, Loss Aux: 6.112e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18628, It: 0, Loss Data: 4.545e-02, Loss Eqns: 7.507e-01, Loss Aux: 5.816e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18629, It: 0, Loss Data: 4.453e-02, Loss Eqns: 7.450e-01, Loss Aux: 5.621e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18630, It: 0, Loss Data: 3.817e-02, Loss Eqns: 7.710e-01, Loss Aux: 5.302e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18631, It: 0, Loss Data: 3.771e-02, Loss Eqns: 7.564e-01, Loss Aux: 5.262e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18632, It: 0, Loss Data: 3.758e-02, Loss Eqns: 7.785e-01, Loss Aux: 5.109e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18633, It: 0, Loss Data: 4.267e-02, Loss Eqns: 7.834e-01, Loss Aux: 4.737e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18634, It: 0, Loss Data: 3.825e-02, Loss Eqns: 7.507e-01, Loss Aux: 5.133e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18635, It: 0, Loss Data: 4.418e-02, Loss Eqns: 7.258e-01, Loss Aux: 6.096e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18636, It: 0, Loss Data: 4.210e-02, Loss Eqns: 7.455e-01, Loss Aux: 5.887e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18637, It: 0, Loss Data: 4.570e-02, Loss Eqns: 7.449e-01, Loss Aux: 5.336e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18638, It: 0, Loss Data: 4.169e-02, Loss Eqns: 7.707e-01, Loss Aux: 5.137e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18639, It: 0, Loss Data: 4.417e-02, Loss Eqns: 7.706e-01, Loss Aux: 5.102e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18640, It: 0, Loss Data: 4.295e-02, Loss Eqns: 7.433e-01, Loss Aux: 5.001e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18641, It: 0, Loss Data: 4.763e-02, Loss Eqns: 7.709e-01, Loss Aux: 5.121e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18642, It: 0, Loss Data: 3.780e-02, Loss Eqns: 7.163e-01, Loss Aux: 5.142e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18643, It: 0, Loss Data: 3.961e-02, Loss Eqns: 7.328e-01, Loss Aux: 5.415e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18644, It: 0, Loss Data: 4.510e-02, Loss Eqns: 7.598e-01, Loss Aux: 5.427e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18645, It: 0, Loss Data: 4.219e-02, Loss Eqns: 7.528e-01, Loss Aux: 5.454e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18646, It: 0, Loss Data: 4.295e-02, Loss Eqns: 7.604e-01, Loss Aux: 5.258e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18647, It: 0, Loss Data: 3.634e-02, Loss Eqns: 7.365e-01, Loss Aux: 5.016e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18648, It: 0, Loss Data: 4.181e-02, Loss Eqns: 7.787e-01, Loss Aux: 5.052e-02, Time: 0.206, Learning Rate: 1.0e-03\n",
      "Epoch: 18649, It: 0, Loss Data: 4.507e-02, Loss Eqns: 7.349e-01, Loss Aux: 5.507e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18650, It: 0, Loss Data: 4.182e-02, Loss Eqns: 7.477e-01, Loss Aux: 5.692e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18651, It: 0, Loss Data: 4.291e-02, Loss Eqns: 7.820e-01, Loss Aux: 5.252e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18652, It: 0, Loss Data: 4.134e-02, Loss Eqns: 7.803e-01, Loss Aux: 5.085e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18653, It: 0, Loss Data: 3.570e-02, Loss Eqns: 7.634e-01, Loss Aux: 5.150e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18654, It: 0, Loss Data: 4.196e-02, Loss Eqns: 7.561e-01, Loss Aux: 5.497e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 18655, It: 0, Loss Data: 4.225e-02, Loss Eqns: 7.805e-01, Loss Aux: 5.643e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18656, It: 0, Loss Data: 3.886e-02, Loss Eqns: 7.808e-01, Loss Aux: 5.254e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18657, It: 0, Loss Data: 3.844e-02, Loss Eqns: 7.622e-01, Loss Aux: 5.082e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 18658, It: 0, Loss Data: 4.151e-02, Loss Eqns: 7.711e-01, Loss Aux: 5.194e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18659, It: 0, Loss Data: 4.478e-02, Loss Eqns: 7.718e-01, Loss Aux: 5.903e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18660, It: 0, Loss Data: 3.622e-02, Loss Eqns: 7.595e-01, Loss Aux: 5.850e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18661, It: 0, Loss Data: 4.361e-02, Loss Eqns: 7.532e-01, Loss Aux: 5.156e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18662, It: 0, Loss Data: 4.324e-02, Loss Eqns: 7.515e-01, Loss Aux: 5.199e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18663, It: 0, Loss Data: 3.953e-02, Loss Eqns: 7.530e-01, Loss Aux: 5.352e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18664, It: 0, Loss Data: 3.671e-02, Loss Eqns: 7.362e-01, Loss Aux: 5.341e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18665, It: 0, Loss Data: 4.099e-02, Loss Eqns: 7.500e-01, Loss Aux: 5.237e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18666, It: 0, Loss Data: 4.035e-02, Loss Eqns: 7.654e-01, Loss Aux: 5.270e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18667, It: 0, Loss Data: 4.187e-02, Loss Eqns: 7.257e-01, Loss Aux: 5.254e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18668, It: 0, Loss Data: 4.118e-02, Loss Eqns: 7.542e-01, Loss Aux: 5.394e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18669, It: 0, Loss Data: 4.668e-02, Loss Eqns: 7.384e-01, Loss Aux: 5.099e-02, Time: 0.231, Learning Rate: 1.0e-03\n",
      "Epoch: 18670, It: 0, Loss Data: 4.005e-02, Loss Eqns: 7.480e-01, Loss Aux: 5.244e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18671, It: 0, Loss Data: 4.179e-02, Loss Eqns: 7.754e-01, Loss Aux: 4.941e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18672, It: 0, Loss Data: 3.788e-02, Loss Eqns: 7.597e-01, Loss Aux: 5.651e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18673, It: 0, Loss Data: 4.019e-02, Loss Eqns: 7.494e-01, Loss Aux: 6.170e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18674, It: 0, Loss Data: 4.333e-02, Loss Eqns: 7.566e-01, Loss Aux: 5.487e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18675, It: 0, Loss Data: 4.136e-02, Loss Eqns: 7.419e-01, Loss Aux: 4.865e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18676, It: 0, Loss Data: 4.107e-02, Loss Eqns: 7.779e-01, Loss Aux: 4.809e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18677, It: 0, Loss Data: 3.908e-02, Loss Eqns: 7.399e-01, Loss Aux: 5.531e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18678, It: 0, Loss Data: 3.994e-02, Loss Eqns: 7.816e-01, Loss Aux: 6.428e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18679, It: 0, Loss Data: 4.357e-02, Loss Eqns: 7.315e-01, Loss Aux: 5.173e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18680, It: 0, Loss Data: 4.022e-02, Loss Eqns: 7.577e-01, Loss Aux: 4.899e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18681, It: 0, Loss Data: 3.769e-02, Loss Eqns: 7.442e-01, Loss Aux: 5.557e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18682, It: 0, Loss Data: 4.208e-02, Loss Eqns: 7.443e-01, Loss Aux: 6.094e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18683, It: 0, Loss Data: 4.316e-02, Loss Eqns: 7.261e-01, Loss Aux: 5.273e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18684, It: 0, Loss Data: 4.135e-02, Loss Eqns: 7.498e-01, Loss Aux: 4.849e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18685, It: 0, Loss Data: 4.665e-02, Loss Eqns: 7.665e-01, Loss Aux: 5.146e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18686, It: 0, Loss Data: 4.177e-02, Loss Eqns: 7.585e-01, Loss Aux: 5.841e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18687, It: 0, Loss Data: 3.654e-02, Loss Eqns: 7.470e-01, Loss Aux: 5.627e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18688, It: 0, Loss Data: 3.928e-02, Loss Eqns: 7.366e-01, Loss Aux: 5.044e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18689, It: 0, Loss Data: 3.829e-02, Loss Eqns: 7.576e-01, Loss Aux: 5.141e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18690, It: 0, Loss Data: 4.351e-02, Loss Eqns: 7.389e-01, Loss Aux: 5.424e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18691, It: 0, Loss Data: 3.752e-02, Loss Eqns: 7.608e-01, Loss Aux: 5.456e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18692, It: 0, Loss Data: 3.746e-02, Loss Eqns: 7.034e-01, Loss Aux: 5.212e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18693, It: 0, Loss Data: 4.550e-02, Loss Eqns: 7.446e-01, Loss Aux: 5.300e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18694, It: 0, Loss Data: 3.916e-02, Loss Eqns: 7.417e-01, Loss Aux: 5.467e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18695, It: 0, Loss Data: 3.779e-02, Loss Eqns: 6.993e-01, Loss Aux: 5.726e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18696, It: 0, Loss Data: 3.606e-02, Loss Eqns: 7.230e-01, Loss Aux: 5.716e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18697, It: 0, Loss Data: 4.151e-02, Loss Eqns: 6.911e-01, Loss Aux: 5.646e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18698, It: 0, Loss Data: 4.124e-02, Loss Eqns: 7.241e-01, Loss Aux: 5.225e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18699, It: 0, Loss Data: 4.472e-02, Loss Eqns: 7.097e-01, Loss Aux: 5.111e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18700, It: 0, Loss Data: 3.549e-02, Loss Eqns: 7.426e-01, Loss Aux: 4.997e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18701, It: 0, Loss Data: 4.134e-02, Loss Eqns: 7.322e-01, Loss Aux: 5.288e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18702, It: 0, Loss Data: 3.658e-02, Loss Eqns: 7.244e-01, Loss Aux: 5.758e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18703, It: 0, Loss Data: 4.391e-02, Loss Eqns: 7.042e-01, Loss Aux: 5.746e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18704, It: 0, Loss Data: 3.981e-02, Loss Eqns: 7.009e-01, Loss Aux: 5.604e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18705, It: 0, Loss Data: 3.884e-02, Loss Eqns: 7.531e-01, Loss Aux: 5.335e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18706, It: 0, Loss Data: 4.179e-02, Loss Eqns: 7.474e-01, Loss Aux: 5.184e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18707, It: 0, Loss Data: 4.208e-02, Loss Eqns: 7.526e-01, Loss Aux: 4.903e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18708, It: 0, Loss Data: 4.265e-02, Loss Eqns: 7.596e-01, Loss Aux: 4.885e-02, Time: 0.223, Learning Rate: 1.0e-03\n",
      "Epoch: 18709, It: 0, Loss Data: 4.509e-02, Loss Eqns: 7.423e-01, Loss Aux: 5.456e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18710, It: 0, Loss Data: 3.941e-02, Loss Eqns: 7.207e-01, Loss Aux: 5.477e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18711, It: 0, Loss Data: 4.234e-02, Loss Eqns: 7.308e-01, Loss Aux: 5.309e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18712, It: 0, Loss Data: 4.436e-02, Loss Eqns: 7.182e-01, Loss Aux: 5.342e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18713, It: 0, Loss Data: 4.180e-02, Loss Eqns: 7.813e-01, Loss Aux: 5.480e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18714, It: 0, Loss Data: 4.455e-02, Loss Eqns: 7.409e-01, Loss Aux: 5.244e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18715, It: 0, Loss Data: 4.413e-02, Loss Eqns: 7.508e-01, Loss Aux: 5.011e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18716, It: 0, Loss Data: 3.517e-02, Loss Eqns: 7.797e-01, Loss Aux: 5.005e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18717, It: 0, Loss Data: 4.087e-02, Loss Eqns: 7.665e-01, Loss Aux: 5.317e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 18718, It: 0, Loss Data: 4.180e-02, Loss Eqns: 7.641e-01, Loss Aux: 5.308e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18719, It: 0, Loss Data: 4.134e-02, Loss Eqns: 7.652e-01, Loss Aux: 5.117e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18720, It: 0, Loss Data: 4.373e-02, Loss Eqns: 7.706e-01, Loss Aux: 5.084e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18721, It: 0, Loss Data: 4.556e-02, Loss Eqns: 7.671e-01, Loss Aux: 5.603e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18722, It: 0, Loss Data: 4.375e-02, Loss Eqns: 7.813e-01, Loss Aux: 6.050e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18723, It: 0, Loss Data: 3.932e-02, Loss Eqns: 7.589e-01, Loss Aux: 5.326e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18724, It: 0, Loss Data: 3.874e-02, Loss Eqns: 7.669e-01, Loss Aux: 4.987e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18725, It: 0, Loss Data: 3.921e-02, Loss Eqns: 7.449e-01, Loss Aux: 5.038e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18726, It: 0, Loss Data: 4.251e-02, Loss Eqns: 7.378e-01, Loss Aux: 5.250e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18727, It: 0, Loss Data: 4.146e-02, Loss Eqns: 7.468e-01, Loss Aux: 5.412e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18728, It: 0, Loss Data: 4.646e-02, Loss Eqns: 7.663e-01, Loss Aux: 5.130e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18729, It: 0, Loss Data: 4.125e-02, Loss Eqns: 7.578e-01, Loss Aux: 5.215e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 18730, It: 0, Loss Data: 3.679e-02, Loss Eqns: 7.463e-01, Loss Aux: 5.355e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18731, It: 0, Loss Data: 4.030e-02, Loss Eqns: 7.678e-01, Loss Aux: 5.524e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18732, It: 0, Loss Data: 4.008e-02, Loss Eqns: 7.597e-01, Loss Aux: 4.891e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18733, It: 0, Loss Data: 3.421e-02, Loss Eqns: 7.629e-01, Loss Aux: 4.528e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18734, It: 0, Loss Data: 3.915e-02, Loss Eqns: 7.601e-01, Loss Aux: 4.942e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 18735, It: 0, Loss Data: 4.128e-02, Loss Eqns: 7.377e-01, Loss Aux: 6.089e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18736, It: 0, Loss Data: 4.201e-02, Loss Eqns: 7.261e-01, Loss Aux: 6.246e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18737, It: 0, Loss Data: 3.931e-02, Loss Eqns: 7.460e-01, Loss Aux: 5.075e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18738, It: 0, Loss Data: 4.258e-02, Loss Eqns: 7.168e-01, Loss Aux: 4.793e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18739, It: 0, Loss Data: 3.850e-02, Loss Eqns: 7.426e-01, Loss Aux: 4.899e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18740, It: 0, Loss Data: 4.008e-02, Loss Eqns: 7.290e-01, Loss Aux: 5.350e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18741, It: 0, Loss Data: 4.265e-02, Loss Eqns: 7.403e-01, Loss Aux: 5.480e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18742, It: 0, Loss Data: 4.173e-02, Loss Eqns: 7.762e-01, Loss Aux: 5.241e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18743, It: 0, Loss Data: 4.623e-02, Loss Eqns: 7.779e-01, Loss Aux: 5.398e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 18744, It: 0, Loss Data: 4.189e-02, Loss Eqns: 8.066e-01, Loss Aux: 5.495e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18745, It: 0, Loss Data: 4.123e-02, Loss Eqns: 7.888e-01, Loss Aux: 5.673e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18746, It: 0, Loss Data: 3.995e-02, Loss Eqns: 7.603e-01, Loss Aux: 5.232e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18747, It: 0, Loss Data: 4.136e-02, Loss Eqns: 7.762e-01, Loss Aux: 5.363e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18748, It: 0, Loss Data: 4.322e-02, Loss Eqns: 7.626e-01, Loss Aux: 5.568e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18749, It: 0, Loss Data: 3.745e-02, Loss Eqns: 7.150e-01, Loss Aux: 5.455e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18750, It: 0, Loss Data: 3.843e-02, Loss Eqns: 7.352e-01, Loss Aux: 5.027e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18751, It: 0, Loss Data: 3.930e-02, Loss Eqns: 7.462e-01, Loss Aux: 5.078e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18752, It: 0, Loss Data: 4.318e-02, Loss Eqns: 7.504e-01, Loss Aux: 5.418e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18753, It: 0, Loss Data: 3.558e-02, Loss Eqns: 7.054e-01, Loss Aux: 5.333e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18754, It: 0, Loss Data: 3.807e-02, Loss Eqns: 7.121e-01, Loss Aux: 5.610e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18755, It: 0, Loss Data: 4.293e-02, Loss Eqns: 7.374e-01, Loss Aux: 6.178e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18756, It: 0, Loss Data: 4.448e-02, Loss Eqns: 7.215e-01, Loss Aux: 5.504e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18757, It: 0, Loss Data: 4.229e-02, Loss Eqns: 7.739e-01, Loss Aux: 4.949e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 18758, It: 0, Loss Data: 4.193e-02, Loss Eqns: 7.773e-01, Loss Aux: 5.112e-02, Time: 0.220, Learning Rate: 1.0e-03\n",
      "Epoch: 18759, It: 0, Loss Data: 4.176e-02, Loss Eqns: 7.575e-01, Loss Aux: 5.341e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 18760, It: 0, Loss Data: 4.178e-02, Loss Eqns: 7.791e-01, Loss Aux: 5.421e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18761, It: 0, Loss Data: 3.566e-02, Loss Eqns: 7.697e-01, Loss Aux: 5.309e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18762, It: 0, Loss Data: 4.200e-02, Loss Eqns: 7.897e-01, Loss Aux: 5.197e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 18763, It: 0, Loss Data: 4.421e-02, Loss Eqns: 7.865e-01, Loss Aux: 5.545e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18764, It: 0, Loss Data: 4.370e-02, Loss Eqns: 7.161e-01, Loss Aux: 5.368e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18765, It: 0, Loss Data: 3.532e-02, Loss Eqns: 7.712e-01, Loss Aux: 4.596e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18766, It: 0, Loss Data: 4.424e-02, Loss Eqns: 7.594e-01, Loss Aux: 4.849e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18767, It: 0, Loss Data: 3.637e-02, Loss Eqns: 7.519e-01, Loss Aux: 5.693e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18768, It: 0, Loss Data: 3.725e-02, Loss Eqns: 7.588e-01, Loss Aux: 5.840e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18769, It: 0, Loss Data: 4.070e-02, Loss Eqns: 7.794e-01, Loss Aux: 5.266e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18770, It: 0, Loss Data: 3.751e-02, Loss Eqns: 7.737e-01, Loss Aux: 5.055e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18771, It: 0, Loss Data: 4.358e-02, Loss Eqns: 7.730e-01, Loss Aux: 5.163e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18772, It: 0, Loss Data: 3.640e-02, Loss Eqns: 7.090e-01, Loss Aux: 5.323e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18773, It: 0, Loss Data: 5.006e-02, Loss Eqns: 7.288e-01, Loss Aux: 5.326e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18774, It: 0, Loss Data: 3.949e-02, Loss Eqns: 7.137e-01, Loss Aux: 5.022e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18775, It: 0, Loss Data: 4.147e-02, Loss Eqns: 7.602e-01, Loss Aux: 5.244e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18776, It: 0, Loss Data: 3.882e-02, Loss Eqns: 7.247e-01, Loss Aux: 5.533e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18777, It: 0, Loss Data: 4.224e-02, Loss Eqns: 7.358e-01, Loss Aux: 5.437e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18778, It: 0, Loss Data: 4.551e-02, Loss Eqns: 7.241e-01, Loss Aux: 5.182e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18779, It: 0, Loss Data: 4.058e-02, Loss Eqns: 7.748e-01, Loss Aux: 5.181e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 18780, It: 0, Loss Data: 3.833e-02, Loss Eqns: 7.311e-01, Loss Aux: 5.193e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18781, It: 0, Loss Data: 4.169e-02, Loss Eqns: 7.335e-01, Loss Aux: 5.372e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 18782, It: 0, Loss Data: 4.050e-02, Loss Eqns: 7.797e-01, Loss Aux: 5.692e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18783, It: 0, Loss Data: 4.084e-02, Loss Eqns: 7.316e-01, Loss Aux: 5.167e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18784, It: 0, Loss Data: 4.179e-02, Loss Eqns: 7.618e-01, Loss Aux: 5.040e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18785, It: 0, Loss Data: 3.850e-02, Loss Eqns: 7.658e-01, Loss Aux: 4.885e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18786, It: 0, Loss Data: 3.916e-02, Loss Eqns: 7.440e-01, Loss Aux: 5.262e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18787, It: 0, Loss Data: 4.062e-02, Loss Eqns: 7.130e-01, Loss Aux: 5.660e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18788, It: 0, Loss Data: 4.328e-02, Loss Eqns: 7.659e-01, Loss Aux: 5.735e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18789, It: 0, Loss Data: 4.117e-02, Loss Eqns: 7.562e-01, Loss Aux: 5.181e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18790, It: 0, Loss Data: 4.032e-02, Loss Eqns: 8.148e-01, Loss Aux: 4.859e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18791, It: 0, Loss Data: 4.165e-02, Loss Eqns: 7.779e-01, Loss Aux: 5.550e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18792, It: 0, Loss Data: 4.610e-02, Loss Eqns: 7.667e-01, Loss Aux: 6.190e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18793, It: 0, Loss Data: 4.108e-02, Loss Eqns: 7.653e-01, Loss Aux: 5.257e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18794, It: 0, Loss Data: 4.049e-02, Loss Eqns: 8.075e-01, Loss Aux: 4.812e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18795, It: 0, Loss Data: 3.746e-02, Loss Eqns: 7.866e-01, Loss Aux: 5.188e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18796, It: 0, Loss Data: 3.777e-02, Loss Eqns: 7.631e-01, Loss Aux: 5.630e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18797, It: 0, Loss Data: 3.812e-02, Loss Eqns: 7.367e-01, Loss Aux: 5.345e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18798, It: 0, Loss Data: 3.885e-02, Loss Eqns: 7.357e-01, Loss Aux: 4.979e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18799, It: 0, Loss Data: 4.112e-02, Loss Eqns: 7.567e-01, Loss Aux: 5.203e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18800, It: 0, Loss Data: 4.023e-02, Loss Eqns: 7.761e-01, Loss Aux: 5.520e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18801, It: 0, Loss Data: 3.700e-02, Loss Eqns: 7.649e-01, Loss Aux: 5.345e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18802, It: 0, Loss Data: 4.102e-02, Loss Eqns: 7.509e-01, Loss Aux: 4.915e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18803, It: 0, Loss Data: 4.015e-02, Loss Eqns: 7.744e-01, Loss Aux: 5.306e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18804, It: 0, Loss Data: 4.554e-02, Loss Eqns: 7.430e-01, Loss Aux: 5.684e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18805, It: 0, Loss Data: 3.800e-02, Loss Eqns: 7.218e-01, Loss Aux: 5.299e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18806, It: 0, Loss Data: 3.558e-02, Loss Eqns: 7.501e-01, Loss Aux: 4.918e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18807, It: 0, Loss Data: 3.781e-02, Loss Eqns: 7.279e-01, Loss Aux: 5.466e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18808, It: 0, Loss Data: 3.829e-02, Loss Eqns: 7.658e-01, Loss Aux: 5.882e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18809, It: 0, Loss Data: 3.631e-02, Loss Eqns: 7.321e-01, Loss Aux: 5.766e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18810, It: 0, Loss Data: 4.233e-02, Loss Eqns: 7.158e-01, Loss Aux: 5.605e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18811, It: 0, Loss Data: 4.058e-02, Loss Eqns: 7.074e-01, Loss Aux: 5.109e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18812, It: 0, Loss Data: 3.579e-02, Loss Eqns: 7.183e-01, Loss Aux: 4.984e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18813, It: 0, Loss Data: 4.150e-02, Loss Eqns: 7.280e-01, Loss Aux: 5.212e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18814, It: 0, Loss Data: 3.427e-02, Loss Eqns: 7.460e-01, Loss Aux: 5.751e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18815, It: 0, Loss Data: 3.861e-02, Loss Eqns: 7.365e-01, Loss Aux: 5.712e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18816, It: 0, Loss Data: 4.653e-02, Loss Eqns: 7.465e-01, Loss Aux: 5.068e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18817, It: 0, Loss Data: 4.201e-02, Loss Eqns: 7.749e-01, Loss Aux: 4.871e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18818, It: 0, Loss Data: 3.969e-02, Loss Eqns: 7.447e-01, Loss Aux: 5.170e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18819, It: 0, Loss Data: 4.166e-02, Loss Eqns: 7.191e-01, Loss Aux: 5.606e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18820, It: 0, Loss Data: 3.443e-02, Loss Eqns: 7.290e-01, Loss Aux: 5.810e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18821, It: 0, Loss Data: 4.223e-02, Loss Eqns: 7.527e-01, Loss Aux: 5.957e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18822, It: 0, Loss Data: 3.883e-02, Loss Eqns: 7.575e-01, Loss Aux: 5.685e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18823, It: 0, Loss Data: 4.518e-02, Loss Eqns: 7.192e-01, Loss Aux: 5.128e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18824, It: 0, Loss Data: 4.357e-02, Loss Eqns: 7.204e-01, Loss Aux: 5.103e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18825, It: 0, Loss Data: 4.294e-02, Loss Eqns: 7.482e-01, Loss Aux: 5.467e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18826, It: 0, Loss Data: 3.784e-02, Loss Eqns: 7.876e-01, Loss Aux: 5.580e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18827, It: 0, Loss Data: 3.606e-02, Loss Eqns: 7.702e-01, Loss Aux: 5.259e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18828, It: 0, Loss Data: 4.229e-02, Loss Eqns: 7.621e-01, Loss Aux: 5.178e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18829, It: 0, Loss Data: 3.938e-02, Loss Eqns: 7.748e-01, Loss Aux: 6.010e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18830, It: 0, Loss Data: 4.155e-02, Loss Eqns: 7.761e-01, Loss Aux: 6.379e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18831, It: 0, Loss Data: 4.146e-02, Loss Eqns: 7.523e-01, Loss Aux: 5.449e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18832, It: 0, Loss Data: 3.422e-02, Loss Eqns: 7.734e-01, Loss Aux: 5.090e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18833, It: 0, Loss Data: 4.328e-02, Loss Eqns: 7.735e-01, Loss Aux: 5.222e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18834, It: 0, Loss Data: 4.425e-02, Loss Eqns: 7.833e-01, Loss Aux: 5.374e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18835, It: 0, Loss Data: 3.863e-02, Loss Eqns: 7.485e-01, Loss Aux: 5.398e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 18836, It: 0, Loss Data: 3.961e-02, Loss Eqns: 7.396e-01, Loss Aux: 5.234e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18837, It: 0, Loss Data: 4.073e-02, Loss Eqns: 7.295e-01, Loss Aux: 5.315e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18838, It: 0, Loss Data: 4.044e-02, Loss Eqns: 7.003e-01, Loss Aux: 5.349e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18839, It: 0, Loss Data: 3.616e-02, Loss Eqns: 7.296e-01, Loss Aux: 5.229e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18840, It: 0, Loss Data: 4.566e-02, Loss Eqns: 7.324e-01, Loss Aux: 5.474e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18841, It: 0, Loss Data: 3.448e-02, Loss Eqns: 7.405e-01, Loss Aux: 6.275e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18842, It: 0, Loss Data: 3.935e-02, Loss Eqns: 7.469e-01, Loss Aux: 6.562e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18843, It: 0, Loss Data: 3.647e-02, Loss Eqns: 7.716e-01, Loss Aux: 5.450e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18844, It: 0, Loss Data: 4.347e-02, Loss Eqns: 7.169e-01, Loss Aux: 5.222e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18845, It: 0, Loss Data: 4.235e-02, Loss Eqns: 7.589e-01, Loss Aux: 5.088e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18846, It: 0, Loss Data: 4.358e-02, Loss Eqns: 7.122e-01, Loss Aux: 5.059e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18847, It: 0, Loss Data: 4.214e-02, Loss Eqns: 7.473e-01, Loss Aux: 4.978e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18848, It: 0, Loss Data: 3.477e-02, Loss Eqns: 7.373e-01, Loss Aux: 4.968e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18849, It: 0, Loss Data: 3.794e-02, Loss Eqns: 7.475e-01, Loss Aux: 5.360e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18850, It: 0, Loss Data: 4.103e-02, Loss Eqns: 7.071e-01, Loss Aux: 5.648e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18851, It: 0, Loss Data: 3.956e-02, Loss Eqns: 7.137e-01, Loss Aux: 5.262e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 18852, It: 0, Loss Data: 3.870e-02, Loss Eqns: 7.117e-01, Loss Aux: 5.177e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 18853, It: 0, Loss Data: 3.870e-02, Loss Eqns: 7.329e-01, Loss Aux: 5.930e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18854, It: 0, Loss Data: 3.370e-02, Loss Eqns: 7.103e-01, Loss Aux: 5.979e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18855, It: 0, Loss Data: 4.261e-02, Loss Eqns: 7.327e-01, Loss Aux: 5.321e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18856, It: 0, Loss Data: 4.396e-02, Loss Eqns: 7.657e-01, Loss Aux: 5.327e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18857, It: 0, Loss Data: 3.804e-02, Loss Eqns: 7.177e-01, Loss Aux: 5.446e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18858, It: 0, Loss Data: 3.939e-02, Loss Eqns: 7.612e-01, Loss Aux: 5.697e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18859, It: 0, Loss Data: 3.920e-02, Loss Eqns: 7.059e-01, Loss Aux: 5.567e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 18860, It: 0, Loss Data: 3.793e-02, Loss Eqns: 7.549e-01, Loss Aux: 5.369e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 18861, It: 0, Loss Data: 4.057e-02, Loss Eqns: 7.238e-01, Loss Aux: 5.527e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 18862, It: 0, Loss Data: 4.271e-02, Loss Eqns: 7.460e-01, Loss Aux: 5.740e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18863, It: 0, Loss Data: 3.793e-02, Loss Eqns: 7.443e-01, Loss Aux: 5.255e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18864, It: 0, Loss Data: 4.131e-02, Loss Eqns: 7.368e-01, Loss Aux: 4.656e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18865, It: 0, Loss Data: 3.983e-02, Loss Eqns: 7.115e-01, Loss Aux: 4.742e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18866, It: 0, Loss Data: 4.394e-02, Loss Eqns: 7.227e-01, Loss Aux: 5.470e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18867, It: 0, Loss Data: 3.904e-02, Loss Eqns: 7.578e-01, Loss Aux: 5.412e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18868, It: 0, Loss Data: 4.241e-02, Loss Eqns: 7.430e-01, Loss Aux: 4.771e-02, Time: 0.147, Learning Rate: 1.0e-03\n",
      "Epoch: 18869, It: 0, Loss Data: 3.917e-02, Loss Eqns: 7.236e-01, Loss Aux: 5.021e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18870, It: 0, Loss Data: 3.556e-02, Loss Eqns: 7.421e-01, Loss Aux: 5.266e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18871, It: 0, Loss Data: 4.375e-02, Loss Eqns: 7.260e-01, Loss Aux: 5.063e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 18872, It: 0, Loss Data: 3.919e-02, Loss Eqns: 7.457e-01, Loss Aux: 5.109e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18873, It: 0, Loss Data: 3.659e-02, Loss Eqns: 7.680e-01, Loss Aux: 5.182e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18874, It: 0, Loss Data: 4.041e-02, Loss Eqns: 7.407e-01, Loss Aux: 5.276e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18875, It: 0, Loss Data: 4.558e-02, Loss Eqns: 7.360e-01, Loss Aux: 5.352e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18876, It: 0, Loss Data: 3.423e-02, Loss Eqns: 7.389e-01, Loss Aux: 5.225e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18877, It: 0, Loss Data: 3.785e-02, Loss Eqns: 7.509e-01, Loss Aux: 5.229e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18878, It: 0, Loss Data: 3.825e-02, Loss Eqns: 7.754e-01, Loss Aux: 5.462e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18879, It: 0, Loss Data: 4.210e-02, Loss Eqns: 7.391e-01, Loss Aux: 5.707e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18880, It: 0, Loss Data: 4.206e-02, Loss Eqns: 7.620e-01, Loss Aux: 5.573e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18881, It: 0, Loss Data: 4.138e-02, Loss Eqns: 7.727e-01, Loss Aux: 5.375e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18882, It: 0, Loss Data: 3.873e-02, Loss Eqns: 7.443e-01, Loss Aux: 4.843e-02, Time: 0.226, Learning Rate: 1.0e-03\n",
      "Epoch: 18883, It: 0, Loss Data: 4.206e-02, Loss Eqns: 7.405e-01, Loss Aux: 4.834e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18884, It: 0, Loss Data: 3.986e-02, Loss Eqns: 7.113e-01, Loss Aux: 5.508e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18885, It: 0, Loss Data: 4.516e-02, Loss Eqns: 7.420e-01, Loss Aux: 5.587e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18886, It: 0, Loss Data: 3.513e-02, Loss Eqns: 7.301e-01, Loss Aux: 5.050e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18887, It: 0, Loss Data: 3.897e-02, Loss Eqns: 7.389e-01, Loss Aux: 5.096e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18888, It: 0, Loss Data: 4.038e-02, Loss Eqns: 7.458e-01, Loss Aux: 5.323e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18889, It: 0, Loss Data: 3.612e-02, Loss Eqns: 7.371e-01, Loss Aux: 5.269e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18890, It: 0, Loss Data: 3.838e-02, Loss Eqns: 7.367e-01, Loss Aux: 5.023e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18891, It: 0, Loss Data: 3.882e-02, Loss Eqns: 7.309e-01, Loss Aux: 5.399e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 18892, It: 0, Loss Data: 3.624e-02, Loss Eqns: 7.141e-01, Loss Aux: 6.524e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18893, It: 0, Loss Data: 4.250e-02, Loss Eqns: 7.339e-01, Loss Aux: 6.573e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18894, It: 0, Loss Data: 4.554e-02, Loss Eqns: 7.120e-01, Loss Aux: 5.469e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18895, It: 0, Loss Data: 3.570e-02, Loss Eqns: 7.510e-01, Loss Aux: 5.105e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18896, It: 0, Loss Data: 3.859e-02, Loss Eqns: 7.112e-01, Loss Aux: 5.454e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18897, It: 0, Loss Data: 4.258e-02, Loss Eqns: 7.215e-01, Loss Aux: 6.075e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18898, It: 0, Loss Data: 4.003e-02, Loss Eqns: 7.084e-01, Loss Aux: 5.655e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18899, It: 0, Loss Data: 3.948e-02, Loss Eqns: 7.395e-01, Loss Aux: 5.226e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18900, It: 0, Loss Data: 4.108e-02, Loss Eqns: 7.237e-01, Loss Aux: 4.999e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18901, It: 0, Loss Data: 3.754e-02, Loss Eqns: 7.448e-01, Loss Aux: 5.175e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18902, It: 0, Loss Data: 4.048e-02, Loss Eqns: 7.187e-01, Loss Aux: 5.630e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18903, It: 0, Loss Data: 4.498e-02, Loss Eqns: 6.918e-01, Loss Aux: 5.114e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18904, It: 0, Loss Data: 3.778e-02, Loss Eqns: 7.038e-01, Loss Aux: 5.224e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18905, It: 0, Loss Data: 3.692e-02, Loss Eqns: 7.233e-01, Loss Aux: 5.415e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 18906, It: 0, Loss Data: 3.819e-02, Loss Eqns: 7.341e-01, Loss Aux: 5.405e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18907, It: 0, Loss Data: 3.984e-02, Loss Eqns: 7.432e-01, Loss Aux: 5.207e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18908, It: 0, Loss Data: 3.980e-02, Loss Eqns: 7.113e-01, Loss Aux: 5.110e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18909, It: 0, Loss Data: 3.710e-02, Loss Eqns: 7.294e-01, Loss Aux: 5.282e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18910, It: 0, Loss Data: 3.532e-02, Loss Eqns: 7.367e-01, Loss Aux: 6.233e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18911, It: 0, Loss Data: 4.009e-02, Loss Eqns: 7.151e-01, Loss Aux: 6.311e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18912, It: 0, Loss Data: 3.544e-02, Loss Eqns: 7.089e-01, Loss Aux: 5.322e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18913, It: 0, Loss Data: 3.635e-02, Loss Eqns: 7.410e-01, Loss Aux: 4.680e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18914, It: 0, Loss Data: 3.896e-02, Loss Eqns: 7.318e-01, Loss Aux: 5.075e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18915, It: 0, Loss Data: 4.058e-02, Loss Eqns: 7.504e-01, Loss Aux: 6.064e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18916, It: 0, Loss Data: 3.827e-02, Loss Eqns: 7.549e-01, Loss Aux: 5.960e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18917, It: 0, Loss Data: 3.782e-02, Loss Eqns: 7.392e-01, Loss Aux: 5.244e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18918, It: 0, Loss Data: 3.971e-02, Loss Eqns: 7.422e-01, Loss Aux: 5.570e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18919, It: 0, Loss Data: 3.935e-02, Loss Eqns: 7.154e-01, Loss Aux: 5.917e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18920, It: 0, Loss Data: 4.143e-02, Loss Eqns: 7.352e-01, Loss Aux: 5.652e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 18921, It: 0, Loss Data: 3.791e-02, Loss Eqns: 7.519e-01, Loss Aux: 5.107e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18922, It: 0, Loss Data: 3.617e-02, Loss Eqns: 7.212e-01, Loss Aux: 5.024e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18923, It: 0, Loss Data: 3.580e-02, Loss Eqns: 7.308e-01, Loss Aux: 5.709e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18924, It: 0, Loss Data: 3.849e-02, Loss Eqns: 7.608e-01, Loss Aux: 6.223e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18925, It: 0, Loss Data: 4.073e-02, Loss Eqns: 7.189e-01, Loss Aux: 5.451e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18926, It: 0, Loss Data: 4.256e-02, Loss Eqns: 7.678e-01, Loss Aux: 5.072e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 18927, It: 0, Loss Data: 3.815e-02, Loss Eqns: 7.408e-01, Loss Aux: 5.109e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 18928, It: 0, Loss Data: 3.575e-02, Loss Eqns: 7.686e-01, Loss Aux: 5.530e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18929, It: 0, Loss Data: 3.755e-02, Loss Eqns: 7.252e-01, Loss Aux: 5.304e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18930, It: 0, Loss Data: 3.923e-02, Loss Eqns: 7.489e-01, Loss Aux: 4.918e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18931, It: 0, Loss Data: 3.678e-02, Loss Eqns: 7.126e-01, Loss Aux: 5.251e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18932, It: 0, Loss Data: 5.363e-02, Loss Eqns: 8.283e-01, Loss Aux: 4.783e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18933, It: 0, Loss Data: 5.613e-02, Loss Eqns: 8.006e-01, Loss Aux: 6.707e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18934, It: 0, Loss Data: 4.390e-02, Loss Eqns: 7.448e-01, Loss Aux: 5.570e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 18935, It: 0, Loss Data: 5.823e-02, Loss Eqns: 8.649e-01, Loss Aux: 4.829e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18936, It: 0, Loss Data: 4.289e-02, Loss Eqns: 7.361e-01, Loss Aux: 6.284e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 18937, It: 0, Loss Data: 5.491e-02, Loss Eqns: 7.960e-01, Loss Aux: 7.940e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 18938, It: 0, Loss Data: 4.374e-02, Loss Eqns: 7.439e-01, Loss Aux: 5.419e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18939, It: 0, Loss Data: 5.564e-02, Loss Eqns: 8.651e-01, Loss Aux: 4.764e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 18940, It: 0, Loss Data: 3.913e-02, Loss Eqns: 7.430e-01, Loss Aux: 5.107e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18941, It: 0, Loss Data: 4.655e-02, Loss Eqns: 8.477e-01, Loss Aux: 7.164e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18942, It: 0, Loss Data: 4.527e-02, Loss Eqns: 7.238e-01, Loss Aux: 5.577e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18943, It: 0, Loss Data: 4.986e-02, Loss Eqns: 8.086e-01, Loss Aux: 4.771e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18944, It: 0, Loss Data: 4.465e-02, Loss Eqns: 7.606e-01, Loss Aux: 5.296e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18945, It: 0, Loss Data: 4.574e-02, Loss Eqns: 7.895e-01, Loss Aux: 6.529e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18946, It: 0, Loss Data: 3.501e-02, Loss Eqns: 7.401e-01, Loss Aux: 5.347e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18947, It: 0, Loss Data: 3.854e-02, Loss Eqns: 7.434e-01, Loss Aux: 4.753e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18948, It: 0, Loss Data: 4.043e-02, Loss Eqns: 7.454e-01, Loss Aux: 5.315e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18949, It: 0, Loss Data: 4.071e-02, Loss Eqns: 7.755e-01, Loss Aux: 5.722e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 18950, It: 0, Loss Data: 3.839e-02, Loss Eqns: 7.410e-01, Loss Aux: 5.210e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 18951, It: 0, Loss Data: 4.437e-02, Loss Eqns: 7.314e-01, Loss Aux: 5.139e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18952, It: 0, Loss Data: 4.285e-02, Loss Eqns: 7.477e-01, Loss Aux: 5.703e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18953, It: 0, Loss Data: 4.187e-02, Loss Eqns: 7.294e-01, Loss Aux: 5.994e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18954, It: 0, Loss Data: 4.018e-02, Loss Eqns: 7.634e-01, Loss Aux: 5.695e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 18955, It: 0, Loss Data: 3.561e-02, Loss Eqns: 7.220e-01, Loss Aux: 5.244e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18956, It: 0, Loss Data: 3.276e-02, Loss Eqns: 7.576e-01, Loss Aux: 5.486e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18957, It: 0, Loss Data: 4.149e-02, Loss Eqns: 7.317e-01, Loss Aux: 5.860e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18958, It: 0, Loss Data: 4.070e-02, Loss Eqns: 7.512e-01, Loss Aux: 5.497e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 18959, It: 0, Loss Data: 3.758e-02, Loss Eqns: 7.262e-01, Loss Aux: 5.360e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 18960, It: 0, Loss Data: 3.960e-02, Loss Eqns: 7.318e-01, Loss Aux: 5.745e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18961, It: 0, Loss Data: 4.134e-02, Loss Eqns: 6.979e-01, Loss Aux: 5.596e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 18962, It: 0, Loss Data: 4.057e-02, Loss Eqns: 7.200e-01, Loss Aux: 5.316e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18963, It: 0, Loss Data: 3.780e-02, Loss Eqns: 7.104e-01, Loss Aux: 5.769e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18964, It: 0, Loss Data: 3.897e-02, Loss Eqns: 7.231e-01, Loss Aux: 5.883e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 18965, It: 0, Loss Data: 3.884e-02, Loss Eqns: 7.234e-01, Loss Aux: 5.334e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 18966, It: 0, Loss Data: 4.057e-02, Loss Eqns: 7.476e-01, Loss Aux: 5.247e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 18967, It: 0, Loss Data: 3.920e-02, Loss Eqns: 7.206e-01, Loss Aux: 5.596e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18968, It: 0, Loss Data: 3.844e-02, Loss Eqns: 7.362e-01, Loss Aux: 5.419e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18969, It: 0, Loss Data: 3.830e-02, Loss Eqns: 7.238e-01, Loss Aux: 4.905e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 18970, It: 0, Loss Data: 4.180e-02, Loss Eqns: 7.023e-01, Loss Aux: 5.323e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18971, It: 0, Loss Data: 3.660e-02, Loss Eqns: 7.033e-01, Loss Aux: 6.034e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 18972, It: 0, Loss Data: 3.369e-02, Loss Eqns: 7.421e-01, Loss Aux: 5.759e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 18973, It: 0, Loss Data: 3.776e-02, Loss Eqns: 6.914e-01, Loss Aux: 5.061e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 18974, It: 0, Loss Data: 4.408e-02, Loss Eqns: 7.163e-01, Loss Aux: 5.312e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 18975, It: 0, Loss Data: 3.711e-02, Loss Eqns: 7.033e-01, Loss Aux: 6.055e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18976, It: 0, Loss Data: 4.293e-02, Loss Eqns: 7.243e-01, Loss Aux: 5.447e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 18977, It: 0, Loss Data: 4.006e-02, Loss Eqns: 7.198e-01, Loss Aux: 5.158e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 18978, It: 0, Loss Data: 3.944e-02, Loss Eqns: 7.325e-01, Loss Aux: 5.595e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18979, It: 0, Loss Data: 3.560e-02, Loss Eqns: 7.405e-01, Loss Aux: 6.520e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 18980, It: 0, Loss Data: 4.083e-02, Loss Eqns: 7.465e-01, Loss Aux: 5.932e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18981, It: 0, Loss Data: 4.315e-02, Loss Eqns: 7.773e-01, Loss Aux: 5.140e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 18982, It: 0, Loss Data: 3.628e-02, Loss Eqns: 7.782e-01, Loss Aux: 4.814e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 18983, It: 0, Loss Data: 3.927e-02, Loss Eqns: 7.455e-01, Loss Aux: 5.634e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 18984, It: 0, Loss Data: 3.770e-02, Loss Eqns: 7.271e-01, Loss Aux: 6.363e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 18985, It: 0, Loss Data: 4.137e-02, Loss Eqns: 7.077e-01, Loss Aux: 5.589e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 18986, It: 0, Loss Data: 4.207e-02, Loss Eqns: 7.345e-01, Loss Aux: 5.262e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18987, It: 0, Loss Data: 4.109e-02, Loss Eqns: 7.009e-01, Loss Aux: 5.564e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18988, It: 0, Loss Data: 4.200e-02, Loss Eqns: 7.237e-01, Loss Aux: 5.357e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 18989, It: 0, Loss Data: 3.775e-02, Loss Eqns: 7.148e-01, Loss Aux: 5.090e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18990, It: 0, Loss Data: 3.805e-02, Loss Eqns: 7.497e-01, Loss Aux: 5.301e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18991, It: 0, Loss Data: 3.554e-02, Loss Eqns: 7.421e-01, Loss Aux: 6.095e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 18992, It: 0, Loss Data: 4.077e-02, Loss Eqns: 7.130e-01, Loss Aux: 6.671e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 18993, It: 0, Loss Data: 3.443e-02, Loss Eqns: 7.355e-01, Loss Aux: 5.587e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 18994, It: 0, Loss Data: 4.105e-02, Loss Eqns: 7.361e-01, Loss Aux: 5.144e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 18995, It: 0, Loss Data: 4.309e-02, Loss Eqns: 7.573e-01, Loss Aux: 5.739e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 18996, It: 0, Loss Data: 3.872e-02, Loss Eqns: 7.268e-01, Loss Aux: 5.267e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 18997, It: 0, Loss Data: 4.246e-02, Loss Eqns: 7.433e-01, Loss Aux: 5.078e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 18998, It: 0, Loss Data: 3.638e-02, Loss Eqns: 7.052e-01, Loss Aux: 5.573e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 18999, It: 0, Loss Data: 3.687e-02, Loss Eqns: 7.436e-01, Loss Aux: 6.486e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19000, It: 0, Loss Data: 3.933e-02, Loss Eqns: 7.270e-01, Loss Aux: 5.689e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19001, It: 0, Loss Data: 4.350e-02, Loss Eqns: 7.405e-01, Loss Aux: 4.929e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19002, It: 0, Loss Data: 3.938e-02, Loss Eqns: 7.481e-01, Loss Aux: 5.026e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19003, It: 0, Loss Data: 4.020e-02, Loss Eqns: 7.822e-01, Loss Aux: 5.053e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19004, It: 0, Loss Data: 3.463e-02, Loss Eqns: 7.392e-01, Loss Aux: 5.870e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19005, It: 0, Loss Data: 3.927e-02, Loss Eqns: 7.358e-01, Loss Aux: 6.737e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19006, It: 0, Loss Data: 3.604e-02, Loss Eqns: 7.316e-01, Loss Aux: 5.490e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19007, It: 0, Loss Data: 3.700e-02, Loss Eqns: 7.268e-01, Loss Aux: 4.792e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19008, It: 0, Loss Data: 3.674e-02, Loss Eqns: 7.306e-01, Loss Aux: 4.887e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19009, It: 0, Loss Data: 4.316e-02, Loss Eqns: 7.399e-01, Loss Aux: 5.712e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19010, It: 0, Loss Data: 3.648e-02, Loss Eqns: 7.521e-01, Loss Aux: 5.928e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19011, It: 0, Loss Data: 4.287e-02, Loss Eqns: 7.511e-01, Loss Aux: 5.464e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19012, It: 0, Loss Data: 3.918e-02, Loss Eqns: 7.517e-01, Loss Aux: 5.213e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19013, It: 0, Loss Data: 3.719e-02, Loss Eqns: 7.277e-01, Loss Aux: 5.999e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19014, It: 0, Loss Data: 4.059e-02, Loss Eqns: 6.915e-01, Loss Aux: 5.976e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19015, It: 0, Loss Data: 3.906e-02, Loss Eqns: 7.381e-01, Loss Aux: 5.315e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19016, It: 0, Loss Data: 4.154e-02, Loss Eqns: 7.272e-01, Loss Aux: 5.238e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19017, It: 0, Loss Data: 3.539e-02, Loss Eqns: 7.410e-01, Loss Aux: 6.246e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19018, It: 0, Loss Data: 4.247e-02, Loss Eqns: 7.393e-01, Loss Aux: 6.425e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19019, It: 0, Loss Data: 3.758e-02, Loss Eqns: 7.558e-01, Loss Aux: 5.320e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19020, It: 0, Loss Data: 6.488e-02, Loss Eqns: 8.333e-01, Loss Aux: 5.221e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19021, It: 0, Loss Data: 5.385e-02, Loss Eqns: 8.321e-01, Loss Aux: 7.262e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19022, It: 0, Loss Data: 4.975e-02, Loss Eqns: 7.299e-01, Loss Aux: 1.003e-01, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19023, It: 0, Loss Data: 5.653e-02, Loss Eqns: 8.612e-01, Loss Aux: 6.117e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19024, It: 0, Loss Data: 5.031e-02, Loss Eqns: 7.201e-01, Loss Aux: 5.555e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19025, It: 0, Loss Data: 4.531e-02, Loss Eqns: 9.288e-01, Loss Aux: 6.547e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19026, It: 0, Loss Data: 3.813e-02, Loss Eqns: 7.358e-01, Loss Aux: 5.342e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19027, It: 0, Loss Data: 4.566e-02, Loss Eqns: 8.635e-01, Loss Aux: 5.157e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19028, It: 0, Loss Data: 4.464e-02, Loss Eqns: 7.432e-01, Loss Aux: 5.102e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19029, It: 0, Loss Data: 4.627e-02, Loss Eqns: 8.020e-01, Loss Aux: 6.258e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19030, It: 0, Loss Data: 4.174e-02, Loss Eqns: 7.008e-01, Loss Aux: 6.465e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19031, It: 0, Loss Data: 4.652e-02, Loss Eqns: 7.732e-01, Loss Aux: 5.568e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19032, It: 0, Loss Data: 3.670e-02, Loss Eqns: 7.272e-01, Loss Aux: 5.401e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19033, It: 0, Loss Data: 4.651e-02, Loss Eqns: 7.957e-01, Loss Aux: 5.431e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19034, It: 0, Loss Data: 4.124e-02, Loss Eqns: 7.242e-01, Loss Aux: 5.655e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19035, It: 0, Loss Data: 4.240e-02, Loss Eqns: 7.752e-01, Loss Aux: 5.582e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19036, It: 0, Loss Data: 3.882e-02, Loss Eqns: 7.474e-01, Loss Aux: 5.908e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19037, It: 0, Loss Data: 3.646e-02, Loss Eqns: 7.517e-01, Loss Aux: 5.948e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19038, It: 0, Loss Data: 3.444e-02, Loss Eqns: 7.071e-01, Loss Aux: 5.620e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19039, It: 0, Loss Data: 4.817e-02, Loss Eqns: 7.159e-01, Loss Aux: 5.950e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19040, It: 0, Loss Data: 4.065e-02, Loss Eqns: 7.204e-01, Loss Aux: 5.785e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19041, It: 0, Loss Data: 3.750e-02, Loss Eqns: 7.695e-01, Loss Aux: 5.263e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19042, It: 0, Loss Data: 4.087e-02, Loss Eqns: 7.471e-01, Loss Aux: 5.381e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19043, It: 0, Loss Data: 3.706e-02, Loss Eqns: 7.275e-01, Loss Aux: 5.663e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19044, It: 0, Loss Data: 4.035e-02, Loss Eqns: 7.546e-01, Loss Aux: 5.330e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19045, It: 0, Loss Data: 3.676e-02, Loss Eqns: 7.452e-01, Loss Aux: 5.165e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19046, It: 0, Loss Data: 4.241e-02, Loss Eqns: 7.144e-01, Loss Aux: 5.683e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19047, It: 0, Loss Data: 3.756e-02, Loss Eqns: 7.316e-01, Loss Aux: 6.005e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19048, It: 0, Loss Data: 3.899e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.828e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19049, It: 0, Loss Data: 3.410e-02, Loss Eqns: 7.308e-01, Loss Aux: 5.492e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 19050, It: 0, Loss Data: 3.552e-02, Loss Eqns: 7.275e-01, Loss Aux: 5.325e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19051, It: 0, Loss Data: 3.651e-02, Loss Eqns: 7.125e-01, Loss Aux: 5.538e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19052, It: 0, Loss Data: 4.002e-02, Loss Eqns: 7.240e-01, Loss Aux: 6.187e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19053, It: 0, Loss Data: 3.565e-02, Loss Eqns: 7.207e-01, Loss Aux: 6.277e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19054, It: 0, Loss Data: 3.730e-02, Loss Eqns: 7.191e-01, Loss Aux: 5.277e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19055, It: 0, Loss Data: 4.080e-02, Loss Eqns: 6.899e-01, Loss Aux: 5.349e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19056, It: 0, Loss Data: 4.044e-02, Loss Eqns: 7.790e-01, Loss Aux: 5.504e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19057, It: 0, Loss Data: 4.121e-02, Loss Eqns: 7.188e-01, Loss Aux: 5.612e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19058, It: 0, Loss Data: 3.081e-02, Loss Eqns: 7.013e-01, Loss Aux: 5.018e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19059, It: 0, Loss Data: 3.540e-02, Loss Eqns: 7.174e-01, Loss Aux: 5.401e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19060, It: 0, Loss Data: 3.441e-02, Loss Eqns: 7.039e-01, Loss Aux: 6.819e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19061, It: 0, Loss Data: 3.783e-02, Loss Eqns: 6.570e-01, Loss Aux: 6.344e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19062, It: 0, Loss Data: 4.045e-02, Loss Eqns: 7.074e-01, Loss Aux: 5.493e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19063, It: 0, Loss Data: 3.634e-02, Loss Eqns: 7.123e-01, Loss Aux: 5.116e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19064, It: 0, Loss Data: 3.822e-02, Loss Eqns: 7.285e-01, Loss Aux: 5.233e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19065, It: 0, Loss Data: 4.145e-02, Loss Eqns: 7.155e-01, Loss Aux: 5.830e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19066, It: 0, Loss Data: 3.494e-02, Loss Eqns: 6.687e-01, Loss Aux: 5.671e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19067, It: 0, Loss Data: 3.412e-02, Loss Eqns: 7.447e-01, Loss Aux: 5.322e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19068, It: 0, Loss Data: 3.294e-02, Loss Eqns: 7.232e-01, Loss Aux: 5.474e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19069, It: 0, Loss Data: 3.934e-02, Loss Eqns: 7.131e-01, Loss Aux: 5.749e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19070, It: 0, Loss Data: 3.179e-02, Loss Eqns: 7.052e-01, Loss Aux: 5.607e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19071, It: 0, Loss Data: 4.318e-02, Loss Eqns: 7.171e-01, Loss Aux: 5.592e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19072, It: 0, Loss Data: 3.863e-02, Loss Eqns: 7.249e-01, Loss Aux: 5.863e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19073, It: 0, Loss Data: 3.715e-02, Loss Eqns: 7.162e-01, Loss Aux: 5.713e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19074, It: 0, Loss Data: 3.820e-02, Loss Eqns: 7.129e-01, Loss Aux: 5.580e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19075, It: 0, Loss Data: 3.960e-02, Loss Eqns: 7.301e-01, Loss Aux: 5.567e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19076, It: 0, Loss Data: 3.845e-02, Loss Eqns: 6.945e-01, Loss Aux: 5.567e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19077, It: 0, Loss Data: 3.932e-02, Loss Eqns: 7.370e-01, Loss Aux: 5.201e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19078, It: 0, Loss Data: 4.288e-02, Loss Eqns: 7.264e-01, Loss Aux: 5.354e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19079, It: 0, Loss Data: 4.119e-02, Loss Eqns: 7.235e-01, Loss Aux: 5.622e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19080, It: 0, Loss Data: 3.691e-02, Loss Eqns: 7.237e-01, Loss Aux: 5.204e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19081, It: 0, Loss Data: 4.100e-02, Loss Eqns: 7.285e-01, Loss Aux: 5.151e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19082, It: 0, Loss Data: 3.660e-02, Loss Eqns: 7.178e-01, Loss Aux: 5.460e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19083, It: 0, Loss Data: 3.813e-02, Loss Eqns: 7.518e-01, Loss Aux: 5.419e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19084, It: 0, Loss Data: 4.460e-02, Loss Eqns: 6.984e-01, Loss Aux: 5.631e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19085, It: 0, Loss Data: 3.609e-02, Loss Eqns: 7.073e-01, Loss Aux: 5.939e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19086, It: 0, Loss Data: 3.798e-02, Loss Eqns: 7.505e-01, Loss Aux: 5.727e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19087, It: 0, Loss Data: 3.990e-02, Loss Eqns: 7.073e-01, Loss Aux: 5.592e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19088, It: 0, Loss Data: 3.622e-02, Loss Eqns: 6.910e-01, Loss Aux: 5.830e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19089, It: 0, Loss Data: 3.578e-02, Loss Eqns: 7.264e-01, Loss Aux: 5.604e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19090, It: 0, Loss Data: 3.589e-02, Loss Eqns: 7.058e-01, Loss Aux: 5.481e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19091, It: 0, Loss Data: 4.062e-02, Loss Eqns: 6.858e-01, Loss Aux: 5.493e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19092, It: 0, Loss Data: 3.567e-02, Loss Eqns: 7.301e-01, Loss Aux: 5.432e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19093, It: 0, Loss Data: 3.889e-02, Loss Eqns: 7.348e-01, Loss Aux: 5.037e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19094, It: 0, Loss Data: 3.909e-02, Loss Eqns: 7.233e-01, Loss Aux: 5.156e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19095, It: 0, Loss Data: 3.864e-02, Loss Eqns: 7.222e-01, Loss Aux: 5.693e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19096, It: 0, Loss Data: 4.059e-02, Loss Eqns: 7.304e-01, Loss Aux: 5.662e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19097, It: 0, Loss Data: 3.763e-02, Loss Eqns: 7.117e-01, Loss Aux: 5.741e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19098, It: 0, Loss Data: 3.566e-02, Loss Eqns: 7.042e-01, Loss Aux: 6.250e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19099, It: 0, Loss Data: 4.246e-02, Loss Eqns: 7.250e-01, Loss Aux: 5.993e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19100, It: 0, Loss Data: 3.490e-02, Loss Eqns: 7.337e-01, Loss Aux: 5.234e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19101, It: 0, Loss Data: 3.866e-02, Loss Eqns: 7.127e-01, Loss Aux: 5.148e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19102, It: 0, Loss Data: 4.058e-02, Loss Eqns: 7.125e-01, Loss Aux: 5.643e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19103, It: 0, Loss Data: 3.840e-02, Loss Eqns: 6.883e-01, Loss Aux: 5.922e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19104, It: 0, Loss Data: 3.441e-02, Loss Eqns: 6.977e-01, Loss Aux: 5.522e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19105, It: 0, Loss Data: 3.881e-02, Loss Eqns: 7.056e-01, Loss Aux: 5.339e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19106, It: 0, Loss Data: 3.799e-02, Loss Eqns: 7.217e-01, Loss Aux: 5.302e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19107, It: 0, Loss Data: 3.841e-02, Loss Eqns: 7.271e-01, Loss Aux: 5.369e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19108, It: 0, Loss Data: 3.664e-02, Loss Eqns: 7.321e-01, Loss Aux: 5.214e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19109, It: 0, Loss Data: 3.573e-02, Loss Eqns: 6.973e-01, Loss Aux: 5.244e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19110, It: 0, Loss Data: 4.349e-02, Loss Eqns: 7.483e-01, Loss Aux: 6.175e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19111, It: 0, Loss Data: 3.703e-02, Loss Eqns: 7.416e-01, Loss Aux: 6.461e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19112, It: 0, Loss Data: 4.023e-02, Loss Eqns: 7.560e-01, Loss Aux: 5.589e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19113, It: 0, Loss Data: 4.297e-02, Loss Eqns: 7.126e-01, Loss Aux: 5.021e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19114, It: 0, Loss Data: 3.896e-02, Loss Eqns: 7.669e-01, Loss Aux: 5.472e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19115, It: 0, Loss Data: 3.907e-02, Loss Eqns: 7.237e-01, Loss Aux: 5.875e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19116, It: 0, Loss Data: 3.524e-02, Loss Eqns: 7.160e-01, Loss Aux: 6.316e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19117, It: 0, Loss Data: 3.562e-02, Loss Eqns: 7.589e-01, Loss Aux: 6.112e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19118, It: 0, Loss Data: 4.012e-02, Loss Eqns: 7.627e-01, Loss Aux: 5.431e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19119, It: 0, Loss Data: 3.709e-02, Loss Eqns: 7.214e-01, Loss Aux: 5.249e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19120, It: 0, Loss Data: 4.339e-02, Loss Eqns: 7.243e-01, Loss Aux: 5.190e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19121, It: 0, Loss Data: 4.071e-02, Loss Eqns: 7.640e-01, Loss Aux: 5.280e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19122, It: 0, Loss Data: 4.052e-02, Loss Eqns: 7.297e-01, Loss Aux: 5.283e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19123, It: 0, Loss Data: 4.014e-02, Loss Eqns: 7.650e-01, Loss Aux: 6.067e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19124, It: 0, Loss Data: 3.941e-02, Loss Eqns: 7.460e-01, Loss Aux: 6.434e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19125, It: 0, Loss Data: 3.857e-02, Loss Eqns: 7.121e-01, Loss Aux: 6.054e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19126, It: 0, Loss Data: 3.807e-02, Loss Eqns: 7.277e-01, Loss Aux: 5.239e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19127, It: 0, Loss Data: 3.634e-02, Loss Eqns: 7.165e-01, Loss Aux: 5.054e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19128, It: 0, Loss Data: 3.669e-02, Loss Eqns: 6.947e-01, Loss Aux: 5.498e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19129, It: 0, Loss Data: 3.901e-02, Loss Eqns: 7.166e-01, Loss Aux: 5.943e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19130, It: 0, Loss Data: 4.058e-02, Loss Eqns: 7.397e-01, Loss Aux: 5.417e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19131, It: 0, Loss Data: 3.405e-02, Loss Eqns: 7.138e-01, Loss Aux: 5.152e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19132, It: 0, Loss Data: 3.693e-02, Loss Eqns: 7.132e-01, Loss Aux: 5.332e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19133, It: 0, Loss Data: 4.026e-02, Loss Eqns: 7.153e-01, Loss Aux: 5.886e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19134, It: 0, Loss Data: 4.253e-02, Loss Eqns: 7.280e-01, Loss Aux: 5.543e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19135, It: 0, Loss Data: 3.633e-02, Loss Eqns: 7.135e-01, Loss Aux: 5.304e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19136, It: 0, Loss Data: 3.470e-02, Loss Eqns: 7.319e-01, Loss Aux: 5.482e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19137, It: 0, Loss Data: 4.459e-02, Loss Eqns: 7.385e-01, Loss Aux: 5.798e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19138, It: 0, Loss Data: 4.190e-02, Loss Eqns: 7.273e-01, Loss Aux: 5.588e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19139, It: 0, Loss Data: 4.101e-02, Loss Eqns: 7.237e-01, Loss Aux: 5.151e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19140, It: 0, Loss Data: 3.615e-02, Loss Eqns: 7.766e-01, Loss Aux: 5.510e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19141, It: 0, Loss Data: 4.060e-02, Loss Eqns: 7.303e-01, Loss Aux: 6.253e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19142, It: 0, Loss Data: 4.022e-02, Loss Eqns: 7.474e-01, Loss Aux: 6.297e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 19143, It: 0, Loss Data: 3.541e-02, Loss Eqns: 7.177e-01, Loss Aux: 5.635e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19144, It: 0, Loss Data: 3.252e-02, Loss Eqns: 7.858e-01, Loss Aux: 5.488e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19145, It: 0, Loss Data: 3.927e-02, Loss Eqns: 7.072e-01, Loss Aux: 5.970e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19146, It: 0, Loss Data: 4.376e-02, Loss Eqns: 7.293e-01, Loss Aux: 5.972e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19147, It: 0, Loss Data: 3.591e-02, Loss Eqns: 7.132e-01, Loss Aux: 5.499e-02, Time: 0.201, Learning Rate: 1.0e-03\n",
      "Epoch: 19148, It: 0, Loss Data: 3.848e-02, Loss Eqns: 7.686e-01, Loss Aux: 5.176e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19149, It: 0, Loss Data: 3.759e-02, Loss Eqns: 7.372e-01, Loss Aux: 5.181e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19150, It: 0, Loss Data: 4.056e-02, Loss Eqns: 7.213e-01, Loss Aux: 5.587e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19151, It: 0, Loss Data: 3.953e-02, Loss Eqns: 7.598e-01, Loss Aux: 5.721e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19152, It: 0, Loss Data: 4.150e-02, Loss Eqns: 7.258e-01, Loss Aux: 5.518e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19153, It: 0, Loss Data: 3.932e-02, Loss Eqns: 7.287e-01, Loss Aux: 5.283e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19154, It: 0, Loss Data: 3.614e-02, Loss Eqns: 7.182e-01, Loss Aux: 5.712e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19155, It: 0, Loss Data: 3.913e-02, Loss Eqns: 7.493e-01, Loss Aux: 6.374e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19156, It: 0, Loss Data: 3.271e-02, Loss Eqns: 7.374e-01, Loss Aux: 5.832e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19157, It: 0, Loss Data: 4.012e-02, Loss Eqns: 7.375e-01, Loss Aux: 5.513e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19158, It: 0, Loss Data: 3.291e-02, Loss Eqns: 7.194e-01, Loss Aux: 6.053e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19159, It: 0, Loss Data: 4.056e-02, Loss Eqns: 7.282e-01, Loss Aux: 6.038e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19160, It: 0, Loss Data: 3.735e-02, Loss Eqns: 7.110e-01, Loss Aux: 5.358e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19161, It: 0, Loss Data: 3.841e-02, Loss Eqns: 7.508e-01, Loss Aux: 5.256e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19162, It: 0, Loss Data: 3.601e-02, Loss Eqns: 7.629e-01, Loss Aux: 5.296e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19163, It: 0, Loss Data: 3.616e-02, Loss Eqns: 7.466e-01, Loss Aux: 5.590e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19164, It: 0, Loss Data: 3.644e-02, Loss Eqns: 7.060e-01, Loss Aux: 5.438e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19165, It: 0, Loss Data: 3.466e-02, Loss Eqns: 6.970e-01, Loss Aux: 5.726e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19166, It: 0, Loss Data: 3.417e-02, Loss Eqns: 7.013e-01, Loss Aux: 5.502e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19167, It: 0, Loss Data: 3.976e-02, Loss Eqns: 6.941e-01, Loss Aux: 4.834e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19168, It: 0, Loss Data: 3.821e-02, Loss Eqns: 7.279e-01, Loss Aux: 4.730e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19169, It: 0, Loss Data: 3.591e-02, Loss Eqns: 7.190e-01, Loss Aux: 5.162e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19170, It: 0, Loss Data: 3.660e-02, Loss Eqns: 7.361e-01, Loss Aux: 6.022e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19171, It: 0, Loss Data: 4.059e-02, Loss Eqns: 7.083e-01, Loss Aux: 6.365e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19172, It: 0, Loss Data: 4.008e-02, Loss Eqns: 7.416e-01, Loss Aux: 5.517e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19173, It: 0, Loss Data: 4.393e-02, Loss Eqns: 7.399e-01, Loss Aux: 4.949e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19174, It: 0, Loss Data: 3.590e-02, Loss Eqns: 7.589e-01, Loss Aux: 5.178e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19175, It: 0, Loss Data: 4.088e-02, Loss Eqns: 6.991e-01, Loss Aux: 5.922e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19176, It: 0, Loss Data: 3.759e-02, Loss Eqns: 7.344e-01, Loss Aux: 5.760e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19177, It: 0, Loss Data: 4.625e-02, Loss Eqns: 7.415e-01, Loss Aux: 5.818e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19178, It: 0, Loss Data: 3.626e-02, Loss Eqns: 7.555e-01, Loss Aux: 5.989e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19179, It: 0, Loss Data: 3.643e-02, Loss Eqns: 7.221e-01, Loss Aux: 5.885e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19180, It: 0, Loss Data: 3.743e-02, Loss Eqns: 7.680e-01, Loss Aux: 5.766e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19181, It: 0, Loss Data: 3.804e-02, Loss Eqns: 7.384e-01, Loss Aux: 5.202e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19182, It: 0, Loss Data: 3.652e-02, Loss Eqns: 7.699e-01, Loss Aux: 5.080e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19183, It: 0, Loss Data: 3.637e-02, Loss Eqns: 7.439e-01, Loss Aux: 5.869e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19184, It: 0, Loss Data: 3.176e-02, Loss Eqns: 7.287e-01, Loss Aux: 5.725e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19185, It: 0, Loss Data: 3.736e-02, Loss Eqns: 7.088e-01, Loss Aux: 5.054e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19186, It: 0, Loss Data: 4.004e-02, Loss Eqns: 7.400e-01, Loss Aux: 4.905e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19187, It: 0, Loss Data: 4.599e-02, Loss Eqns: 7.006e-01, Loss Aux: 5.481e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19188, It: 0, Loss Data: 4.194e-02, Loss Eqns: 7.170e-01, Loss Aux: 5.953e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19189, It: 0, Loss Data: 3.882e-02, Loss Eqns: 7.325e-01, Loss Aux: 5.460e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19190, It: 0, Loss Data: 3.538e-02, Loss Eqns: 7.606e-01, Loss Aux: 5.250e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19191, It: 0, Loss Data: 3.616e-02, Loss Eqns: 7.297e-01, Loss Aux: 5.545e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19192, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.999e-01, Loss Aux: 5.617e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19193, It: 0, Loss Data: 3.288e-02, Loss Eqns: 7.114e-01, Loss Aux: 5.517e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19194, It: 0, Loss Data: 3.745e-02, Loss Eqns: 7.299e-01, Loss Aux: 5.771e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19195, It: 0, Loss Data: 4.040e-02, Loss Eqns: 7.158e-01, Loss Aux: 5.944e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19196, It: 0, Loss Data: 3.494e-02, Loss Eqns: 7.465e-01, Loss Aux: 5.581e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19197, It: 0, Loss Data: 3.747e-02, Loss Eqns: 7.130e-01, Loss Aux: 5.373e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19198, It: 0, Loss Data: 3.367e-02, Loss Eqns: 7.344e-01, Loss Aux: 5.732e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19199, It: 0, Loss Data: 4.331e-02, Loss Eqns: 7.023e-01, Loss Aux: 5.691e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19200, It: 0, Loss Data: 4.186e-02, Loss Eqns: 7.077e-01, Loss Aux: 5.289e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19201, It: 0, Loss Data: 3.467e-02, Loss Eqns: 7.204e-01, Loss Aux: 5.232e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19202, It: 0, Loss Data: 3.426e-02, Loss Eqns: 7.372e-01, Loss Aux: 5.744e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19203, It: 0, Loss Data: 3.886e-02, Loss Eqns: 7.132e-01, Loss Aux: 6.644e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19204, It: 0, Loss Data: 3.214e-02, Loss Eqns: 7.234e-01, Loss Aux: 6.320e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19205, It: 0, Loss Data: 3.489e-02, Loss Eqns: 7.236e-01, Loss Aux: 5.298e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19206, It: 0, Loss Data: 3.205e-02, Loss Eqns: 7.454e-01, Loss Aux: 5.270e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19207, It: 0, Loss Data: 3.470e-02, Loss Eqns: 6.856e-01, Loss Aux: 5.539e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19208, It: 0, Loss Data: 3.761e-02, Loss Eqns: 6.908e-01, Loss Aux: 6.090e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19209, It: 0, Loss Data: 4.004e-02, Loss Eqns: 6.978e-01, Loss Aux: 6.006e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19210, It: 0, Loss Data: 3.803e-02, Loss Eqns: 7.233e-01, Loss Aux: 5.572e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19211, It: 0, Loss Data: 3.930e-02, Loss Eqns: 7.092e-01, Loss Aux: 5.053e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19212, It: 0, Loss Data: 3.959e-02, Loss Eqns: 7.026e-01, Loss Aux: 5.161e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19213, It: 0, Loss Data: 3.964e-02, Loss Eqns: 7.156e-01, Loss Aux: 5.751e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19214, It: 0, Loss Data: 3.954e-02, Loss Eqns: 7.201e-01, Loss Aux: 5.480e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19215, It: 0, Loss Data: 3.895e-02, Loss Eqns: 7.240e-01, Loss Aux: 5.355e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19216, It: 0, Loss Data: 3.374e-02, Loss Eqns: 7.116e-01, Loss Aux: 5.890e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19217, It: 0, Loss Data: 3.591e-02, Loss Eqns: 7.249e-01, Loss Aux: 5.531e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19218, It: 0, Loss Data: 3.938e-02, Loss Eqns: 7.171e-01, Loss Aux: 5.002e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19219, It: 0, Loss Data: 3.671e-02, Loss Eqns: 7.085e-01, Loss Aux: 5.377e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19220, It: 0, Loss Data: 3.439e-02, Loss Eqns: 7.312e-01, Loss Aux: 5.924e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19221, It: 0, Loss Data: 3.738e-02, Loss Eqns: 7.653e-01, Loss Aux: 5.981e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19222, It: 0, Loss Data: 3.449e-02, Loss Eqns: 7.198e-01, Loss Aux: 5.431e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19223, It: 0, Loss Data: 3.747e-02, Loss Eqns: 7.354e-01, Loss Aux: 5.877e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19224, It: 0, Loss Data: 3.501e-02, Loss Eqns: 6.956e-01, Loss Aux: 5.910e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19225, It: 0, Loss Data: 3.708e-02, Loss Eqns: 7.050e-01, Loss Aux: 5.180e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19226, It: 0, Loss Data: 4.114e-02, Loss Eqns: 7.000e-01, Loss Aux: 5.526e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19227, It: 0, Loss Data: 3.956e-02, Loss Eqns: 7.112e-01, Loss Aux: 6.031e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19228, It: 0, Loss Data: 3.674e-02, Loss Eqns: 7.240e-01, Loss Aux: 6.020e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19229, It: 0, Loss Data: 3.886e-02, Loss Eqns: 7.716e-01, Loss Aux: 5.530e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19230, It: 0, Loss Data: 3.706e-02, Loss Eqns: 7.018e-01, Loss Aux: 5.124e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19231, It: 0, Loss Data: 3.407e-02, Loss Eqns: 7.441e-01, Loss Aux: 4.954e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19232, It: 0, Loss Data: 3.653e-02, Loss Eqns: 6.936e-01, Loss Aux: 5.974e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19233, It: 0, Loss Data: 3.594e-02, Loss Eqns: 7.066e-01, Loss Aux: 6.348e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19234, It: 0, Loss Data: 3.807e-02, Loss Eqns: 7.218e-01, Loss Aux: 5.253e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19235, It: 0, Loss Data: 3.724e-02, Loss Eqns: 7.274e-01, Loss Aux: 5.196e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19236, It: 0, Loss Data: 3.577e-02, Loss Eqns: 7.407e-01, Loss Aux: 5.887e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19237, It: 0, Loss Data: 3.789e-02, Loss Eqns: 7.092e-01, Loss Aux: 6.322e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19238, It: 0, Loss Data: 3.748e-02, Loss Eqns: 6.910e-01, Loss Aux: 5.186e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19239, It: 0, Loss Data: 3.819e-02, Loss Eqns: 7.290e-01, Loss Aux: 5.013e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19240, It: 0, Loss Data: 4.062e-02, Loss Eqns: 6.781e-01, Loss Aux: 6.517e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19241, It: 0, Loss Data: 4.180e-02, Loss Eqns: 7.206e-01, Loss Aux: 6.254e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19242, It: 0, Loss Data: 3.637e-02, Loss Eqns: 7.327e-01, Loss Aux: 5.494e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19243, It: 0, Loss Data: 3.359e-02, Loss Eqns: 7.647e-01, Loss Aux: 5.566e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19244, It: 0, Loss Data: 4.664e-02, Loss Eqns: 7.080e-01, Loss Aux: 6.548e-02, Time: 0.199, Learning Rate: 1.0e-03\n",
      "Epoch: 19245, It: 0, Loss Data: 3.669e-02, Loss Eqns: 7.850e-01, Loss Aux: 5.820e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19246, It: 0, Loss Data: 3.325e-02, Loss Eqns: 6.737e-01, Loss Aux: 5.230e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19247, It: 0, Loss Data: 3.840e-02, Loss Eqns: 7.643e-01, Loss Aux: 5.437e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19248, It: 0, Loss Data: 4.120e-02, Loss Eqns: 7.487e-01, Loss Aux: 5.774e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19249, It: 0, Loss Data: 3.768e-02, Loss Eqns: 7.672e-01, Loss Aux: 5.858e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19250, It: 0, Loss Data: 3.943e-02, Loss Eqns: 7.221e-01, Loss Aux: 5.379e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19251, It: 0, Loss Data: 3.805e-02, Loss Eqns: 7.961e-01, Loss Aux: 5.110e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19252, It: 0, Loss Data: 3.767e-02, Loss Eqns: 7.022e-01, Loss Aux: 5.322e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19253, It: 0, Loss Data: 3.794e-02, Loss Eqns: 7.356e-01, Loss Aux: 6.221e-02, Time: 0.144, Learning Rate: 1.0e-03\n",
      "Epoch: 19254, It: 0, Loss Data: 3.779e-02, Loss Eqns: 6.994e-01, Loss Aux: 5.814e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19255, It: 0, Loss Data: 3.840e-02, Loss Eqns: 7.398e-01, Loss Aux: 5.006e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 19256, It: 0, Loss Data: 3.833e-02, Loss Eqns: 7.113e-01, Loss Aux: 5.203e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19257, It: 0, Loss Data: 3.578e-02, Loss Eqns: 6.878e-01, Loss Aux: 5.969e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19258, It: 0, Loss Data: 3.516e-02, Loss Eqns: 7.025e-01, Loss Aux: 6.342e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19259, It: 0, Loss Data: 3.879e-02, Loss Eqns: 6.999e-01, Loss Aux: 5.247e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19260, It: 0, Loss Data: 3.983e-02, Loss Eqns: 6.821e-01, Loss Aux: 5.232e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19261, It: 0, Loss Data: 3.074e-02, Loss Eqns: 7.003e-01, Loss Aux: 6.221e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19262, It: 0, Loss Data: 4.030e-02, Loss Eqns: 7.069e-01, Loss Aux: 6.140e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19263, It: 0, Loss Data: 3.748e-02, Loss Eqns: 7.117e-01, Loss Aux: 5.277e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19264, It: 0, Loss Data: 4.109e-02, Loss Eqns: 7.118e-01, Loss Aux: 5.521e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19265, It: 0, Loss Data: 3.839e-02, Loss Eqns: 7.040e-01, Loss Aux: 6.044e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19266, It: 0, Loss Data: 3.457e-02, Loss Eqns: 7.160e-01, Loss Aux: 5.423e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19267, It: 0, Loss Data: 3.988e-02, Loss Eqns: 7.067e-01, Loss Aux: 5.153e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19268, It: 0, Loss Data: 3.725e-02, Loss Eqns: 7.867e-01, Loss Aux: 5.220e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19269, It: 0, Loss Data: 3.848e-02, Loss Eqns: 7.019e-01, Loss Aux: 5.617e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19270, It: 0, Loss Data: 3.581e-02, Loss Eqns: 7.099e-01, Loss Aux: 5.869e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19271, It: 0, Loss Data: 3.357e-02, Loss Eqns: 7.369e-01, Loss Aux: 5.319e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19272, It: 0, Loss Data: 3.573e-02, Loss Eqns: 6.974e-01, Loss Aux: 5.009e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19273, It: 0, Loss Data: 3.568e-02, Loss Eqns: 6.816e-01, Loss Aux: 5.334e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19274, It: 0, Loss Data: 3.724e-02, Loss Eqns: 6.939e-01, Loss Aux: 6.465e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19275, It: 0, Loss Data: 3.911e-02, Loss Eqns: 6.944e-01, Loss Aux: 5.771e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19276, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.982e-01, Loss Aux: 5.174e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19277, It: 0, Loss Data: 3.194e-02, Loss Eqns: 7.210e-01, Loss Aux: 5.192e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19278, It: 0, Loss Data: 4.214e-02, Loss Eqns: 6.751e-01, Loss Aux: 5.820e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19279, It: 0, Loss Data: 3.919e-02, Loss Eqns: 7.187e-01, Loss Aux: 6.070e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19280, It: 0, Loss Data: 3.525e-02, Loss Eqns: 7.229e-01, Loss Aux: 5.162e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19281, It: 0, Loss Data: 3.491e-02, Loss Eqns: 7.149e-01, Loss Aux: 5.239e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19282, It: 0, Loss Data: 4.246e-02, Loss Eqns: 6.753e-01, Loss Aux: 6.470e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19283, It: 0, Loss Data: 3.286e-02, Loss Eqns: 7.373e-01, Loss Aux: 6.056e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19284, It: 0, Loss Data: 3.657e-02, Loss Eqns: 7.649e-01, Loss Aux: 5.472e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19285, It: 0, Loss Data: 3.554e-02, Loss Eqns: 7.506e-01, Loss Aux: 5.757e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19286, It: 0, Loss Data: 3.627e-02, Loss Eqns: 7.141e-01, Loss Aux: 5.666e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19287, It: 0, Loss Data: 4.604e-02, Loss Eqns: 7.334e-01, Loss Aux: 5.307e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19288, It: 0, Loss Data: 3.775e-02, Loss Eqns: 7.229e-01, Loss Aux: 5.323e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19289, It: 0, Loss Data: 3.623e-02, Loss Eqns: 7.515e-01, Loss Aux: 5.560e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19290, It: 0, Loss Data: 4.348e-02, Loss Eqns: 7.678e-01, Loss Aux: 5.789e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 19291, It: 0, Loss Data: 3.453e-02, Loss Eqns: 7.423e-01, Loss Aux: 6.169e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19292, It: 0, Loss Data: 3.361e-02, Loss Eqns: 7.424e-01, Loss Aux: 5.363e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19293, It: 0, Loss Data: 3.910e-02, Loss Eqns: 6.885e-01, Loss Aux: 5.567e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19294, It: 0, Loss Data: 4.120e-02, Loss Eqns: 6.775e-01, Loss Aux: 6.182e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19295, It: 0, Loss Data: 3.595e-02, Loss Eqns: 6.978e-01, Loss Aux: 6.517e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19296, It: 0, Loss Data: 3.622e-02, Loss Eqns: 7.228e-01, Loss Aux: 5.554e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19297, It: 0, Loss Data: 3.855e-02, Loss Eqns: 7.290e-01, Loss Aux: 4.912e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19298, It: 0, Loss Data: 3.583e-02, Loss Eqns: 7.185e-01, Loss Aux: 5.385e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19299, It: 0, Loss Data: 3.438e-02, Loss Eqns: 6.865e-01, Loss Aux: 5.984e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19300, It: 0, Loss Data: 3.737e-02, Loss Eqns: 7.143e-01, Loss Aux: 5.638e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19301, It: 0, Loss Data: 3.808e-02, Loss Eqns: 7.088e-01, Loss Aux: 5.478e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19302, It: 0, Loss Data: 3.767e-02, Loss Eqns: 6.945e-01, Loss Aux: 5.878e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19303, It: 0, Loss Data: 3.461e-02, Loss Eqns: 7.359e-01, Loss Aux: 5.979e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19304, It: 0, Loss Data: 4.176e-02, Loss Eqns: 7.280e-01, Loss Aux: 5.496e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19305, It: 0, Loss Data: 3.679e-02, Loss Eqns: 6.863e-01, Loss Aux: 5.601e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19306, It: 0, Loss Data: 3.403e-02, Loss Eqns: 7.036e-01, Loss Aux: 6.029e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19307, It: 0, Loss Data: 4.025e-02, Loss Eqns: 7.015e-01, Loss Aux: 6.077e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19308, It: 0, Loss Data: 3.988e-02, Loss Eqns: 7.192e-01, Loss Aux: 5.950e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19309, It: 0, Loss Data: 3.729e-02, Loss Eqns: 7.210e-01, Loss Aux: 5.192e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19310, It: 0, Loss Data: 3.812e-02, Loss Eqns: 7.279e-01, Loss Aux: 5.329e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19311, It: 0, Loss Data: 3.863e-02, Loss Eqns: 7.097e-01, Loss Aux: 5.751e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19312, It: 0, Loss Data: 3.662e-02, Loss Eqns: 7.852e-01, Loss Aux: 5.850e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19313, It: 0, Loss Data: 3.782e-02, Loss Eqns: 7.283e-01, Loss Aux: 5.596e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19314, It: 0, Loss Data: 3.598e-02, Loss Eqns: 7.341e-01, Loss Aux: 5.389e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19315, It: 0, Loss Data: 3.807e-02, Loss Eqns: 7.227e-01, Loss Aux: 5.064e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19316, It: 0, Loss Data: 3.544e-02, Loss Eqns: 7.545e-01, Loss Aux: 5.386e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19317, It: 0, Loss Data: 3.469e-02, Loss Eqns: 6.907e-01, Loss Aux: 6.582e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19318, It: 0, Loss Data: 3.400e-02, Loss Eqns: 7.124e-01, Loss Aux: 6.278e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19319, It: 0, Loss Data: 3.691e-02, Loss Eqns: 7.606e-01, Loss Aux: 5.486e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19320, It: 0, Loss Data: 3.688e-02, Loss Eqns: 7.421e-01, Loss Aux: 5.873e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19321, It: 0, Loss Data: 3.737e-02, Loss Eqns: 7.002e-01, Loss Aux: 5.771e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19322, It: 0, Loss Data: 3.842e-02, Loss Eqns: 7.182e-01, Loss Aux: 5.165e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19323, It: 0, Loss Data: 3.802e-02, Loss Eqns: 7.155e-01, Loss Aux: 5.691e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19324, It: 0, Loss Data: 4.172e-02, Loss Eqns: 7.416e-01, Loss Aux: 6.589e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19325, It: 0, Loss Data: 3.613e-02, Loss Eqns: 7.245e-01, Loss Aux: 6.077e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19326, It: 0, Loss Data: 3.591e-02, Loss Eqns: 7.065e-01, Loss Aux: 6.339e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19327, It: 0, Loss Data: 3.817e-02, Loss Eqns: 7.339e-01, Loss Aux: 6.130e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19328, It: 0, Loss Data: 3.536e-02, Loss Eqns: 7.310e-01, Loss Aux: 5.460e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19329, It: 0, Loss Data: 3.741e-02, Loss Eqns: 7.013e-01, Loss Aux: 5.335e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19330, It: 0, Loss Data: 3.565e-02, Loss Eqns: 7.238e-01, Loss Aux: 5.670e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19331, It: 0, Loss Data: 3.629e-02, Loss Eqns: 7.088e-01, Loss Aux: 5.398e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19332, It: 0, Loss Data: 4.092e-02, Loss Eqns: 7.006e-01, Loss Aux: 5.240e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19333, It: 0, Loss Data: 3.690e-02, Loss Eqns: 7.035e-01, Loss Aux: 5.852e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19334, It: 0, Loss Data: 3.966e-02, Loss Eqns: 6.976e-01, Loss Aux: 6.155e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19335, It: 0, Loss Data: 3.700e-02, Loss Eqns: 7.135e-01, Loss Aux: 5.348e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19336, It: 0, Loss Data: 4.035e-02, Loss Eqns: 6.984e-01, Loss Aux: 5.249e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19337, It: 0, Loss Data: 3.975e-02, Loss Eqns: 7.154e-01, Loss Aux: 5.262e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19338, It: 0, Loss Data: 3.619e-02, Loss Eqns: 7.066e-01, Loss Aux: 5.713e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19339, It: 0, Loss Data: 3.398e-02, Loss Eqns: 7.374e-01, Loss Aux: 5.967e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19340, It: 0, Loss Data: 3.646e-02, Loss Eqns: 7.348e-01, Loss Aux: 6.132e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19341, It: 0, Loss Data: 3.576e-02, Loss Eqns: 7.495e-01, Loss Aux: 5.925e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19342, It: 0, Loss Data: 3.212e-02, Loss Eqns: 7.380e-01, Loss Aux: 5.704e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19343, It: 0, Loss Data: 3.406e-02, Loss Eqns: 7.508e-01, Loss Aux: 5.321e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19344, It: 0, Loss Data: 4.096e-02, Loss Eqns: 6.807e-01, Loss Aux: 5.862e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19345, It: 0, Loss Data: 3.965e-02, Loss Eqns: 7.120e-01, Loss Aux: 6.396e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19346, It: 0, Loss Data: 3.366e-02, Loss Eqns: 7.103e-01, Loss Aux: 5.411e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19347, It: 0, Loss Data: 3.481e-02, Loss Eqns: 7.127e-01, Loss Aux: 5.340e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19348, It: 0, Loss Data: 4.172e-02, Loss Eqns: 7.295e-01, Loss Aux: 6.113e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19349, It: 0, Loss Data: 3.678e-02, Loss Eqns: 7.039e-01, Loss Aux: 5.763e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19350, It: 0, Loss Data: 4.151e-02, Loss Eqns: 6.867e-01, Loss Aux: 5.168e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19351, It: 0, Loss Data: 8.039e-02, Loss Eqns: 8.189e-01, Loss Aux: 4.993e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19352, It: 0, Loss Data: 1.166e-01, Loss Eqns: 1.119e+00, Loss Aux: 1.410e-01, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19353, It: 0, Loss Data: 4.317e-02, Loss Eqns: 7.586e-01, Loss Aux: 1.065e-01, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19354, It: 0, Loss Data: 9.818e-02, Loss Eqns: 1.114e+00, Loss Aux: 5.159e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19355, It: 0, Loss Data: 3.980e-02, Loss Eqns: 8.022e-01, Loss Aux: 5.629e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 19356, It: 0, Loss Data: 8.813e-02, Loss Eqns: 1.211e+00, Loss Aux: 9.959e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19357, It: 0, Loss Data: 5.137e-02, Loss Eqns: 9.174e-01, Loss Aux: 6.493e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19358, It: 0, Loss Data: 7.111e-02, Loss Eqns: 1.083e+00, Loss Aux: 5.553e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19359, It: 0, Loss Data: 4.161e-02, Loss Eqns: 7.806e-01, Loss Aux: 5.950e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19360, It: 0, Loss Data: 6.774e-02, Loss Eqns: 1.118e+00, Loss Aux: 7.028e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19361, It: 0, Loss Data: 4.926e-02, Loss Eqns: 7.807e-01, Loss Aux: 5.638e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19362, It: 0, Loss Data: 6.266e-02, Loss Eqns: 1.006e+00, Loss Aux: 5.271e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19363, It: 0, Loss Data: 4.846e-02, Loss Eqns: 8.093e-01, Loss Aux: 6.291e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19364, It: 0, Loss Data: 5.118e-02, Loss Eqns: 1.008e+00, Loss Aux: 6.117e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19365, It: 0, Loss Data: 5.258e-02, Loss Eqns: 7.618e-01, Loss Aux: 5.315e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19366, It: 0, Loss Data: 4.638e-02, Loss Eqns: 8.513e-01, Loss Aux: 5.594e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19367, It: 0, Loss Data: 4.521e-02, Loss Eqns: 7.794e-01, Loss Aux: 6.996e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19368, It: 0, Loss Data: 4.737e-02, Loss Eqns: 8.739e-01, Loss Aux: 6.082e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19369, It: 0, Loss Data: 4.828e-02, Loss Eqns: 7.731e-01, Loss Aux: 5.203e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19370, It: 0, Loss Data: 4.814e-02, Loss Eqns: 8.574e-01, Loss Aux: 5.741e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19371, It: 0, Loss Data: 4.629e-02, Loss Eqns: 7.791e-01, Loss Aux: 7.911e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19372, It: 0, Loss Data: 3.614e-02, Loss Eqns: 7.489e-01, Loss Aux: 6.713e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19373, It: 0, Loss Data: 4.552e-02, Loss Eqns: 7.407e-01, Loss Aux: 5.431e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19374, It: 0, Loss Data: 4.497e-02, Loss Eqns: 7.361e-01, Loss Aux: 5.800e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19375, It: 0, Loss Data: 3.994e-02, Loss Eqns: 7.129e-01, Loss Aux: 7.087e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 19376, It: 0, Loss Data: 3.742e-02, Loss Eqns: 7.823e-01, Loss Aux: 6.519e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19377, It: 0, Loss Data: 4.906e-02, Loss Eqns: 7.269e-01, Loss Aux: 5.672e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19378, It: 0, Loss Data: 3.808e-02, Loss Eqns: 7.524e-01, Loss Aux: 6.497e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19379, It: 0, Loss Data: 3.971e-02, Loss Eqns: 7.553e-01, Loss Aux: 8.318e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19380, It: 0, Loss Data: 5.083e-02, Loss Eqns: 7.990e-01, Loss Aux: 5.628e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19381, It: 0, Loss Data: 3.555e-02, Loss Eqns: 7.395e-01, Loss Aux: 6.349e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19382, It: 0, Loss Data: 5.267e-02, Loss Eqns: 8.517e-01, Loss Aux: 7.256e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19383, It: 0, Loss Data: 4.232e-02, Loss Eqns: 7.447e-01, Loss Aux: 5.637e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19384, It: 0, Loss Data: 5.009e-02, Loss Eqns: 7.716e-01, Loss Aux: 5.436e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19385, It: 0, Loss Data: 3.826e-02, Loss Eqns: 7.654e-01, Loss Aux: 6.750e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19386, It: 0, Loss Data: 4.523e-02, Loss Eqns: 7.372e-01, Loss Aux: 6.482e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19387, It: 0, Loss Data: 4.076e-02, Loss Eqns: 7.350e-01, Loss Aux: 5.356e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19388, It: 0, Loss Data: 4.241e-02, Loss Eqns: 7.398e-01, Loss Aux: 5.299e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19389, It: 0, Loss Data: 3.589e-02, Loss Eqns: 7.289e-01, Loss Aux: 5.950e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19390, It: 0, Loss Data: 4.373e-02, Loss Eqns: 7.684e-01, Loss Aux: 6.868e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19391, It: 0, Loss Data: 3.824e-02, Loss Eqns: 7.231e-01, Loss Aux: 6.300e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19392, It: 0, Loss Data: 3.566e-02, Loss Eqns: 7.321e-01, Loss Aux: 5.690e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19393, It: 0, Loss Data: 3.877e-02, Loss Eqns: 7.228e-01, Loss Aux: 5.842e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19394, It: 0, Loss Data: 3.948e-02, Loss Eqns: 7.127e-01, Loss Aux: 5.808e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19395, It: 0, Loss Data: 3.359e-02, Loss Eqns: 7.164e-01, Loss Aux: 5.513e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19396, It: 0, Loss Data: 4.037e-02, Loss Eqns: 7.086e-01, Loss Aux: 5.668e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19397, It: 0, Loss Data: 4.284e-02, Loss Eqns: 6.822e-01, Loss Aux: 6.098e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19398, It: 0, Loss Data: 4.391e-02, Loss Eqns: 6.933e-01, Loss Aux: 6.131e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19399, It: 0, Loss Data: 3.903e-02, Loss Eqns: 6.900e-01, Loss Aux: 5.708e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19400, It: 0, Loss Data: 3.728e-02, Loss Eqns: 6.997e-01, Loss Aux: 5.721e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19401, It: 0, Loss Data: 4.044e-02, Loss Eqns: 6.995e-01, Loss Aux: 6.138e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19402, It: 0, Loss Data: 3.907e-02, Loss Eqns: 6.901e-01, Loss Aux: 5.984e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19403, It: 0, Loss Data: 3.841e-02, Loss Eqns: 7.608e-01, Loss Aux: 5.628e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19404, It: 0, Loss Data: 3.605e-02, Loss Eqns: 7.023e-01, Loss Aux: 6.276e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19405, It: 0, Loss Data: 3.597e-02, Loss Eqns: 7.192e-01, Loss Aux: 6.737e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19406, It: 0, Loss Data: 3.639e-02, Loss Eqns: 7.196e-01, Loss Aux: 6.237e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19407, It: 0, Loss Data: 3.860e-02, Loss Eqns: 7.046e-01, Loss Aux: 5.797e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19408, It: 0, Loss Data: 3.405e-02, Loss Eqns: 7.143e-01, Loss Aux: 5.798e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19409, It: 0, Loss Data: 3.791e-02, Loss Eqns: 7.177e-01, Loss Aux: 6.123e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19410, It: 0, Loss Data: 3.672e-02, Loss Eqns: 6.959e-01, Loss Aux: 5.970e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19411, It: 0, Loss Data: 3.312e-02, Loss Eqns: 7.135e-01, Loss Aux: 5.744e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19412, It: 0, Loss Data: 3.395e-02, Loss Eqns: 6.936e-01, Loss Aux: 5.839e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19413, It: 0, Loss Data: 3.688e-02, Loss Eqns: 6.721e-01, Loss Aux: 5.694e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19414, It: 0, Loss Data: 3.894e-02, Loss Eqns: 6.967e-01, Loss Aux: 5.440e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19415, It: 0, Loss Data: 3.553e-02, Loss Eqns: 6.734e-01, Loss Aux: 5.820e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19416, It: 0, Loss Data: 3.652e-02, Loss Eqns: 7.156e-01, Loss Aux: 6.347e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19417, It: 0, Loss Data: 3.742e-02, Loss Eqns: 7.050e-01, Loss Aux: 6.013e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19418, It: 0, Loss Data: 3.923e-02, Loss Eqns: 6.748e-01, Loss Aux: 5.807e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19419, It: 0, Loss Data: 3.479e-02, Loss Eqns: 6.776e-01, Loss Aux: 5.916e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19420, It: 0, Loss Data: 3.600e-02, Loss Eqns: 6.741e-01, Loss Aux: 6.192e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19421, It: 0, Loss Data: 3.821e-02, Loss Eqns: 6.771e-01, Loss Aux: 6.248e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19422, It: 0, Loss Data: 3.472e-02, Loss Eqns: 6.818e-01, Loss Aux: 6.000e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19423, It: 0, Loss Data: 3.660e-02, Loss Eqns: 6.988e-01, Loss Aux: 5.966e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19424, It: 0, Loss Data: 3.391e-02, Loss Eqns: 6.898e-01, Loss Aux: 6.108e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19425, It: 0, Loss Data: 3.779e-02, Loss Eqns: 6.848e-01, Loss Aux: 6.277e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19426, It: 0, Loss Data: 3.399e-02, Loss Eqns: 7.141e-01, Loss Aux: 6.156e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19427, It: 0, Loss Data: 3.359e-02, Loss Eqns: 7.209e-01, Loss Aux: 5.992e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19428, It: 0, Loss Data: 4.073e-02, Loss Eqns: 6.683e-01, Loss Aux: 5.911e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19429, It: 0, Loss Data: 3.511e-02, Loss Eqns: 6.782e-01, Loss Aux: 5.509e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19430, It: 0, Loss Data: 3.713e-02, Loss Eqns: 6.887e-01, Loss Aux: 5.253e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19431, It: 0, Loss Data: 3.313e-02, Loss Eqns: 6.843e-01, Loss Aux: 5.468e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19432, It: 0, Loss Data: 3.303e-02, Loss Eqns: 7.111e-01, Loss Aux: 6.231e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19433, It: 0, Loss Data: 4.029e-02, Loss Eqns: 6.996e-01, Loss Aux: 6.635e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19434, It: 0, Loss Data: 3.997e-02, Loss Eqns: 7.088e-01, Loss Aux: 6.148e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19435, It: 0, Loss Data: 3.924e-02, Loss Eqns: 6.873e-01, Loss Aux: 5.849e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19436, It: 0, Loss Data: 3.707e-02, Loss Eqns: 6.684e-01, Loss Aux: 5.598e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19437, It: 0, Loss Data: 3.003e-02, Loss Eqns: 6.950e-01, Loss Aux: 5.347e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19438, It: 0, Loss Data: 3.675e-02, Loss Eqns: 7.188e-01, Loss Aux: 5.428e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19439, It: 0, Loss Data: 3.498e-02, Loss Eqns: 6.967e-01, Loss Aux: 6.558e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19440, It: 0, Loss Data: 4.170e-02, Loss Eqns: 7.087e-01, Loss Aux: 6.648e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19441, It: 0, Loss Data: 4.017e-02, Loss Eqns: 6.931e-01, Loss Aux: 5.593e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19442, It: 0, Loss Data: 3.455e-02, Loss Eqns: 6.937e-01, Loss Aux: 5.583e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19443, It: 0, Loss Data: 3.378e-02, Loss Eqns: 6.721e-01, Loss Aux: 6.554e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19444, It: 0, Loss Data: 3.803e-02, Loss Eqns: 6.962e-01, Loss Aux: 6.410e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19445, It: 0, Loss Data: 3.453e-02, Loss Eqns: 6.642e-01, Loss Aux: 5.545e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19446, It: 0, Loss Data: 3.842e-02, Loss Eqns: 7.108e-01, Loss Aux: 5.508e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19447, It: 0, Loss Data: 3.332e-02, Loss Eqns: 6.867e-01, Loss Aux: 6.134e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19448, It: 0, Loss Data: 3.445e-02, Loss Eqns: 6.635e-01, Loss Aux: 6.570e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19449, It: 0, Loss Data: 2.760e-02, Loss Eqns: 7.020e-01, Loss Aux: 6.121e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19450, It: 0, Loss Data: 3.881e-02, Loss Eqns: 6.962e-01, Loss Aux: 5.597e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19451, It: 0, Loss Data: 3.630e-02, Loss Eqns: 7.090e-01, Loss Aux: 5.306e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19452, It: 0, Loss Data: 3.560e-02, Loss Eqns: 6.944e-01, Loss Aux: 5.540e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19453, It: 0, Loss Data: 3.956e-02, Loss Eqns: 6.822e-01, Loss Aux: 5.859e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19454, It: 0, Loss Data: 3.543e-02, Loss Eqns: 6.985e-01, Loss Aux: 5.990e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19455, It: 0, Loss Data: 3.846e-02, Loss Eqns: 6.892e-01, Loss Aux: 5.881e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19456, It: 0, Loss Data: 3.798e-02, Loss Eqns: 6.954e-01, Loss Aux: 6.025e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19457, It: 0, Loss Data: 3.731e-02, Loss Eqns: 6.729e-01, Loss Aux: 5.511e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19458, It: 0, Loss Data: 3.807e-02, Loss Eqns: 7.148e-01, Loss Aux: 5.421e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19459, It: 0, Loss Data: 3.493e-02, Loss Eqns: 6.990e-01, Loss Aux: 5.388e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19460, It: 0, Loss Data: 4.025e-02, Loss Eqns: 7.167e-01, Loss Aux: 5.407e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19461, It: 0, Loss Data: 4.008e-02, Loss Eqns: 7.043e-01, Loss Aux: 6.079e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19462, It: 0, Loss Data: 3.495e-02, Loss Eqns: 6.785e-01, Loss Aux: 6.486e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19463, It: 0, Loss Data: 3.785e-02, Loss Eqns: 7.180e-01, Loss Aux: 5.706e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19464, It: 0, Loss Data: 4.034e-02, Loss Eqns: 7.144e-01, Loss Aux: 5.165e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19465, It: 0, Loss Data: 3.453e-02, Loss Eqns: 6.818e-01, Loss Aux: 5.467e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19466, It: 0, Loss Data: 3.825e-02, Loss Eqns: 6.886e-01, Loss Aux: 6.595e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19467, It: 0, Loss Data: 3.590e-02, Loss Eqns: 6.902e-01, Loss Aux: 6.324e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19468, It: 0, Loss Data: 3.523e-02, Loss Eqns: 6.822e-01, Loss Aux: 5.772e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19469, It: 0, Loss Data: 3.707e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.525e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19470, It: 0, Loss Data: 3.505e-02, Loss Eqns: 6.864e-01, Loss Aux: 5.060e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19471, It: 0, Loss Data: 3.763e-02, Loss Eqns: 6.922e-01, Loss Aux: 5.290e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19472, It: 0, Loss Data: 3.357e-02, Loss Eqns: 7.094e-01, Loss Aux: 6.286e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19473, It: 0, Loss Data: 3.767e-02, Loss Eqns: 7.228e-01, Loss Aux: 6.879e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19474, It: 0, Loss Data: 3.893e-02, Loss Eqns: 7.624e-01, Loss Aux: 6.040e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19475, It: 0, Loss Data: 3.384e-02, Loss Eqns: 7.245e-01, Loss Aux: 5.427e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19476, It: 0, Loss Data: 4.054e-02, Loss Eqns: 6.872e-01, Loss Aux: 5.739e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19477, It: 0, Loss Data: 3.747e-02, Loss Eqns: 6.912e-01, Loss Aux: 6.026e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19478, It: 0, Loss Data: 3.656e-02, Loss Eqns: 7.418e-01, Loss Aux: 5.769e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19479, It: 0, Loss Data: 3.295e-02, Loss Eqns: 7.018e-01, Loss Aux: 5.507e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19480, It: 0, Loss Data: 3.165e-02, Loss Eqns: 7.061e-01, Loss Aux: 5.479e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19481, It: 0, Loss Data: 3.721e-02, Loss Eqns: 7.148e-01, Loss Aux: 5.896e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19482, It: 0, Loss Data: 3.225e-02, Loss Eqns: 6.911e-01, Loss Aux: 5.861e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19483, It: 0, Loss Data: 3.306e-02, Loss Eqns: 7.260e-01, Loss Aux: 5.561e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19484, It: 0, Loss Data: 3.505e-02, Loss Eqns: 6.982e-01, Loss Aux: 6.062e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19485, It: 0, Loss Data: 3.985e-02, Loss Eqns: 7.207e-01, Loss Aux: 5.911e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19486, It: 0, Loss Data: 3.463e-02, Loss Eqns: 6.937e-01, Loss Aux: 5.012e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19487, It: 0, Loss Data: 3.702e-02, Loss Eqns: 7.576e-01, Loss Aux: 5.116e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19488, It: 0, Loss Data: 3.087e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.494e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 19489, It: 0, Loss Data: 3.850e-02, Loss Eqns: 7.175e-01, Loss Aux: 5.939e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19490, It: 0, Loss Data: 4.035e-02, Loss Eqns: 6.774e-01, Loss Aux: 5.702e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19491, It: 0, Loss Data: 3.959e-02, Loss Eqns: 6.866e-01, Loss Aux: 5.692e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19492, It: 0, Loss Data: 3.593e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.775e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19493, It: 0, Loss Data: 3.090e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.401e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19494, It: 0, Loss Data: 3.920e-02, Loss Eqns: 7.147e-01, Loss Aux: 5.623e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19495, It: 0, Loss Data: 3.337e-02, Loss Eqns: 6.936e-01, Loss Aux: 6.130e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19496, It: 0, Loss Data: 3.506e-02, Loss Eqns: 7.003e-01, Loss Aux: 6.044e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19497, It: 0, Loss Data: 3.634e-02, Loss Eqns: 6.624e-01, Loss Aux: 6.053e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19498, It: 0, Loss Data: 3.617e-02, Loss Eqns: 6.962e-01, Loss Aux: 5.977e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19499, It: 0, Loss Data: 3.913e-02, Loss Eqns: 6.849e-01, Loss Aux: 5.513e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19500, It: 0, Loss Data: 3.797e-02, Loss Eqns: 6.750e-01, Loss Aux: 5.590e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19501, It: 0, Loss Data: 3.248e-02, Loss Eqns: 6.881e-01, Loss Aux: 5.756e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19502, It: 0, Loss Data: 3.685e-02, Loss Eqns: 6.783e-01, Loss Aux: 5.851e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19503, It: 0, Loss Data: 3.696e-02, Loss Eqns: 6.933e-01, Loss Aux: 6.426e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19504, It: 0, Loss Data: 3.628e-02, Loss Eqns: 6.696e-01, Loss Aux: 6.625e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19505, It: 0, Loss Data: 3.473e-02, Loss Eqns: 6.660e-01, Loss Aux: 5.605e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19506, It: 0, Loss Data: 3.780e-02, Loss Eqns: 6.831e-01, Loss Aux: 5.304e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19507, It: 0, Loss Data: 3.760e-02, Loss Eqns: 6.617e-01, Loss Aux: 6.483e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19508, It: 0, Loss Data: 3.730e-02, Loss Eqns: 6.730e-01, Loss Aux: 6.915e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19509, It: 0, Loss Data: 3.552e-02, Loss Eqns: 7.054e-01, Loss Aux: 5.689e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19510, It: 0, Loss Data: 3.413e-02, Loss Eqns: 6.967e-01, Loss Aux: 5.324e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19511, It: 0, Loss Data: 3.435e-02, Loss Eqns: 6.957e-01, Loss Aux: 5.747e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19512, It: 0, Loss Data: 4.130e-02, Loss Eqns: 7.020e-01, Loss Aux: 6.865e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19513, It: 0, Loss Data: 3.750e-02, Loss Eqns: 7.115e-01, Loss Aux: 5.847e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19514, It: 0, Loss Data: 3.876e-02, Loss Eqns: 6.946e-01, Loss Aux: 5.419e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19515, It: 0, Loss Data: 3.449e-02, Loss Eqns: 6.989e-01, Loss Aux: 6.555e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19516, It: 0, Loss Data: 4.121e-02, Loss Eqns: 7.177e-01, Loss Aux: 6.501e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19517, It: 0, Loss Data: 3.653e-02, Loss Eqns: 7.109e-01, Loss Aux: 5.524e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19518, It: 0, Loss Data: 4.355e-02, Loss Eqns: 6.858e-01, Loss Aux: 5.747e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19519, It: 0, Loss Data: 3.331e-02, Loss Eqns: 7.273e-01, Loss Aux: 6.077e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19520, It: 0, Loss Data: 3.642e-02, Loss Eqns: 6.986e-01, Loss Aux: 5.680e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19521, It: 0, Loss Data: 4.260e-02, Loss Eqns: 7.076e-01, Loss Aux: 5.764e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19522, It: 0, Loss Data: 3.105e-02, Loss Eqns: 7.645e-01, Loss Aux: 6.174e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19523, It: 0, Loss Data: 3.712e-02, Loss Eqns: 7.121e-01, Loss Aux: 6.501e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19524, It: 0, Loss Data: 3.436e-02, Loss Eqns: 7.601e-01, Loss Aux: 5.596e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19525, It: 0, Loss Data: 4.008e-02, Loss Eqns: 8.052e-01, Loss Aux: 5.350e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19526, It: 0, Loss Data: 3.750e-02, Loss Eqns: 7.739e-01, Loss Aux: 5.794e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19527, It: 0, Loss Data: 3.948e-02, Loss Eqns: 7.247e-01, Loss Aux: 5.660e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19528, It: 0, Loss Data: 3.556e-02, Loss Eqns: 7.869e-01, Loss Aux: 5.504e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19529, It: 0, Loss Data: 3.594e-02, Loss Eqns: 6.878e-01, Loss Aux: 6.267e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19530, It: 0, Loss Data: 3.986e-02, Loss Eqns: 7.514e-01, Loss Aux: 5.893e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19531, It: 0, Loss Data: 3.527e-02, Loss Eqns: 7.177e-01, Loss Aux: 5.292e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19532, It: 0, Loss Data: 3.321e-02, Loss Eqns: 7.657e-01, Loss Aux: 5.257e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 19533, It: 0, Loss Data: 3.518e-02, Loss Eqns: 6.863e-01, Loss Aux: 6.078e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 19534, It: 0, Loss Data: 3.334e-02, Loss Eqns: 7.216e-01, Loss Aux: 6.285e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19535, It: 0, Loss Data: 3.336e-02, Loss Eqns: 7.099e-01, Loss Aux: 5.447e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19536, It: 0, Loss Data: 3.690e-02, Loss Eqns: 6.671e-01, Loss Aux: 5.308e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19537, It: 0, Loss Data: 3.876e-02, Loss Eqns: 7.035e-01, Loss Aux: 6.248e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19538, It: 0, Loss Data: 3.688e-02, Loss Eqns: 6.878e-01, Loss Aux: 6.553e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19539, It: 0, Loss Data: 4.105e-02, Loss Eqns: 6.600e-01, Loss Aux: 5.755e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19540, It: 0, Loss Data: 4.036e-02, Loss Eqns: 6.935e-01, Loss Aux: 5.603e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19541, It: 0, Loss Data: 3.608e-02, Loss Eqns: 6.815e-01, Loss Aux: 6.276e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19542, It: 0, Loss Data: 3.248e-02, Loss Eqns: 6.862e-01, Loss Aux: 6.371e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19543, It: 0, Loss Data: 4.055e-02, Loss Eqns: 7.205e-01, Loss Aux: 5.688e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19544, It: 0, Loss Data: 3.351e-02, Loss Eqns: 7.157e-01, Loss Aux: 5.326e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19545, It: 0, Loss Data: 3.811e-02, Loss Eqns: 7.255e-01, Loss Aux: 5.793e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19546, It: 0, Loss Data: 3.733e-02, Loss Eqns: 6.971e-01, Loss Aux: 5.675e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19547, It: 0, Loss Data: 3.920e-02, Loss Eqns: 7.061e-01, Loss Aux: 5.504e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19548, It: 0, Loss Data: 3.382e-02, Loss Eqns: 7.068e-01, Loss Aux: 5.674e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19549, It: 0, Loss Data: 3.617e-02, Loss Eqns: 6.965e-01, Loss Aux: 6.050e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19550, It: 0, Loss Data: 3.881e-02, Loss Eqns: 6.972e-01, Loss Aux: 6.828e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19551, It: 0, Loss Data: 3.292e-02, Loss Eqns: 6.928e-01, Loss Aux: 5.481e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19552, It: 0, Loss Data: 3.854e-02, Loss Eqns: 6.866e-01, Loss Aux: 5.235e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19553, It: 0, Loss Data: 3.854e-02, Loss Eqns: 7.196e-01, Loss Aux: 5.860e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19554, It: 0, Loss Data: 3.670e-02, Loss Eqns: 6.632e-01, Loss Aux: 6.015e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19555, It: 0, Loss Data: 3.057e-02, Loss Eqns: 7.238e-01, Loss Aux: 5.821e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19556, It: 0, Loss Data: 3.471e-02, Loss Eqns: 7.059e-01, Loss Aux: 5.905e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19557, It: 0, Loss Data: 3.464e-02, Loss Eqns: 7.320e-01, Loss Aux: 5.915e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19558, It: 0, Loss Data: 2.976e-02, Loss Eqns: 7.441e-01, Loss Aux: 5.670e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19559, It: 0, Loss Data: 3.503e-02, Loss Eqns: 7.620e-01, Loss Aux: 5.552e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19560, It: 0, Loss Data: 4.057e-02, Loss Eqns: 7.019e-01, Loss Aux: 5.507e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19561, It: 0, Loss Data: 3.774e-02, Loss Eqns: 6.781e-01, Loss Aux: 5.470e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19562, It: 0, Loss Data: 3.601e-02, Loss Eqns: 7.048e-01, Loss Aux: 5.664e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19563, It: 0, Loss Data: 3.910e-02, Loss Eqns: 6.879e-01, Loss Aux: 5.809e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19564, It: 0, Loss Data: 3.808e-02, Loss Eqns: 7.370e-01, Loss Aux: 5.963e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19565, It: 0, Loss Data: 3.603e-02, Loss Eqns: 7.416e-01, Loss Aux: 5.604e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19566, It: 0, Loss Data: 3.216e-02, Loss Eqns: 6.844e-01, Loss Aux: 5.689e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19567, It: 0, Loss Data: 3.970e-02, Loss Eqns: 6.952e-01, Loss Aux: 6.813e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19568, It: 0, Loss Data: 3.312e-02, Loss Eqns: 7.183e-01, Loss Aux: 6.106e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19569, It: 0, Loss Data: 3.550e-02, Loss Eqns: 7.147e-01, Loss Aux: 5.205e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19570, It: 0, Loss Data: 3.442e-02, Loss Eqns: 6.894e-01, Loss Aux: 5.355e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19571, It: 0, Loss Data: 3.560e-02, Loss Eqns: 6.802e-01, Loss Aux: 6.075e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19572, It: 0, Loss Data: 3.428e-02, Loss Eqns: 7.188e-01, Loss Aux: 5.599e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19573, It: 0, Loss Data: 4.044e-02, Loss Eqns: 7.240e-01, Loss Aux: 5.171e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19574, It: 0, Loss Data: 4.013e-02, Loss Eqns: 7.203e-01, Loss Aux: 5.620e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19575, It: 0, Loss Data: 3.944e-02, Loss Eqns: 7.135e-01, Loss Aux: 5.858e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19576, It: 0, Loss Data: 3.690e-02, Loss Eqns: 7.232e-01, Loss Aux: 5.356e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19577, It: 0, Loss Data: 3.558e-02, Loss Eqns: 6.982e-01, Loss Aux: 5.488e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19578, It: 0, Loss Data: 3.444e-02, Loss Eqns: 7.233e-01, Loss Aux: 5.708e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19579, It: 0, Loss Data: 3.311e-02, Loss Eqns: 7.219e-01, Loss Aux: 5.378e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19580, It: 0, Loss Data: 3.108e-02, Loss Eqns: 7.087e-01, Loss Aux: 5.421e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19581, It: 0, Loss Data: 3.867e-02, Loss Eqns: 6.948e-01, Loss Aux: 6.113e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19582, It: 0, Loss Data: 3.970e-02, Loss Eqns: 7.220e-01, Loss Aux: 6.456e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19583, It: 0, Loss Data: 4.296e-02, Loss Eqns: 7.116e-01, Loss Aux: 5.695e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19584, It: 0, Loss Data: 3.751e-02, Loss Eqns: 7.375e-01, Loss Aux: 5.905e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19585, It: 0, Loss Data: 3.499e-02, Loss Eqns: 7.087e-01, Loss Aux: 6.596e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19586, It: 0, Loss Data: 3.899e-02, Loss Eqns: 7.390e-01, Loss Aux: 5.715e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19587, It: 0, Loss Data: 4.003e-02, Loss Eqns: 7.114e-01, Loss Aux: 5.375e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19588, It: 0, Loss Data: 4.091e-02, Loss Eqns: 7.176e-01, Loss Aux: 7.330e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19589, It: 0, Loss Data: 3.408e-02, Loss Eqns: 7.010e-01, Loss Aux: 6.917e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19590, It: 0, Loss Data: 3.446e-02, Loss Eqns: 7.317e-01, Loss Aux: 5.505e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19591, It: 0, Loss Data: 3.733e-02, Loss Eqns: 6.999e-01, Loss Aux: 5.735e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19592, It: 0, Loss Data: 3.460e-02, Loss Eqns: 6.983e-01, Loss Aux: 6.199e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19593, It: 0, Loss Data: 3.559e-02, Loss Eqns: 7.048e-01, Loss Aux: 5.531e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19594, It: 0, Loss Data: 3.253e-02, Loss Eqns: 7.566e-01, Loss Aux: 5.172e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19595, It: 0, Loss Data: 3.383e-02, Loss Eqns: 7.005e-01, Loss Aux: 5.682e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19596, It: 0, Loss Data: 3.896e-02, Loss Eqns: 7.076e-01, Loss Aux: 6.514e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19597, It: 0, Loss Data: 3.517e-02, Loss Eqns: 7.171e-01, Loss Aux: 6.033e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19598, It: 0, Loss Data: 3.216e-02, Loss Eqns: 6.870e-01, Loss Aux: 5.778e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19599, It: 0, Loss Data: 4.200e-02, Loss Eqns: 7.236e-01, Loss Aux: 5.955e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 19600, It: 0, Loss Data: 3.785e-02, Loss Eqns: 6.635e-01, Loss Aux: 5.789e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19601, It: 0, Loss Data: 3.116e-02, Loss Eqns: 7.175e-01, Loss Aux: 5.585e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19602, It: 0, Loss Data: 3.847e-02, Loss Eqns: 7.026e-01, Loss Aux: 5.865e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19603, It: 0, Loss Data: 3.684e-02, Loss Eqns: 7.378e-01, Loss Aux: 6.182e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19604, It: 0, Loss Data: 3.363e-02, Loss Eqns: 6.984e-01, Loss Aux: 6.075e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19605, It: 0, Loss Data: 3.160e-02, Loss Eqns: 7.072e-01, Loss Aux: 5.661e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19606, It: 0, Loss Data: 3.193e-02, Loss Eqns: 7.542e-01, Loss Aux: 5.523e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19607, It: 0, Loss Data: 3.866e-02, Loss Eqns: 6.886e-01, Loss Aux: 5.989e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19608, It: 0, Loss Data: 3.663e-02, Loss Eqns: 6.818e-01, Loss Aux: 5.942e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19609, It: 0, Loss Data: 3.760e-02, Loss Eqns: 7.165e-01, Loss Aux: 5.792e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19610, It: 0, Loss Data: 3.178e-02, Loss Eqns: 7.341e-01, Loss Aux: 5.364e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19611, It: 0, Loss Data: 3.329e-02, Loss Eqns: 6.738e-01, Loss Aux: 5.670e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19612, It: 0, Loss Data: 3.415e-02, Loss Eqns: 7.060e-01, Loss Aux: 5.825e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19613, It: 0, Loss Data: 3.159e-02, Loss Eqns: 6.947e-01, Loss Aux: 5.570e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19614, It: 0, Loss Data: 3.818e-02, Loss Eqns: 7.214e-01, Loss Aux: 5.456e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19615, It: 0, Loss Data: 3.869e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.957e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19616, It: 0, Loss Data: 3.772e-02, Loss Eqns: 7.074e-01, Loss Aux: 6.306e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19617, It: 0, Loss Data: 3.820e-02, Loss Eqns: 7.166e-01, Loss Aux: 5.795e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19618, It: 0, Loss Data: 3.474e-02, Loss Eqns: 6.695e-01, Loss Aux: 5.506e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19619, It: 0, Loss Data: 3.754e-02, Loss Eqns: 7.116e-01, Loss Aux: 5.556e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19620, It: 0, Loss Data: 3.469e-02, Loss Eqns: 7.118e-01, Loss Aux: 6.032e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19621, It: 0, Loss Data: 3.401e-02, Loss Eqns: 6.910e-01, Loss Aux: 6.106e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19622, It: 0, Loss Data: 3.506e-02, Loss Eqns: 7.227e-01, Loss Aux: 6.068e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19623, It: 0, Loss Data: 3.849e-02, Loss Eqns: 7.228e-01, Loss Aux: 5.532e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19624, It: 0, Loss Data: 3.496e-02, Loss Eqns: 7.117e-01, Loss Aux: 5.400e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19625, It: 0, Loss Data: 3.366e-02, Loss Eqns: 7.235e-01, Loss Aux: 5.795e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19626, It: 0, Loss Data: 3.698e-02, Loss Eqns: 6.728e-01, Loss Aux: 5.820e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19627, It: 0, Loss Data: 3.749e-02, Loss Eqns: 7.348e-01, Loss Aux: 5.553e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19628, It: 0, Loss Data: 3.346e-02, Loss Eqns: 6.963e-01, Loss Aux: 5.533e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19629, It: 0, Loss Data: 3.901e-02, Loss Eqns: 7.052e-01, Loss Aux: 5.812e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19630, It: 0, Loss Data: 3.382e-02, Loss Eqns: 7.030e-01, Loss Aux: 5.257e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19631, It: 0, Loss Data: 4.056e-02, Loss Eqns: 7.099e-01, Loss Aux: 5.349e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19632, It: 0, Loss Data: 3.212e-02, Loss Eqns: 6.702e-01, Loss Aux: 6.790e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19633, It: 0, Loss Data: 3.298e-02, Loss Eqns: 7.043e-01, Loss Aux: 6.696e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19634, It: 0, Loss Data: 3.864e-02, Loss Eqns: 6.700e-01, Loss Aux: 5.549e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19635, It: 0, Loss Data: 3.760e-02, Loss Eqns: 7.099e-01, Loss Aux: 5.107e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19636, It: 0, Loss Data: 3.456e-02, Loss Eqns: 7.087e-01, Loss Aux: 5.655e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 19637, It: 0, Loss Data: 4.399e-02, Loss Eqns: 6.950e-01, Loss Aux: 5.483e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19638, It: 0, Loss Data: 4.107e-02, Loss Eqns: 7.289e-01, Loss Aux: 5.795e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19639, It: 0, Loss Data: 3.116e-02, Loss Eqns: 6.949e-01, Loss Aux: 5.879e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19640, It: 0, Loss Data: 3.160e-02, Loss Eqns: 7.216e-01, Loss Aux: 6.046e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19641, It: 0, Loss Data: 3.620e-02, Loss Eqns: 7.204e-01, Loss Aux: 5.759e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19642, It: 0, Loss Data: 3.759e-02, Loss Eqns: 7.151e-01, Loss Aux: 5.555e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19643, It: 0, Loss Data: 3.707e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.740e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19644, It: 0, Loss Data: 3.630e-02, Loss Eqns: 7.112e-01, Loss Aux: 5.995e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19645, It: 0, Loss Data: 4.004e-02, Loss Eqns: 6.926e-01, Loss Aux: 6.032e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19646, It: 0, Loss Data: 3.510e-02, Loss Eqns: 6.890e-01, Loss Aux: 6.216e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19647, It: 0, Loss Data: 3.579e-02, Loss Eqns: 7.316e-01, Loss Aux: 6.005e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19648, It: 0, Loss Data: 3.320e-02, Loss Eqns: 7.532e-01, Loss Aux: 5.223e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19649, It: 0, Loss Data: 3.561e-02, Loss Eqns: 6.781e-01, Loss Aux: 5.673e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19650, It: 0, Loss Data: 3.081e-02, Loss Eqns: 7.020e-01, Loss Aux: 5.808e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19651, It: 0, Loss Data: 3.593e-02, Loss Eqns: 7.176e-01, Loss Aux: 5.661e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19652, It: 0, Loss Data: 3.983e-02, Loss Eqns: 7.010e-01, Loss Aux: 5.511e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19653, It: 0, Loss Data: 3.743e-02, Loss Eqns: 7.354e-01, Loss Aux: 6.194e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19654, It: 0, Loss Data: 3.248e-02, Loss Eqns: 7.293e-01, Loss Aux: 7.185e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19655, It: 0, Loss Data: 3.727e-02, Loss Eqns: 6.955e-01, Loss Aux: 7.003e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19656, It: 0, Loss Data: 3.765e-02, Loss Eqns: 7.464e-01, Loss Aux: 6.132e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19657, It: 0, Loss Data: 3.177e-02, Loss Eqns: 8.309e-01, Loss Aux: 5.353e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19658, It: 0, Loss Data: 3.903e-02, Loss Eqns: 8.576e-01, Loss Aux: 5.194e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19659, It: 0, Loss Data: 3.388e-02, Loss Eqns: 8.285e-01, Loss Aux: 5.190e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19660, It: 0, Loss Data: 4.022e-02, Loss Eqns: 7.822e-01, Loss Aux: 6.238e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19661, It: 0, Loss Data: 3.540e-02, Loss Eqns: 7.124e-01, Loss Aux: 6.199e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19662, It: 0, Loss Data: 3.210e-02, Loss Eqns: 7.342e-01, Loss Aux: 5.398e-02, Time: 0.200, Learning Rate: 1.0e-03\n",
      "Epoch: 19663, It: 0, Loss Data: 3.538e-02, Loss Eqns: 6.792e-01, Loss Aux: 5.233e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19664, It: 0, Loss Data: 3.455e-02, Loss Eqns: 7.121e-01, Loss Aux: 5.292e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19665, It: 0, Loss Data: 3.534e-02, Loss Eqns: 7.461e-01, Loss Aux: 5.584e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19666, It: 0, Loss Data: 3.926e-02, Loss Eqns: 7.448e-01, Loss Aux: 5.319e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19667, It: 0, Loss Data: 3.281e-02, Loss Eqns: 7.155e-01, Loss Aux: 5.486e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19668, It: 0, Loss Data: 3.119e-02, Loss Eqns: 6.797e-01, Loss Aux: 6.304e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19669, It: 0, Loss Data: 3.827e-02, Loss Eqns: 6.664e-01, Loss Aux: 6.538e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19670, It: 0, Loss Data: 3.637e-02, Loss Eqns: 6.836e-01, Loss Aux: 5.557e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19671, It: 0, Loss Data: 3.912e-02, Loss Eqns: 7.102e-01, Loss Aux: 5.479e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19672, It: 0, Loss Data: 3.718e-02, Loss Eqns: 7.148e-01, Loss Aux: 5.759e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19673, It: 0, Loss Data: 3.394e-02, Loss Eqns: 7.105e-01, Loss Aux: 5.500e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19674, It: 0, Loss Data: 3.956e-02, Loss Eqns: 7.036e-01, Loss Aux: 5.560e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19675, It: 0, Loss Data: 3.600e-02, Loss Eqns: 6.848e-01, Loss Aux: 6.209e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19676, It: 0, Loss Data: 3.794e-02, Loss Eqns: 7.118e-01, Loss Aux: 7.080e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19677, It: 0, Loss Data: 3.847e-02, Loss Eqns: 7.467e-01, Loss Aux: 6.264e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19678, It: 0, Loss Data: 3.693e-02, Loss Eqns: 6.902e-01, Loss Aux: 5.439e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19679, It: 0, Loss Data: 3.654e-02, Loss Eqns: 7.355e-01, Loss Aux: 5.513e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19680, It: 0, Loss Data: 3.136e-02, Loss Eqns: 7.363e-01, Loss Aux: 5.540e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19681, It: 0, Loss Data: 3.152e-02, Loss Eqns: 7.431e-01, Loss Aux: 5.788e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19682, It: 0, Loss Data: 3.320e-02, Loss Eqns: 7.561e-01, Loss Aux: 5.714e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19683, It: 0, Loss Data: 3.116e-02, Loss Eqns: 7.076e-01, Loss Aux: 5.754e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19684, It: 0, Loss Data: 3.442e-02, Loss Eqns: 7.014e-01, Loss Aux: 6.326e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19685, It: 0, Loss Data: 3.733e-02, Loss Eqns: 6.949e-01, Loss Aux: 6.728e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19686, It: 0, Loss Data: 3.639e-02, Loss Eqns: 7.094e-01, Loss Aux: 6.322e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19687, It: 0, Loss Data: 4.026e-02, Loss Eqns: 7.195e-01, Loss Aux: 5.962e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19688, It: 0, Loss Data: 4.137e-02, Loss Eqns: 7.310e-01, Loss Aux: 5.889e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19689, It: 0, Loss Data: 3.456e-02, Loss Eqns: 6.925e-01, Loss Aux: 5.598e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19690, It: 0, Loss Data: 3.345e-02, Loss Eqns: 7.474e-01, Loss Aux: 5.371e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19691, It: 0, Loss Data: 3.604e-02, Loss Eqns: 6.885e-01, Loss Aux: 5.449e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19692, It: 0, Loss Data: 3.806e-02, Loss Eqns: 6.773e-01, Loss Aux: 6.909e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19693, It: 0, Loss Data: 3.557e-02, Loss Eqns: 7.018e-01, Loss Aux: 6.950e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19694, It: 0, Loss Data: 3.875e-02, Loss Eqns: 7.168e-01, Loss Aux: 6.114e-02, Time: 0.193, Learning Rate: 1.0e-03\n",
      "Epoch: 19695, It: 0, Loss Data: 3.590e-02, Loss Eqns: 7.226e-01, Loss Aux: 5.595e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19696, It: 0, Loss Data: 3.867e-02, Loss Eqns: 7.233e-01, Loss Aux: 5.551e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19697, It: 0, Loss Data: 3.400e-02, Loss Eqns: 7.519e-01, Loss Aux: 5.549e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19698, It: 0, Loss Data: 4.010e-02, Loss Eqns: 7.671e-01, Loss Aux: 6.081e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19699, It: 0, Loss Data: 3.459e-02, Loss Eqns: 7.269e-01, Loss Aux: 6.460e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19700, It: 0, Loss Data: 3.422e-02, Loss Eqns: 7.202e-01, Loss Aux: 5.846e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19701, It: 0, Loss Data: 3.621e-02, Loss Eqns: 7.063e-01, Loss Aux: 5.966e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19702, It: 0, Loss Data: 3.457e-02, Loss Eqns: 7.172e-01, Loss Aux: 6.364e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19703, It: 0, Loss Data: 3.159e-02, Loss Eqns: 6.871e-01, Loss Aux: 5.505e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19704, It: 0, Loss Data: 3.994e-02, Loss Eqns: 6.996e-01, Loss Aux: 5.244e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19705, It: 0, Loss Data: 3.615e-02, Loss Eqns: 7.048e-01, Loss Aux: 5.814e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19706, It: 0, Loss Data: 3.671e-02, Loss Eqns: 7.058e-01, Loss Aux: 6.234e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19707, It: 0, Loss Data: 3.923e-02, Loss Eqns: 7.289e-01, Loss Aux: 5.278e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19708, It: 0, Loss Data: 3.454e-02, Loss Eqns: 7.338e-01, Loss Aux: 5.213e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19709, It: 0, Loss Data: 4.138e-02, Loss Eqns: 7.468e-01, Loss Aux: 6.853e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19710, It: 0, Loss Data: 3.436e-02, Loss Eqns: 7.257e-01, Loss Aux: 6.378e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19711, It: 0, Loss Data: 3.950e-02, Loss Eqns: 7.133e-01, Loss Aux: 5.548e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19712, It: 0, Loss Data: 3.597e-02, Loss Eqns: 7.228e-01, Loss Aux: 5.872e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19713, It: 0, Loss Data: 3.941e-02, Loss Eqns: 7.166e-01, Loss Aux: 6.645e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19714, It: 0, Loss Data: 3.417e-02, Loss Eqns: 7.578e-01, Loss Aux: 5.766e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19715, It: 0, Loss Data: 3.869e-02, Loss Eqns: 7.425e-01, Loss Aux: 5.899e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19716, It: 0, Loss Data: 3.586e-02, Loss Eqns: 7.260e-01, Loss Aux: 7.126e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19717, It: 0, Loss Data: 3.611e-02, Loss Eqns: 6.573e-01, Loss Aux: 6.382e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19718, It: 0, Loss Data: 3.760e-02, Loss Eqns: 7.102e-01, Loss Aux: 5.596e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19719, It: 0, Loss Data: 3.349e-02, Loss Eqns: 7.112e-01, Loss Aux: 6.002e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19720, It: 0, Loss Data: 3.087e-02, Loss Eqns: 7.433e-01, Loss Aux: 5.681e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19721, It: 0, Loss Data: 3.384e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.727e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19722, It: 0, Loss Data: 3.748e-02, Loss Eqns: 7.047e-01, Loss Aux: 6.118e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19723, It: 0, Loss Data: 3.480e-02, Loss Eqns: 7.088e-01, Loss Aux: 5.854e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19724, It: 0, Loss Data: 3.167e-02, Loss Eqns: 7.029e-01, Loss Aux: 5.298e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 19725, It: 0, Loss Data: 3.383e-02, Loss Eqns: 7.030e-01, Loss Aux: 5.276e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19726, It: 0, Loss Data: 3.265e-02, Loss Eqns: 7.167e-01, Loss Aux: 5.533e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19727, It: 0, Loss Data: 3.514e-02, Loss Eqns: 7.001e-01, Loss Aux: 5.695e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19728, It: 0, Loss Data: 3.596e-02, Loss Eqns: 6.589e-01, Loss Aux: 5.727e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19729, It: 0, Loss Data: 3.469e-02, Loss Eqns: 6.892e-01, Loss Aux: 5.970e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19730, It: 0, Loss Data: 3.655e-02, Loss Eqns: 6.640e-01, Loss Aux: 6.664e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19731, It: 0, Loss Data: 3.460e-02, Loss Eqns: 6.673e-01, Loss Aux: 5.745e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19732, It: 0, Loss Data: 3.570e-02, Loss Eqns: 7.191e-01, Loss Aux: 5.250e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19733, It: 0, Loss Data: 3.886e-02, Loss Eqns: 6.893e-01, Loss Aux: 5.690e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19734, It: 0, Loss Data: 3.694e-02, Loss Eqns: 6.989e-01, Loss Aux: 6.553e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19735, It: 0, Loss Data: 3.207e-02, Loss Eqns: 6.770e-01, Loss Aux: 6.437e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19736, It: 0, Loss Data: 3.315e-02, Loss Eqns: 7.113e-01, Loss Aux: 5.412e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19737, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.735e-01, Loss Aux: 5.450e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19738, It: 0, Loss Data: 3.259e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.666e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19739, It: 0, Loss Data: 3.373e-02, Loss Eqns: 7.202e-01, Loss Aux: 5.557e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19740, It: 0, Loss Data: 3.300e-02, Loss Eqns: 7.337e-01, Loss Aux: 5.549e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19741, It: 0, Loss Data: 3.230e-02, Loss Eqns: 6.957e-01, Loss Aux: 5.463e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19742, It: 0, Loss Data: 3.214e-02, Loss Eqns: 6.736e-01, Loss Aux: 5.580e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19743, It: 0, Loss Data: 3.721e-02, Loss Eqns: 6.640e-01, Loss Aux: 5.960e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19744, It: 0, Loss Data: 3.810e-02, Loss Eqns: 6.691e-01, Loss Aux: 6.602e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 19745, It: 0, Loss Data: 3.353e-02, Loss Eqns: 7.178e-01, Loss Aux: 5.887e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19746, It: 0, Loss Data: 3.499e-02, Loss Eqns: 7.204e-01, Loss Aux: 6.136e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19747, It: 0, Loss Data: 4.588e-02, Loss Eqns: 6.920e-01, Loss Aux: 6.804e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19748, It: 0, Loss Data: 3.555e-02, Loss Eqns: 6.641e-01, Loss Aux: 5.798e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19749, It: 0, Loss Data: 3.570e-02, Loss Eqns: 7.258e-01, Loss Aux: 5.412e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19750, It: 0, Loss Data: 3.570e-02, Loss Eqns: 7.025e-01, Loss Aux: 5.690e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19751, It: 0, Loss Data: 3.664e-02, Loss Eqns: 6.817e-01, Loss Aux: 6.338e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19752, It: 0, Loss Data: 4.069e-02, Loss Eqns: 6.853e-01, Loss Aux: 5.440e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19753, It: 0, Loss Data: 3.377e-02, Loss Eqns: 6.987e-01, Loss Aux: 5.066e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19754, It: 0, Loss Data: 3.678e-02, Loss Eqns: 6.844e-01, Loss Aux: 6.531e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19755, It: 0, Loss Data: 4.217e-02, Loss Eqns: 6.901e-01, Loss Aux: 7.356e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19756, It: 0, Loss Data: 3.751e-02, Loss Eqns: 6.877e-01, Loss Aux: 5.554e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19757, It: 0, Loss Data: 3.589e-02, Loss Eqns: 7.071e-01, Loss Aux: 5.203e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19758, It: 0, Loss Data: 3.664e-02, Loss Eqns: 7.116e-01, Loss Aux: 5.637e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19759, It: 0, Loss Data: 3.414e-02, Loss Eqns: 7.178e-01, Loss Aux: 6.393e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19760, It: 0, Loss Data: 3.779e-02, Loss Eqns: 6.891e-01, Loss Aux: 6.101e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19761, It: 0, Loss Data: 3.652e-02, Loss Eqns: 7.540e-01, Loss Aux: 5.428e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19762, It: 0, Loss Data: 3.265e-02, Loss Eqns: 6.914e-01, Loss Aux: 5.489e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19763, It: 0, Loss Data: 3.850e-02, Loss Eqns: 6.947e-01, Loss Aux: 6.636e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19764, It: 0, Loss Data: 3.816e-02, Loss Eqns: 6.528e-01, Loss Aux: 7.152e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19765, It: 0, Loss Data: 3.701e-02, Loss Eqns: 7.705e-01, Loss Aux: 5.946e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19766, It: 0, Loss Data: 3.351e-02, Loss Eqns: 7.210e-01, Loss Aux: 5.454e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19767, It: 0, Loss Data: 3.326e-02, Loss Eqns: 7.221e-01, Loss Aux: 5.626e-02, Time: 0.148, Learning Rate: 1.0e-03\n",
      "Epoch: 19768, It: 0, Loss Data: 3.225e-02, Loss Eqns: 6.914e-01, Loss Aux: 5.822e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19769, It: 0, Loss Data: 3.206e-02, Loss Eqns: 6.796e-01, Loss Aux: 5.547e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19770, It: 0, Loss Data: 3.619e-02, Loss Eqns: 6.731e-01, Loss Aux: 5.598e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19771, It: 0, Loss Data: 3.559e-02, Loss Eqns: 6.850e-01, Loss Aux: 5.373e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19772, It: 0, Loss Data: 3.337e-02, Loss Eqns: 6.897e-01, Loss Aux: 5.329e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19773, It: 0, Loss Data: 3.714e-02, Loss Eqns: 6.967e-01, Loss Aux: 5.226e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19774, It: 0, Loss Data: 3.856e-02, Loss Eqns: 6.844e-01, Loss Aux: 5.905e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19775, It: 0, Loss Data: 3.332e-02, Loss Eqns: 6.909e-01, Loss Aux: 6.434e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19776, It: 0, Loss Data: 3.269e-02, Loss Eqns: 6.989e-01, Loss Aux: 5.648e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19777, It: 0, Loss Data: 3.691e-02, Loss Eqns: 6.743e-01, Loss Aux: 5.647e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19778, It: 0, Loss Data: 3.531e-02, Loss Eqns: 6.923e-01, Loss Aux: 5.806e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19779, It: 0, Loss Data: 3.236e-02, Loss Eqns: 7.066e-01, Loss Aux: 5.753e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19780, It: 0, Loss Data: 3.619e-02, Loss Eqns: 7.119e-01, Loss Aux: 5.605e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19781, It: 0, Loss Data: 3.522e-02, Loss Eqns: 6.874e-01, Loss Aux: 5.759e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19782, It: 0, Loss Data: 2.995e-02, Loss Eqns: 6.806e-01, Loss Aux: 5.998e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19783, It: 0, Loss Data: 3.657e-02, Loss Eqns: 6.837e-01, Loss Aux: 6.780e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19784, It: 0, Loss Data: 3.291e-02, Loss Eqns: 6.714e-01, Loss Aux: 6.452e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19785, It: 0, Loss Data: 3.637e-02, Loss Eqns: 6.775e-01, Loss Aux: 5.780e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19786, It: 0, Loss Data: 3.128e-02, Loss Eqns: 6.902e-01, Loss Aux: 5.474e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19787, It: 0, Loss Data: 3.324e-02, Loss Eqns: 7.088e-01, Loss Aux: 5.482e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19788, It: 0, Loss Data: 3.137e-02, Loss Eqns: 6.835e-01, Loss Aux: 5.843e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19789, It: 0, Loss Data: 3.887e-02, Loss Eqns: 7.103e-01, Loss Aux: 6.566e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19790, It: 0, Loss Data: 3.325e-02, Loss Eqns: 6.935e-01, Loss Aux: 6.415e-02, Time: 0.149, Learning Rate: 1.0e-03\n",
      "Epoch: 19791, It: 0, Loss Data: 3.010e-02, Loss Eqns: 6.546e-01, Loss Aux: 5.373e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19792, It: 0, Loss Data: 3.598e-02, Loss Eqns: 7.208e-01, Loss Aux: 5.266e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19793, It: 0, Loss Data: 3.677e-02, Loss Eqns: 6.964e-01, Loss Aux: 5.824e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19794, It: 0, Loss Data: 3.310e-02, Loss Eqns: 6.790e-01, Loss Aux: 5.916e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19795, It: 0, Loss Data: 3.414e-02, Loss Eqns: 6.516e-01, Loss Aux: 5.747e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19796, It: 0, Loss Data: 3.046e-02, Loss Eqns: 6.976e-01, Loss Aux: 5.579e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19797, It: 0, Loss Data: 3.340e-02, Loss Eqns: 6.785e-01, Loss Aux: 5.840e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19798, It: 0, Loss Data: 3.813e-02, Loss Eqns: 6.924e-01, Loss Aux: 5.542e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 19799, It: 0, Loss Data: 3.592e-02, Loss Eqns: 6.915e-01, Loss Aux: 5.946e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19800, It: 0, Loss Data: 3.282e-02, Loss Eqns: 6.871e-01, Loss Aux: 6.223e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19801, It: 0, Loss Data: 3.454e-02, Loss Eqns: 6.649e-01, Loss Aux: 6.067e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 19802, It: 0, Loss Data: 3.608e-02, Loss Eqns: 6.703e-01, Loss Aux: 6.352e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19803, It: 0, Loss Data: 3.567e-02, Loss Eqns: 6.810e-01, Loss Aux: 5.951e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19804, It: 0, Loss Data: 4.077e-02, Loss Eqns: 6.519e-01, Loss Aux: 5.504e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19805, It: 0, Loss Data: 3.502e-02, Loss Eqns: 6.833e-01, Loss Aux: 6.060e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19806, It: 0, Loss Data: 3.890e-02, Loss Eqns: 6.834e-01, Loss Aux: 6.653e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19807, It: 0, Loss Data: 3.563e-02, Loss Eqns: 7.052e-01, Loss Aux: 6.196e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19808, It: 0, Loss Data: 3.767e-02, Loss Eqns: 7.199e-01, Loss Aux: 5.323e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19809, It: 0, Loss Data: 3.046e-02, Loss Eqns: 7.179e-01, Loss Aux: 5.175e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19810, It: 0, Loss Data: 3.735e-02, Loss Eqns: 6.859e-01, Loss Aux: 5.611e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19811, It: 0, Loss Data: 3.661e-02, Loss Eqns: 6.708e-01, Loss Aux: 5.648e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19812, It: 0, Loss Data: 3.688e-02, Loss Eqns: 6.937e-01, Loss Aux: 5.569e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19813, It: 0, Loss Data: 3.840e-02, Loss Eqns: 7.241e-01, Loss Aux: 5.550e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19814, It: 0, Loss Data: 3.754e-02, Loss Eqns: 6.830e-01, Loss Aux: 5.789e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19815, It: 0, Loss Data: 3.404e-02, Loss Eqns: 7.364e-01, Loss Aux: 5.835e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19816, It: 0, Loss Data: 3.269e-02, Loss Eqns: 7.075e-01, Loss Aux: 5.364e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19817, It: 0, Loss Data: 3.485e-02, Loss Eqns: 7.292e-01, Loss Aux: 5.923e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19818, It: 0, Loss Data: 3.377e-02, Loss Eqns: 6.760e-01, Loss Aux: 6.345e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19819, It: 0, Loss Data: 3.467e-02, Loss Eqns: 7.297e-01, Loss Aux: 5.976e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19820, It: 0, Loss Data: 3.705e-02, Loss Eqns: 6.612e-01, Loss Aux: 5.787e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19821, It: 0, Loss Data: 3.546e-02, Loss Eqns: 6.834e-01, Loss Aux: 6.387e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19822, It: 0, Loss Data: 3.686e-02, Loss Eqns: 7.355e-01, Loss Aux: 5.983e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19823, It: 0, Loss Data: 3.647e-02, Loss Eqns: 7.072e-01, Loss Aux: 5.580e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19824, It: 0, Loss Data: 3.523e-02, Loss Eqns: 7.348e-01, Loss Aux: 5.753e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19825, It: 0, Loss Data: 3.405e-02, Loss Eqns: 7.455e-01, Loss Aux: 5.985e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19826, It: 0, Loss Data: 3.483e-02, Loss Eqns: 7.304e-01, Loss Aux: 6.580e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19827, It: 0, Loss Data: 3.790e-02, Loss Eqns: 7.169e-01, Loss Aux: 6.392e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19828, It: 0, Loss Data: 3.784e-02, Loss Eqns: 7.259e-01, Loss Aux: 5.713e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19829, It: 0, Loss Data: 3.575e-02, Loss Eqns: 7.341e-01, Loss Aux: 5.933e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19830, It: 0, Loss Data: 3.429e-02, Loss Eqns: 7.212e-01, Loss Aux: 5.981e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19831, It: 0, Loss Data: 3.660e-02, Loss Eqns: 7.541e-01, Loss Aux: 5.412e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19832, It: 0, Loss Data: 3.407e-02, Loss Eqns: 6.938e-01, Loss Aux: 5.755e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19833, It: 0, Loss Data: 3.221e-02, Loss Eqns: 7.216e-01, Loss Aux: 5.920e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19834, It: 0, Loss Data: 3.568e-02, Loss Eqns: 6.773e-01, Loss Aux: 5.440e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19835, It: 0, Loss Data: 3.320e-02, Loss Eqns: 7.041e-01, Loss Aux: 5.303e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19836, It: 0, Loss Data: 3.265e-02, Loss Eqns: 7.164e-01, Loss Aux: 5.698e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19837, It: 0, Loss Data: 3.715e-02, Loss Eqns: 7.099e-01, Loss Aux: 6.172e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19838, It: 0, Loss Data: 3.688e-02, Loss Eqns: 6.992e-01, Loss Aux: 5.718e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19839, It: 0, Loss Data: 3.363e-02, Loss Eqns: 7.095e-01, Loss Aux: 5.614e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19840, It: 0, Loss Data: 3.348e-02, Loss Eqns: 7.500e-01, Loss Aux: 6.072e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19841, It: 0, Loss Data: 3.299e-02, Loss Eqns: 7.095e-01, Loss Aux: 6.107e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19842, It: 0, Loss Data: 3.395e-02, Loss Eqns: 6.750e-01, Loss Aux: 5.871e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19843, It: 0, Loss Data: 3.342e-02, Loss Eqns: 7.337e-01, Loss Aux: 5.670e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19844, It: 0, Loss Data: 3.489e-02, Loss Eqns: 7.302e-01, Loss Aux: 5.755e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19845, It: 0, Loss Data: 3.380e-02, Loss Eqns: 6.862e-01, Loss Aux: 6.923e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19846, It: 0, Loss Data: 3.737e-02, Loss Eqns: 6.790e-01, Loss Aux: 7.064e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19847, It: 0, Loss Data: 3.782e-02, Loss Eqns: 6.471e-01, Loss Aux: 5.614e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19848, It: 0, Loss Data: 3.943e-02, Loss Eqns: 6.642e-01, Loss Aux: 5.364e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19849, It: 0, Loss Data: 3.206e-02, Loss Eqns: 7.202e-01, Loss Aux: 6.095e-02, Time: 0.168, Learning Rate: 1.0e-03\n",
      "Epoch: 19850, It: 0, Loss Data: 3.214e-02, Loss Eqns: 6.989e-01, Loss Aux: 6.081e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19851, It: 0, Loss Data: 3.455e-02, Loss Eqns: 6.991e-01, Loss Aux: 6.089e-02, Time: 0.183, Learning Rate: 1.0e-03\n",
      "Epoch: 19852, It: 0, Loss Data: 3.540e-02, Loss Eqns: 6.892e-01, Loss Aux: 6.462e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19853, It: 0, Loss Data: 3.152e-02, Loss Eqns: 7.067e-01, Loss Aux: 6.061e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19854, It: 0, Loss Data: 3.393e-02, Loss Eqns: 6.867e-01, Loss Aux: 5.585e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19855, It: 0, Loss Data: 3.697e-02, Loss Eqns: 6.695e-01, Loss Aux: 5.689e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19856, It: 0, Loss Data: 3.507e-02, Loss Eqns: 6.420e-01, Loss Aux: 5.756e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19857, It: 0, Loss Data: 3.344e-02, Loss Eqns: 6.819e-01, Loss Aux: 5.571e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19858, It: 0, Loss Data: 3.275e-02, Loss Eqns: 6.972e-01, Loss Aux: 5.600e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19859, It: 0, Loss Data: 3.199e-02, Loss Eqns: 7.008e-01, Loss Aux: 5.843e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19860, It: 0, Loss Data: 3.167e-02, Loss Eqns: 6.852e-01, Loss Aux: 5.692e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19861, It: 0, Loss Data: 3.349e-02, Loss Eqns: 6.946e-01, Loss Aux: 5.917e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19862, It: 0, Loss Data: 3.058e-02, Loss Eqns: 7.022e-01, Loss Aux: 5.692e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19863, It: 0, Loss Data: 3.699e-02, Loss Eqns: 6.696e-01, Loss Aux: 5.703e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19864, It: 0, Loss Data: 3.962e-02, Loss Eqns: 6.984e-01, Loss Aux: 5.929e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19865, It: 0, Loss Data: 3.774e-02, Loss Eqns: 6.842e-01, Loss Aux: 6.294e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19866, It: 0, Loss Data: 3.240e-02, Loss Eqns: 7.007e-01, Loss Aux: 5.946e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19867, It: 0, Loss Data: 3.470e-02, Loss Eqns: 7.045e-01, Loss Aux: 5.538e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 19868, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.827e-01, Loss Aux: 6.140e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19869, It: 0, Loss Data: 3.516e-02, Loss Eqns: 6.898e-01, Loss Aux: 6.648e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19870, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.798e-01, Loss Aux: 5.440e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19871, It: 0, Loss Data: 3.887e-02, Loss Eqns: 7.337e-01, Loss Aux: 5.167e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19872, It: 0, Loss Data: 3.720e-02, Loss Eqns: 6.930e-01, Loss Aux: 6.089e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19873, It: 0, Loss Data: 3.264e-02, Loss Eqns: 7.048e-01, Loss Aux: 6.525e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19874, It: 0, Loss Data: 3.581e-02, Loss Eqns: 6.854e-01, Loss Aux: 5.902e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19875, It: 0, Loss Data: 3.533e-02, Loss Eqns: 6.822e-01, Loss Aux: 5.848e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19876, It: 0, Loss Data: 3.597e-02, Loss Eqns: 6.974e-01, Loss Aux: 6.015e-02, Time: 0.175, Learning Rate: 1.0e-03\n",
      "Epoch: 19877, It: 0, Loss Data: 3.494e-02, Loss Eqns: 7.187e-01, Loss Aux: 5.896e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19878, It: 0, Loss Data: 3.511e-02, Loss Eqns: 6.808e-01, Loss Aux: 5.909e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19879, It: 0, Loss Data: 3.359e-02, Loss Eqns: 6.832e-01, Loss Aux: 6.150e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19880, It: 0, Loss Data: 3.721e-02, Loss Eqns: 6.990e-01, Loss Aux: 6.230e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19881, It: 0, Loss Data: 3.852e-02, Loss Eqns: 7.397e-01, Loss Aux: 5.530e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19882, It: 0, Loss Data: 3.169e-02, Loss Eqns: 6.753e-01, Loss Aux: 5.352e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19883, It: 0, Loss Data: 3.433e-02, Loss Eqns: 7.186e-01, Loss Aux: 5.398e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19884, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.898e-01, Loss Aux: 5.851e-02, Time: 0.195, Learning Rate: 1.0e-03\n",
      "Epoch: 19885, It: 0, Loss Data: 3.552e-02, Loss Eqns: 6.812e-01, Loss Aux: 5.673e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19886, It: 0, Loss Data: 3.445e-02, Loss Eqns: 7.163e-01, Loss Aux: 6.053e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19887, It: 0, Loss Data: 3.562e-02, Loss Eqns: 6.860e-01, Loss Aux: 6.483e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19888, It: 0, Loss Data: 2.936e-02, Loss Eqns: 7.229e-01, Loss Aux: 5.814e-02, Time: 0.196, Learning Rate: 1.0e-03\n",
      "Epoch: 19889, It: 0, Loss Data: 3.429e-02, Loss Eqns: 7.033e-01, Loss Aux: 5.733e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19890, It: 0, Loss Data: 3.344e-02, Loss Eqns: 6.961e-01, Loss Aux: 5.533e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19891, It: 0, Loss Data: 3.192e-02, Loss Eqns: 7.286e-01, Loss Aux: 5.721e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19892, It: 0, Loss Data: 3.767e-02, Loss Eqns: 6.942e-01, Loss Aux: 5.855e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19893, It: 0, Loss Data: 3.184e-02, Loss Eqns: 6.928e-01, Loss Aux: 6.249e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19894, It: 0, Loss Data: 3.545e-02, Loss Eqns: 6.915e-01, Loss Aux: 5.765e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19895, It: 0, Loss Data: 3.708e-02, Loss Eqns: 6.728e-01, Loss Aux: 5.803e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19896, It: 0, Loss Data: 3.322e-02, Loss Eqns: 7.057e-01, Loss Aux: 5.672e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19897, It: 0, Loss Data: 2.855e-02, Loss Eqns: 7.512e-01, Loss Aux: 5.881e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19898, It: 0, Loss Data: 3.372e-02, Loss Eqns: 7.334e-01, Loss Aux: 5.832e-02, Time: 0.178, Learning Rate: 1.0e-03\n",
      "Epoch: 19899, It: 0, Loss Data: 3.588e-02, Loss Eqns: 7.659e-01, Loss Aux: 5.922e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19900, It: 0, Loss Data: 3.616e-02, Loss Eqns: 7.902e-01, Loss Aux: 6.022e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19901, It: 0, Loss Data: 3.548e-02, Loss Eqns: 7.789e-01, Loss Aux: 5.455e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19902, It: 0, Loss Data: 3.212e-02, Loss Eqns: 7.543e-01, Loss Aux: 5.663e-02, Time: 0.190, Learning Rate: 1.0e-03\n",
      "Epoch: 19903, It: 0, Loss Data: 3.965e-02, Loss Eqns: 6.544e-01, Loss Aux: 6.951e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19904, It: 0, Loss Data: 3.158e-02, Loss Eqns: 6.903e-01, Loss Aux: 6.796e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19905, It: 0, Loss Data: 3.473e-02, Loss Eqns: 7.024e-01, Loss Aux: 5.898e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 19906, It: 0, Loss Data: 4.071e-02, Loss Eqns: 7.268e-01, Loss Aux: 5.618e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19907, It: 0, Loss Data: 2.974e-02, Loss Eqns: 7.193e-01, Loss Aux: 6.105e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19908, It: 0, Loss Data: 3.369e-02, Loss Eqns: 7.314e-01, Loss Aux: 6.322e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19909, It: 0, Loss Data: 4.220e-02, Loss Eqns: 7.013e-01, Loss Aux: 6.743e-02, Time: 0.152, Learning Rate: 1.0e-03\n",
      "Epoch: 19910, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.852e-01, Loss Aux: 6.071e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19911, It: 0, Loss Data: 3.366e-02, Loss Eqns: 7.136e-01, Loss Aux: 5.526e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19912, It: 0, Loss Data: 3.178e-02, Loss Eqns: 7.617e-01, Loss Aux: 5.892e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19913, It: 0, Loss Data: 3.436e-02, Loss Eqns: 6.992e-01, Loss Aux: 6.710e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19914, It: 0, Loss Data: 3.609e-02, Loss Eqns: 7.218e-01, Loss Aux: 5.966e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19915, It: 0, Loss Data: 3.490e-02, Loss Eqns: 6.874e-01, Loss Aux: 5.398e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19916, It: 0, Loss Data: 3.566e-02, Loss Eqns: 6.889e-01, Loss Aux: 5.476e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19917, It: 0, Loss Data: 3.391e-02, Loss Eqns: 7.017e-01, Loss Aux: 5.651e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19918, It: 0, Loss Data: 3.942e-02, Loss Eqns: 6.442e-01, Loss Aux: 5.611e-02, Time: 0.171, Learning Rate: 1.0e-03\n",
      "Epoch: 19919, It: 0, Loss Data: 3.798e-02, Loss Eqns: 7.070e-01, Loss Aux: 6.144e-02, Time: 0.198, Learning Rate: 1.0e-03\n",
      "Epoch: 19920, It: 0, Loss Data: 3.447e-02, Loss Eqns: 6.646e-01, Loss Aux: 5.346e-02, Time: 0.180, Learning Rate: 1.0e-03\n",
      "Epoch: 19921, It: 0, Loss Data: 3.696e-02, Loss Eqns: 7.096e-01, Loss Aux: 5.740e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19922, It: 0, Loss Data: 3.351e-02, Loss Eqns: 6.925e-01, Loss Aux: 6.389e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19923, It: 0, Loss Data: 3.506e-02, Loss Eqns: 6.970e-01, Loss Aux: 5.681e-02, Time: 0.154, Learning Rate: 1.0e-03\n",
      "Epoch: 19924, It: 0, Loss Data: 3.191e-02, Loss Eqns: 6.770e-01, Loss Aux: 5.623e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19925, It: 0, Loss Data: 3.567e-02, Loss Eqns: 6.874e-01, Loss Aux: 7.035e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19926, It: 0, Loss Data: 2.938e-02, Loss Eqns: 7.050e-01, Loss Aux: 6.191e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19927, It: 0, Loss Data: 3.598e-02, Loss Eqns: 6.879e-01, Loss Aux: 5.737e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19928, It: 0, Loss Data: 3.683e-02, Loss Eqns: 6.929e-01, Loss Aux: 5.744e-02, Time: 0.164, Learning Rate: 1.0e-03\n",
      "Epoch: 19929, It: 0, Loss Data: 3.402e-02, Loss Eqns: 6.874e-01, Loss Aux: 6.631e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19930, It: 0, Loss Data: 3.735e-02, Loss Eqns: 7.034e-01, Loss Aux: 6.356e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19931, It: 0, Loss Data: 3.632e-02, Loss Eqns: 7.246e-01, Loss Aux: 5.585e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19932, It: 0, Loss Data: 3.254e-02, Loss Eqns: 6.771e-01, Loss Aux: 5.261e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19933, It: 0, Loss Data: 3.431e-02, Loss Eqns: 6.973e-01, Loss Aux: 5.856e-02, Time: 0.191, Learning Rate: 1.0e-03\n",
      "Epoch: 19934, It: 0, Loss Data: 3.280e-02, Loss Eqns: 6.746e-01, Loss Aux: 7.491e-02, Time: 0.192, Learning Rate: 1.0e-03\n",
      "Epoch: 19935, It: 0, Loss Data: 3.482e-02, Loss Eqns: 7.398e-01, Loss Aux: 7.465e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19936, It: 0, Loss Data: 3.569e-02, Loss Eqns: 6.861e-01, Loss Aux: 5.873e-02, Time: 0.182, Learning Rate: 1.0e-03\n",
      "Epoch: 19937, It: 0, Loss Data: 3.476e-02, Loss Eqns: 6.769e-01, Loss Aux: 5.656e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19938, It: 0, Loss Data: 3.612e-02, Loss Eqns: 6.829e-01, Loss Aux: 5.542e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19939, It: 0, Loss Data: 3.486e-02, Loss Eqns: 7.146e-01, Loss Aux: 5.343e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19940, It: 0, Loss Data: 3.639e-02, Loss Eqns: 7.187e-01, Loss Aux: 5.624e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19941, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.782e-01, Loss Aux: 7.873e-02, Time: 0.187, Learning Rate: 1.0e-03\n",
      "Epoch: 19942, It: 0, Loss Data: 3.910e-02, Loss Eqns: 6.875e-01, Loss Aux: 8.035e-02, Time: 0.186, Learning Rate: 1.0e-03\n",
      "Epoch: 19943, It: 0, Loss Data: 3.646e-02, Loss Eqns: 7.026e-01, Loss Aux: 5.157e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19944, It: 0, Loss Data: 3.968e-02, Loss Eqns: 7.028e-01, Loss Aux: 5.808e-02, Time: 0.203, Learning Rate: 1.0e-03\n",
      "Epoch: 19945, It: 0, Loss Data: 3.616e-02, Loss Eqns: 7.154e-01, Loss Aux: 6.310e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19946, It: 0, Loss Data: 3.933e-02, Loss Eqns: 6.807e-01, Loss Aux: 5.628e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19947, It: 0, Loss Data: 3.818e-02, Loss Eqns: 6.944e-01, Loss Aux: 5.995e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 19948, It: 0, Loss Data: 3.840e-02, Loss Eqns: 7.119e-01, Loss Aux: 6.712e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19949, It: 0, Loss Data: 3.436e-02, Loss Eqns: 7.325e-01, Loss Aux: 5.617e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19950, It: 0, Loss Data: 3.510e-02, Loss Eqns: 7.049e-01, Loss Aux: 5.638e-02, Time: 0.161, Learning Rate: 1.0e-03\n",
      "Epoch: 19951, It: 0, Loss Data: 3.600e-02, Loss Eqns: 6.818e-01, Loss Aux: 5.997e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19952, It: 0, Loss Data: 3.523e-02, Loss Eqns: 7.496e-01, Loss Aux: 6.507e-02, Time: 0.188, Learning Rate: 1.0e-03\n",
      "Epoch: 19953, It: 0, Loss Data: 3.768e-02, Loss Eqns: 7.037e-01, Loss Aux: 6.091e-02, Time: 0.150, Learning Rate: 1.0e-03\n",
      "Epoch: 19954, It: 0, Loss Data: 3.213e-02, Loss Eqns: 7.282e-01, Loss Aux: 5.627e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19955, It: 0, Loss Data: 2.847e-02, Loss Eqns: 6.896e-01, Loss Aux: 5.568e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19956, It: 0, Loss Data: 3.212e-02, Loss Eqns: 7.097e-01, Loss Aux: 5.953e-02, Time: 0.153, Learning Rate: 1.0e-03\n",
      "Epoch: 19957, It: 0, Loss Data: 3.973e-02, Loss Eqns: 6.913e-01, Loss Aux: 6.204e-02, Time: 0.160, Learning Rate: 1.0e-03\n",
      "Epoch: 19958, It: 0, Loss Data: 3.650e-02, Loss Eqns: 6.776e-01, Loss Aux: 5.823e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19959, It: 0, Loss Data: 3.226e-02, Loss Eqns: 7.263e-01, Loss Aux: 5.524e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19960, It: 0, Loss Data: 3.754e-02, Loss Eqns: 7.314e-01, Loss Aux: 6.512e-02, Time: 0.159, Learning Rate: 1.0e-03\n",
      "Epoch: 19961, It: 0, Loss Data: 3.566e-02, Loss Eqns: 6.927e-01, Loss Aux: 5.986e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19962, It: 0, Loss Data: 3.278e-02, Loss Eqns: 7.000e-01, Loss Aux: 5.612e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19963, It: 0, Loss Data: 3.598e-02, Loss Eqns: 7.033e-01, Loss Aux: 5.974e-02, Time: 0.146, Learning Rate: 1.0e-03\n",
      "Epoch: 19964, It: 0, Loss Data: 3.562e-02, Loss Eqns: 6.564e-01, Loss Aux: 7.117e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19965, It: 0, Loss Data: 3.133e-02, Loss Eqns: 6.715e-01, Loss Aux: 5.822e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19966, It: 0, Loss Data: 3.445e-02, Loss Eqns: 6.828e-01, Loss Aux: 5.560e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19967, It: 0, Loss Data: 3.290e-02, Loss Eqns: 6.574e-01, Loss Aux: 6.552e-02, Time: 0.169, Learning Rate: 1.0e-03\n",
      "Epoch: 19968, It: 0, Loss Data: 3.853e-02, Loss Eqns: 6.975e-01, Loss Aux: 7.193e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19969, It: 0, Loss Data: 3.531e-02, Loss Eqns: 6.847e-01, Loss Aux: 5.712e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19970, It: 0, Loss Data: 3.244e-02, Loss Eqns: 7.320e-01, Loss Aux: 5.540e-02, Time: 0.156, Learning Rate: 1.0e-03\n",
      "Epoch: 19971, It: 0, Loss Data: 3.326e-02, Loss Eqns: 7.032e-01, Loss Aux: 6.121e-02, Time: 0.176, Learning Rate: 1.0e-03\n",
      "Epoch: 19972, It: 0, Loss Data: 3.372e-02, Loss Eqns: 6.967e-01, Loss Aux: 6.677e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19973, It: 0, Loss Data: 3.380e-02, Loss Eqns: 6.562e-01, Loss Aux: 5.531e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19974, It: 0, Loss Data: 3.667e-02, Loss Eqns: 7.070e-01, Loss Aux: 5.314e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19975, It: 0, Loss Data: 3.625e-02, Loss Eqns: 7.035e-01, Loss Aux: 5.278e-02, Time: 0.172, Learning Rate: 1.0e-03\n",
      "Epoch: 19976, It: 0, Loss Data: 3.557e-02, Loss Eqns: 6.589e-01, Loss Aux: 5.678e-02, Time: 0.151, Learning Rate: 1.0e-03\n",
      "Epoch: 19977, It: 0, Loss Data: 2.867e-02, Loss Eqns: 7.223e-01, Loss Aux: 5.726e-02, Time: 0.173, Learning Rate: 1.0e-03\n",
      "Epoch: 19978, It: 0, Loss Data: 3.506e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.177e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19979, It: 0, Loss Data: 3.992e-02, Loss Eqns: 6.994e-01, Loss Aux: 5.349e-02, Time: 0.158, Learning Rate: 1.0e-03\n",
      "Epoch: 19980, It: 0, Loss Data: 3.492e-02, Loss Eqns: 6.599e-01, Loss Aux: 6.702e-02, Time: 0.162, Learning Rate: 1.0e-03\n",
      "Epoch: 19981, It: 0, Loss Data: 3.320e-02, Loss Eqns: 6.451e-01, Loss Aux: 6.778e-02, Time: 0.155, Learning Rate: 1.0e-03\n",
      "Epoch: 19982, It: 0, Loss Data: 3.790e-02, Loss Eqns: 7.051e-01, Loss Aux: 5.525e-02, Time: 0.163, Learning Rate: 1.0e-03\n",
      "Epoch: 19983, It: 0, Loss Data: 3.444e-02, Loss Eqns: 6.744e-01, Loss Aux: 5.593e-02, Time: 0.165, Learning Rate: 1.0e-03\n",
      "Epoch: 19984, It: 0, Loss Data: 3.142e-02, Loss Eqns: 6.824e-01, Loss Aux: 6.030e-02, Time: 0.174, Learning Rate: 1.0e-03\n",
      "Epoch: 19985, It: 0, Loss Data: 3.161e-02, Loss Eqns: 6.962e-01, Loss Aux: 5.819e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19986, It: 0, Loss Data: 3.361e-02, Loss Eqns: 6.912e-01, Loss Aux: 5.521e-02, Time: 0.170, Learning Rate: 1.0e-03\n",
      "Epoch: 19987, It: 0, Loss Data: 3.515e-02, Loss Eqns: 6.879e-01, Loss Aux: 5.828e-02, Time: 0.157, Learning Rate: 1.0e-03\n",
      "Epoch: 19988, It: 0, Loss Data: 3.626e-02, Loss Eqns: 7.014e-01, Loss Aux: 6.185e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19989, It: 0, Loss Data: 3.536e-02, Loss Eqns: 6.678e-01, Loss Aux: 6.405e-02, Time: 0.167, Learning Rate: 1.0e-03\n",
      "Epoch: 19990, It: 0, Loss Data: 2.829e-02, Loss Eqns: 7.041e-01, Loss Aux: 6.241e-02, Time: 0.166, Learning Rate: 1.0e-03\n",
      "Epoch: 19991, It: 0, Loss Data: 3.572e-02, Loss Eqns: 6.852e-01, Loss Aux: 6.124e-02, Time: 0.197, Learning Rate: 1.0e-03\n",
      "Epoch: 19992, It: 0, Loss Data: 3.305e-02, Loss Eqns: 6.950e-01, Loss Aux: 5.791e-02, Time: 0.185, Learning Rate: 1.0e-03\n",
      "Epoch: 19993, It: 0, Loss Data: 3.446e-02, Loss Eqns: 6.476e-01, Loss Aux: 5.931e-02, Time: 0.184, Learning Rate: 1.0e-03\n",
      "Epoch: 19994, It: 0, Loss Data: 3.264e-02, Loss Eqns: 7.527e-01, Loss Aux: 5.816e-02, Time: 0.194, Learning Rate: 1.0e-03\n",
      "Epoch: 19995, It: 0, Loss Data: 3.098e-02, Loss Eqns: 7.020e-01, Loss Aux: 5.370e-02, Time: 0.179, Learning Rate: 1.0e-03\n",
      "Epoch: 19996, It: 0, Loss Data: 3.614e-02, Loss Eqns: 6.796e-01, Loss Aux: 5.352e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 19997, It: 0, Loss Data: 3.507e-02, Loss Eqns: 6.744e-01, Loss Aux: 5.918e-02, Time: 0.177, Learning Rate: 1.0e-03\n",
      "Epoch: 19998, It: 0, Loss Data: 3.524e-02, Loss Eqns: 6.602e-01, Loss Aux: 5.885e-02, Time: 0.189, Learning Rate: 1.0e-03\n",
      "Epoch: 19999, It: 0, Loss Data: 3.553e-02, Loss Eqns: 6.567e-01, Loss Aux: 5.699e-02, Time: 0.181, Learning Rate: 1.0e-03\n",
      "Epoch: 0, It: 0, Loss Data: 3.661e-02, Loss Eqns: 7.026e-01, Loss Aux: 5.685e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1, It: 0, Loss Data: 3.310e-02, Loss Eqns: 6.710e-01, Loss Aux: 5.671e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 2, It: 0, Loss Data: 3.503e-02, Loss Eqns: 7.196e-01, Loss Aux: 5.691e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 3, It: 0, Loss Data: 3.750e-02, Loss Eqns: 6.643e-01, Loss Aux: 5.699e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 4, It: 0, Loss Data: 3.453e-02, Loss Eqns: 6.703e-01, Loss Aux: 5.660e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 5, It: 0, Loss Data: 3.389e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.599e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 6, It: 0, Loss Data: 3.174e-02, Loss Eqns: 6.644e-01, Loss Aux: 5.575e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 7, It: 0, Loss Data: 3.621e-02, Loss Eqns: 6.509e-01, Loss Aux: 5.574e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 8, It: 0, Loss Data: 2.883e-02, Loss Eqns: 6.886e-01, Loss Aux: 5.568e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 9, It: 0, Loss Data: 3.465e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.568e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 10, It: 0, Loss Data: 3.303e-02, Loss Eqns: 6.680e-01, Loss Aux: 5.588e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 11, It: 0, Loss Data: 3.689e-02, Loss Eqns: 6.682e-01, Loss Aux: 5.611e-02, Time: 0.199, Learning Rate: 1.0e-04\n",
      "Epoch: 12, It: 0, Loss Data: 3.251e-02, Loss Eqns: 6.774e-01, Loss Aux: 5.646e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 13, It: 0, Loss Data: 3.088e-02, Loss Eqns: 6.884e-01, Loss Aux: 5.687e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 14, It: 0, Loss Data: 3.547e-02, Loss Eqns: 6.878e-01, Loss Aux: 5.765e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 15, It: 0, Loss Data: 3.726e-02, Loss Eqns: 6.623e-01, Loss Aux: 5.847e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 16, It: 0, Loss Data: 3.767e-02, Loss Eqns: 6.880e-01, Loss Aux: 5.920e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 17, It: 0, Loss Data: 3.360e-02, Loss Eqns: 6.893e-01, Loss Aux: 5.969e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 18, It: 0, Loss Data: 3.619e-02, Loss Eqns: 7.031e-01, Loss Aux: 6.000e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 19, It: 0, Loss Data: 3.308e-02, Loss Eqns: 6.616e-01, Loss Aux: 5.973e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 20, It: 0, Loss Data: 3.456e-02, Loss Eqns: 6.631e-01, Loss Aux: 5.886e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 21, It: 0, Loss Data: 3.181e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.812e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 22, It: 0, Loss Data: 3.813e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.743e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 23, It: 0, Loss Data: 3.755e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.688e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 24, It: 0, Loss Data: 3.168e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.658e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 25, It: 0, Loss Data: 3.230e-02, Loss Eqns: 6.702e-01, Loss Aux: 5.634e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 26, It: 0, Loss Data: 3.323e-02, Loss Eqns: 6.820e-01, Loss Aux: 5.639e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 27, It: 0, Loss Data: 3.541e-02, Loss Eqns: 6.495e-01, Loss Aux: 5.653e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 28, It: 0, Loss Data: 3.846e-02, Loss Eqns: 7.014e-01, Loss Aux: 5.666e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 29, It: 0, Loss Data: 3.279e-02, Loss Eqns: 6.715e-01, Loss Aux: 5.678e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 30, It: 0, Loss Data: 3.452e-02, Loss Eqns: 6.629e-01, Loss Aux: 5.678e-02, Time: 0.198, Learning Rate: 1.0e-04\n",
      "Epoch: 31, It: 0, Loss Data: 3.288e-02, Loss Eqns: 6.657e-01, Loss Aux: 5.703e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 32, It: 0, Loss Data: 3.260e-02, Loss Eqns: 6.959e-01, Loss Aux: 5.698e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 33, It: 0, Loss Data: 3.603e-02, Loss Eqns: 7.318e-01, Loss Aux: 5.694e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 34, It: 0, Loss Data: 3.067e-02, Loss Eqns: 6.694e-01, Loss Aux: 5.675e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 35, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.609e-01, Loss Aux: 5.674e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 36, It: 0, Loss Data: 3.283e-02, Loss Eqns: 6.704e-01, Loss Aux: 5.708e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 37, It: 0, Loss Data: 3.454e-02, Loss Eqns: 6.733e-01, Loss Aux: 5.761e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 38, It: 0, Loss Data: 3.306e-02, Loss Eqns: 7.144e-01, Loss Aux: 5.795e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 39, It: 0, Loss Data: 3.777e-02, Loss Eqns: 6.714e-01, Loss Aux: 5.814e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 40, It: 0, Loss Data: 3.256e-02, Loss Eqns: 6.849e-01, Loss Aux: 5.805e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 41, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.717e-01, Loss Aux: 5.777e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 42, It: 0, Loss Data: 3.255e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.716e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 43, It: 0, Loss Data: 2.991e-02, Loss Eqns: 6.903e-01, Loss Aux: 5.659e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 44, It: 0, Loss Data: 2.989e-02, Loss Eqns: 6.879e-01, Loss Aux: 5.586e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 45, It: 0, Loss Data: 3.594e-02, Loss Eqns: 6.792e-01, Loss Aux: 5.531e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 46, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.425e-01, Loss Aux: 5.499e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 47, It: 0, Loss Data: 3.839e-02, Loss Eqns: 6.562e-01, Loss Aux: 5.490e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 48, It: 0, Loss Data: 3.155e-02, Loss Eqns: 6.853e-01, Loss Aux: 5.528e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 49, It: 0, Loss Data: 3.266e-02, Loss Eqns: 6.342e-01, Loss Aux: 5.581e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 50, It: 0, Loss Data: 3.112e-02, Loss Eqns: 6.629e-01, Loss Aux: 5.620e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 51, It: 0, Loss Data: 3.253e-02, Loss Eqns: 6.533e-01, Loss Aux: 5.638e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 52, It: 0, Loss Data: 3.221e-02, Loss Eqns: 6.849e-01, Loss Aux: 5.631e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 53, It: 0, Loss Data: 3.286e-02, Loss Eqns: 6.668e-01, Loss Aux: 5.622e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 54, It: 0, Loss Data: 3.239e-02, Loss Eqns: 6.629e-01, Loss Aux: 5.603e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 55, It: 0, Loss Data: 2.856e-02, Loss Eqns: 6.578e-01, Loss Aux: 5.578e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 56, It: 0, Loss Data: 3.145e-02, Loss Eqns: 7.236e-01, Loss Aux: 5.561e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 57, It: 0, Loss Data: 3.561e-02, Loss Eqns: 6.938e-01, Loss Aux: 5.553e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 58, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.554e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 59, It: 0, Loss Data: 3.555e-02, Loss Eqns: 6.769e-01, Loss Aux: 5.566e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 60, It: 0, Loss Data: 3.069e-02, Loss Eqns: 6.621e-01, Loss Aux: 5.608e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 61, It: 0, Loss Data: 3.884e-02, Loss Eqns: 6.595e-01, Loss Aux: 5.643e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 62, It: 0, Loss Data: 3.467e-02, Loss Eqns: 7.122e-01, Loss Aux: 5.689e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 63, It: 0, Loss Data: 3.809e-02, Loss Eqns: 6.853e-01, Loss Aux: 5.714e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 64, It: 0, Loss Data: 3.541e-02, Loss Eqns: 6.608e-01, Loss Aux: 5.725e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 65, It: 0, Loss Data: 3.254e-02, Loss Eqns: 6.527e-01, Loss Aux: 5.726e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 66, It: 0, Loss Data: 2.954e-02, Loss Eqns: 6.433e-01, Loss Aux: 5.724e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 67, It: 0, Loss Data: 3.471e-02, Loss Eqns: 6.995e-01, Loss Aux: 5.698e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 68, It: 0, Loss Data: 3.387e-02, Loss Eqns: 6.376e-01, Loss Aux: 5.642e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 69, It: 0, Loss Data: 3.255e-02, Loss Eqns: 6.505e-01, Loss Aux: 5.631e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 70, It: 0, Loss Data: 3.284e-02, Loss Eqns: 6.904e-01, Loss Aux: 5.637e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 71, It: 0, Loss Data: 3.186e-02, Loss Eqns: 6.928e-01, Loss Aux: 5.654e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 72, It: 0, Loss Data: 3.494e-02, Loss Eqns: 6.680e-01, Loss Aux: 5.685e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 73, It: 0, Loss Data: 3.348e-02, Loss Eqns: 6.636e-01, Loss Aux: 5.743e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 74, It: 0, Loss Data: 3.174e-02, Loss Eqns: 6.553e-01, Loss Aux: 5.790e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 75, It: 0, Loss Data: 3.293e-02, Loss Eqns: 6.577e-01, Loss Aux: 5.849e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 76, It: 0, Loss Data: 3.409e-02, Loss Eqns: 6.473e-01, Loss Aux: 5.871e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 77, It: 0, Loss Data: 3.585e-02, Loss Eqns: 6.802e-01, Loss Aux: 5.902e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 78, It: 0, Loss Data: 3.945e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.874e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 79, It: 0, Loss Data: 3.446e-02, Loss Eqns: 6.345e-01, Loss Aux: 5.800e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 80, It: 0, Loss Data: 3.239e-02, Loss Eqns: 6.647e-01, Loss Aux: 5.718e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 81, It: 0, Loss Data: 3.782e-02, Loss Eqns: 6.501e-01, Loss Aux: 5.628e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 82, It: 0, Loss Data: 3.488e-02, Loss Eqns: 6.602e-01, Loss Aux: 5.556e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 83, It: 0, Loss Data: 3.527e-02, Loss Eqns: 6.779e-01, Loss Aux: 5.523e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 84, It: 0, Loss Data: 3.359e-02, Loss Eqns: 6.453e-01, Loss Aux: 5.513e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 85, It: 0, Loss Data: 3.276e-02, Loss Eqns: 6.702e-01, Loss Aux: 5.520e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 86, It: 0, Loss Data: 3.299e-02, Loss Eqns: 6.451e-01, Loss Aux: 5.569e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 87, It: 0, Loss Data: 3.489e-02, Loss Eqns: 6.938e-01, Loss Aux: 5.663e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 88, It: 0, Loss Data: 3.300e-02, Loss Eqns: 6.417e-01, Loss Aux: 5.765e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 89, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.813e-01, Loss Aux: 5.826e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 90, It: 0, Loss Data: 3.071e-02, Loss Eqns: 6.788e-01, Loss Aux: 5.891e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 91, It: 0, Loss Data: 3.284e-02, Loss Eqns: 6.936e-01, Loss Aux: 5.932e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 92, It: 0, Loss Data: 3.684e-02, Loss Eqns: 6.842e-01, Loss Aux: 5.962e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 93, It: 0, Loss Data: 3.644e-02, Loss Eqns: 7.331e-01, Loss Aux: 5.934e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 94, It: 0, Loss Data: 3.677e-02, Loss Eqns: 6.420e-01, Loss Aux: 5.888e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 95, It: 0, Loss Data: 3.359e-02, Loss Eqns: 6.924e-01, Loss Aux: 5.854e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 96, It: 0, Loss Data: 3.306e-02, Loss Eqns: 6.481e-01, Loss Aux: 5.818e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 97, It: 0, Loss Data: 3.286e-02, Loss Eqns: 6.570e-01, Loss Aux: 5.784e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 98, It: 0, Loss Data: 3.074e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.751e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 99, It: 0, Loss Data: 3.469e-02, Loss Eqns: 6.773e-01, Loss Aux: 5.726e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 100, It: 0, Loss Data: 3.300e-02, Loss Eqns: 6.701e-01, Loss Aux: 5.710e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 101, It: 0, Loss Data: 3.131e-02, Loss Eqns: 6.694e-01, Loss Aux: 5.688e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 102, It: 0, Loss Data: 3.239e-02, Loss Eqns: 7.004e-01, Loss Aux: 5.692e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 103, It: 0, Loss Data: 3.816e-02, Loss Eqns: 6.580e-01, Loss Aux: 5.671e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 104, It: 0, Loss Data: 3.345e-02, Loss Eqns: 6.771e-01, Loss Aux: 5.659e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 105, It: 0, Loss Data: 2.804e-02, Loss Eqns: 6.832e-01, Loss Aux: 5.658e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 106, It: 0, Loss Data: 3.774e-02, Loss Eqns: 6.514e-01, Loss Aux: 5.702e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 107, It: 0, Loss Data: 3.732e-02, Loss Eqns: 6.522e-01, Loss Aux: 5.759e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 108, It: 0, Loss Data: 3.484e-02, Loss Eqns: 6.637e-01, Loss Aux: 5.849e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 109, It: 0, Loss Data: 3.213e-02, Loss Eqns: 6.801e-01, Loss Aux: 5.937e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 110, It: 0, Loss Data: 3.394e-02, Loss Eqns: 6.622e-01, Loss Aux: 6.020e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 111, It: 0, Loss Data: 3.488e-02, Loss Eqns: 6.641e-01, Loss Aux: 6.056e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 112, It: 0, Loss Data: 3.003e-02, Loss Eqns: 6.911e-01, Loss Aux: 6.024e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 113, It: 0, Loss Data: 3.710e-02, Loss Eqns: 7.203e-01, Loss Aux: 5.958e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 114, It: 0, Loss Data: 3.543e-02, Loss Eqns: 6.290e-01, Loss Aux: 5.838e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 115, It: 0, Loss Data: 2.966e-02, Loss Eqns: 6.764e-01, Loss Aux: 5.725e-02, Time: 0.198, Learning Rate: 1.0e-04\n",
      "Epoch: 116, It: 0, Loss Data: 3.425e-02, Loss Eqns: 6.951e-01, Loss Aux: 5.635e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 117, It: 0, Loss Data: 3.734e-02, Loss Eqns: 6.633e-01, Loss Aux: 5.608e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 118, It: 0, Loss Data: 3.223e-02, Loss Eqns: 6.935e-01, Loss Aux: 5.599e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 119, It: 0, Loss Data: 3.445e-02, Loss Eqns: 6.748e-01, Loss Aux: 5.655e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 120, It: 0, Loss Data: 3.507e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.757e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 121, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.618e-01, Loss Aux: 5.908e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 122, It: 0, Loss Data: 3.508e-02, Loss Eqns: 6.728e-01, Loss Aux: 6.039e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 123, It: 0, Loss Data: 3.452e-02, Loss Eqns: 6.765e-01, Loss Aux: 6.111e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 124, It: 0, Loss Data: 3.261e-02, Loss Eqns: 7.182e-01, Loss Aux: 6.146e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 125, It: 0, Loss Data: 3.617e-02, Loss Eqns: 6.772e-01, Loss Aux: 6.118e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 126, It: 0, Loss Data: 3.610e-02, Loss Eqns: 6.423e-01, Loss Aux: 6.027e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 127, It: 0, Loss Data: 3.077e-02, Loss Eqns: 6.484e-01, Loss Aux: 5.890e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 128, It: 0, Loss Data: 3.330e-02, Loss Eqns: 6.488e-01, Loss Aux: 5.777e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 129, It: 0, Loss Data: 3.348e-02, Loss Eqns: 6.838e-01, Loss Aux: 5.720e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 130, It: 0, Loss Data: 3.513e-02, Loss Eqns: 6.799e-01, Loss Aux: 5.699e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 131, It: 0, Loss Data: 3.754e-02, Loss Eqns: 6.767e-01, Loss Aux: 5.698e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 132, It: 0, Loss Data: 3.599e-02, Loss Eqns: 6.669e-01, Loss Aux: 5.734e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 133, It: 0, Loss Data: 3.303e-02, Loss Eqns: 6.676e-01, Loss Aux: 5.801e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 134, It: 0, Loss Data: 3.197e-02, Loss Eqns: 7.187e-01, Loss Aux: 5.879e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 135, It: 0, Loss Data: 3.606e-02, Loss Eqns: 6.681e-01, Loss Aux: 5.949e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 136, It: 0, Loss Data: 3.353e-02, Loss Eqns: 6.791e-01, Loss Aux: 5.975e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 137, It: 0, Loss Data: 3.484e-02, Loss Eqns: 6.992e-01, Loss Aux: 5.936e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 138, It: 0, Loss Data: 3.025e-02, Loss Eqns: 6.615e-01, Loss Aux: 5.853e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 139, It: 0, Loss Data: 3.009e-02, Loss Eqns: 6.714e-01, Loss Aux: 5.763e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 140, It: 0, Loss Data: 3.478e-02, Loss Eqns: 6.725e-01, Loss Aux: 5.656e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 141, It: 0, Loss Data: 3.391e-02, Loss Eqns: 6.635e-01, Loss Aux: 5.591e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 142, It: 0, Loss Data: 3.107e-02, Loss Eqns: 6.522e-01, Loss Aux: 5.559e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 143, It: 0, Loss Data: 3.407e-02, Loss Eqns: 6.787e-01, Loss Aux: 5.606e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 144, It: 0, Loss Data: 3.605e-02, Loss Eqns: 6.851e-01, Loss Aux: 5.689e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 145, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.572e-01, Loss Aux: 5.778e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 146, It: 0, Loss Data: 3.763e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.843e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 147, It: 0, Loss Data: 3.324e-02, Loss Eqns: 6.833e-01, Loss Aux: 5.867e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 148, It: 0, Loss Data: 3.191e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.875e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 149, It: 0, Loss Data: 3.315e-02, Loss Eqns: 6.751e-01, Loss Aux: 5.875e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 150, It: 0, Loss Data: 3.344e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.848e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 151, It: 0, Loss Data: 3.724e-02, Loss Eqns: 6.537e-01, Loss Aux: 5.829e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 152, It: 0, Loss Data: 3.261e-02, Loss Eqns: 6.621e-01, Loss Aux: 5.796e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 153, It: 0, Loss Data: 3.793e-02, Loss Eqns: 6.939e-01, Loss Aux: 5.742e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 154, It: 0, Loss Data: 3.042e-02, Loss Eqns: 7.191e-01, Loss Aux: 5.708e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 155, It: 0, Loss Data: 2.935e-02, Loss Eqns: 6.933e-01, Loss Aux: 5.674e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 156, It: 0, Loss Data: 3.177e-02, Loss Eqns: 6.902e-01, Loss Aux: 5.672e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 157, It: 0, Loss Data: 3.401e-02, Loss Eqns: 7.110e-01, Loss Aux: 5.675e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 158, It: 0, Loss Data: 3.388e-02, Loss Eqns: 6.480e-01, Loss Aux: 5.666e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 159, It: 0, Loss Data: 3.797e-02, Loss Eqns: 6.790e-01, Loss Aux: 5.681e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 160, It: 0, Loss Data: 3.275e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.686e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 161, It: 0, Loss Data: 3.623e-02, Loss Eqns: 6.705e-01, Loss Aux: 5.693e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 162, It: 0, Loss Data: 3.822e-02, Loss Eqns: 6.740e-01, Loss Aux: 5.706e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 163, It: 0, Loss Data: 3.268e-02, Loss Eqns: 6.845e-01, Loss Aux: 5.679e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 164, It: 0, Loss Data: 3.001e-02, Loss Eqns: 6.792e-01, Loss Aux: 5.634e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 165, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.767e-01, Loss Aux: 5.606e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 166, It: 0, Loss Data: 3.317e-02, Loss Eqns: 6.694e-01, Loss Aux: 5.617e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 167, It: 0, Loss Data: 3.182e-02, Loss Eqns: 6.757e-01, Loss Aux: 5.665e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 168, It: 0, Loss Data: 3.081e-02, Loss Eqns: 6.290e-01, Loss Aux: 5.713e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 169, It: 0, Loss Data: 3.524e-02, Loss Eqns: 6.839e-01, Loss Aux: 5.767e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 170, It: 0, Loss Data: 3.197e-02, Loss Eqns: 6.564e-01, Loss Aux: 5.804e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 171, It: 0, Loss Data: 3.313e-02, Loss Eqns: 6.514e-01, Loss Aux: 5.810e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 172, It: 0, Loss Data: 3.950e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.822e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 173, It: 0, Loss Data: 2.933e-02, Loss Eqns: 6.531e-01, Loss Aux: 5.796e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 174, It: 0, Loss Data: 3.108e-02, Loss Eqns: 6.778e-01, Loss Aux: 5.736e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 175, It: 0, Loss Data: 2.926e-02, Loss Eqns: 6.994e-01, Loss Aux: 5.673e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 176, It: 0, Loss Data: 3.267e-02, Loss Eqns: 6.949e-01, Loss Aux: 5.625e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 177, It: 0, Loss Data: 3.218e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.590e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 178, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.738e-01, Loss Aux: 5.576e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 179, It: 0, Loss Data: 3.414e-02, Loss Eqns: 6.666e-01, Loss Aux: 5.608e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 180, It: 0, Loss Data: 3.318e-02, Loss Eqns: 6.594e-01, Loss Aux: 5.695e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 181, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.780e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 182, It: 0, Loss Data: 3.232e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.851e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 183, It: 0, Loss Data: 3.145e-02, Loss Eqns: 6.857e-01, Loss Aux: 5.842e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 184, It: 0, Loss Data: 3.059e-02, Loss Eqns: 6.574e-01, Loss Aux: 5.806e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 185, It: 0, Loss Data: 3.449e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.776e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 186, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.642e-01, Loss Aux: 5.749e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 187, It: 0, Loss Data: 3.444e-02, Loss Eqns: 7.294e-01, Loss Aux: 5.732e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 188, It: 0, Loss Data: 3.688e-02, Loss Eqns: 6.656e-01, Loss Aux: 5.773e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 189, It: 0, Loss Data: 3.013e-02, Loss Eqns: 6.746e-01, Loss Aux: 5.802e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 190, It: 0, Loss Data: 3.099e-02, Loss Eqns: 6.829e-01, Loss Aux: 5.826e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 191, It: 0, Loss Data: 3.454e-02, Loss Eqns: 6.337e-01, Loss Aux: 5.887e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 192, It: 0, Loss Data: 3.321e-02, Loss Eqns: 6.761e-01, Loss Aux: 5.926e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 193, It: 0, Loss Data: 3.099e-02, Loss Eqns: 6.923e-01, Loss Aux: 5.964e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 194, It: 0, Loss Data: 3.126e-02, Loss Eqns: 7.063e-01, Loss Aux: 5.982e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 195, It: 0, Loss Data: 3.132e-02, Loss Eqns: 6.855e-01, Loss Aux: 5.958e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 196, It: 0, Loss Data: 3.375e-02, Loss Eqns: 6.552e-01, Loss Aux: 5.919e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 197, It: 0, Loss Data: 2.962e-02, Loss Eqns: 6.487e-01, Loss Aux: 5.836e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 198, It: 0, Loss Data: 3.521e-02, Loss Eqns: 6.766e-01, Loss Aux: 5.750e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 199, It: 0, Loss Data: 3.162e-02, Loss Eqns: 6.593e-01, Loss Aux: 5.647e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 200, It: 0, Loss Data: 3.335e-02, Loss Eqns: 6.704e-01, Loss Aux: 5.600e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 201, It: 0, Loss Data: 3.529e-02, Loss Eqns: 6.585e-01, Loss Aux: 5.591e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 202, It: 0, Loss Data: 2.353e-02, Loss Eqns: 6.655e-01, Loss Aux: 5.580e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 203, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.610e-01, Loss Aux: 5.590e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 204, It: 0, Loss Data: 3.047e-02, Loss Eqns: 6.558e-01, Loss Aux: 5.608e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 205, It: 0, Loss Data: 3.513e-02, Loss Eqns: 6.330e-01, Loss Aux: 5.625e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 206, It: 0, Loss Data: 3.671e-02, Loss Eqns: 6.868e-01, Loss Aux: 5.647e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 207, It: 0, Loss Data: 3.823e-02, Loss Eqns: 6.593e-01, Loss Aux: 5.683e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 208, It: 0, Loss Data: 3.494e-02, Loss Eqns: 6.708e-01, Loss Aux: 5.717e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 209, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.504e-01, Loss Aux: 5.746e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 210, It: 0, Loss Data: 3.487e-02, Loss Eqns: 6.536e-01, Loss Aux: 5.790e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 211, It: 0, Loss Data: 3.713e-02, Loss Eqns: 6.775e-01, Loss Aux: 5.803e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 212, It: 0, Loss Data: 3.199e-02, Loss Eqns: 6.952e-01, Loss Aux: 5.791e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 213, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.773e-01, Loss Aux: 5.769e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 214, It: 0, Loss Data: 3.816e-02, Loss Eqns: 6.701e-01, Loss Aux: 5.720e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 215, It: 0, Loss Data: 3.353e-02, Loss Eqns: 6.484e-01, Loss Aux: 5.686e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 216, It: 0, Loss Data: 3.001e-02, Loss Eqns: 6.948e-01, Loss Aux: 5.654e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 217, It: 0, Loss Data: 3.414e-02, Loss Eqns: 6.753e-01, Loss Aux: 5.662e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 218, It: 0, Loss Data: 3.314e-02, Loss Eqns: 6.757e-01, Loss Aux: 5.740e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 219, It: 0, Loss Data: 3.328e-02, Loss Eqns: 6.428e-01, Loss Aux: 5.826e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 220, It: 0, Loss Data: 3.265e-02, Loss Eqns: 6.744e-01, Loss Aux: 5.866e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 221, It: 0, Loss Data: 3.363e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.881e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 222, It: 0, Loss Data: 3.222e-02, Loss Eqns: 6.653e-01, Loss Aux: 5.868e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 223, It: 0, Loss Data: 2.993e-02, Loss Eqns: 6.756e-01, Loss Aux: 5.844e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 224, It: 0, Loss Data: 3.334e-02, Loss Eqns: 6.260e-01, Loss Aux: 5.795e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 225, It: 0, Loss Data: 3.666e-02, Loss Eqns: 6.432e-01, Loss Aux: 5.724e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 226, It: 0, Loss Data: 3.618e-02, Loss Eqns: 6.773e-01, Loss Aux: 5.675e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 227, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.725e-01, Loss Aux: 5.659e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 228, It: 0, Loss Data: 3.395e-02, Loss Eqns: 6.842e-01, Loss Aux: 5.693e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 229, It: 0, Loss Data: 3.610e-02, Loss Eqns: 6.528e-01, Loss Aux: 5.752e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 230, It: 0, Loss Data: 3.289e-02, Loss Eqns: 6.423e-01, Loss Aux: 5.834e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 231, It: 0, Loss Data: 3.097e-02, Loss Eqns: 6.644e-01, Loss Aux: 5.887e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 232, It: 0, Loss Data: 3.323e-02, Loss Eqns: 6.444e-01, Loss Aux: 5.882e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 233, It: 0, Loss Data: 3.091e-02, Loss Eqns: 6.621e-01, Loss Aux: 5.821e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 234, It: 0, Loss Data: 3.325e-02, Loss Eqns: 6.476e-01, Loss Aux: 5.787e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 235, It: 0, Loss Data: 3.734e-02, Loss Eqns: 6.620e-01, Loss Aux: 5.765e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 236, It: 0, Loss Data: 3.491e-02, Loss Eqns: 6.429e-01, Loss Aux: 5.782e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 237, It: 0, Loss Data: 3.106e-02, Loss Eqns: 6.735e-01, Loss Aux: 5.785e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 238, It: 0, Loss Data: 3.589e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.803e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 239, It: 0, Loss Data: 2.805e-02, Loss Eqns: 6.452e-01, Loss Aux: 5.843e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 240, It: 0, Loss Data: 3.588e-02, Loss Eqns: 6.914e-01, Loss Aux: 5.862e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 241, It: 0, Loss Data: 2.779e-02, Loss Eqns: 6.435e-01, Loss Aux: 5.872e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 242, It: 0, Loss Data: 3.269e-02, Loss Eqns: 6.782e-01, Loss Aux: 5.839e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 243, It: 0, Loss Data: 3.055e-02, Loss Eqns: 6.740e-01, Loss Aux: 5.778e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 244, It: 0, Loss Data: 2.986e-02, Loss Eqns: 6.728e-01, Loss Aux: 5.705e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 245, It: 0, Loss Data: 3.128e-02, Loss Eqns: 6.673e-01, Loss Aux: 5.640e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 246, It: 0, Loss Data: 3.342e-02, Loss Eqns: 6.794e-01, Loss Aux: 5.593e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 247, It: 0, Loss Data: 3.508e-02, Loss Eqns: 6.675e-01, Loss Aux: 5.595e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 248, It: 0, Loss Data: 3.556e-02, Loss Eqns: 7.077e-01, Loss Aux: 5.607e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 249, It: 0, Loss Data: 3.119e-02, Loss Eqns: 7.086e-01, Loss Aux: 5.637e-02, Time: 0.204, Learning Rate: 1.0e-04\n",
      "Epoch: 250, It: 0, Loss Data: 2.982e-02, Loss Eqns: 6.565e-01, Loss Aux: 5.693e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 251, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.666e-01, Loss Aux: 5.733e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 252, It: 0, Loss Data: 2.877e-02, Loss Eqns: 6.720e-01, Loss Aux: 5.768e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 253, It: 0, Loss Data: 3.319e-02, Loss Eqns: 6.477e-01, Loss Aux: 5.788e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 254, It: 0, Loss Data: 3.576e-02, Loss Eqns: 6.445e-01, Loss Aux: 5.836e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 255, It: 0, Loss Data: 3.323e-02, Loss Eqns: 6.526e-01, Loss Aux: 5.838e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 256, It: 0, Loss Data: 3.383e-02, Loss Eqns: 6.855e-01, Loss Aux: 5.827e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 257, It: 0, Loss Data: 3.653e-02, Loss Eqns: 6.628e-01, Loss Aux: 5.779e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 258, It: 0, Loss Data: 3.480e-02, Loss Eqns: 6.710e-01, Loss Aux: 5.766e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 259, It: 0, Loss Data: 3.532e-02, Loss Eqns: 6.614e-01, Loss Aux: 5.759e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 260, It: 0, Loss Data: 3.550e-02, Loss Eqns: 6.420e-01, Loss Aux: 5.752e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 261, It: 0, Loss Data: 3.104e-02, Loss Eqns: 6.670e-01, Loss Aux: 5.768e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 262, It: 0, Loss Data: 3.096e-02, Loss Eqns: 7.018e-01, Loss Aux: 5.806e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 263, It: 0, Loss Data: 3.268e-02, Loss Eqns: 6.691e-01, Loss Aux: 5.854e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 264, It: 0, Loss Data: 3.882e-02, Loss Eqns: 7.008e-01, Loss Aux: 5.896e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 265, It: 0, Loss Data: 3.395e-02, Loss Eqns: 7.053e-01, Loss Aux: 5.941e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 266, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.759e-01, Loss Aux: 5.931e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 267, It: 0, Loss Data: 2.951e-02, Loss Eqns: 6.798e-01, Loss Aux: 5.835e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 268, It: 0, Loss Data: 3.360e-02, Loss Eqns: 6.476e-01, Loss Aux: 5.734e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 269, It: 0, Loss Data: 2.857e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.647e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 270, It: 0, Loss Data: 3.012e-02, Loss Eqns: 6.739e-01, Loss Aux: 5.568e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 271, It: 0, Loss Data: 3.528e-02, Loss Eqns: 6.680e-01, Loss Aux: 5.515e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 272, It: 0, Loss Data: 3.097e-02, Loss Eqns: 6.517e-01, Loss Aux: 5.503e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 273, It: 0, Loss Data: 3.311e-02, Loss Eqns: 6.343e-01, Loss Aux: 5.530e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 274, It: 0, Loss Data: 3.467e-02, Loss Eqns: 6.975e-01, Loss Aux: 5.591e-02, Time: 0.200, Learning Rate: 1.0e-04\n",
      "Epoch: 275, It: 0, Loss Data: 3.557e-02, Loss Eqns: 6.613e-01, Loss Aux: 5.664e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 276, It: 0, Loss Data: 3.731e-02, Loss Eqns: 6.575e-01, Loss Aux: 5.747e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 277, It: 0, Loss Data: 3.306e-02, Loss Eqns: 6.692e-01, Loss Aux: 5.845e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 278, It: 0, Loss Data: 3.506e-02, Loss Eqns: 7.117e-01, Loss Aux: 5.912e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 279, It: 0, Loss Data: 2.715e-02, Loss Eqns: 6.439e-01, Loss Aux: 5.953e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 280, It: 0, Loss Data: 2.900e-02, Loss Eqns: 6.836e-01, Loss Aux: 5.964e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 281, It: 0, Loss Data: 3.624e-02, Loss Eqns: 6.181e-01, Loss Aux: 5.982e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 282, It: 0, Loss Data: 3.333e-02, Loss Eqns: 6.630e-01, Loss Aux: 5.956e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 283, It: 0, Loss Data: 3.313e-02, Loss Eqns: 6.567e-01, Loss Aux: 5.931e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 284, It: 0, Loss Data: 3.117e-02, Loss Eqns: 6.413e-01, Loss Aux: 5.887e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 285, It: 0, Loss Data: 3.624e-02, Loss Eqns: 6.969e-01, Loss Aux: 5.847e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 286, It: 0, Loss Data: 3.425e-02, Loss Eqns: 6.594e-01, Loss Aux: 5.792e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 287, It: 0, Loss Data: 3.594e-02, Loss Eqns: 6.724e-01, Loss Aux: 5.733e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 288, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.947e-01, Loss Aux: 5.665e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 289, It: 0, Loss Data: 3.022e-02, Loss Eqns: 6.706e-01, Loss Aux: 5.609e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 290, It: 0, Loss Data: 2.833e-02, Loss Eqns: 6.668e-01, Loss Aux: 5.594e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 291, It: 0, Loss Data: 3.180e-02, Loss Eqns: 6.325e-01, Loss Aux: 5.620e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 292, It: 0, Loss Data: 3.139e-02, Loss Eqns: 6.833e-01, Loss Aux: 5.698e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 293, It: 0, Loss Data: 3.285e-02, Loss Eqns: 7.079e-01, Loss Aux: 5.791e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 294, It: 0, Loss Data: 3.059e-02, Loss Eqns: 6.543e-01, Loss Aux: 5.876e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 295, It: 0, Loss Data: 3.596e-02, Loss Eqns: 6.639e-01, Loss Aux: 5.953e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 296, It: 0, Loss Data: 2.778e-02, Loss Eqns: 6.967e-01, Loss Aux: 6.031e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 297, It: 0, Loss Data: 3.299e-02, Loss Eqns: 6.685e-01, Loss Aux: 6.111e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 298, It: 0, Loss Data: 3.447e-02, Loss Eqns: 6.547e-01, Loss Aux: 6.141e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 299, It: 0, Loss Data: 3.260e-02, Loss Eqns: 6.431e-01, Loss Aux: 6.093e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 300, It: 0, Loss Data: 3.400e-02, Loss Eqns: 6.634e-01, Loss Aux: 6.033e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 301, It: 0, Loss Data: 3.145e-02, Loss Eqns: 6.996e-01, Loss Aux: 5.940e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 302, It: 0, Loss Data: 3.272e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.861e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 303, It: 0, Loss Data: 3.008e-02, Loss Eqns: 6.555e-01, Loss Aux: 5.820e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 304, It: 0, Loss Data: 3.155e-02, Loss Eqns: 6.779e-01, Loss Aux: 5.793e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 305, It: 0, Loss Data: 3.243e-02, Loss Eqns: 6.654e-01, Loss Aux: 5.787e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 306, It: 0, Loss Data: 3.169e-02, Loss Eqns: 6.763e-01, Loss Aux: 5.792e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 307, It: 0, Loss Data: 3.046e-02, Loss Eqns: 6.417e-01, Loss Aux: 5.814e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 308, It: 0, Loss Data: 3.107e-02, Loss Eqns: 6.767e-01, Loss Aux: 5.834e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 309, It: 0, Loss Data: 3.161e-02, Loss Eqns: 6.484e-01, Loss Aux: 5.856e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 310, It: 0, Loss Data: 3.044e-02, Loss Eqns: 6.615e-01, Loss Aux: 5.884e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 311, It: 0, Loss Data: 3.317e-02, Loss Eqns: 6.919e-01, Loss Aux: 5.906e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 312, It: 0, Loss Data: 3.289e-02, Loss Eqns: 6.448e-01, Loss Aux: 5.900e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 313, It: 0, Loss Data: 3.067e-02, Loss Eqns: 6.835e-01, Loss Aux: 5.832e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 314, It: 0, Loss Data: 3.477e-02, Loss Eqns: 6.685e-01, Loss Aux: 5.768e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 315, It: 0, Loss Data: 3.272e-02, Loss Eqns: 6.790e-01, Loss Aux: 5.711e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 316, It: 0, Loss Data: 3.371e-02, Loss Eqns: 6.926e-01, Loss Aux: 5.666e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 317, It: 0, Loss Data: 3.421e-02, Loss Eqns: 6.590e-01, Loss Aux: 5.648e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 318, It: 0, Loss Data: 3.493e-02, Loss Eqns: 6.411e-01, Loss Aux: 5.629e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 319, It: 0, Loss Data: 3.374e-02, Loss Eqns: 6.514e-01, Loss Aux: 5.642e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 320, It: 0, Loss Data: 3.193e-02, Loss Eqns: 7.177e-01, Loss Aux: 5.707e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 321, It: 0, Loss Data: 3.049e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.804e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 322, It: 0, Loss Data: 3.284e-02, Loss Eqns: 7.019e-01, Loss Aux: 5.921e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 323, It: 0, Loss Data: 3.058e-02, Loss Eqns: 6.796e-01, Loss Aux: 5.987e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 324, It: 0, Loss Data: 3.296e-02, Loss Eqns: 7.058e-01, Loss Aux: 6.017e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 325, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.645e-01, Loss Aux: 6.071e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 326, It: 0, Loss Data: 3.226e-02, Loss Eqns: 6.644e-01, Loss Aux: 6.053e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 327, It: 0, Loss Data: 3.134e-02, Loss Eqns: 6.659e-01, Loss Aux: 5.993e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 328, It: 0, Loss Data: 3.479e-02, Loss Eqns: 6.972e-01, Loss Aux: 5.917e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 329, It: 0, Loss Data: 3.151e-02, Loss Eqns: 6.745e-01, Loss Aux: 5.835e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 330, It: 0, Loss Data: 3.213e-02, Loss Eqns: 6.513e-01, Loss Aux: 5.793e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 331, It: 0, Loss Data: 3.387e-02, Loss Eqns: 6.818e-01, Loss Aux: 5.753e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 332, It: 0, Loss Data: 2.958e-02, Loss Eqns: 6.961e-01, Loss Aux: 5.733e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 333, It: 0, Loss Data: 3.083e-02, Loss Eqns: 6.487e-01, Loss Aux: 5.724e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 334, It: 0, Loss Data: 3.191e-02, Loss Eqns: 6.647e-01, Loss Aux: 5.756e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 335, It: 0, Loss Data: 3.353e-02, Loss Eqns: 6.976e-01, Loss Aux: 5.802e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 336, It: 0, Loss Data: 3.161e-02, Loss Eqns: 6.429e-01, Loss Aux: 5.829e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 337, It: 0, Loss Data: 2.759e-02, Loss Eqns: 6.493e-01, Loss Aux: 5.874e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 338, It: 0, Loss Data: 3.244e-02, Loss Eqns: 6.760e-01, Loss Aux: 5.885e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 339, It: 0, Loss Data: 2.863e-02, Loss Eqns: 6.561e-01, Loss Aux: 5.883e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 340, It: 0, Loss Data: 3.410e-02, Loss Eqns: 6.634e-01, Loss Aux: 5.845e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 341, It: 0, Loss Data: 3.135e-02, Loss Eqns: 6.412e-01, Loss Aux: 5.755e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 342, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.690e-01, Loss Aux: 5.713e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 343, It: 0, Loss Data: 3.359e-02, Loss Eqns: 6.482e-01, Loss Aux: 5.711e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 344, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.855e-01, Loss Aux: 5.713e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 345, It: 0, Loss Data: 2.898e-02, Loss Eqns: 6.906e-01, Loss Aux: 5.718e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 346, It: 0, Loss Data: 3.272e-02, Loss Eqns: 6.939e-01, Loss Aux: 5.726e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 347, It: 0, Loss Data: 2.797e-02, Loss Eqns: 6.535e-01, Loss Aux: 5.742e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 348, It: 0, Loss Data: 3.226e-02, Loss Eqns: 6.322e-01, Loss Aux: 5.742e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 349, It: 0, Loss Data: 3.322e-02, Loss Eqns: 6.624e-01, Loss Aux: 5.710e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 350, It: 0, Loss Data: 3.782e-02, Loss Eqns: 6.558e-01, Loss Aux: 5.695e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 351, It: 0, Loss Data: 3.558e-02, Loss Eqns: 6.483e-01, Loss Aux: 5.675e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 352, It: 0, Loss Data: 3.270e-02, Loss Eqns: 6.871e-01, Loss Aux: 5.662e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 353, It: 0, Loss Data: 3.516e-02, Loss Eqns: 6.795e-01, Loss Aux: 5.690e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 354, It: 0, Loss Data: 3.470e-02, Loss Eqns: 6.495e-01, Loss Aux: 5.724e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 355, It: 0, Loss Data: 3.057e-02, Loss Eqns: 6.573e-01, Loss Aux: 5.765e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 356, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.310e-01, Loss Aux: 5.791e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 357, It: 0, Loss Data: 2.909e-02, Loss Eqns: 6.517e-01, Loss Aux: 5.832e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 358, It: 0, Loss Data: 3.458e-02, Loss Eqns: 6.586e-01, Loss Aux: 5.852e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 359, It: 0, Loss Data: 3.101e-02, Loss Eqns: 6.965e-01, Loss Aux: 5.849e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 360, It: 0, Loss Data: 3.423e-02, Loss Eqns: 6.669e-01, Loss Aux: 5.856e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 361, It: 0, Loss Data: 3.183e-02, Loss Eqns: 6.490e-01, Loss Aux: 5.878e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 362, It: 0, Loss Data: 2.870e-02, Loss Eqns: 6.758e-01, Loss Aux: 5.878e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 363, It: 0, Loss Data: 3.377e-02, Loss Eqns: 6.419e-01, Loss Aux: 5.885e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 364, It: 0, Loss Data: 2.913e-02, Loss Eqns: 6.667e-01, Loss Aux: 5.879e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 365, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.643e-01, Loss Aux: 5.865e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 366, It: 0, Loss Data: 3.218e-02, Loss Eqns: 6.557e-01, Loss Aux: 5.811e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 367, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.567e-01, Loss Aux: 5.762e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 368, It: 0, Loss Data: 3.083e-02, Loss Eqns: 6.778e-01, Loss Aux: 5.726e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 369, It: 0, Loss Data: 3.197e-02, Loss Eqns: 6.657e-01, Loss Aux: 5.664e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 370, It: 0, Loss Data: 3.141e-02, Loss Eqns: 6.687e-01, Loss Aux: 5.587e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 371, It: 0, Loss Data: 3.307e-02, Loss Eqns: 6.296e-01, Loss Aux: 5.563e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 372, It: 0, Loss Data: 3.259e-02, Loss Eqns: 6.592e-01, Loss Aux: 5.582e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 373, It: 0, Loss Data: 3.470e-02, Loss Eqns: 7.004e-01, Loss Aux: 5.679e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 374, It: 0, Loss Data: 3.695e-02, Loss Eqns: 6.706e-01, Loss Aux: 5.812e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 375, It: 0, Loss Data: 3.284e-02, Loss Eqns: 6.992e-01, Loss Aux: 5.914e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 376, It: 0, Loss Data: 2.972e-02, Loss Eqns: 6.692e-01, Loss Aux: 5.992e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 377, It: 0, Loss Data: 2.906e-02, Loss Eqns: 6.529e-01, Loss Aux: 5.947e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 378, It: 0, Loss Data: 3.352e-02, Loss Eqns: 6.813e-01, Loss Aux: 5.876e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 379, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.787e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 380, It: 0, Loss Data: 3.153e-02, Loss Eqns: 6.574e-01, Loss Aux: 5.697e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 381, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.813e-01, Loss Aux: 5.609e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 382, It: 0, Loss Data: 2.683e-02, Loss Eqns: 6.774e-01, Loss Aux: 5.562e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 383, It: 0, Loss Data: 3.614e-02, Loss Eqns: 6.643e-01, Loss Aux: 5.565e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 384, It: 0, Loss Data: 3.203e-02, Loss Eqns: 6.740e-01, Loss Aux: 5.621e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 385, It: 0, Loss Data: 3.031e-02, Loss Eqns: 7.048e-01, Loss Aux: 5.709e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 386, It: 0, Loss Data: 3.025e-02, Loss Eqns: 6.891e-01, Loss Aux: 5.791e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 387, It: 0, Loss Data: 3.565e-02, Loss Eqns: 6.613e-01, Loss Aux: 5.844e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 388, It: 0, Loss Data: 2.958e-02, Loss Eqns: 6.687e-01, Loss Aux: 5.837e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 389, It: 0, Loss Data: 3.629e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.790e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 390, It: 0, Loss Data: 3.555e-02, Loss Eqns: 6.829e-01, Loss Aux: 5.748e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 391, It: 0, Loss Data: 3.259e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.670e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 392, It: 0, Loss Data: 3.504e-02, Loss Eqns: 6.987e-01, Loss Aux: 5.635e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 393, It: 0, Loss Data: 2.995e-02, Loss Eqns: 6.667e-01, Loss Aux: 5.617e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 394, It: 0, Loss Data: 3.135e-02, Loss Eqns: 6.620e-01, Loss Aux: 5.615e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 395, It: 0, Loss Data: 3.742e-02, Loss Eqns: 7.033e-01, Loss Aux: 5.650e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 396, It: 0, Loss Data: 3.249e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.712e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 397, It: 0, Loss Data: 3.254e-02, Loss Eqns: 6.885e-01, Loss Aux: 5.755e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 398, It: 0, Loss Data: 2.946e-02, Loss Eqns: 6.480e-01, Loss Aux: 5.769e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 399, It: 0, Loss Data: 3.182e-02, Loss Eqns: 6.726e-01, Loss Aux: 5.783e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 400, It: 0, Loss Data: 3.165e-02, Loss Eqns: 6.509e-01, Loss Aux: 5.774e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 401, It: 0, Loss Data: 3.528e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.778e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 402, It: 0, Loss Data: 3.364e-02, Loss Eqns: 6.630e-01, Loss Aux: 5.796e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 403, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.798e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 404, It: 0, Loss Data: 3.123e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.778e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 405, It: 0, Loss Data: 3.081e-02, Loss Eqns: 6.609e-01, Loss Aux: 5.777e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 406, It: 0, Loss Data: 3.450e-02, Loss Eqns: 6.384e-01, Loss Aux: 5.782e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 407, It: 0, Loss Data: 3.246e-02, Loss Eqns: 6.451e-01, Loss Aux: 5.773e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 408, It: 0, Loss Data: 3.100e-02, Loss Eqns: 6.699e-01, Loss Aux: 5.742e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 409, It: 0, Loss Data: 3.149e-02, Loss Eqns: 6.736e-01, Loss Aux: 5.718e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 410, It: 0, Loss Data: 2.694e-02, Loss Eqns: 6.528e-01, Loss Aux: 5.692e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 411, It: 0, Loss Data: 3.478e-02, Loss Eqns: 6.634e-01, Loss Aux: 5.706e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 412, It: 0, Loss Data: 3.058e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.684e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 413, It: 0, Loss Data: 3.139e-02, Loss Eqns: 6.702e-01, Loss Aux: 5.698e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 414, It: 0, Loss Data: 3.538e-02, Loss Eqns: 6.903e-01, Loss Aux: 5.720e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 415, It: 0, Loss Data: 3.275e-02, Loss Eqns: 7.090e-01, Loss Aux: 5.767e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 416, It: 0, Loss Data: 2.925e-02, Loss Eqns: 6.972e-01, Loss Aux: 5.797e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 417, It: 0, Loss Data: 3.032e-02, Loss Eqns: 6.689e-01, Loss Aux: 5.826e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 418, It: 0, Loss Data: 3.436e-02, Loss Eqns: 6.366e-01, Loss Aux: 5.823e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 419, It: 0, Loss Data: 2.999e-02, Loss Eqns: 6.609e-01, Loss Aux: 5.777e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 420, It: 0, Loss Data: 2.549e-02, Loss Eqns: 6.461e-01, Loss Aux: 5.725e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 421, It: 0, Loss Data: 3.243e-02, Loss Eqns: 6.546e-01, Loss Aux: 5.700e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 422, It: 0, Loss Data: 3.637e-02, Loss Eqns: 6.830e-01, Loss Aux: 5.700e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 423, It: 0, Loss Data: 2.922e-02, Loss Eqns: 6.546e-01, Loss Aux: 5.728e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 424, It: 0, Loss Data: 3.369e-02, Loss Eqns: 6.681e-01, Loss Aux: 5.754e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 425, It: 0, Loss Data: 2.972e-02, Loss Eqns: 6.711e-01, Loss Aux: 5.773e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 426, It: 0, Loss Data: 3.069e-02, Loss Eqns: 6.444e-01, Loss Aux: 5.782e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 427, It: 0, Loss Data: 3.415e-02, Loss Eqns: 6.543e-01, Loss Aux: 5.760e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 428, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.740e-01, Loss Aux: 5.736e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 429, It: 0, Loss Data: 3.265e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.683e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 430, It: 0, Loss Data: 3.293e-02, Loss Eqns: 6.644e-01, Loss Aux: 5.636e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 431, It: 0, Loss Data: 3.237e-02, Loss Eqns: 6.375e-01, Loss Aux: 5.630e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 432, It: 0, Loss Data: 3.493e-02, Loss Eqns: 6.760e-01, Loss Aux: 5.675e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 433, It: 0, Loss Data: 3.223e-02, Loss Eqns: 6.498e-01, Loss Aux: 5.713e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 434, It: 0, Loss Data: 2.854e-02, Loss Eqns: 6.428e-01, Loss Aux: 5.734e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 435, It: 0, Loss Data: 2.839e-02, Loss Eqns: 6.471e-01, Loss Aux: 5.770e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 436, It: 0, Loss Data: 2.802e-02, Loss Eqns: 6.730e-01, Loss Aux: 5.772e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 437, It: 0, Loss Data: 3.124e-02, Loss Eqns: 6.746e-01, Loss Aux: 5.762e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 438, It: 0, Loss Data: 3.349e-02, Loss Eqns: 6.641e-01, Loss Aux: 5.686e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 439, It: 0, Loss Data: 3.576e-02, Loss Eqns: 6.707e-01, Loss Aux: 5.646e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 440, It: 0, Loss Data: 3.234e-02, Loss Eqns: 6.500e-01, Loss Aux: 5.601e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 441, It: 0, Loss Data: 3.324e-02, Loss Eqns: 6.437e-01, Loss Aux: 5.564e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 442, It: 0, Loss Data: 3.175e-02, Loss Eqns: 6.598e-01, Loss Aux: 5.570e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 443, It: 0, Loss Data: 3.150e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.576e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 444, It: 0, Loss Data: 3.218e-02, Loss Eqns: 6.212e-01, Loss Aux: 5.612e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 445, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.301e-01, Loss Aux: 5.679e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 446, It: 0, Loss Data: 2.976e-02, Loss Eqns: 6.461e-01, Loss Aux: 5.744e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 447, It: 0, Loss Data: 3.204e-02, Loss Eqns: 6.706e-01, Loss Aux: 5.789e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 448, It: 0, Loss Data: 3.215e-02, Loss Eqns: 6.981e-01, Loss Aux: 5.818e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 449, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.536e-01, Loss Aux: 5.801e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 450, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.184e-01, Loss Aux: 5.717e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 451, It: 0, Loss Data: 3.210e-02, Loss Eqns: 6.549e-01, Loss Aux: 5.614e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 452, It: 0, Loss Data: 3.140e-02, Loss Eqns: 6.665e-01, Loss Aux: 5.545e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 453, It: 0, Loss Data: 3.289e-02, Loss Eqns: 6.693e-01, Loss Aux: 5.522e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 454, It: 0, Loss Data: 3.475e-02, Loss Eqns: 6.817e-01, Loss Aux: 5.547e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 455, It: 0, Loss Data: 3.247e-02, Loss Eqns: 6.353e-01, Loss Aux: 5.598e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 456, It: 0, Loss Data: 3.702e-02, Loss Eqns: 6.265e-01, Loss Aux: 5.691e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 457, It: 0, Loss Data: 3.285e-02, Loss Eqns: 6.234e-01, Loss Aux: 5.770e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 458, It: 0, Loss Data: 3.301e-02, Loss Eqns: 6.695e-01, Loss Aux: 5.851e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 459, It: 0, Loss Data: 3.165e-02, Loss Eqns: 6.794e-01, Loss Aux: 5.919e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 460, It: 0, Loss Data: 3.345e-02, Loss Eqns: 6.549e-01, Loss Aux: 5.915e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 461, It: 0, Loss Data: 3.332e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.873e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 462, It: 0, Loss Data: 3.254e-02, Loss Eqns: 6.915e-01, Loss Aux: 5.847e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 463, It: 0, Loss Data: 3.280e-02, Loss Eqns: 6.917e-01, Loss Aux: 5.788e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 464, It: 0, Loss Data: 3.255e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.705e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 465, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.648e-01, Loss Aux: 5.660e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 466, It: 0, Loss Data: 3.175e-02, Loss Eqns: 6.787e-01, Loss Aux: 5.618e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 467, It: 0, Loss Data: 3.101e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.585e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 468, It: 0, Loss Data: 3.655e-02, Loss Eqns: 6.717e-01, Loss Aux: 5.591e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 469, It: 0, Loss Data: 3.444e-02, Loss Eqns: 6.591e-01, Loss Aux: 5.623e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 470, It: 0, Loss Data: 3.113e-02, Loss Eqns: 6.758e-01, Loss Aux: 5.716e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 471, It: 0, Loss Data: 3.381e-02, Loss Eqns: 6.689e-01, Loss Aux: 5.894e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 472, It: 0, Loss Data: 3.069e-02, Loss Eqns: 6.700e-01, Loss Aux: 6.055e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 473, It: 0, Loss Data: 3.151e-02, Loss Eqns: 6.816e-01, Loss Aux: 6.126e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 474, It: 0, Loss Data: 3.256e-02, Loss Eqns: 6.660e-01, Loss Aux: 6.156e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 475, It: 0, Loss Data: 3.332e-02, Loss Eqns: 7.410e-01, Loss Aux: 6.124e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 476, It: 0, Loss Data: 3.493e-02, Loss Eqns: 6.530e-01, Loss Aux: 6.108e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 477, It: 0, Loss Data: 3.519e-02, Loss Eqns: 6.430e-01, Loss Aux: 6.063e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 478, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.614e-01, Loss Aux: 6.005e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 479, It: 0, Loss Data: 3.246e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.924e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 480, It: 0, Loss Data: 3.397e-02, Loss Eqns: 6.651e-01, Loss Aux: 5.882e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 481, It: 0, Loss Data: 3.478e-02, Loss Eqns: 6.455e-01, Loss Aux: 5.853e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 482, It: 0, Loss Data: 3.071e-02, Loss Eqns: 6.247e-01, Loss Aux: 5.823e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 483, It: 0, Loss Data: 3.368e-02, Loss Eqns: 7.083e-01, Loss Aux: 5.805e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 484, It: 0, Loss Data: 3.191e-02, Loss Eqns: 7.161e-01, Loss Aux: 5.791e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 485, It: 0, Loss Data: 3.193e-02, Loss Eqns: 6.512e-01, Loss Aux: 5.783e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 486, It: 0, Loss Data: 3.371e-02, Loss Eqns: 6.590e-01, Loss Aux: 5.774e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 487, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.816e-01, Loss Aux: 5.793e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 488, It: 0, Loss Data: 3.459e-02, Loss Eqns: 6.850e-01, Loss Aux: 5.805e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 489, It: 0, Loss Data: 2.842e-02, Loss Eqns: 6.364e-01, Loss Aux: 5.792e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 490, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.738e-01, Loss Aux: 5.776e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 491, It: 0, Loss Data: 3.242e-02, Loss Eqns: 6.567e-01, Loss Aux: 5.752e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 492, It: 0, Loss Data: 3.125e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.736e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 493, It: 0, Loss Data: 3.052e-02, Loss Eqns: 7.028e-01, Loss Aux: 5.746e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 494, It: 0, Loss Data: 3.128e-02, Loss Eqns: 6.706e-01, Loss Aux: 5.766e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 495, It: 0, Loss Data: 2.815e-02, Loss Eqns: 6.753e-01, Loss Aux: 5.784e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 496, It: 0, Loss Data: 2.868e-02, Loss Eqns: 6.387e-01, Loss Aux: 5.793e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 497, It: 0, Loss Data: 3.405e-02, Loss Eqns: 6.718e-01, Loss Aux: 5.802e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 498, It: 0, Loss Data: 3.698e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.869e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 499, It: 0, Loss Data: 3.269e-02, Loss Eqns: 6.704e-01, Loss Aux: 5.897e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 500, It: 0, Loss Data: 3.172e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.883e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 501, It: 0, Loss Data: 3.203e-02, Loss Eqns: 6.934e-01, Loss Aux: 5.874e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 502, It: 0, Loss Data: 3.262e-02, Loss Eqns: 6.519e-01, Loss Aux: 5.840e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 503, It: 0, Loss Data: 3.291e-02, Loss Eqns: 6.420e-01, Loss Aux: 5.779e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 504, It: 0, Loss Data: 3.060e-02, Loss Eqns: 6.519e-01, Loss Aux: 5.699e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 505, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.563e-01, Loss Aux: 5.640e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 506, It: 0, Loss Data: 3.088e-02, Loss Eqns: 6.654e-01, Loss Aux: 5.644e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 507, It: 0, Loss Data: 3.214e-02, Loss Eqns: 6.669e-01, Loss Aux: 5.648e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 508, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.689e-01, Loss Aux: 5.691e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 509, It: 0, Loss Data: 3.388e-02, Loss Eqns: 6.465e-01, Loss Aux: 5.757e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 510, It: 0, Loss Data: 3.383e-02, Loss Eqns: 6.198e-01, Loss Aux: 5.803e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 511, It: 0, Loss Data: 3.209e-02, Loss Eqns: 6.526e-01, Loss Aux: 5.781e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 512, It: 0, Loss Data: 3.312e-02, Loss Eqns: 6.725e-01, Loss Aux: 5.763e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 513, It: 0, Loss Data: 3.280e-02, Loss Eqns: 6.697e-01, Loss Aux: 5.718e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 514, It: 0, Loss Data: 3.008e-02, Loss Eqns: 6.526e-01, Loss Aux: 5.649e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 515, It: 0, Loss Data: 3.435e-02, Loss Eqns: 6.681e-01, Loss Aux: 5.620e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 516, It: 0, Loss Data: 3.161e-02, Loss Eqns: 6.545e-01, Loss Aux: 5.619e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 517, It: 0, Loss Data: 2.848e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.601e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 518, It: 0, Loss Data: 3.237e-02, Loss Eqns: 6.537e-01, Loss Aux: 5.605e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 519, It: 0, Loss Data: 3.261e-02, Loss Eqns: 6.841e-01, Loss Aux: 5.618e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 520, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.871e-01, Loss Aux: 5.667e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 521, It: 0, Loss Data: 3.238e-02, Loss Eqns: 6.663e-01, Loss Aux: 5.735e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 522, It: 0, Loss Data: 3.395e-02, Loss Eqns: 6.781e-01, Loss Aux: 5.802e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 523, It: 0, Loss Data: 3.111e-02, Loss Eqns: 6.599e-01, Loss Aux: 5.834e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 524, It: 0, Loss Data: 3.055e-02, Loss Eqns: 6.713e-01, Loss Aux: 5.825e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 525, It: 0, Loss Data: 3.459e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.766e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 526, It: 0, Loss Data: 3.001e-02, Loss Eqns: 6.798e-01, Loss Aux: 5.655e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 527, It: 0, Loss Data: 3.207e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.573e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 528, It: 0, Loss Data: 3.261e-02, Loss Eqns: 6.588e-01, Loss Aux: 5.504e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 529, It: 0, Loss Data: 3.208e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.481e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 530, It: 0, Loss Data: 3.257e-02, Loss Eqns: 6.642e-01, Loss Aux: 5.471e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 531, It: 0, Loss Data: 2.771e-02, Loss Eqns: 6.951e-01, Loss Aux: 5.495e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 532, It: 0, Loss Data: 3.286e-02, Loss Eqns: 6.401e-01, Loss Aux: 5.567e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 533, It: 0, Loss Data: 3.524e-02, Loss Eqns: 6.868e-01, Loss Aux: 5.675e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 534, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.728e-01, Loss Aux: 5.823e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 535, It: 0, Loss Data: 3.570e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.912e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 536, It: 0, Loss Data: 3.183e-02, Loss Eqns: 6.203e-01, Loss Aux: 5.924e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 537, It: 0, Loss Data: 3.294e-02, Loss Eqns: 6.687e-01, Loss Aux: 5.921e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 538, It: 0, Loss Data: 3.220e-02, Loss Eqns: 6.707e-01, Loss Aux: 5.907e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 539, It: 0, Loss Data: 3.700e-02, Loss Eqns: 6.879e-01, Loss Aux: 5.855e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 540, It: 0, Loss Data: 3.408e-02, Loss Eqns: 6.572e-01, Loss Aux: 5.766e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 541, It: 0, Loss Data: 3.223e-02, Loss Eqns: 6.734e-01, Loss Aux: 5.674e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 542, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.525e-01, Loss Aux: 5.579e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 543, It: 0, Loss Data: 3.383e-02, Loss Eqns: 6.860e-01, Loss Aux: 5.558e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 544, It: 0, Loss Data: 3.063e-02, Loss Eqns: 6.614e-01, Loss Aux: 5.576e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 545, It: 0, Loss Data: 3.117e-02, Loss Eqns: 6.902e-01, Loss Aux: 5.657e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 546, It: 0, Loss Data: 3.245e-02, Loss Eqns: 6.790e-01, Loss Aux: 5.781e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 547, It: 0, Loss Data: 3.057e-02, Loss Eqns: 6.669e-01, Loss Aux: 5.862e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 548, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.752e-01, Loss Aux: 5.880e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 549, It: 0, Loss Data: 3.143e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.901e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 550, It: 0, Loss Data: 3.095e-02, Loss Eqns: 6.881e-01, Loss Aux: 5.884e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 551, It: 0, Loss Data: 3.460e-02, Loss Eqns: 6.715e-01, Loss Aux: 5.855e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 552, It: 0, Loss Data: 3.027e-02, Loss Eqns: 6.430e-01, Loss Aux: 5.803e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 553, It: 0, Loss Data: 3.128e-02, Loss Eqns: 6.565e-01, Loss Aux: 5.786e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 554, It: 0, Loss Data: 3.375e-02, Loss Eqns: 6.763e-01, Loss Aux: 5.806e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 555, It: 0, Loss Data: 2.991e-02, Loss Eqns: 6.627e-01, Loss Aux: 5.866e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 556, It: 0, Loss Data: 3.244e-02, Loss Eqns: 6.570e-01, Loss Aux: 5.895e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 557, It: 0, Loss Data: 3.218e-02, Loss Eqns: 6.574e-01, Loss Aux: 5.926e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 558, It: 0, Loss Data: 3.273e-02, Loss Eqns: 6.646e-01, Loss Aux: 5.884e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 559, It: 0, Loss Data: 2.817e-02, Loss Eqns: 6.695e-01, Loss Aux: 5.807e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 560, It: 0, Loss Data: 3.305e-02, Loss Eqns: 6.697e-01, Loss Aux: 5.708e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 561, It: 0, Loss Data: 3.528e-02, Loss Eqns: 6.881e-01, Loss Aux: 5.657e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 562, It: 0, Loss Data: 3.143e-02, Loss Eqns: 6.796e-01, Loss Aux: 5.652e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 563, It: 0, Loss Data: 3.159e-02, Loss Eqns: 7.209e-01, Loss Aux: 5.665e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 564, It: 0, Loss Data: 3.181e-02, Loss Eqns: 6.717e-01, Loss Aux: 5.689e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 565, It: 0, Loss Data: 3.521e-02, Loss Eqns: 6.673e-01, Loss Aux: 5.733e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 566, It: 0, Loss Data: 3.056e-02, Loss Eqns: 6.824e-01, Loss Aux: 5.774e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 567, It: 0, Loss Data: 3.402e-02, Loss Eqns: 6.563e-01, Loss Aux: 5.827e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 568, It: 0, Loss Data: 3.192e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.854e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 569, It: 0, Loss Data: 3.260e-02, Loss Eqns: 6.499e-01, Loss Aux: 5.841e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 570, It: 0, Loss Data: 3.696e-02, Loss Eqns: 6.982e-01, Loss Aux: 5.811e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 571, It: 0, Loss Data: 3.428e-02, Loss Eqns: 6.628e-01, Loss Aux: 5.742e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 572, It: 0, Loss Data: 3.237e-02, Loss Eqns: 6.473e-01, Loss Aux: 5.710e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 573, It: 0, Loss Data: 3.008e-02, Loss Eqns: 7.220e-01, Loss Aux: 5.694e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 574, It: 0, Loss Data: 3.028e-02, Loss Eqns: 6.703e-01, Loss Aux: 5.658e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 575, It: 0, Loss Data: 2.792e-02, Loss Eqns: 7.098e-01, Loss Aux: 5.653e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 576, It: 0, Loss Data: 3.493e-02, Loss Eqns: 6.471e-01, Loss Aux: 5.714e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 577, It: 0, Loss Data: 3.713e-02, Loss Eqns: 6.405e-01, Loss Aux: 5.822e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 578, It: 0, Loss Data: 3.264e-02, Loss Eqns: 6.632e-01, Loss Aux: 5.969e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 579, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.546e-01, Loss Aux: 6.059e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 580, It: 0, Loss Data: 3.201e-02, Loss Eqns: 6.801e-01, Loss Aux: 6.059e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 581, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.896e-01, Loss Aux: 5.987e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 582, It: 0, Loss Data: 3.179e-02, Loss Eqns: 6.538e-01, Loss Aux: 5.925e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 583, It: 0, Loss Data: 3.614e-02, Loss Eqns: 6.177e-01, Loss Aux: 5.811e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 584, It: 0, Loss Data: 3.374e-02, Loss Eqns: 6.583e-01, Loss Aux: 5.758e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 585, It: 0, Loss Data: 3.609e-02, Loss Eqns: 6.655e-01, Loss Aux: 5.756e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 586, It: 0, Loss Data: 3.476e-02, Loss Eqns: 7.062e-01, Loss Aux: 5.793e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 587, It: 0, Loss Data: 3.502e-02, Loss Eqns: 6.541e-01, Loss Aux: 5.865e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 588, It: 0, Loss Data: 3.280e-02, Loss Eqns: 6.639e-01, Loss Aux: 5.915e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 589, It: 0, Loss Data: 3.310e-02, Loss Eqns: 6.566e-01, Loss Aux: 5.942e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 590, It: 0, Loss Data: 3.071e-02, Loss Eqns: 6.691e-01, Loss Aux: 5.927e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 591, It: 0, Loss Data: 3.334e-02, Loss Eqns: 6.387e-01, Loss Aux: 5.872e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 592, It: 0, Loss Data: 3.347e-02, Loss Eqns: 6.630e-01, Loss Aux: 5.779e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 593, It: 0, Loss Data: 2.869e-02, Loss Eqns: 6.790e-01, Loss Aux: 5.699e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 594, It: 0, Loss Data: 3.489e-02, Loss Eqns: 6.260e-01, Loss Aux: 5.622e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 595, It: 0, Loss Data: 2.938e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.581e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 596, It: 0, Loss Data: 3.335e-02, Loss Eqns: 6.920e-01, Loss Aux: 5.622e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 597, It: 0, Loss Data: 3.328e-02, Loss Eqns: 6.494e-01, Loss Aux: 5.667e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 598, It: 0, Loss Data: 3.032e-02, Loss Eqns: 6.658e-01, Loss Aux: 5.759e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 599, It: 0, Loss Data: 3.102e-02, Loss Eqns: 6.699e-01, Loss Aux: 5.844e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 600, It: 0, Loss Data: 3.084e-02, Loss Eqns: 6.793e-01, Loss Aux: 5.905e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 601, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.730e-01, Loss Aux: 5.934e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 602, It: 0, Loss Data: 3.328e-02, Loss Eqns: 6.536e-01, Loss Aux: 5.925e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 603, It: 0, Loss Data: 3.403e-02, Loss Eqns: 6.686e-01, Loss Aux: 5.931e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 604, It: 0, Loss Data: 3.075e-02, Loss Eqns: 6.796e-01, Loss Aux: 5.970e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 605, It: 0, Loss Data: 2.596e-02, Loss Eqns: 6.402e-01, Loss Aux: 5.939e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 606, It: 0, Loss Data: 3.290e-02, Loss Eqns: 6.761e-01, Loss Aux: 5.866e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 607, It: 0, Loss Data: 3.161e-02, Loss Eqns: 6.692e-01, Loss Aux: 5.777e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 608, It: 0, Loss Data: 3.359e-02, Loss Eqns: 6.442e-01, Loss Aux: 5.709e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 609, It: 0, Loss Data: 2.943e-02, Loss Eqns: 6.440e-01, Loss Aux: 5.629e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 610, It: 0, Loss Data: 3.275e-02, Loss Eqns: 6.554e-01, Loss Aux: 5.601e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 611, It: 0, Loss Data: 3.128e-02, Loss Eqns: 6.874e-01, Loss Aux: 5.617e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 612, It: 0, Loss Data: 3.140e-02, Loss Eqns: 6.601e-01, Loss Aux: 5.663e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 613, It: 0, Loss Data: 3.425e-02, Loss Eqns: 6.268e-01, Loss Aux: 5.746e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 614, It: 0, Loss Data: 3.472e-02, Loss Eqns: 6.550e-01, Loss Aux: 5.798e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 615, It: 0, Loss Data: 3.423e-02, Loss Eqns: 6.694e-01, Loss Aux: 5.806e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 616, It: 0, Loss Data: 3.141e-02, Loss Eqns: 6.591e-01, Loss Aux: 5.776e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 617, It: 0, Loss Data: 3.599e-02, Loss Eqns: 6.586e-01, Loss Aux: 5.740e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 618, It: 0, Loss Data: 3.147e-02, Loss Eqns: 6.613e-01, Loss Aux: 5.730e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 619, It: 0, Loss Data: 3.111e-02, Loss Eqns: 6.496e-01, Loss Aux: 5.725e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 620, It: 0, Loss Data: 3.330e-02, Loss Eqns: 6.320e-01, Loss Aux: 5.731e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 621, It: 0, Loss Data: 2.810e-02, Loss Eqns: 6.684e-01, Loss Aux: 5.707e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 622, It: 0, Loss Data: 3.322e-02, Loss Eqns: 6.580e-01, Loss Aux: 5.717e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 623, It: 0, Loss Data: 3.088e-02, Loss Eqns: 6.656e-01, Loss Aux: 5.672e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 624, It: 0, Loss Data: 2.977e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.648e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 625, It: 0, Loss Data: 3.110e-02, Loss Eqns: 6.460e-01, Loss Aux: 5.609e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 626, It: 0, Loss Data: 3.056e-02, Loss Eqns: 6.349e-01, Loss Aux: 5.597e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 627, It: 0, Loss Data: 3.129e-02, Loss Eqns: 6.399e-01, Loss Aux: 5.664e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 628, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.733e-01, Loss Aux: 5.704e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 629, It: 0, Loss Data: 4.275e-02, Loss Eqns: 6.683e-01, Loss Aux: 5.759e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 630, It: 0, Loss Data: 3.454e-02, Loss Eqns: 6.555e-01, Loss Aux: 5.778e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 631, It: 0, Loss Data: 3.360e-02, Loss Eqns: 6.694e-01, Loss Aux: 5.750e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 632, It: 0, Loss Data: 3.301e-02, Loss Eqns: 6.664e-01, Loss Aux: 5.668e-02, Time: 0.145, Learning Rate: 1.0e-04\n",
      "Epoch: 633, It: 0, Loss Data: 3.296e-02, Loss Eqns: 6.626e-01, Loss Aux: 5.615e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 634, It: 0, Loss Data: 3.408e-02, Loss Eqns: 6.579e-01, Loss Aux: 5.590e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 635, It: 0, Loss Data: 3.211e-02, Loss Eqns: 6.374e-01, Loss Aux: 5.577e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 636, It: 0, Loss Data: 2.690e-02, Loss Eqns: 6.340e-01, Loss Aux: 5.547e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 637, It: 0, Loss Data: 3.141e-02, Loss Eqns: 6.543e-01, Loss Aux: 5.556e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 638, It: 0, Loss Data: 3.094e-02, Loss Eqns: 6.578e-01, Loss Aux: 5.564e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 639, It: 0, Loss Data: 3.403e-02, Loss Eqns: 6.991e-01, Loss Aux: 5.600e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 640, It: 0, Loss Data: 3.336e-02, Loss Eqns: 6.514e-01, Loss Aux: 5.667e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 641, It: 0, Loss Data: 2.821e-02, Loss Eqns: 6.601e-01, Loss Aux: 5.731e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 642, It: 0, Loss Data: 3.301e-02, Loss Eqns: 6.861e-01, Loss Aux: 5.777e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 643, It: 0, Loss Data: 3.078e-02, Loss Eqns: 6.364e-01, Loss Aux: 5.822e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 644, It: 0, Loss Data: 3.032e-02, Loss Eqns: 6.884e-01, Loss Aux: 5.795e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 645, It: 0, Loss Data: 3.527e-02, Loss Eqns: 6.674e-01, Loss Aux: 5.711e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 646, It: 0, Loss Data: 2.779e-02, Loss Eqns: 6.528e-01, Loss Aux: 5.649e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 647, It: 0, Loss Data: 3.390e-02, Loss Eqns: 6.906e-01, Loss Aux: 5.656e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 648, It: 0, Loss Data: 3.234e-02, Loss Eqns: 6.623e-01, Loss Aux: 5.735e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 649, It: 0, Loss Data: 3.201e-02, Loss Eqns: 6.437e-01, Loss Aux: 5.878e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 650, It: 0, Loss Data: 2.882e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.996e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 651, It: 0, Loss Data: 3.216e-02, Loss Eqns: 6.553e-01, Loss Aux: 6.075e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 652, It: 0, Loss Data: 3.259e-02, Loss Eqns: 6.888e-01, Loss Aux: 6.076e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 653, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.361e-01, Loss Aux: 6.043e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 654, It: 0, Loss Data: 3.072e-02, Loss Eqns: 6.751e-01, Loss Aux: 6.036e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 655, It: 0, Loss Data: 2.831e-02, Loss Eqns: 6.422e-01, Loss Aux: 5.981e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 656, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.710e-01, Loss Aux: 6.014e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 657, It: 0, Loss Data: 3.065e-02, Loss Eqns: 6.665e-01, Loss Aux: 6.060e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 658, It: 0, Loss Data: 3.107e-02, Loss Eqns: 6.527e-01, Loss Aux: 6.069e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 659, It: 0, Loss Data: 3.231e-02, Loss Eqns: 6.542e-01, Loss Aux: 6.020e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 660, It: 0, Loss Data: 3.337e-02, Loss Eqns: 6.205e-01, Loss Aux: 5.977e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 661, It: 0, Loss Data: 3.221e-02, Loss Eqns: 6.759e-01, Loss Aux: 5.930e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 662, It: 0, Loss Data: 3.303e-02, Loss Eqns: 6.633e-01, Loss Aux: 5.857e-02, Time: 0.200, Learning Rate: 1.0e-04\n",
      "Epoch: 663, It: 0, Loss Data: 3.507e-02, Loss Eqns: 6.367e-01, Loss Aux: 5.787e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 664, It: 0, Loss Data: 3.551e-02, Loss Eqns: 6.762e-01, Loss Aux: 5.721e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 665, It: 0, Loss Data: 3.209e-02, Loss Eqns: 6.717e-01, Loss Aux: 5.706e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 666, It: 0, Loss Data: 2.881e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.700e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 667, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.554e-01, Loss Aux: 5.711e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 668, It: 0, Loss Data: 3.565e-02, Loss Eqns: 6.647e-01, Loss Aux: 5.771e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 669, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.666e-01, Loss Aux: 5.803e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 670, It: 0, Loss Data: 2.923e-02, Loss Eqns: 6.550e-01, Loss Aux: 5.802e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 671, It: 0, Loss Data: 3.132e-02, Loss Eqns: 6.593e-01, Loss Aux: 5.766e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 672, It: 0, Loss Data: 3.256e-02, Loss Eqns: 6.387e-01, Loss Aux: 5.716e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 673, It: 0, Loss Data: 2.899e-02, Loss Eqns: 6.671e-01, Loss Aux: 5.678e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 674, It: 0, Loss Data: 3.234e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.653e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 675, It: 0, Loss Data: 3.648e-02, Loss Eqns: 6.863e-01, Loss Aux: 5.688e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 676, It: 0, Loss Data: 3.252e-02, Loss Eqns: 6.506e-01, Loss Aux: 5.709e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 677, It: 0, Loss Data: 3.316e-02, Loss Eqns: 6.508e-01, Loss Aux: 5.735e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 678, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.715e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 679, It: 0, Loss Data: 3.273e-02, Loss Eqns: 6.525e-01, Loss Aux: 5.730e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 680, It: 0, Loss Data: 3.402e-02, Loss Eqns: 6.710e-01, Loss Aux: 5.782e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 681, It: 0, Loss Data: 2.939e-02, Loss Eqns: 6.686e-01, Loss Aux: 5.855e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 682, It: 0, Loss Data: 3.530e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.891e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 683, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.367e-01, Loss Aux: 5.942e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 684, It: 0, Loss Data: 2.962e-02, Loss Eqns: 6.356e-01, Loss Aux: 5.991e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 685, It: 0, Loss Data: 3.256e-02, Loss Eqns: 6.335e-01, Loss Aux: 6.065e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 686, It: 0, Loss Data: 3.100e-02, Loss Eqns: 6.617e-01, Loss Aux: 6.105e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 687, It: 0, Loss Data: 2.980e-02, Loss Eqns: 6.545e-01, Loss Aux: 6.049e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 688, It: 0, Loss Data: 3.528e-02, Loss Eqns: 6.771e-01, Loss Aux: 5.978e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 689, It: 0, Loss Data: 3.227e-02, Loss Eqns: 6.412e-01, Loss Aux: 5.860e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 690, It: 0, Loss Data: 3.168e-02, Loss Eqns: 6.641e-01, Loss Aux: 5.719e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 691, It: 0, Loss Data: 3.367e-02, Loss Eqns: 7.020e-01, Loss Aux: 5.632e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 692, It: 0, Loss Data: 2.996e-02, Loss Eqns: 6.812e-01, Loss Aux: 5.580e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 693, It: 0, Loss Data: 3.286e-02, Loss Eqns: 6.165e-01, Loss Aux: 5.552e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 694, It: 0, Loss Data: 3.283e-02, Loss Eqns: 6.526e-01, Loss Aux: 5.577e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 695, It: 0, Loss Data: 3.148e-02, Loss Eqns: 6.761e-01, Loss Aux: 5.648e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 696, It: 0, Loss Data: 3.250e-02, Loss Eqns: 6.630e-01, Loss Aux: 5.717e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 697, It: 0, Loss Data: 3.155e-02, Loss Eqns: 6.787e-01, Loss Aux: 5.770e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 698, It: 0, Loss Data: 3.229e-02, Loss Eqns: 6.783e-01, Loss Aux: 5.833e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 699, It: 0, Loss Data: 3.149e-02, Loss Eqns: 6.326e-01, Loss Aux: 5.890e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 700, It: 0, Loss Data: 3.413e-02, Loss Eqns: 6.428e-01, Loss Aux: 5.911e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 701, It: 0, Loss Data: 2.998e-02, Loss Eqns: 6.140e-01, Loss Aux: 5.899e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 702, It: 0, Loss Data: 3.107e-02, Loss Eqns: 6.681e-01, Loss Aux: 5.882e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 703, It: 0, Loss Data: 3.520e-02, Loss Eqns: 6.826e-01, Loss Aux: 5.850e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 704, It: 0, Loss Data: 2.846e-02, Loss Eqns: 6.245e-01, Loss Aux: 5.817e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 705, It: 0, Loss Data: 2.652e-02, Loss Eqns: 6.535e-01, Loss Aux: 5.807e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 706, It: 0, Loss Data: 3.208e-02, Loss Eqns: 6.464e-01, Loss Aux: 5.856e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 707, It: 0, Loss Data: 3.287e-02, Loss Eqns: 6.684e-01, Loss Aux: 5.848e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 708, It: 0, Loss Data: 3.380e-02, Loss Eqns: 6.756e-01, Loss Aux: 5.801e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 709, It: 0, Loss Data: 3.125e-02, Loss Eqns: 6.485e-01, Loss Aux: 5.773e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 710, It: 0, Loss Data: 3.147e-02, Loss Eqns: 6.932e-01, Loss Aux: 5.714e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 711, It: 0, Loss Data: 3.008e-02, Loss Eqns: 6.393e-01, Loss Aux: 5.693e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 712, It: 0, Loss Data: 3.369e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.706e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 713, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.858e-01, Loss Aux: 5.751e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 714, It: 0, Loss Data: 3.044e-02, Loss Eqns: 6.673e-01, Loss Aux: 5.788e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 715, It: 0, Loss Data: 2.933e-02, Loss Eqns: 6.707e-01, Loss Aux: 5.783e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 716, It: 0, Loss Data: 3.365e-02, Loss Eqns: 6.676e-01, Loss Aux: 5.761e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 717, It: 0, Loss Data: 2.945e-02, Loss Eqns: 6.688e-01, Loss Aux: 5.704e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 718, It: 0, Loss Data: 3.333e-02, Loss Eqns: 6.533e-01, Loss Aux: 5.716e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 719, It: 0, Loss Data: 3.041e-02, Loss Eqns: 6.750e-01, Loss Aux: 5.734e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 720, It: 0, Loss Data: 2.986e-02, Loss Eqns: 6.310e-01, Loss Aux: 5.769e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 721, It: 0, Loss Data: 2.983e-02, Loss Eqns: 6.409e-01, Loss Aux: 5.821e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 722, It: 0, Loss Data: 2.960e-02, Loss Eqns: 6.355e-01, Loss Aux: 5.861e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 723, It: 0, Loss Data: 3.550e-02, Loss Eqns: 6.411e-01, Loss Aux: 5.928e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 724, It: 0, Loss Data: 3.581e-02, Loss Eqns: 6.512e-01, Loss Aux: 5.942e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 725, It: 0, Loss Data: 3.209e-02, Loss Eqns: 6.742e-01, Loss Aux: 5.982e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 726, It: 0, Loss Data: 3.160e-02, Loss Eqns: 6.572e-01, Loss Aux: 5.922e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 727, It: 0, Loss Data: 2.972e-02, Loss Eqns: 6.509e-01, Loss Aux: 5.882e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 728, It: 0, Loss Data: 3.279e-02, Loss Eqns: 6.979e-01, Loss Aux: 5.851e-02, Time: 0.199, Learning Rate: 1.0e-04\n",
      "Epoch: 729, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.545e-01, Loss Aux: 5.827e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 730, It: 0, Loss Data: 2.719e-02, Loss Eqns: 6.436e-01, Loss Aux: 5.802e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 731, It: 0, Loss Data: 2.989e-02, Loss Eqns: 6.701e-01, Loss Aux: 5.775e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 732, It: 0, Loss Data: 3.320e-02, Loss Eqns: 6.493e-01, Loss Aux: 5.748e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 733, It: 0, Loss Data: 2.960e-02, Loss Eqns: 6.114e-01, Loss Aux: 5.718e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 734, It: 0, Loss Data: 3.506e-02, Loss Eqns: 6.342e-01, Loss Aux: 5.728e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 735, It: 0, Loss Data: 2.961e-02, Loss Eqns: 6.542e-01, Loss Aux: 5.798e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 736, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.087e-01, Loss Aux: 5.867e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 737, It: 0, Loss Data: 3.597e-02, Loss Eqns: 6.222e-01, Loss Aux: 5.924e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 738, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.715e-01, Loss Aux: 5.905e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 739, It: 0, Loss Data: 3.268e-02, Loss Eqns: 6.329e-01, Loss Aux: 5.829e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 740, It: 0, Loss Data: 3.216e-02, Loss Eqns: 6.782e-01, Loss Aux: 5.753e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 741, It: 0, Loss Data: 3.211e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.722e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 742, It: 0, Loss Data: 2.844e-02, Loss Eqns: 6.234e-01, Loss Aux: 5.670e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 743, It: 0, Loss Data: 3.322e-02, Loss Eqns: 6.499e-01, Loss Aux: 5.675e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 744, It: 0, Loss Data: 3.607e-02, Loss Eqns: 6.475e-01, Loss Aux: 5.717e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 745, It: 0, Loss Data: 3.080e-02, Loss Eqns: 6.674e-01, Loss Aux: 5.766e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 746, It: 0, Loss Data: 3.336e-02, Loss Eqns: 6.705e-01, Loss Aux: 5.820e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 747, It: 0, Loss Data: 2.940e-02, Loss Eqns: 6.862e-01, Loss Aux: 5.862e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 748, It: 0, Loss Data: 3.460e-02, Loss Eqns: 6.526e-01, Loss Aux: 5.820e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 749, It: 0, Loss Data: 3.111e-02, Loss Eqns: 6.659e-01, Loss Aux: 5.757e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 750, It: 0, Loss Data: 3.182e-02, Loss Eqns: 6.384e-01, Loss Aux: 5.687e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 751, It: 0, Loss Data: 3.457e-02, Loss Eqns: 6.804e-01, Loss Aux: 5.633e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 752, It: 0, Loss Data: 3.112e-02, Loss Eqns: 6.174e-01, Loss Aux: 5.623e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 753, It: 0, Loss Data: 3.234e-02, Loss Eqns: 6.320e-01, Loss Aux: 5.672e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 754, It: 0, Loss Data: 3.765e-02, Loss Eqns: 6.451e-01, Loss Aux: 5.819e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 755, It: 0, Loss Data: 3.117e-02, Loss Eqns: 6.762e-01, Loss Aux: 5.944e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 756, It: 0, Loss Data: 2.904e-02, Loss Eqns: 6.578e-01, Loss Aux: 6.006e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 757, It: 0, Loss Data: 3.570e-02, Loss Eqns: 6.527e-01, Loss Aux: 6.072e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 758, It: 0, Loss Data: 3.154e-02, Loss Eqns: 6.663e-01, Loss Aux: 6.035e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 759, It: 0, Loss Data: 3.282e-02, Loss Eqns: 6.668e-01, Loss Aux: 5.922e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 760, It: 0, Loss Data: 3.120e-02, Loss Eqns: 6.427e-01, Loss Aux: 5.797e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 761, It: 0, Loss Data: 3.180e-02, Loss Eqns: 6.368e-01, Loss Aux: 5.677e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 762, It: 0, Loss Data: 2.917e-02, Loss Eqns: 6.442e-01, Loss Aux: 5.593e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 763, It: 0, Loss Data: 3.490e-02, Loss Eqns: 6.697e-01, Loss Aux: 5.526e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 764, It: 0, Loss Data: 2.806e-02, Loss Eqns: 6.759e-01, Loss Aux: 5.511e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 765, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.734e-01, Loss Aux: 5.574e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 766, It: 0, Loss Data: 3.017e-02, Loss Eqns: 6.745e-01, Loss Aux: 5.718e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 767, It: 0, Loss Data: 2.765e-02, Loss Eqns: 6.852e-01, Loss Aux: 5.913e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 768, It: 0, Loss Data: 3.439e-02, Loss Eqns: 6.142e-01, Loss Aux: 6.148e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 769, It: 0, Loss Data: 3.503e-02, Loss Eqns: 6.504e-01, Loss Aux: 6.219e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 770, It: 0, Loss Data: 3.062e-02, Loss Eqns: 6.612e-01, Loss Aux: 6.162e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 771, It: 0, Loss Data: 3.250e-02, Loss Eqns: 6.493e-01, Loss Aux: 6.060e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 772, It: 0, Loss Data: 3.702e-02, Loss Eqns: 6.301e-01, Loss Aux: 5.963e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 773, It: 0, Loss Data: 3.870e-02, Loss Eqns: 6.550e-01, Loss Aux: 5.869e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 774, It: 0, Loss Data: 3.168e-02, Loss Eqns: 6.668e-01, Loss Aux: 5.834e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 775, It: 0, Loss Data: 3.200e-02, Loss Eqns: 6.489e-01, Loss Aux: 5.786e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 776, It: 0, Loss Data: 3.553e-02, Loss Eqns: 6.371e-01, Loss Aux: 5.787e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 777, It: 0, Loss Data: 3.042e-02, Loss Eqns: 6.557e-01, Loss Aux: 5.778e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 778, It: 0, Loss Data: 3.411e-02, Loss Eqns: 6.949e-01, Loss Aux: 5.766e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 779, It: 0, Loss Data: 2.774e-02, Loss Eqns: 6.564e-01, Loss Aux: 5.764e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 780, It: 0, Loss Data: 3.211e-02, Loss Eqns: 6.202e-01, Loss Aux: 5.699e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 781, It: 0, Loss Data: 2.650e-02, Loss Eqns: 6.579e-01, Loss Aux: 5.633e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 782, It: 0, Loss Data: 3.392e-02, Loss Eqns: 6.626e-01, Loss Aux: 5.615e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 783, It: 0, Loss Data: 3.334e-02, Loss Eqns: 6.750e-01, Loss Aux: 5.620e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 784, It: 0, Loss Data: 3.157e-02, Loss Eqns: 6.756e-01, Loss Aux: 5.638e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 785, It: 0, Loss Data: 3.025e-02, Loss Eqns: 6.367e-01, Loss Aux: 5.649e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 786, It: 0, Loss Data: 2.787e-02, Loss Eqns: 6.460e-01, Loss Aux: 5.688e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 787, It: 0, Loss Data: 3.343e-02, Loss Eqns: 6.154e-01, Loss Aux: 5.745e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 788, It: 0, Loss Data: 3.062e-02, Loss Eqns: 6.619e-01, Loss Aux: 5.831e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 789, It: 0, Loss Data: 3.682e-02, Loss Eqns: 6.661e-01, Loss Aux: 5.937e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 790, It: 0, Loss Data: 3.162e-02, Loss Eqns: 6.432e-01, Loss Aux: 5.938e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 791, It: 0, Loss Data: 3.118e-02, Loss Eqns: 6.616e-01, Loss Aux: 5.927e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 792, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.390e-01, Loss Aux: 5.847e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 793, It: 0, Loss Data: 3.319e-02, Loss Eqns: 6.586e-01, Loss Aux: 5.751e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 794, It: 0, Loss Data: 2.975e-02, Loss Eqns: 6.629e-01, Loss Aux: 5.666e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 795, It: 0, Loss Data: 3.427e-02, Loss Eqns: 6.766e-01, Loss Aux: 5.622e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 796, It: 0, Loss Data: 3.486e-02, Loss Eqns: 6.372e-01, Loss Aux: 5.655e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 797, It: 0, Loss Data: 2.919e-02, Loss Eqns: 6.470e-01, Loss Aux: 5.730e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 798, It: 0, Loss Data: 3.328e-02, Loss Eqns: 6.769e-01, Loss Aux: 5.759e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 799, It: 0, Loss Data: 3.097e-02, Loss Eqns: 6.638e-01, Loss Aux: 5.760e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 800, It: 0, Loss Data: 2.908e-02, Loss Eqns: 6.557e-01, Loss Aux: 5.746e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 801, It: 0, Loss Data: 3.411e-02, Loss Eqns: 6.370e-01, Loss Aux: 5.733e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 802, It: 0, Loss Data: 2.989e-02, Loss Eqns: 6.314e-01, Loss Aux: 5.757e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 803, It: 0, Loss Data: 2.998e-02, Loss Eqns: 6.423e-01, Loss Aux: 5.793e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 804, It: 0, Loss Data: 2.955e-02, Loss Eqns: 6.354e-01, Loss Aux: 5.780e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 805, It: 0, Loss Data: 2.786e-02, Loss Eqns: 6.476e-01, Loss Aux: 5.752e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 806, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.682e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 807, It: 0, Loss Data: 3.048e-02, Loss Eqns: 6.385e-01, Loss Aux: 5.628e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 808, It: 0, Loss Data: 3.025e-02, Loss Eqns: 6.723e-01, Loss Aux: 5.600e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 809, It: 0, Loss Data: 3.579e-02, Loss Eqns: 6.622e-01, Loss Aux: 5.621e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 810, It: 0, Loss Data: 2.965e-02, Loss Eqns: 6.887e-01, Loss Aux: 5.681e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 811, It: 0, Loss Data: 3.437e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.751e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 812, It: 0, Loss Data: 3.482e-02, Loss Eqns: 6.485e-01, Loss Aux: 5.796e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 813, It: 0, Loss Data: 2.883e-02, Loss Eqns: 6.553e-01, Loss Aux: 5.797e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 814, It: 0, Loss Data: 3.006e-02, Loss Eqns: 6.264e-01, Loss Aux: 5.782e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 815, It: 0, Loss Data: 3.074e-02, Loss Eqns: 6.491e-01, Loss Aux: 5.751e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 816, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.616e-01, Loss Aux: 5.792e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 817, It: 0, Loss Data: 3.280e-02, Loss Eqns: 6.798e-01, Loss Aux: 5.876e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 818, It: 0, Loss Data: 3.156e-02, Loss Eqns: 6.928e-01, Loss Aux: 5.964e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 819, It: 0, Loss Data: 3.103e-02, Loss Eqns: 6.480e-01, Loss Aux: 6.027e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 820, It: 0, Loss Data: 3.143e-02, Loss Eqns: 6.920e-01, Loss Aux: 6.031e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 821, It: 0, Loss Data: 3.462e-02, Loss Eqns: 6.639e-01, Loss Aux: 6.021e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 822, It: 0, Loss Data: 3.213e-02, Loss Eqns: 6.425e-01, Loss Aux: 5.974e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 823, It: 0, Loss Data: 3.264e-02, Loss Eqns: 6.606e-01, Loss Aux: 5.941e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 824, It: 0, Loss Data: 3.106e-02, Loss Eqns: 6.809e-01, Loss Aux: 5.924e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 825, It: 0, Loss Data: 3.338e-02, Loss Eqns: 6.516e-01, Loss Aux: 5.860e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 826, It: 0, Loss Data: 3.243e-02, Loss Eqns: 6.517e-01, Loss Aux: 5.810e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 827, It: 0, Loss Data: 3.241e-02, Loss Eqns: 6.832e-01, Loss Aux: 5.766e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 828, It: 0, Loss Data: 2.874e-02, Loss Eqns: 6.609e-01, Loss Aux: 5.752e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 829, It: 0, Loss Data: 3.145e-02, Loss Eqns: 6.409e-01, Loss Aux: 5.740e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 830, It: 0, Loss Data: 3.129e-02, Loss Eqns: 6.486e-01, Loss Aux: 5.732e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 831, It: 0, Loss Data: 3.090e-02, Loss Eqns: 6.595e-01, Loss Aux: 5.754e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 832, It: 0, Loss Data: 2.938e-02, Loss Eqns: 6.614e-01, Loss Aux: 5.782e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 833, It: 0, Loss Data: 3.303e-02, Loss Eqns: 6.800e-01, Loss Aux: 5.878e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 834, It: 0, Loss Data: 3.112e-02, Loss Eqns: 6.436e-01, Loss Aux: 6.000e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 835, It: 0, Loss Data: 3.285e-02, Loss Eqns: 6.735e-01, Loss Aux: 6.128e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 836, It: 0, Loss Data: 3.115e-02, Loss Eqns: 6.537e-01, Loss Aux: 6.220e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 837, It: 0, Loss Data: 3.095e-02, Loss Eqns: 6.477e-01, Loss Aux: 6.225e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 838, It: 0, Loss Data: 3.102e-02, Loss Eqns: 6.252e-01, Loss Aux: 6.191e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 839, It: 0, Loss Data: 3.346e-02, Loss Eqns: 6.335e-01, Loss Aux: 6.108e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 840, It: 0, Loss Data: 3.335e-02, Loss Eqns: 7.107e-01, Loss Aux: 5.971e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 841, It: 0, Loss Data: 3.626e-02, Loss Eqns: 6.605e-01, Loss Aux: 5.783e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 842, It: 0, Loss Data: 3.245e-02, Loss Eqns: 6.465e-01, Loss Aux: 5.620e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 843, It: 0, Loss Data: 3.334e-02, Loss Eqns: 6.792e-01, Loss Aux: 5.563e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 844, It: 0, Loss Data: 3.330e-02, Loss Eqns: 7.083e-01, Loss Aux: 5.572e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 845, It: 0, Loss Data: 3.334e-02, Loss Eqns: 7.147e-01, Loss Aux: 5.670e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 846, It: 0, Loss Data: 3.248e-02, Loss Eqns: 7.024e-01, Loss Aux: 5.834e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 847, It: 0, Loss Data: 2.956e-02, Loss Eqns: 6.393e-01, Loss Aux: 6.031e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 848, It: 0, Loss Data: 3.266e-02, Loss Eqns: 6.365e-01, Loss Aux: 6.222e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 849, It: 0, Loss Data: 3.298e-02, Loss Eqns: 6.404e-01, Loss Aux: 6.305e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 850, It: 0, Loss Data: 2.967e-02, Loss Eqns: 6.872e-01, Loss Aux: 6.292e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 851, It: 0, Loss Data: 3.385e-02, Loss Eqns: 6.309e-01, Loss Aux: 6.195e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 852, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.487e-01, Loss Aux: 6.018e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 853, It: 0, Loss Data: 3.008e-02, Loss Eqns: 6.761e-01, Loss Aux: 5.860e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 854, It: 0, Loss Data: 3.333e-02, Loss Eqns: 6.208e-01, Loss Aux: 5.734e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 855, It: 0, Loss Data: 3.131e-02, Loss Eqns: 6.407e-01, Loss Aux: 5.668e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 856, It: 0, Loss Data: 3.235e-02, Loss Eqns: 6.564e-01, Loss Aux: 5.696e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 857, It: 0, Loss Data: 3.288e-02, Loss Eqns: 6.351e-01, Loss Aux: 5.786e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 858, It: 0, Loss Data: 3.530e-02, Loss Eqns: 6.222e-01, Loss Aux: 5.933e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 859, It: 0, Loss Data: 3.677e-02, Loss Eqns: 6.350e-01, Loss Aux: 6.019e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 860, It: 0, Loss Data: 2.922e-02, Loss Eqns: 6.492e-01, Loss Aux: 6.014e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 861, It: 0, Loss Data: 3.262e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.989e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 862, It: 0, Loss Data: 3.003e-02, Loss Eqns: 6.561e-01, Loss Aux: 5.910e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 863, It: 0, Loss Data: 3.528e-02, Loss Eqns: 6.264e-01, Loss Aux: 5.768e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 864, It: 0, Loss Data: 2.892e-02, Loss Eqns: 6.572e-01, Loss Aux: 5.681e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 865, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.640e-01, Loss Aux: 5.626e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 866, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.634e-01, Loss Aux: 5.609e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 867, It: 0, Loss Data: 3.200e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.637e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 868, It: 0, Loss Data: 2.674e-02, Loss Eqns: 6.429e-01, Loss Aux: 5.741e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 869, It: 0, Loss Data: 3.129e-02, Loss Eqns: 6.477e-01, Loss Aux: 5.895e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 870, It: 0, Loss Data: 3.040e-02, Loss Eqns: 6.632e-01, Loss Aux: 6.004e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 871, It: 0, Loss Data: 2.884e-02, Loss Eqns: 6.718e-01, Loss Aux: 6.042e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 872, It: 0, Loss Data: 3.108e-02, Loss Eqns: 6.304e-01, Loss Aux: 6.022e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 873, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.986e-01, Loss Aux: 5.984e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 874, It: 0, Loss Data: 3.273e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.912e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 875, It: 0, Loss Data: 3.558e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.863e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 876, It: 0, Loss Data: 3.107e-02, Loss Eqns: 6.631e-01, Loss Aux: 5.831e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 877, It: 0, Loss Data: 3.399e-02, Loss Eqns: 6.231e-01, Loss Aux: 5.768e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 878, It: 0, Loss Data: 2.610e-02, Loss Eqns: 6.691e-01, Loss Aux: 5.708e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 879, It: 0, Loss Data: 3.220e-02, Loss Eqns: 6.481e-01, Loss Aux: 5.689e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 880, It: 0, Loss Data: 2.947e-02, Loss Eqns: 6.538e-01, Loss Aux: 5.702e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 881, It: 0, Loss Data: 3.054e-02, Loss Eqns: 6.823e-01, Loss Aux: 5.735e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 882, It: 0, Loss Data: 2.930e-02, Loss Eqns: 6.568e-01, Loss Aux: 5.770e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 883, It: 0, Loss Data: 3.403e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.792e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 884, It: 0, Loss Data: 2.956e-02, Loss Eqns: 6.188e-01, Loss Aux: 5.740e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 885, It: 0, Loss Data: 2.869e-02, Loss Eqns: 6.484e-01, Loss Aux: 5.693e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 886, It: 0, Loss Data: 3.419e-02, Loss Eqns: 6.834e-01, Loss Aux: 5.712e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 887, It: 0, Loss Data: 3.489e-02, Loss Eqns: 6.751e-01, Loss Aux: 5.755e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 888, It: 0, Loss Data: 2.777e-02, Loss Eqns: 6.551e-01, Loss Aux: 5.818e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 889, It: 0, Loss Data: 3.170e-02, Loss Eqns: 6.484e-01, Loss Aux: 5.866e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 890, It: 0, Loss Data: 3.415e-02, Loss Eqns: 6.698e-01, Loss Aux: 5.943e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 891, It: 0, Loss Data: 3.092e-02, Loss Eqns: 6.326e-01, Loss Aux: 5.957e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 892, It: 0, Loss Data: 3.192e-02, Loss Eqns: 6.566e-01, Loss Aux: 5.886e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 893, It: 0, Loss Data: 3.379e-02, Loss Eqns: 6.528e-01, Loss Aux: 5.834e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 894, It: 0, Loss Data: 2.480e-02, Loss Eqns: 6.664e-01, Loss Aux: 5.762e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 895, It: 0, Loss Data: 3.275e-02, Loss Eqns: 6.769e-01, Loss Aux: 5.727e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 896, It: 0, Loss Data: 3.154e-02, Loss Eqns: 6.706e-01, Loss Aux: 5.678e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 897, It: 0, Loss Data: 3.592e-02, Loss Eqns: 6.114e-01, Loss Aux: 5.638e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 898, It: 0, Loss Data: 3.199e-02, Loss Eqns: 6.679e-01, Loss Aux: 5.637e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 899, It: 0, Loss Data: 3.087e-02, Loss Eqns: 6.229e-01, Loss Aux: 5.637e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 900, It: 0, Loss Data: 3.173e-02, Loss Eqns: 6.617e-01, Loss Aux: 5.696e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 901, It: 0, Loss Data: 3.028e-02, Loss Eqns: 6.562e-01, Loss Aux: 5.724e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 902, It: 0, Loss Data: 2.867e-02, Loss Eqns: 6.249e-01, Loss Aux: 5.755e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 903, It: 0, Loss Data: 2.909e-02, Loss Eqns: 6.556e-01, Loss Aux: 5.785e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 904, It: 0, Loss Data: 3.084e-02, Loss Eqns: 6.535e-01, Loss Aux: 5.839e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 905, It: 0, Loss Data: 2.920e-02, Loss Eqns: 6.560e-01, Loss Aux: 5.852e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 906, It: 0, Loss Data: 3.730e-02, Loss Eqns: 6.452e-01, Loss Aux: 6.015e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 907, It: 0, Loss Data: 3.425e-02, Loss Eqns: 6.916e-01, Loss Aux: 6.179e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 908, It: 0, Loss Data: 2.888e-02, Loss Eqns: 6.470e-01, Loss Aux: 6.303e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 909, It: 0, Loss Data: 3.434e-02, Loss Eqns: 6.523e-01, Loss Aux: 6.339e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 910, It: 0, Loss Data: 3.379e-02, Loss Eqns: 6.854e-01, Loss Aux: 6.244e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 911, It: 0, Loss Data: 3.299e-02, Loss Eqns: 6.514e-01, Loss Aux: 6.083e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 912, It: 0, Loss Data: 2.874e-02, Loss Eqns: 6.311e-01, Loss Aux: 5.917e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 913, It: 0, Loss Data: 3.589e-02, Loss Eqns: 6.759e-01, Loss Aux: 5.813e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 914, It: 0, Loss Data: 3.372e-02, Loss Eqns: 6.641e-01, Loss Aux: 5.778e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 915, It: 0, Loss Data: 2.975e-02, Loss Eqns: 6.339e-01, Loss Aux: 5.781e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 916, It: 0, Loss Data: 3.238e-02, Loss Eqns: 6.636e-01, Loss Aux: 5.877e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 917, It: 0, Loss Data: 3.000e-02, Loss Eqns: 6.299e-01, Loss Aux: 6.004e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 918, It: 0, Loss Data: 2.916e-02, Loss Eqns: 6.189e-01, Loss Aux: 6.081e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 919, It: 0, Loss Data: 3.355e-02, Loss Eqns: 5.955e-01, Loss Aux: 6.144e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 920, It: 0, Loss Data: 2.612e-02, Loss Eqns: 6.352e-01, Loss Aux: 6.080e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 921, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.792e-01, Loss Aux: 5.936e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 922, It: 0, Loss Data: 3.383e-02, Loss Eqns: 6.489e-01, Loss Aux: 5.835e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 923, It: 0, Loss Data: 3.260e-02, Loss Eqns: 6.221e-01, Loss Aux: 5.749e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 924, It: 0, Loss Data: 2.806e-02, Loss Eqns: 6.736e-01, Loss Aux: 5.753e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 925, It: 0, Loss Data: 3.105e-02, Loss Eqns: 6.302e-01, Loss Aux: 5.754e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 926, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.550e-01, Loss Aux: 5.718e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 927, It: 0, Loss Data: 2.864e-02, Loss Eqns: 6.559e-01, Loss Aux: 5.736e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 928, It: 0, Loss Data: 3.151e-02, Loss Eqns: 6.715e-01, Loss Aux: 5.763e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 929, It: 0, Loss Data: 2.595e-02, Loss Eqns: 6.785e-01, Loss Aux: 5.869e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 930, It: 0, Loss Data: 3.307e-02, Loss Eqns: 6.633e-01, Loss Aux: 5.950e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 931, It: 0, Loss Data: 3.491e-02, Loss Eqns: 6.669e-01, Loss Aux: 6.005e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 932, It: 0, Loss Data: 2.738e-02, Loss Eqns: 6.730e-01, Loss Aux: 5.984e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 933, It: 0, Loss Data: 2.827e-02, Loss Eqns: 6.607e-01, Loss Aux: 5.943e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 934, It: 0, Loss Data: 3.416e-02, Loss Eqns: 6.330e-01, Loss Aux: 5.897e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 935, It: 0, Loss Data: 3.073e-02, Loss Eqns: 6.382e-01, Loss Aux: 5.874e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 936, It: 0, Loss Data: 2.974e-02, Loss Eqns: 6.583e-01, Loss Aux: 5.858e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 937, It: 0, Loss Data: 3.110e-02, Loss Eqns: 6.331e-01, Loss Aux: 5.919e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 938, It: 0, Loss Data: 3.260e-02, Loss Eqns: 6.313e-01, Loss Aux: 5.950e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 939, It: 0, Loss Data: 3.255e-02, Loss Eqns: 6.628e-01, Loss Aux: 5.948e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 940, It: 0, Loss Data: 3.176e-02, Loss Eqns: 6.583e-01, Loss Aux: 5.920e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 941, It: 0, Loss Data: 3.307e-02, Loss Eqns: 6.363e-01, Loss Aux: 5.859e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 942, It: 0, Loss Data: 3.328e-02, Loss Eqns: 6.335e-01, Loss Aux: 5.723e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 943, It: 0, Loss Data: 3.408e-02, Loss Eqns: 6.501e-01, Loss Aux: 5.586e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 944, It: 0, Loss Data: 2.966e-02, Loss Eqns: 6.529e-01, Loss Aux: 5.519e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 945, It: 0, Loss Data: 2.726e-02, Loss Eqns: 6.687e-01, Loss Aux: 5.505e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 946, It: 0, Loss Data: 2.855e-02, Loss Eqns: 6.154e-01, Loss Aux: 5.523e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 947, It: 0, Loss Data: 3.270e-02, Loss Eqns: 6.262e-01, Loss Aux: 5.582e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 948, It: 0, Loss Data: 3.230e-02, Loss Eqns: 6.431e-01, Loss Aux: 5.703e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 949, It: 0, Loss Data: 3.192e-02, Loss Eqns: 6.129e-01, Loss Aux: 5.793e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 950, It: 0, Loss Data: 3.158e-02, Loss Eqns: 6.548e-01, Loss Aux: 5.818e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 951, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.314e-01, Loss Aux: 5.816e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 952, It: 0, Loss Data: 2.794e-02, Loss Eqns: 6.628e-01, Loss Aux: 5.806e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 953, It: 0, Loss Data: 3.737e-02, Loss Eqns: 6.143e-01, Loss Aux: 5.740e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 954, It: 0, Loss Data: 2.714e-02, Loss Eqns: 6.811e-01, Loss Aux: 5.731e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 955, It: 0, Loss Data: 3.271e-02, Loss Eqns: 6.814e-01, Loss Aux: 5.789e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 956, It: 0, Loss Data: 2.969e-02, Loss Eqns: 6.804e-01, Loss Aux: 5.788e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 957, It: 0, Loss Data: 2.973e-02, Loss Eqns: 6.635e-01, Loss Aux: 5.777e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 958, It: 0, Loss Data: 3.212e-02, Loss Eqns: 6.101e-01, Loss Aux: 5.764e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 959, It: 0, Loss Data: 3.140e-02, Loss Eqns: 6.604e-01, Loss Aux: 5.732e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 960, It: 0, Loss Data: 2.956e-02, Loss Eqns: 6.457e-01, Loss Aux: 5.675e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 961, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.286e-01, Loss Aux: 5.639e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 962, It: 0, Loss Data: 3.159e-02, Loss Eqns: 6.545e-01, Loss Aux: 5.711e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 963, It: 0, Loss Data: 3.006e-02, Loss Eqns: 6.391e-01, Loss Aux: 5.756e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 964, It: 0, Loss Data: 3.034e-02, Loss Eqns: 6.099e-01, Loss Aux: 5.812e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 965, It: 0, Loss Data: 3.572e-02, Loss Eqns: 6.986e-01, Loss Aux: 5.860e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 966, It: 0, Loss Data: 3.352e-02, Loss Eqns: 6.675e-01, Loss Aux: 5.907e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 967, It: 0, Loss Data: 3.338e-02, Loss Eqns: 6.068e-01, Loss Aux: 5.919e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 968, It: 0, Loss Data: 2.807e-02, Loss Eqns: 6.561e-01, Loss Aux: 5.932e-02, Time: 0.146, Learning Rate: 1.0e-04\n",
      "Epoch: 969, It: 0, Loss Data: 3.555e-02, Loss Eqns: 6.592e-01, Loss Aux: 6.046e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 970, It: 0, Loss Data: 3.686e-02, Loss Eqns: 6.641e-01, Loss Aux: 6.138e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 971, It: 0, Loss Data: 2.984e-02, Loss Eqns: 6.397e-01, Loss Aux: 6.169e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 972, It: 0, Loss Data: 3.143e-02, Loss Eqns: 6.586e-01, Loss Aux: 6.092e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 973, It: 0, Loss Data: 2.919e-02, Loss Eqns: 6.320e-01, Loss Aux: 5.981e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 974, It: 0, Loss Data: 3.246e-02, Loss Eqns: 6.142e-01, Loss Aux: 5.832e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 975, It: 0, Loss Data: 3.214e-02, Loss Eqns: 6.719e-01, Loss Aux: 5.695e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 976, It: 0, Loss Data: 3.361e-02, Loss Eqns: 6.852e-01, Loss Aux: 5.646e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 977, It: 0, Loss Data: 3.813e-02, Loss Eqns: 6.290e-01, Loss Aux: 5.658e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 978, It: 0, Loss Data: 3.072e-02, Loss Eqns: 6.750e-01, Loss Aux: 5.727e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 979, It: 0, Loss Data: 2.831e-02, Loss Eqns: 6.479e-01, Loss Aux: 5.840e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 980, It: 0, Loss Data: 3.105e-02, Loss Eqns: 6.815e-01, Loss Aux: 5.905e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 981, It: 0, Loss Data: 2.866e-02, Loss Eqns: 6.693e-01, Loss Aux: 5.928e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 982, It: 0, Loss Data: 3.086e-02, Loss Eqns: 6.577e-01, Loss Aux: 5.925e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 983, It: 0, Loss Data: 3.245e-02, Loss Eqns: 6.532e-01, Loss Aux: 5.961e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 984, It: 0, Loss Data: 2.743e-02, Loss Eqns: 6.550e-01, Loss Aux: 6.047e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 985, It: 0, Loss Data: 2.931e-02, Loss Eqns: 6.745e-01, Loss Aux: 6.102e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 986, It: 0, Loss Data: 2.883e-02, Loss Eqns: 6.668e-01, Loss Aux: 6.212e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 987, It: 0, Loss Data: 3.270e-02, Loss Eqns: 6.347e-01, Loss Aux: 6.341e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 988, It: 0, Loss Data: 2.925e-02, Loss Eqns: 6.492e-01, Loss Aux: 6.348e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 989, It: 0, Loss Data: 3.001e-02, Loss Eqns: 6.451e-01, Loss Aux: 6.282e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 990, It: 0, Loss Data: 3.122e-02, Loss Eqns: 6.519e-01, Loss Aux: 6.127e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 991, It: 0, Loss Data: 2.923e-02, Loss Eqns: 6.615e-01, Loss Aux: 5.978e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 992, It: 0, Loss Data: 3.456e-02, Loss Eqns: 6.524e-01, Loss Aux: 5.818e-02, Time: 0.199, Learning Rate: 1.0e-04\n",
      "Epoch: 993, It: 0, Loss Data: 2.860e-02, Loss Eqns: 6.460e-01, Loss Aux: 5.710e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 994, It: 0, Loss Data: 3.364e-02, Loss Eqns: 6.216e-01, Loss Aux: 5.709e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 995, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.479e-01, Loss Aux: 5.759e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 996, It: 0, Loss Data: 3.136e-02, Loss Eqns: 6.415e-01, Loss Aux: 5.867e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 997, It: 0, Loss Data: 3.097e-02, Loss Eqns: 7.071e-01, Loss Aux: 5.994e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 998, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.654e-01, Loss Aux: 6.086e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 999, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.610e-01, Loss Aux: 6.077e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1000, It: 0, Loss Data: 3.415e-02, Loss Eqns: 6.468e-01, Loss Aux: 6.038e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1001, It: 0, Loss Data: 3.336e-02, Loss Eqns: 6.619e-01, Loss Aux: 6.000e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1002, It: 0, Loss Data: 2.953e-02, Loss Eqns: 6.496e-01, Loss Aux: 5.944e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1003, It: 0, Loss Data: 2.800e-02, Loss Eqns: 6.784e-01, Loss Aux: 5.931e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1004, It: 0, Loss Data: 3.169e-02, Loss Eqns: 6.696e-01, Loss Aux: 5.924e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1005, It: 0, Loss Data: 2.956e-02, Loss Eqns: 6.533e-01, Loss Aux: 5.954e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1006, It: 0, Loss Data: 3.479e-02, Loss Eqns: 6.262e-01, Loss Aux: 6.037e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1007, It: 0, Loss Data: 2.913e-02, Loss Eqns: 6.501e-01, Loss Aux: 6.070e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1008, It: 0, Loss Data: 2.845e-02, Loss Eqns: 6.485e-01, Loss Aux: 6.056e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1009, It: 0, Loss Data: 3.114e-02, Loss Eqns: 6.221e-01, Loss Aux: 5.973e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1010, It: 0, Loss Data: 3.278e-02, Loss Eqns: 6.493e-01, Loss Aux: 5.866e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1011, It: 0, Loss Data: 3.238e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.748e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1012, It: 0, Loss Data: 2.985e-02, Loss Eqns: 6.684e-01, Loss Aux: 5.675e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1013, It: 0, Loss Data: 3.389e-02, Loss Eqns: 6.626e-01, Loss Aux: 5.679e-02, Time: 0.200, Learning Rate: 1.0e-04\n",
      "Epoch: 1014, It: 0, Loss Data: 2.885e-02, Loss Eqns: 6.870e-01, Loss Aux: 5.732e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1015, It: 0, Loss Data: 2.898e-02, Loss Eqns: 6.510e-01, Loss Aux: 5.758e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1016, It: 0, Loss Data: 3.465e-02, Loss Eqns: 6.518e-01, Loss Aux: 5.817e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1017, It: 0, Loss Data: 3.622e-02, Loss Eqns: 6.383e-01, Loss Aux: 5.902e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1018, It: 0, Loss Data: 3.219e-02, Loss Eqns: 6.619e-01, Loss Aux: 6.010e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1019, It: 0, Loss Data: 3.085e-02, Loss Eqns: 6.888e-01, Loss Aux: 6.043e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1020, It: 0, Loss Data: 3.428e-02, Loss Eqns: 6.410e-01, Loss Aux: 6.050e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1021, It: 0, Loss Data: 3.239e-02, Loss Eqns: 6.588e-01, Loss Aux: 6.100e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1022, It: 0, Loss Data: 3.242e-02, Loss Eqns: 6.766e-01, Loss Aux: 6.139e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1023, It: 0, Loss Data: 3.197e-02, Loss Eqns: 6.779e-01, Loss Aux: 6.146e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1024, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.656e-01, Loss Aux: 6.122e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1025, It: 0, Loss Data: 2.659e-02, Loss Eqns: 6.597e-01, Loss Aux: 6.115e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1026, It: 0, Loss Data: 2.916e-02, Loss Eqns: 6.431e-01, Loss Aux: 6.125e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1027, It: 0, Loss Data: 3.190e-02, Loss Eqns: 6.385e-01, Loss Aux: 6.191e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1028, It: 0, Loss Data: 3.436e-02, Loss Eqns: 6.499e-01, Loss Aux: 6.207e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1029, It: 0, Loss Data: 3.201e-02, Loss Eqns: 6.308e-01, Loss Aux: 6.203e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1030, It: 0, Loss Data: 3.372e-02, Loss Eqns: 6.441e-01, Loss Aux: 6.176e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1031, It: 0, Loss Data: 3.476e-02, Loss Eqns: 6.320e-01, Loss Aux: 6.068e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1032, It: 0, Loss Data: 3.019e-02, Loss Eqns: 6.621e-01, Loss Aux: 5.931e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1033, It: 0, Loss Data: 3.342e-02, Loss Eqns: 6.644e-01, Loss Aux: 5.857e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1034, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.365e-01, Loss Aux: 5.792e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1035, It: 0, Loss Data: 3.350e-02, Loss Eqns: 6.584e-01, Loss Aux: 5.780e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1036, It: 0, Loss Data: 3.306e-02, Loss Eqns: 6.666e-01, Loss Aux: 5.835e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1037, It: 0, Loss Data: 2.973e-02, Loss Eqns: 6.558e-01, Loss Aux: 5.910e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1038, It: 0, Loss Data: 3.034e-02, Loss Eqns: 7.018e-01, Loss Aux: 5.957e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1039, It: 0, Loss Data: 3.238e-02, Loss Eqns: 6.839e-01, Loss Aux: 6.004e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1040, It: 0, Loss Data: 3.568e-02, Loss Eqns: 6.601e-01, Loss Aux: 6.031e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1041, It: 0, Loss Data: 3.234e-02, Loss Eqns: 6.503e-01, Loss Aux: 5.949e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1042, It: 0, Loss Data: 3.005e-02, Loss Eqns: 6.341e-01, Loss Aux: 5.834e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1043, It: 0, Loss Data: 3.266e-02, Loss Eqns: 6.495e-01, Loss Aux: 5.739e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1044, It: 0, Loss Data: 2.811e-02, Loss Eqns: 6.754e-01, Loss Aux: 5.669e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1045, It: 0, Loss Data: 3.151e-02, Loss Eqns: 6.441e-01, Loss Aux: 5.720e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1046, It: 0, Loss Data: 2.723e-02, Loss Eqns: 6.955e-01, Loss Aux: 5.814e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1047, It: 0, Loss Data: 3.391e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.931e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1048, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.440e-01, Loss Aux: 5.971e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1049, It: 0, Loss Data: 3.169e-02, Loss Eqns: 6.549e-01, Loss Aux: 5.932e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1050, It: 0, Loss Data: 3.175e-02, Loss Eqns: 6.729e-01, Loss Aux: 5.818e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1051, It: 0, Loss Data: 3.186e-02, Loss Eqns: 7.420e-01, Loss Aux: 5.718e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1052, It: 0, Loss Data: 3.109e-02, Loss Eqns: 6.760e-01, Loss Aux: 5.671e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1053, It: 0, Loss Data: 2.940e-02, Loss Eqns: 6.535e-01, Loss Aux: 5.637e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1054, It: 0, Loss Data: 3.229e-02, Loss Eqns: 6.509e-01, Loss Aux: 5.608e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1055, It: 0, Loss Data: 3.119e-02, Loss Eqns: 6.427e-01, Loss Aux: 5.633e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1056, It: 0, Loss Data: 2.904e-02, Loss Eqns: 6.129e-01, Loss Aux: 5.687e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1057, It: 0, Loss Data: 3.327e-02, Loss Eqns: 6.690e-01, Loss Aux: 5.789e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1058, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.482e-01, Loss Aux: 5.910e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1059, It: 0, Loss Data: 2.956e-02, Loss Eqns: 6.121e-01, Loss Aux: 6.011e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1060, It: 0, Loss Data: 3.219e-02, Loss Eqns: 6.334e-01, Loss Aux: 6.030e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1061, It: 0, Loss Data: 2.806e-02, Loss Eqns: 6.424e-01, Loss Aux: 5.983e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1062, It: 0, Loss Data: 3.249e-02, Loss Eqns: 6.286e-01, Loss Aux: 5.901e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1063, It: 0, Loss Data: 3.047e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.845e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1064, It: 0, Loss Data: 3.139e-02, Loss Eqns: 6.316e-01, Loss Aux: 5.848e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1065, It: 0, Loss Data: 3.016e-02, Loss Eqns: 6.096e-01, Loss Aux: 5.851e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1066, It: 0, Loss Data: 2.965e-02, Loss Eqns: 6.533e-01, Loss Aux: 5.903e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1067, It: 0, Loss Data: 3.134e-02, Loss Eqns: 6.701e-01, Loss Aux: 5.959e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1068, It: 0, Loss Data: 3.369e-02, Loss Eqns: 6.362e-01, Loss Aux: 5.991e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1069, It: 0, Loss Data: 3.568e-02, Loss Eqns: 6.835e-01, Loss Aux: 5.944e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1070, It: 0, Loss Data: 2.997e-02, Loss Eqns: 6.385e-01, Loss Aux: 5.863e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1071, It: 0, Loss Data: 3.258e-02, Loss Eqns: 6.460e-01, Loss Aux: 5.840e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1072, It: 0, Loss Data: 3.278e-02, Loss Eqns: 6.621e-01, Loss Aux: 5.842e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1073, It: 0, Loss Data: 3.344e-02, Loss Eqns: 6.350e-01, Loss Aux: 5.847e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1074, It: 0, Loss Data: 3.278e-02, Loss Eqns: 6.333e-01, Loss Aux: 5.823e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1075, It: 0, Loss Data: 3.129e-02, Loss Eqns: 6.455e-01, Loss Aux: 5.768e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1076, It: 0, Loss Data: 2.955e-02, Loss Eqns: 6.546e-01, Loss Aux: 5.685e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1077, It: 0, Loss Data: 3.152e-02, Loss Eqns: 6.878e-01, Loss Aux: 5.678e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1078, It: 0, Loss Data: 2.763e-02, Loss Eqns: 6.676e-01, Loss Aux: 5.708e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 1079, It: 0, Loss Data: 2.672e-02, Loss Eqns: 6.353e-01, Loss Aux: 5.734e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 1080, It: 0, Loss Data: 3.412e-02, Loss Eqns: 6.525e-01, Loss Aux: 5.776e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 1081, It: 0, Loss Data: 2.871e-02, Loss Eqns: 6.578e-01, Loss Aux: 5.850e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1082, It: 0, Loss Data: 3.171e-02, Loss Eqns: 6.443e-01, Loss Aux: 5.859e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1083, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.378e-01, Loss Aux: 5.890e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1084, It: 0, Loss Data: 3.279e-02, Loss Eqns: 6.599e-01, Loss Aux: 5.930e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1085, It: 0, Loss Data: 3.244e-02, Loss Eqns: 6.853e-01, Loss Aux: 5.953e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1086, It: 0, Loss Data: 3.063e-02, Loss Eqns: 6.746e-01, Loss Aux: 5.960e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1087, It: 0, Loss Data: 2.863e-02, Loss Eqns: 6.268e-01, Loss Aux: 5.932e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1088, It: 0, Loss Data: 3.266e-02, Loss Eqns: 6.408e-01, Loss Aux: 5.873e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1089, It: 0, Loss Data: 3.212e-02, Loss Eqns: 6.795e-01, Loss Aux: 5.781e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1090, It: 0, Loss Data: 3.044e-02, Loss Eqns: 6.672e-01, Loss Aux: 5.719e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1091, It: 0, Loss Data: 2.752e-02, Loss Eqns: 6.406e-01, Loss Aux: 5.707e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1092, It: 0, Loss Data: 3.121e-02, Loss Eqns: 6.600e-01, Loss Aux: 5.747e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1093, It: 0, Loss Data: 3.363e-02, Loss Eqns: 6.517e-01, Loss Aux: 5.879e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1094, It: 0, Loss Data: 3.247e-02, Loss Eqns: 6.526e-01, Loss Aux: 6.053e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1095, It: 0, Loss Data: 3.258e-02, Loss Eqns: 6.875e-01, Loss Aux: 6.209e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1096, It: 0, Loss Data: 3.115e-02, Loss Eqns: 6.411e-01, Loss Aux: 6.250e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1097, It: 0, Loss Data: 3.076e-02, Loss Eqns: 6.596e-01, Loss Aux: 6.238e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1098, It: 0, Loss Data: 2.831e-02, Loss Eqns: 6.374e-01, Loss Aux: 6.168e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1099, It: 0, Loss Data: 2.942e-02, Loss Eqns: 6.127e-01, Loss Aux: 6.043e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1100, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.523e-01, Loss Aux: 5.995e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1101, It: 0, Loss Data: 2.984e-02, Loss Eqns: 6.587e-01, Loss Aux: 6.024e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1102, It: 0, Loss Data: 3.135e-02, Loss Eqns: 6.488e-01, Loss Aux: 6.072e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1103, It: 0, Loss Data: 3.348e-02, Loss Eqns: 6.644e-01, Loss Aux: 6.114e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1104, It: 0, Loss Data: 3.173e-02, Loss Eqns: 6.557e-01, Loss Aux: 6.070e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1105, It: 0, Loss Data: 3.173e-02, Loss Eqns: 6.626e-01, Loss Aux: 5.992e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1106, It: 0, Loss Data: 2.953e-02, Loss Eqns: 6.164e-01, Loss Aux: 5.885e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1107, It: 0, Loss Data: 2.727e-02, Loss Eqns: 6.257e-01, Loss Aux: 5.809e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1108, It: 0, Loss Data: 3.512e-02, Loss Eqns: 6.631e-01, Loss Aux: 5.814e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1109, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.438e-01, Loss Aux: 5.864e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1110, It: 0, Loss Data: 3.401e-02, Loss Eqns: 6.367e-01, Loss Aux: 5.907e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1111, It: 0, Loss Data: 2.989e-02, Loss Eqns: 6.433e-01, Loss Aux: 5.981e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1112, It: 0, Loss Data: 3.083e-02, Loss Eqns: 6.576e-01, Loss Aux: 6.123e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1113, It: 0, Loss Data: 3.162e-02, Loss Eqns: 6.246e-01, Loss Aux: 6.227e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1114, It: 0, Loss Data: 2.943e-02, Loss Eqns: 6.589e-01, Loss Aux: 6.268e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1115, It: 0, Loss Data: 3.258e-02, Loss Eqns: 6.567e-01, Loss Aux: 6.199e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1116, It: 0, Loss Data: 3.112e-02, Loss Eqns: 6.424e-01, Loss Aux: 6.079e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 1117, It: 0, Loss Data: 2.951e-02, Loss Eqns: 6.411e-01, Loss Aux: 5.954e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1118, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.662e-01, Loss Aux: 5.872e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1119, It: 0, Loss Data: 2.491e-02, Loss Eqns: 6.265e-01, Loss Aux: 5.781e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1120, It: 0, Loss Data: 3.017e-02, Loss Eqns: 6.352e-01, Loss Aux: 5.748e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1121, It: 0, Loss Data: 2.893e-02, Loss Eqns: 6.222e-01, Loss Aux: 5.791e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1122, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.160e-01, Loss Aux: 5.841e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1123, It: 0, Loss Data: 3.229e-02, Loss Eqns: 6.281e-01, Loss Aux: 5.865e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1124, It: 0, Loss Data: 3.217e-02, Loss Eqns: 6.637e-01, Loss Aux: 5.925e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 1125, It: 0, Loss Data: 2.915e-02, Loss Eqns: 6.137e-01, Loss Aux: 5.939e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1126, It: 0, Loss Data: 3.197e-02, Loss Eqns: 6.602e-01, Loss Aux: 5.882e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1127, It: 0, Loss Data: 3.229e-02, Loss Eqns: 6.524e-01, Loss Aux: 5.828e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1128, It: 0, Loss Data: 3.586e-02, Loss Eqns: 6.307e-01, Loss Aux: 5.780e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1129, It: 0, Loss Data: 3.301e-02, Loss Eqns: 6.725e-01, Loss Aux: 5.737e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1130, It: 0, Loss Data: 3.246e-02, Loss Eqns: 6.478e-01, Loss Aux: 5.713e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1131, It: 0, Loss Data: 3.324e-02, Loss Eqns: 6.475e-01, Loss Aux: 5.689e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1132, It: 0, Loss Data: 3.245e-02, Loss Eqns: 6.771e-01, Loss Aux: 5.714e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1133, It: 0, Loss Data: 2.651e-02, Loss Eqns: 6.509e-01, Loss Aux: 5.700e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1134, It: 0, Loss Data: 3.066e-02, Loss Eqns: 6.596e-01, Loss Aux: 5.768e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1135, It: 0, Loss Data: 2.748e-02, Loss Eqns: 6.427e-01, Loss Aux: 5.891e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1136, It: 0, Loss Data: 3.126e-02, Loss Eqns: 6.236e-01, Loss Aux: 5.946e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1137, It: 0, Loss Data: 3.267e-02, Loss Eqns: 6.663e-01, Loss Aux: 6.010e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1138, It: 0, Loss Data: 2.680e-02, Loss Eqns: 6.431e-01, Loss Aux: 6.109e-02, Time: 0.142, Learning Rate: 1.0e-04\n",
      "Epoch: 1139, It: 0, Loss Data: 3.120e-02, Loss Eqns: 6.307e-01, Loss Aux: 6.183e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1140, It: 0, Loss Data: 2.651e-02, Loss Eqns: 6.800e-01, Loss Aux: 6.164e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1141, It: 0, Loss Data: 3.367e-02, Loss Eqns: 6.193e-01, Loss Aux: 6.143e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1142, It: 0, Loss Data: 3.211e-02, Loss Eqns: 6.423e-01, Loss Aux: 6.103e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1143, It: 0, Loss Data: 2.755e-02, Loss Eqns: 6.732e-01, Loss Aux: 6.029e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1144, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.898e-01, Loss Aux: 5.903e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1145, It: 0, Loss Data: 3.121e-02, Loss Eqns: 6.375e-01, Loss Aux: 5.778e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1146, It: 0, Loss Data: 2.967e-02, Loss Eqns: 6.700e-01, Loss Aux: 5.737e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1147, It: 0, Loss Data: 2.936e-02, Loss Eqns: 6.504e-01, Loss Aux: 5.806e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1148, It: 0, Loss Data: 2.798e-02, Loss Eqns: 6.408e-01, Loss Aux: 5.984e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1149, It: 0, Loss Data: 2.824e-02, Loss Eqns: 6.257e-01, Loss Aux: 6.184e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1150, It: 0, Loss Data: 2.839e-02, Loss Eqns: 6.441e-01, Loss Aux: 6.277e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1151, It: 0, Loss Data: 3.059e-02, Loss Eqns: 6.379e-01, Loss Aux: 6.206e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 1152, It: 0, Loss Data: 2.955e-02, Loss Eqns: 6.689e-01, Loss Aux: 6.071e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1153, It: 0, Loss Data: 2.957e-02, Loss Eqns: 6.366e-01, Loss Aux: 5.949e-02, Time: 0.140, Learning Rate: 1.0e-04\n",
      "Epoch: 1154, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.401e-01, Loss Aux: 5.837e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1155, It: 0, Loss Data: 3.451e-02, Loss Eqns: 6.394e-01, Loss Aux: 5.795e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1156, It: 0, Loss Data: 3.658e-02, Loss Eqns: 6.333e-01, Loss Aux: 5.817e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1157, It: 0, Loss Data: 3.157e-02, Loss Eqns: 6.877e-01, Loss Aux: 5.870e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1158, It: 0, Loss Data: 3.529e-02, Loss Eqns: 6.180e-01, Loss Aux: 5.913e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1159, It: 0, Loss Data: 3.124e-02, Loss Eqns: 6.582e-01, Loss Aux: 5.975e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1160, It: 0, Loss Data: 3.481e-02, Loss Eqns: 6.703e-01, Loss Aux: 6.038e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1161, It: 0, Loss Data: 3.353e-02, Loss Eqns: 6.422e-01, Loss Aux: 6.018e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1162, It: 0, Loss Data: 3.094e-02, Loss Eqns: 6.456e-01, Loss Aux: 5.957e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1163, It: 0, Loss Data: 2.551e-02, Loss Eqns: 6.743e-01, Loss Aux: 5.855e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1164, It: 0, Loss Data: 3.160e-02, Loss Eqns: 6.653e-01, Loss Aux: 5.811e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1165, It: 0, Loss Data: 3.115e-02, Loss Eqns: 6.590e-01, Loss Aux: 5.813e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1166, It: 0, Loss Data: 3.023e-02, Loss Eqns: 6.755e-01, Loss Aux: 5.819e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1167, It: 0, Loss Data: 3.006e-02, Loss Eqns: 6.443e-01, Loss Aux: 5.877e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1168, It: 0, Loss Data: 3.203e-02, Loss Eqns: 6.363e-01, Loss Aux: 5.927e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1169, It: 0, Loss Data: 3.561e-02, Loss Eqns: 6.819e-01, Loss Aux: 5.954e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1170, It: 0, Loss Data: 3.285e-02, Loss Eqns: 6.575e-01, Loss Aux: 5.914e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1171, It: 0, Loss Data: 3.357e-02, Loss Eqns: 6.677e-01, Loss Aux: 5.915e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1172, It: 0, Loss Data: 2.775e-02, Loss Eqns: 6.525e-01, Loss Aux: 5.866e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1173, It: 0, Loss Data: 2.998e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.815e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1174, It: 0, Loss Data: 3.054e-02, Loss Eqns: 6.189e-01, Loss Aux: 5.765e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1175, It: 0, Loss Data: 3.193e-02, Loss Eqns: 6.743e-01, Loss Aux: 5.794e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 1176, It: 0, Loss Data: 3.210e-02, Loss Eqns: 6.339e-01, Loss Aux: 5.836e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1177, It: 0, Loss Data: 3.250e-02, Loss Eqns: 6.167e-01, Loss Aux: 5.872e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1178, It: 0, Loss Data: 2.951e-02, Loss Eqns: 6.275e-01, Loss Aux: 5.901e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1179, It: 0, Loss Data: 2.919e-02, Loss Eqns: 6.309e-01, Loss Aux: 5.933e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1180, It: 0, Loss Data: 2.805e-02, Loss Eqns: 6.723e-01, Loss Aux: 5.955e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1181, It: 0, Loss Data: 2.932e-02, Loss Eqns: 6.281e-01, Loss Aux: 6.000e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1182, It: 0, Loss Data: 2.725e-02, Loss Eqns: 6.369e-01, Loss Aux: 6.003e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1183, It: 0, Loss Data: 3.200e-02, Loss Eqns: 6.387e-01, Loss Aux: 5.970e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1184, It: 0, Loss Data: 3.187e-02, Loss Eqns: 6.204e-01, Loss Aux: 5.917e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1185, It: 0, Loss Data: 2.943e-02, Loss Eqns: 6.253e-01, Loss Aux: 5.795e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1186, It: 0, Loss Data: 3.360e-02, Loss Eqns: 6.246e-01, Loss Aux: 5.754e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1187, It: 0, Loss Data: 3.052e-02, Loss Eqns: 6.492e-01, Loss Aux: 5.716e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1188, It: 0, Loss Data: 2.809e-02, Loss Eqns: 6.827e-01, Loss Aux: 5.791e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1189, It: 0, Loss Data: 2.985e-02, Loss Eqns: 6.247e-01, Loss Aux: 5.877e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1190, It: 0, Loss Data: 3.010e-02, Loss Eqns: 6.494e-01, Loss Aux: 5.976e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1191, It: 0, Loss Data: 3.469e-02, Loss Eqns: 6.137e-01, Loss Aux: 5.996e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1192, It: 0, Loss Data: 2.909e-02, Loss Eqns: 6.818e-01, Loss Aux: 5.947e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1193, It: 0, Loss Data: 3.075e-02, Loss Eqns: 6.405e-01, Loss Aux: 5.938e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1194, It: 0, Loss Data: 2.968e-02, Loss Eqns: 6.650e-01, Loss Aux: 5.959e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1195, It: 0, Loss Data: 3.134e-02, Loss Eqns: 6.704e-01, Loss Aux: 6.000e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1196, It: 0, Loss Data: 3.106e-02, Loss Eqns: 6.400e-01, Loss Aux: 6.081e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1197, It: 0, Loss Data: 3.198e-02, Loss Eqns: 6.420e-01, Loss Aux: 6.144e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1198, It: 0, Loss Data: 3.092e-02, Loss Eqns: 6.484e-01, Loss Aux: 6.128e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1199, It: 0, Loss Data: 2.960e-02, Loss Eqns: 6.315e-01, Loss Aux: 6.018e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1200, It: 0, Loss Data: 3.502e-02, Loss Eqns: 6.491e-01, Loss Aux: 5.894e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1201, It: 0, Loss Data: 3.375e-02, Loss Eqns: 6.491e-01, Loss Aux: 5.810e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1202, It: 0, Loss Data: 2.984e-02, Loss Eqns: 6.860e-01, Loss Aux: 5.790e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1203, It: 0, Loss Data: 2.965e-02, Loss Eqns: 6.336e-01, Loss Aux: 5.818e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1204, It: 0, Loss Data: 3.060e-02, Loss Eqns: 6.705e-01, Loss Aux: 5.891e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1205, It: 0, Loss Data: 3.139e-02, Loss Eqns: 6.615e-01, Loss Aux: 5.949e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1206, It: 0, Loss Data: 2.563e-02, Loss Eqns: 6.373e-01, Loss Aux: 5.993e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1207, It: 0, Loss Data: 3.297e-02, Loss Eqns: 6.563e-01, Loss Aux: 6.051e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1208, It: 0, Loss Data: 3.028e-02, Loss Eqns: 6.106e-01, Loss Aux: 6.074e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1209, It: 0, Loss Data: 3.298e-02, Loss Eqns: 6.488e-01, Loss Aux: 6.114e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1210, It: 0, Loss Data: 3.314e-02, Loss Eqns: 6.403e-01, Loss Aux: 6.040e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1211, It: 0, Loss Data: 3.338e-02, Loss Eqns: 6.313e-01, Loss Aux: 5.955e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1212, It: 0, Loss Data: 2.870e-02, Loss Eqns: 6.428e-01, Loss Aux: 5.811e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1213, It: 0, Loss Data: 3.410e-02, Loss Eqns: 6.582e-01, Loss Aux: 5.774e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1214, It: 0, Loss Data: 2.906e-02, Loss Eqns: 6.479e-01, Loss Aux: 5.786e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1215, It: 0, Loss Data: 3.225e-02, Loss Eqns: 6.355e-01, Loss Aux: 5.761e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1216, It: 0, Loss Data: 2.926e-02, Loss Eqns: 6.253e-01, Loss Aux: 5.754e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1217, It: 0, Loss Data: 3.288e-02, Loss Eqns: 6.242e-01, Loss Aux: 5.794e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1218, It: 0, Loss Data: 2.851e-02, Loss Eqns: 6.765e-01, Loss Aux: 5.767e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1219, It: 0, Loss Data: 3.028e-02, Loss Eqns: 6.711e-01, Loss Aux: 5.818e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1220, It: 0, Loss Data: 3.397e-02, Loss Eqns: 6.274e-01, Loss Aux: 5.840e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1221, It: 0, Loss Data: 2.439e-02, Loss Eqns: 6.262e-01, Loss Aux: 5.879e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1222, It: 0, Loss Data: 3.193e-02, Loss Eqns: 6.384e-01, Loss Aux: 5.900e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1223, It: 0, Loss Data: 3.173e-02, Loss Eqns: 6.201e-01, Loss Aux: 5.914e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1224, It: 0, Loss Data: 3.095e-02, Loss Eqns: 6.688e-01, Loss Aux: 5.902e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1225, It: 0, Loss Data: 3.322e-02, Loss Eqns: 6.671e-01, Loss Aux: 5.898e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1226, It: 0, Loss Data: 2.888e-02, Loss Eqns: 6.527e-01, Loss Aux: 5.908e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1227, It: 0, Loss Data: 2.992e-02, Loss Eqns: 6.377e-01, Loss Aux: 5.964e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1228, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.384e-01, Loss Aux: 6.038e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1229, It: 0, Loss Data: 3.457e-02, Loss Eqns: 6.456e-01, Loss Aux: 6.068e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1230, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.294e-01, Loss Aux: 6.130e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1231, It: 0, Loss Data: 2.960e-02, Loss Eqns: 6.638e-01, Loss Aux: 6.134e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1232, It: 0, Loss Data: 3.321e-02, Loss Eqns: 6.624e-01, Loss Aux: 6.168e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1233, It: 0, Loss Data: 2.922e-02, Loss Eqns: 6.407e-01, Loss Aux: 6.135e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1234, It: 0, Loss Data: 2.924e-02, Loss Eqns: 6.337e-01, Loss Aux: 6.017e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1235, It: 0, Loss Data: 3.085e-02, Loss Eqns: 6.500e-01, Loss Aux: 5.807e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1236, It: 0, Loss Data: 2.730e-02, Loss Eqns: 6.302e-01, Loss Aux: 5.635e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1237, It: 0, Loss Data: 2.877e-02, Loss Eqns: 6.463e-01, Loss Aux: 5.580e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1238, It: 0, Loss Data: 3.351e-02, Loss Eqns: 6.461e-01, Loss Aux: 5.561e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1239, It: 0, Loss Data: 3.272e-02, Loss Eqns: 6.690e-01, Loss Aux: 5.687e-02, Time: 0.141, Learning Rate: 1.0e-04\n",
      "Epoch: 1240, It: 0, Loss Data: 3.207e-02, Loss Eqns: 5.985e-01, Loss Aux: 5.745e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1241, It: 0, Loss Data: 2.903e-02, Loss Eqns: 6.737e-01, Loss Aux: 5.820e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1242, It: 0, Loss Data: 3.270e-02, Loss Eqns: 6.566e-01, Loss Aux: 5.991e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1243, It: 0, Loss Data: 3.017e-02, Loss Eqns: 6.480e-01, Loss Aux: 6.138e-02, Time: 0.145, Learning Rate: 1.0e-04\n",
      "Epoch: 1244, It: 0, Loss Data: 3.104e-02, Loss Eqns: 6.411e-01, Loss Aux: 6.227e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1245, It: 0, Loss Data: 2.869e-02, Loss Eqns: 6.320e-01, Loss Aux: 6.291e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1246, It: 0, Loss Data: 2.947e-02, Loss Eqns: 6.061e-01, Loss Aux: 6.310e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1247, It: 0, Loss Data: 3.176e-02, Loss Eqns: 6.358e-01, Loss Aux: 6.335e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1248, It: 0, Loss Data: 3.485e-02, Loss Eqns: 6.317e-01, Loss Aux: 6.328e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1249, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.651e-01, Loss Aux: 6.295e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1250, It: 0, Loss Data: 3.559e-02, Loss Eqns: 6.562e-01, Loss Aux: 6.251e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1251, It: 0, Loss Data: 3.182e-02, Loss Eqns: 6.383e-01, Loss Aux: 6.157e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1252, It: 0, Loss Data: 3.185e-02, Loss Eqns: 6.589e-01, Loss Aux: 6.140e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1253, It: 0, Loss Data: 3.048e-02, Loss Eqns: 6.549e-01, Loss Aux: 6.066e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1254, It: 0, Loss Data: 3.390e-02, Loss Eqns: 6.561e-01, Loss Aux: 5.985e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1255, It: 0, Loss Data: 2.970e-02, Loss Eqns: 6.436e-01, Loss Aux: 5.988e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1256, It: 0, Loss Data: 2.827e-02, Loss Eqns: 6.430e-01, Loss Aux: 5.993e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1257, It: 0, Loss Data: 3.124e-02, Loss Eqns: 5.957e-01, Loss Aux: 6.061e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1258, It: 0, Loss Data: 3.056e-02, Loss Eqns: 6.496e-01, Loss Aux: 6.109e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1259, It: 0, Loss Data: 3.189e-02, Loss Eqns: 6.248e-01, Loss Aux: 6.142e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1260, It: 0, Loss Data: 2.886e-02, Loss Eqns: 6.273e-01, Loss Aux: 6.086e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1261, It: 0, Loss Data: 3.395e-02, Loss Eqns: 6.336e-01, Loss Aux: 6.015e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1262, It: 0, Loss Data: 3.122e-02, Loss Eqns: 6.388e-01, Loss Aux: 5.928e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1263, It: 0, Loss Data: 2.927e-02, Loss Eqns: 6.230e-01, Loss Aux: 5.919e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1264, It: 0, Loss Data: 3.206e-02, Loss Eqns: 6.460e-01, Loss Aux: 5.874e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1265, It: 0, Loss Data: 3.237e-02, Loss Eqns: 6.379e-01, Loss Aux: 5.915e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1266, It: 0, Loss Data: 2.791e-02, Loss Eqns: 6.619e-01, Loss Aux: 5.951e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1267, It: 0, Loss Data: 3.518e-02, Loss Eqns: 6.501e-01, Loss Aux: 6.035e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1268, It: 0, Loss Data: 3.116e-02, Loss Eqns: 6.235e-01, Loss Aux: 6.082e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1269, It: 0, Loss Data: 3.148e-02, Loss Eqns: 6.376e-01, Loss Aux: 6.115e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1270, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.272e-01, Loss Aux: 6.110e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1271, It: 0, Loss Data: 2.805e-02, Loss Eqns: 6.428e-01, Loss Aux: 6.086e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1272, It: 0, Loss Data: 2.889e-02, Loss Eqns: 6.394e-01, Loss Aux: 6.058e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1273, It: 0, Loss Data: 2.970e-02, Loss Eqns: 6.367e-01, Loss Aux: 6.064e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1274, It: 0, Loss Data: 3.220e-02, Loss Eqns: 5.912e-01, Loss Aux: 6.102e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1275, It: 0, Loss Data: 2.965e-02, Loss Eqns: 6.128e-01, Loss Aux: 6.086e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1276, It: 0, Loss Data: 2.957e-02, Loss Eqns: 6.308e-01, Loss Aux: 6.054e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1277, It: 0, Loss Data: 2.960e-02, Loss Eqns: 6.334e-01, Loss Aux: 5.995e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1278, It: 0, Loss Data: 2.777e-02, Loss Eqns: 6.363e-01, Loss Aux: 5.923e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1279, It: 0, Loss Data: 3.115e-02, Loss Eqns: 6.190e-01, Loss Aux: 5.841e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1280, It: 0, Loss Data: 3.059e-02, Loss Eqns: 6.397e-01, Loss Aux: 5.834e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1281, It: 0, Loss Data: 2.826e-02, Loss Eqns: 6.464e-01, Loss Aux: 5.829e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1282, It: 0, Loss Data: 3.186e-02, Loss Eqns: 6.721e-01, Loss Aux: 5.857e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1283, It: 0, Loss Data: 3.073e-02, Loss Eqns: 6.479e-01, Loss Aux: 5.919e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1284, It: 0, Loss Data: 2.980e-02, Loss Eqns: 6.579e-01, Loss Aux: 6.005e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1285, It: 0, Loss Data: 3.079e-02, Loss Eqns: 6.506e-01, Loss Aux: 6.036e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1286, It: 0, Loss Data: 3.368e-02, Loss Eqns: 6.346e-01, Loss Aux: 6.016e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 1287, It: 0, Loss Data: 3.383e-02, Loss Eqns: 6.198e-01, Loss Aux: 5.947e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1288, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.223e-01, Loss Aux: 5.924e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1289, It: 0, Loss Data: 3.172e-02, Loss Eqns: 6.426e-01, Loss Aux: 5.957e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1290, It: 0, Loss Data: 3.068e-02, Loss Eqns: 6.364e-01, Loss Aux: 6.025e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1291, It: 0, Loss Data: 3.141e-02, Loss Eqns: 7.013e-01, Loss Aux: 6.113e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1292, It: 0, Loss Data: 3.336e-02, Loss Eqns: 6.473e-01, Loss Aux: 6.183e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1293, It: 0, Loss Data: 2.987e-02, Loss Eqns: 6.166e-01, Loss Aux: 6.175e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1294, It: 0, Loss Data: 2.896e-02, Loss Eqns: 6.455e-01, Loss Aux: 6.072e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1295, It: 0, Loss Data: 2.758e-02, Loss Eqns: 6.289e-01, Loss Aux: 5.913e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1296, It: 0, Loss Data: 2.970e-02, Loss Eqns: 6.419e-01, Loss Aux: 5.818e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1297, It: 0, Loss Data: 3.108e-02, Loss Eqns: 6.400e-01, Loss Aux: 5.771e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1298, It: 0, Loss Data: 2.868e-02, Loss Eqns: 6.513e-01, Loss Aux: 5.801e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1299, It: 0, Loss Data: 3.561e-02, Loss Eqns: 6.212e-01, Loss Aux: 5.839e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1300, It: 0, Loss Data: 3.488e-02, Loss Eqns: 6.151e-01, Loss Aux: 6.000e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1301, It: 0, Loss Data: 3.096e-02, Loss Eqns: 6.644e-01, Loss Aux: 6.111e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1302, It: 0, Loss Data: 3.070e-02, Loss Eqns: 6.181e-01, Loss Aux: 6.194e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1303, It: 0, Loss Data: 2.709e-02, Loss Eqns: 6.453e-01, Loss Aux: 6.197e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1304, It: 0, Loss Data: 2.982e-02, Loss Eqns: 6.137e-01, Loss Aux: 6.148e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 1305, It: 0, Loss Data: 3.206e-02, Loss Eqns: 6.021e-01, Loss Aux: 6.081e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1306, It: 0, Loss Data: 3.326e-02, Loss Eqns: 6.540e-01, Loss Aux: 6.014e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1307, It: 0, Loss Data: 3.093e-02, Loss Eqns: 5.986e-01, Loss Aux: 5.948e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1308, It: 0, Loss Data: 2.698e-02, Loss Eqns: 6.170e-01, Loss Aux: 5.943e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1309, It: 0, Loss Data: 3.344e-02, Loss Eqns: 6.302e-01, Loss Aux: 5.979e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1310, It: 0, Loss Data: 3.613e-02, Loss Eqns: 6.166e-01, Loss Aux: 6.040e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1311, It: 0, Loss Data: 2.829e-02, Loss Eqns: 6.875e-01, Loss Aux: 6.133e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 1312, It: 0, Loss Data: 3.301e-02, Loss Eqns: 6.727e-01, Loss Aux: 6.166e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1313, It: 0, Loss Data: 3.152e-02, Loss Eqns: 6.319e-01, Loss Aux: 6.189e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1314, It: 0, Loss Data: 2.939e-02, Loss Eqns: 6.479e-01, Loss Aux: 6.156e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1315, It: 0, Loss Data: 3.203e-02, Loss Eqns: 6.450e-01, Loss Aux: 6.089e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 1316, It: 0, Loss Data: 3.203e-02, Loss Eqns: 6.248e-01, Loss Aux: 6.034e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1317, It: 0, Loss Data: 3.254e-02, Loss Eqns: 6.233e-01, Loss Aux: 6.036e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1318, It: 0, Loss Data: 3.115e-02, Loss Eqns: 6.307e-01, Loss Aux: 6.040e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1319, It: 0, Loss Data: 2.885e-02, Loss Eqns: 6.540e-01, Loss Aux: 6.117e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1320, It: 0, Loss Data: 3.265e-02, Loss Eqns: 6.224e-01, Loss Aux: 6.121e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1321, It: 0, Loss Data: 2.908e-02, Loss Eqns: 6.052e-01, Loss Aux: 6.065e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1322, It: 0, Loss Data: 3.704e-02, Loss Eqns: 6.497e-01, Loss Aux: 6.088e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1323, It: 0, Loss Data: 3.166e-02, Loss Eqns: 6.213e-01, Loss Aux: 6.132e-02, Time: 0.198, Learning Rate: 1.0e-04\n",
      "Epoch: 1324, It: 0, Loss Data: 2.952e-02, Loss Eqns: 6.617e-01, Loss Aux: 6.097e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1325, It: 0, Loss Data: 2.862e-02, Loss Eqns: 6.315e-01, Loss Aux: 6.083e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1326, It: 0, Loss Data: 3.312e-02, Loss Eqns: 6.002e-01, Loss Aux: 6.037e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1327, It: 0, Loss Data: 2.757e-02, Loss Eqns: 6.647e-01, Loss Aux: 5.942e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1328, It: 0, Loss Data: 3.220e-02, Loss Eqns: 6.801e-01, Loss Aux: 5.940e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1329, It: 0, Loss Data: 2.939e-02, Loss Eqns: 6.300e-01, Loss Aux: 5.936e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1330, It: 0, Loss Data: 3.459e-02, Loss Eqns: 6.389e-01, Loss Aux: 5.936e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1331, It: 0, Loss Data: 3.168e-02, Loss Eqns: 6.419e-01, Loss Aux: 5.941e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1332, It: 0, Loss Data: 2.988e-02, Loss Eqns: 6.539e-01, Loss Aux: 5.950e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1333, It: 0, Loss Data: 3.069e-02, Loss Eqns: 6.215e-01, Loss Aux: 5.994e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1334, It: 0, Loss Data: 2.970e-02, Loss Eqns: 6.473e-01, Loss Aux: 6.077e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1335, It: 0, Loss Data: 3.262e-02, Loss Eqns: 6.171e-01, Loss Aux: 6.155e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1336, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.376e-01, Loss Aux: 6.275e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1337, It: 0, Loss Data: 2.767e-02, Loss Eqns: 6.230e-01, Loss Aux: 6.299e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1338, It: 0, Loss Data: 3.136e-02, Loss Eqns: 7.021e-01, Loss Aux: 6.230e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1339, It: 0, Loss Data: 2.953e-02, Loss Eqns: 5.994e-01, Loss Aux: 6.049e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1340, It: 0, Loss Data: 3.090e-02, Loss Eqns: 6.334e-01, Loss Aux: 5.975e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1341, It: 0, Loss Data: 3.017e-02, Loss Eqns: 6.720e-01, Loss Aux: 5.963e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1342, It: 0, Loss Data: 3.241e-02, Loss Eqns: 6.247e-01, Loss Aux: 5.948e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1343, It: 0, Loss Data: 2.835e-02, Loss Eqns: 6.377e-01, Loss Aux: 5.988e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1344, It: 0, Loss Data: 3.055e-02, Loss Eqns: 6.196e-01, Loss Aux: 6.032e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1345, It: 0, Loss Data: 3.304e-02, Loss Eqns: 6.586e-01, Loss Aux: 6.125e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1346, It: 0, Loss Data: 3.070e-02, Loss Eqns: 6.220e-01, Loss Aux: 6.087e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1347, It: 0, Loss Data: 2.996e-02, Loss Eqns: 6.392e-01, Loss Aux: 6.066e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1348, It: 0, Loss Data: 3.582e-02, Loss Eqns: 6.202e-01, Loss Aux: 6.015e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1349, It: 0, Loss Data: 3.052e-02, Loss Eqns: 6.347e-01, Loss Aux: 5.979e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1350, It: 0, Loss Data: 3.196e-02, Loss Eqns: 6.328e-01, Loss Aux: 5.927e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1351, It: 0, Loss Data: 2.968e-02, Loss Eqns: 6.428e-01, Loss Aux: 5.938e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1352, It: 0, Loss Data: 3.282e-02, Loss Eqns: 6.142e-01, Loss Aux: 5.933e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 1353, It: 0, Loss Data: 3.193e-02, Loss Eqns: 6.115e-01, Loss Aux: 5.916e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 1354, It: 0, Loss Data: 3.056e-02, Loss Eqns: 6.831e-01, Loss Aux: 5.944e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1355, It: 0, Loss Data: 3.238e-02, Loss Eqns: 6.281e-01, Loss Aux: 5.952e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1356, It: 0, Loss Data: 2.655e-02, Loss Eqns: 5.972e-01, Loss Aux: 6.006e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1357, It: 0, Loss Data: 3.279e-02, Loss Eqns: 6.111e-01, Loss Aux: 6.084e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1358, It: 0, Loss Data: 2.962e-02, Loss Eqns: 6.657e-01, Loss Aux: 6.155e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1359, It: 0, Loss Data: 2.819e-02, Loss Eqns: 6.264e-01, Loss Aux: 6.202e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1360, It: 0, Loss Data: 3.177e-02, Loss Eqns: 6.244e-01, Loss Aux: 6.369e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1361, It: 0, Loss Data: 3.295e-02, Loss Eqns: 6.220e-01, Loss Aux: 6.387e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1362, It: 0, Loss Data: 3.333e-02, Loss Eqns: 6.399e-01, Loss Aux: 6.277e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1363, It: 0, Loss Data: 3.048e-02, Loss Eqns: 6.448e-01, Loss Aux: 6.142e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1364, It: 0, Loss Data: 2.819e-02, Loss Eqns: 6.604e-01, Loss Aux: 5.999e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1365, It: 0, Loss Data: 2.964e-02, Loss Eqns: 6.274e-01, Loss Aux: 5.971e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1366, It: 0, Loss Data: 2.991e-02, Loss Eqns: 6.250e-01, Loss Aux: 6.004e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1367, It: 0, Loss Data: 3.127e-02, Loss Eqns: 6.115e-01, Loss Aux: 6.115e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1368, It: 0, Loss Data: 3.013e-02, Loss Eqns: 6.350e-01, Loss Aux: 6.142e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1369, It: 0, Loss Data: 3.251e-02, Loss Eqns: 6.282e-01, Loss Aux: 6.108e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1370, It: 0, Loss Data: 2.881e-02, Loss Eqns: 6.743e-01, Loss Aux: 6.042e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1371, It: 0, Loss Data: 2.916e-02, Loss Eqns: 6.530e-01, Loss Aux: 5.968e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1372, It: 0, Loss Data: 3.000e-02, Loss Eqns: 6.268e-01, Loss Aux: 5.926e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1373, It: 0, Loss Data: 2.947e-02, Loss Eqns: 6.729e-01, Loss Aux: 6.035e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1374, It: 0, Loss Data: 3.081e-02, Loss Eqns: 6.282e-01, Loss Aux: 6.125e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 1375, It: 0, Loss Data: 2.919e-02, Loss Eqns: 6.484e-01, Loss Aux: 6.130e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1376, It: 0, Loss Data: 3.438e-02, Loss Eqns: 6.497e-01, Loss Aux: 6.089e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1377, It: 0, Loss Data: 3.417e-02, Loss Eqns: 6.397e-01, Loss Aux: 6.047e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1378, It: 0, Loss Data: 3.147e-02, Loss Eqns: 6.461e-01, Loss Aux: 6.050e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1379, It: 0, Loss Data: 3.511e-02, Loss Eqns: 6.385e-01, Loss Aux: 6.022e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1380, It: 0, Loss Data: 2.862e-02, Loss Eqns: 6.352e-01, Loss Aux: 5.998e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1381, It: 0, Loss Data: 3.176e-02, Loss Eqns: 6.291e-01, Loss Aux: 5.969e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1382, It: 0, Loss Data: 2.666e-02, Loss Eqns: 6.834e-01, Loss Aux: 6.015e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1383, It: 0, Loss Data: 3.096e-02, Loss Eqns: 6.339e-01, Loss Aux: 5.981e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1384, It: 0, Loss Data: 3.444e-02, Loss Eqns: 6.933e-01, Loss Aux: 5.894e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1385, It: 0, Loss Data: 3.401e-02, Loss Eqns: 6.841e-01, Loss Aux: 5.794e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1386, It: 0, Loss Data: 2.822e-02, Loss Eqns: 6.525e-01, Loss Aux: 5.736e-02, Time: 0.198, Learning Rate: 1.0e-04\n",
      "Epoch: 1387, It: 0, Loss Data: 3.135e-02, Loss Eqns: 6.416e-01, Loss Aux: 5.773e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1388, It: 0, Loss Data: 3.305e-02, Loss Eqns: 6.296e-01, Loss Aux: 5.890e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1389, It: 0, Loss Data: 2.845e-02, Loss Eqns: 6.388e-01, Loss Aux: 6.034e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1390, It: 0, Loss Data: 3.318e-02, Loss Eqns: 6.286e-01, Loss Aux: 6.182e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1391, It: 0, Loss Data: 3.068e-02, Loss Eqns: 6.210e-01, Loss Aux: 6.256e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1392, It: 0, Loss Data: 2.902e-02, Loss Eqns: 6.069e-01, Loss Aux: 6.220e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1393, It: 0, Loss Data: 3.426e-02, Loss Eqns: 5.999e-01, Loss Aux: 6.118e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1394, It: 0, Loss Data: 3.367e-02, Loss Eqns: 6.174e-01, Loss Aux: 6.020e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1395, It: 0, Loss Data: 3.114e-02, Loss Eqns: 6.295e-01, Loss Aux: 5.926e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1396, It: 0, Loss Data: 3.085e-02, Loss Eqns: 5.962e-01, Loss Aux: 5.835e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1397, It: 0, Loss Data: 3.250e-02, Loss Eqns: 6.394e-01, Loss Aux: 5.767e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1398, It: 0, Loss Data: 3.002e-02, Loss Eqns: 6.511e-01, Loss Aux: 5.851e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1399, It: 0, Loss Data: 3.164e-02, Loss Eqns: 6.527e-01, Loss Aux: 6.018e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1400, It: 0, Loss Data: 3.196e-02, Loss Eqns: 6.435e-01, Loss Aux: 6.125e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1401, It: 0, Loss Data: 2.869e-02, Loss Eqns: 6.431e-01, Loss Aux: 6.074e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 1402, It: 0, Loss Data: 2.811e-02, Loss Eqns: 6.431e-01, Loss Aux: 5.897e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1403, It: 0, Loss Data: 3.149e-02, Loss Eqns: 6.182e-01, Loss Aux: 5.826e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1404, It: 0, Loss Data: 3.156e-02, Loss Eqns: 6.690e-01, Loss Aux: 5.791e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1405, It: 0, Loss Data: 3.108e-02, Loss Eqns: 6.274e-01, Loss Aux: 5.842e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1406, It: 0, Loss Data: 3.103e-02, Loss Eqns: 6.356e-01, Loss Aux: 5.900e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1407, It: 0, Loss Data: 2.849e-02, Loss Eqns: 6.585e-01, Loss Aux: 5.952e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1408, It: 0, Loss Data: 3.393e-02, Loss Eqns: 6.088e-01, Loss Aux: 6.039e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1409, It: 0, Loss Data: 3.167e-02, Loss Eqns: 6.317e-01, Loss Aux: 6.094e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1410, It: 0, Loss Data: 3.080e-02, Loss Eqns: 6.532e-01, Loss Aux: 6.042e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1411, It: 0, Loss Data: 2.617e-02, Loss Eqns: 6.387e-01, Loss Aux: 5.873e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1412, It: 0, Loss Data: 3.315e-02, Loss Eqns: 6.198e-01, Loss Aux: 5.776e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1413, It: 0, Loss Data: 3.066e-02, Loss Eqns: 6.127e-01, Loss Aux: 5.759e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1414, It: 0, Loss Data: 2.970e-02, Loss Eqns: 6.381e-01, Loss Aux: 5.840e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1415, It: 0, Loss Data: 2.802e-02, Loss Eqns: 6.589e-01, Loss Aux: 5.999e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1416, It: 0, Loss Data: 2.941e-02, Loss Eqns: 6.167e-01, Loss Aux: 6.091e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1417, It: 0, Loss Data: 3.109e-02, Loss Eqns: 6.548e-01, Loss Aux: 6.177e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1418, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.002e-01, Loss Aux: 6.243e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1419, It: 0, Loss Data: 3.177e-02, Loss Eqns: 6.375e-01, Loss Aux: 6.247e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1420, It: 0, Loss Data: 2.767e-02, Loss Eqns: 6.503e-01, Loss Aux: 6.218e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1421, It: 0, Loss Data: 3.255e-02, Loss Eqns: 6.436e-01, Loss Aux: 6.177e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1422, It: 0, Loss Data: 3.738e-02, Loss Eqns: 6.266e-01, Loss Aux: 6.096e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1423, It: 0, Loss Data: 2.909e-02, Loss Eqns: 6.079e-01, Loss Aux: 6.004e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1424, It: 0, Loss Data: 3.144e-02, Loss Eqns: 6.467e-01, Loss Aux: 5.966e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1425, It: 0, Loss Data: 3.087e-02, Loss Eqns: 6.310e-01, Loss Aux: 6.026e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1426, It: 0, Loss Data: 3.090e-02, Loss Eqns: 6.187e-01, Loss Aux: 6.173e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1427, It: 0, Loss Data: 2.852e-02, Loss Eqns: 6.194e-01, Loss Aux: 6.284e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1428, It: 0, Loss Data: 3.468e-02, Loss Eqns: 6.029e-01, Loss Aux: 6.396e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1429, It: 0, Loss Data: 3.393e-02, Loss Eqns: 6.548e-01, Loss Aux: 6.401e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1430, It: 0, Loss Data: 3.462e-02, Loss Eqns: 6.423e-01, Loss Aux: 6.356e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1431, It: 0, Loss Data: 3.112e-02, Loss Eqns: 6.459e-01, Loss Aux: 6.316e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1432, It: 0, Loss Data: 2.929e-02, Loss Eqns: 6.240e-01, Loss Aux: 6.257e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1433, It: 0, Loss Data: 3.049e-02, Loss Eqns: 6.227e-01, Loss Aux: 6.167e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1434, It: 0, Loss Data: 3.362e-02, Loss Eqns: 6.250e-01, Loss Aux: 6.082e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1435, It: 0, Loss Data: 2.779e-02, Loss Eqns: 5.963e-01, Loss Aux: 6.065e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1436, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.229e-01, Loss Aux: 6.063e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1437, It: 0, Loss Data: 2.726e-02, Loss Eqns: 6.447e-01, Loss Aux: 6.064e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1438, It: 0, Loss Data: 2.880e-02, Loss Eqns: 6.640e-01, Loss Aux: 6.034e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1439, It: 0, Loss Data: 2.578e-02, Loss Eqns: 6.634e-01, Loss Aux: 5.977e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1440, It: 0, Loss Data: 2.969e-02, Loss Eqns: 6.050e-01, Loss Aux: 5.941e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1441, It: 0, Loss Data: 3.276e-02, Loss Eqns: 6.330e-01, Loss Aux: 5.925e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 1442, It: 0, Loss Data: 3.163e-02, Loss Eqns: 6.288e-01, Loss Aux: 5.964e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1443, It: 0, Loss Data: 3.028e-02, Loss Eqns: 6.513e-01, Loss Aux: 6.056e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 1444, It: 0, Loss Data: 3.312e-02, Loss Eqns: 6.164e-01, Loss Aux: 6.219e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1445, It: 0, Loss Data: 3.220e-02, Loss Eqns: 6.171e-01, Loss Aux: 6.250e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 1446, It: 0, Loss Data: 3.206e-02, Loss Eqns: 6.039e-01, Loss Aux: 6.127e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1447, It: 0, Loss Data: 2.701e-02, Loss Eqns: 6.399e-01, Loss Aux: 6.021e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1448, It: 0, Loss Data: 3.224e-02, Loss Eqns: 6.531e-01, Loss Aux: 5.916e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1449, It: 0, Loss Data: 2.899e-02, Loss Eqns: 6.658e-01, Loss Aux: 5.799e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1450, It: 0, Loss Data: 3.458e-02, Loss Eqns: 5.890e-01, Loss Aux: 5.725e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1451, It: 0, Loss Data: 3.462e-02, Loss Eqns: 6.167e-01, Loss Aux: 5.702e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1452, It: 0, Loss Data: 2.936e-02, Loss Eqns: 6.452e-01, Loss Aux: 5.766e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1453, It: 0, Loss Data: 3.599e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.984e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1454, It: 0, Loss Data: 2.878e-02, Loss Eqns: 6.722e-01, Loss Aux: 6.174e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1455, It: 0, Loss Data: 2.818e-02, Loss Eqns: 6.610e-01, Loss Aux: 6.284e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1456, It: 0, Loss Data: 2.685e-02, Loss Eqns: 6.469e-01, Loss Aux: 6.289e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1457, It: 0, Loss Data: 2.912e-02, Loss Eqns: 6.626e-01, Loss Aux: 6.171e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1458, It: 0, Loss Data: 3.200e-02, Loss Eqns: 6.343e-01, Loss Aux: 5.990e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1459, It: 0, Loss Data: 3.231e-02, Loss Eqns: 6.501e-01, Loss Aux: 5.861e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 1460, It: 0, Loss Data: 3.302e-02, Loss Eqns: 6.024e-01, Loss Aux: 5.825e-02, Time: 0.194, Learning Rate: 1.0e-04\n",
      "Epoch: 1461, It: 0, Loss Data: 3.131e-02, Loss Eqns: 6.260e-01, Loss Aux: 5.878e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1462, It: 0, Loss Data: 3.207e-02, Loss Eqns: 6.291e-01, Loss Aux: 5.972e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1463, It: 0, Loss Data: 3.339e-02, Loss Eqns: 6.264e-01, Loss Aux: 5.982e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1464, It: 0, Loss Data: 2.775e-02, Loss Eqns: 6.361e-01, Loss Aux: 5.967e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1465, It: 0, Loss Data: 2.962e-02, Loss Eqns: 6.404e-01, Loss Aux: 5.984e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1466, It: 0, Loss Data: 3.311e-02, Loss Eqns: 6.195e-01, Loss Aux: 5.958e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1467, It: 0, Loss Data: 3.007e-02, Loss Eqns: 6.224e-01, Loss Aux: 5.940e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1468, It: 0, Loss Data: 2.726e-02, Loss Eqns: 6.296e-01, Loss Aux: 5.939e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1469, It: 0, Loss Data: 3.003e-02, Loss Eqns: 6.298e-01, Loss Aux: 6.015e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1470, It: 0, Loss Data: 3.049e-02, Loss Eqns: 6.343e-01, Loss Aux: 6.075e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1471, It: 0, Loss Data: 3.414e-02, Loss Eqns: 6.250e-01, Loss Aux: 6.123e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1472, It: 0, Loss Data: 3.222e-02, Loss Eqns: 6.528e-01, Loss Aux: 6.097e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1473, It: 0, Loss Data: 3.088e-02, Loss Eqns: 6.513e-01, Loss Aux: 5.998e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 1474, It: 0, Loss Data: 3.020e-02, Loss Eqns: 6.129e-01, Loss Aux: 5.935e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1475, It: 0, Loss Data: 2.726e-02, Loss Eqns: 6.546e-01, Loss Aux: 5.957e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1476, It: 0, Loss Data: 2.850e-02, Loss Eqns: 6.350e-01, Loss Aux: 6.044e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1477, It: 0, Loss Data: 2.670e-02, Loss Eqns: 5.892e-01, Loss Aux: 6.214e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1478, It: 0, Loss Data: 2.837e-02, Loss Eqns: 6.145e-01, Loss Aux: 6.369e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1479, It: 0, Loss Data: 2.799e-02, Loss Eqns: 5.804e-01, Loss Aux: 6.462e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1480, It: 0, Loss Data: 3.122e-02, Loss Eqns: 6.425e-01, Loss Aux: 6.485e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1481, It: 0, Loss Data: 3.378e-02, Loss Eqns: 6.216e-01, Loss Aux: 6.443e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1482, It: 0, Loss Data: 3.076e-02, Loss Eqns: 6.155e-01, Loss Aux: 6.323e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1483, It: 0, Loss Data: 3.078e-02, Loss Eqns: 6.303e-01, Loss Aux: 6.158e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1484, It: 0, Loss Data: 2.875e-02, Loss Eqns: 6.223e-01, Loss Aux: 5.977e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1485, It: 0, Loss Data: 3.339e-02, Loss Eqns: 6.106e-01, Loss Aux: 5.872e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1486, It: 0, Loss Data: 2.838e-02, Loss Eqns: 6.113e-01, Loss Aux: 5.898e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1487, It: 0, Loss Data: 2.872e-02, Loss Eqns: 6.351e-01, Loss Aux: 5.962e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1488, It: 0, Loss Data: 2.917e-02, Loss Eqns: 6.639e-01, Loss Aux: 6.062e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1489, It: 0, Loss Data: 2.964e-02, Loss Eqns: 6.164e-01, Loss Aux: 6.186e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1490, It: 0, Loss Data: 3.024e-02, Loss Eqns: 6.166e-01, Loss Aux: 6.304e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1491, It: 0, Loss Data: 2.885e-02, Loss Eqns: 6.606e-01, Loss Aux: 6.304e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1492, It: 0, Loss Data: 3.067e-02, Loss Eqns: 6.178e-01, Loss Aux: 6.237e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1493, It: 0, Loss Data: 2.941e-02, Loss Eqns: 6.269e-01, Loss Aux: 6.111e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1494, It: 0, Loss Data: 3.308e-02, Loss Eqns: 6.165e-01, Loss Aux: 6.006e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1495, It: 0, Loss Data: 2.607e-02, Loss Eqns: 6.221e-01, Loss Aux: 5.936e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1496, It: 0, Loss Data: 3.098e-02, Loss Eqns: 6.631e-01, Loss Aux: 5.915e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1497, It: 0, Loss Data: 2.920e-02, Loss Eqns: 6.640e-01, Loss Aux: 5.992e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1498, It: 0, Loss Data: 3.463e-02, Loss Eqns: 6.450e-01, Loss Aux: 6.141e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1499, It: 0, Loss Data: 3.482e-02, Loss Eqns: 6.558e-01, Loss Aux: 6.291e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1500, It: 0, Loss Data: 3.092e-02, Loss Eqns: 6.232e-01, Loss Aux: 6.278e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1501, It: 0, Loss Data: 2.858e-02, Loss Eqns: 6.259e-01, Loss Aux: 6.236e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1502, It: 0, Loss Data: 2.990e-02, Loss Eqns: 6.302e-01, Loss Aux: 6.183e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1503, It: 0, Loss Data: 2.820e-02, Loss Eqns: 6.165e-01, Loss Aux: 6.084e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1504, It: 0, Loss Data: 3.180e-02, Loss Eqns: 6.331e-01, Loss Aux: 6.076e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1505, It: 0, Loss Data: 3.124e-02, Loss Eqns: 6.444e-01, Loss Aux: 6.125e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1506, It: 0, Loss Data: 2.953e-02, Loss Eqns: 6.322e-01, Loss Aux: 6.203e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1507, It: 0, Loss Data: 3.169e-02, Loss Eqns: 6.286e-01, Loss Aux: 6.258e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1508, It: 0, Loss Data: 3.428e-02, Loss Eqns: 6.169e-01, Loss Aux: 6.313e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1509, It: 0, Loss Data: 2.522e-02, Loss Eqns: 6.372e-01, Loss Aux: 6.259e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1510, It: 0, Loss Data: 3.427e-02, Loss Eqns: 6.432e-01, Loss Aux: 6.149e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1511, It: 0, Loss Data: 2.919e-02, Loss Eqns: 6.588e-01, Loss Aux: 6.028e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1512, It: 0, Loss Data: 3.110e-02, Loss Eqns: 6.204e-01, Loss Aux: 6.061e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1513, It: 0, Loss Data: 2.925e-02, Loss Eqns: 6.129e-01, Loss Aux: 6.089e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1514, It: 0, Loss Data: 2.821e-02, Loss Eqns: 6.026e-01, Loss Aux: 6.122e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1515, It: 0, Loss Data: 3.134e-02, Loss Eqns: 6.411e-01, Loss Aux: 6.065e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1516, It: 0, Loss Data: 3.173e-02, Loss Eqns: 6.238e-01, Loss Aux: 5.977e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1517, It: 0, Loss Data: 2.927e-02, Loss Eqns: 6.399e-01, Loss Aux: 5.889e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1518, It: 0, Loss Data: 3.371e-02, Loss Eqns: 6.271e-01, Loss Aux: 5.914e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1519, It: 0, Loss Data: 3.070e-02, Loss Eqns: 6.440e-01, Loss Aux: 6.062e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1520, It: 0, Loss Data: 3.114e-02, Loss Eqns: 6.380e-01, Loss Aux: 6.201e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1521, It: 0, Loss Data: 3.013e-02, Loss Eqns: 6.444e-01, Loss Aux: 6.249e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1522, It: 0, Loss Data: 3.084e-02, Loss Eqns: 6.186e-01, Loss Aux: 6.191e-02, Time: 0.196, Learning Rate: 1.0e-04\n",
      "Epoch: 1523, It: 0, Loss Data: 3.144e-02, Loss Eqns: 6.427e-01, Loss Aux: 6.056e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1524, It: 0, Loss Data: 3.429e-02, Loss Eqns: 6.540e-01, Loss Aux: 5.973e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1525, It: 0, Loss Data: 2.632e-02, Loss Eqns: 6.643e-01, Loss Aux: 5.943e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1526, It: 0, Loss Data: 3.120e-02, Loss Eqns: 6.094e-01, Loss Aux: 5.947e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1527, It: 0, Loss Data: 2.899e-02, Loss Eqns: 5.960e-01, Loss Aux: 6.025e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1528, It: 0, Loss Data: 3.346e-02, Loss Eqns: 6.739e-01, Loss Aux: 6.111e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1529, It: 0, Loss Data: 2.939e-02, Loss Eqns: 6.258e-01, Loss Aux: 6.143e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1530, It: 0, Loss Data: 3.149e-02, Loss Eqns: 6.182e-01, Loss Aux: 6.194e-02, Time: 0.192, Learning Rate: 1.0e-04\n",
      "Epoch: 1531, It: 0, Loss Data: 2.954e-02, Loss Eqns: 6.363e-01, Loss Aux: 6.160e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1532, It: 0, Loss Data: 3.132e-02, Loss Eqns: 6.134e-01, Loss Aux: 6.080e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1533, It: 0, Loss Data: 3.104e-02, Loss Eqns: 6.582e-01, Loss Aux: 6.033e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1534, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.505e-01, Loss Aux: 6.076e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1535, It: 0, Loss Data: 2.939e-02, Loss Eqns: 5.933e-01, Loss Aux: 6.116e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1536, It: 0, Loss Data: 2.954e-02, Loss Eqns: 6.314e-01, Loss Aux: 6.073e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1537, It: 0, Loss Data: 3.317e-02, Loss Eqns: 6.185e-01, Loss Aux: 5.977e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1538, It: 0, Loss Data: 3.084e-02, Loss Eqns: 6.116e-01, Loss Aux: 5.849e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1539, It: 0, Loss Data: 3.061e-02, Loss Eqns: 6.475e-01, Loss Aux: 5.800e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1540, It: 0, Loss Data: 2.827e-02, Loss Eqns: 6.625e-01, Loss Aux: 5.832e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1541, It: 0, Loss Data: 3.188e-02, Loss Eqns: 6.089e-01, Loss Aux: 5.976e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1542, It: 0, Loss Data: 3.050e-02, Loss Eqns: 6.444e-01, Loss Aux: 6.139e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1543, It: 0, Loss Data: 2.931e-02, Loss Eqns: 6.413e-01, Loss Aux: 6.342e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1544, It: 0, Loss Data: 2.757e-02, Loss Eqns: 6.192e-01, Loss Aux: 6.524e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1545, It: 0, Loss Data: 2.927e-02, Loss Eqns: 5.798e-01, Loss Aux: 6.555e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1546, It: 0, Loss Data: 3.170e-02, Loss Eqns: 5.949e-01, Loss Aux: 6.456e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1547, It: 0, Loss Data: 3.104e-02, Loss Eqns: 6.303e-01, Loss Aux: 6.395e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1548, It: 0, Loss Data: 3.439e-02, Loss Eqns: 6.271e-01, Loss Aux: 6.375e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1549, It: 0, Loss Data: 3.178e-02, Loss Eqns: 6.213e-01, Loss Aux: 6.436e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1550, It: 0, Loss Data: 3.001e-02, Loss Eqns: 6.038e-01, Loss Aux: 6.520e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1551, It: 0, Loss Data: 2.889e-02, Loss Eqns: 6.058e-01, Loss Aux: 6.538e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1552, It: 0, Loss Data: 2.625e-02, Loss Eqns: 6.102e-01, Loss Aux: 6.454e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1553, It: 0, Loss Data: 2.921e-02, Loss Eqns: 6.451e-01, Loss Aux: 6.294e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1554, It: 0, Loss Data: 2.968e-02, Loss Eqns: 6.339e-01, Loss Aux: 6.170e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1555, It: 0, Loss Data: 2.777e-02, Loss Eqns: 6.296e-01, Loss Aux: 6.113e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1556, It: 0, Loss Data: 3.101e-02, Loss Eqns: 6.292e-01, Loss Aux: 6.139e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1557, It: 0, Loss Data: 3.143e-02, Loss Eqns: 6.464e-01, Loss Aux: 6.181e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1558, It: 0, Loss Data: 2.785e-02, Loss Eqns: 6.043e-01, Loss Aux: 6.251e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 1559, It: 0, Loss Data: 3.108e-02, Loss Eqns: 6.240e-01, Loss Aux: 6.391e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1560, It: 0, Loss Data: 2.957e-02, Loss Eqns: 6.019e-01, Loss Aux: 6.510e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1561, It: 0, Loss Data: 2.884e-02, Loss Eqns: 6.174e-01, Loss Aux: 6.479e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1562, It: 0, Loss Data: 3.157e-02, Loss Eqns: 6.273e-01, Loss Aux: 6.423e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1563, It: 0, Loss Data: 3.179e-02, Loss Eqns: 6.074e-01, Loss Aux: 6.294e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1564, It: 0, Loss Data: 2.664e-02, Loss Eqns: 6.349e-01, Loss Aux: 6.192e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1565, It: 0, Loss Data: 3.389e-02, Loss Eqns: 6.150e-01, Loss Aux: 6.132e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1566, It: 0, Loss Data: 3.075e-02, Loss Eqns: 6.117e-01, Loss Aux: 6.126e-02, Time: 0.148, Learning Rate: 1.0e-04\n",
      "Epoch: 1567, It: 0, Loss Data: 2.628e-02, Loss Eqns: 6.465e-01, Loss Aux: 6.045e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1568, It: 0, Loss Data: 2.718e-02, Loss Eqns: 6.566e-01, Loss Aux: 5.990e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1569, It: 0, Loss Data: 2.785e-02, Loss Eqns: 5.900e-01, Loss Aux: 5.991e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1570, It: 0, Loss Data: 2.974e-02, Loss Eqns: 6.568e-01, Loss Aux: 6.003e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1571, It: 0, Loss Data: 3.025e-02, Loss Eqns: 6.237e-01, Loss Aux: 5.981e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1572, It: 0, Loss Data: 2.836e-02, Loss Eqns: 6.335e-01, Loss Aux: 5.970e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1573, It: 0, Loss Data: 3.123e-02, Loss Eqns: 6.432e-01, Loss Aux: 6.026e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1574, It: 0, Loss Data: 2.514e-02, Loss Eqns: 6.209e-01, Loss Aux: 6.071e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1575, It: 0, Loss Data: 2.942e-02, Loss Eqns: 5.777e-01, Loss Aux: 6.092e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1576, It: 0, Loss Data: 3.211e-02, Loss Eqns: 6.242e-01, Loss Aux: 6.138e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1577, It: 0, Loss Data: 3.202e-02, Loss Eqns: 5.858e-01, Loss Aux: 6.156e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1578, It: 0, Loss Data: 3.176e-02, Loss Eqns: 6.235e-01, Loss Aux: 6.165e-02, Time: 0.198, Learning Rate: 1.0e-04\n",
      "Epoch: 1579, It: 0, Loss Data: 2.878e-02, Loss Eqns: 6.233e-01, Loss Aux: 6.138e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1580, It: 0, Loss Data: 3.589e-02, Loss Eqns: 6.003e-01, Loss Aux: 6.129e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1581, It: 0, Loss Data: 2.900e-02, Loss Eqns: 6.554e-01, Loss Aux: 6.152e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1582, It: 0, Loss Data: 3.016e-02, Loss Eqns: 6.165e-01, Loss Aux: 6.130e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1583, It: 0, Loss Data: 2.784e-02, Loss Eqns: 5.952e-01, Loss Aux: 6.100e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1584, It: 0, Loss Data: 3.141e-02, Loss Eqns: 6.547e-01, Loss Aux: 6.082e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1585, It: 0, Loss Data: 3.067e-02, Loss Eqns: 6.066e-01, Loss Aux: 6.043e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1586, It: 0, Loss Data: 2.825e-02, Loss Eqns: 6.324e-01, Loss Aux: 6.097e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1587, It: 0, Loss Data: 2.931e-02, Loss Eqns: 5.893e-01, Loss Aux: 6.177e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1588, It: 0, Loss Data: 2.756e-02, Loss Eqns: 6.130e-01, Loss Aux: 6.282e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1589, It: 0, Loss Data: 3.081e-02, Loss Eqns: 5.998e-01, Loss Aux: 6.320e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1590, It: 0, Loss Data: 2.925e-02, Loss Eqns: 6.177e-01, Loss Aux: 6.332e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1591, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.259e-01, Loss Aux: 6.346e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1592, It: 0, Loss Data: 2.812e-02, Loss Eqns: 5.963e-01, Loss Aux: 6.349e-02, Time: 0.191, Learning Rate: 1.0e-04\n",
      "Epoch: 1593, It: 0, Loss Data: 2.842e-02, Loss Eqns: 6.380e-01, Loss Aux: 6.252e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1594, It: 0, Loss Data: 3.101e-02, Loss Eqns: 6.180e-01, Loss Aux: 6.135e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1595, It: 0, Loss Data: 2.820e-02, Loss Eqns: 6.142e-01, Loss Aux: 6.011e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1596, It: 0, Loss Data: 2.938e-02, Loss Eqns: 5.956e-01, Loss Aux: 5.940e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1597, It: 0, Loss Data: 3.039e-02, Loss Eqns: 5.958e-01, Loss Aux: 5.937e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1598, It: 0, Loss Data: 3.154e-02, Loss Eqns: 6.134e-01, Loss Aux: 5.954e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1599, It: 0, Loss Data: 3.040e-02, Loss Eqns: 6.631e-01, Loss Aux: 6.068e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1600, It: 0, Loss Data: 3.204e-02, Loss Eqns: 6.316e-01, Loss Aux: 6.213e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1601, It: 0, Loss Data: 2.945e-02, Loss Eqns: 6.071e-01, Loss Aux: 6.355e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1602, It: 0, Loss Data: 3.048e-02, Loss Eqns: 6.024e-01, Loss Aux: 6.410e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1603, It: 0, Loss Data: 3.199e-02, Loss Eqns: 6.183e-01, Loss Aux: 6.366e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1604, It: 0, Loss Data: 3.181e-02, Loss Eqns: 6.302e-01, Loss Aux: 6.299e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1605, It: 0, Loss Data: 2.967e-02, Loss Eqns: 6.045e-01, Loss Aux: 6.211e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1606, It: 0, Loss Data: 3.004e-02, Loss Eqns: 5.925e-01, Loss Aux: 6.099e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1607, It: 0, Loss Data: 2.987e-02, Loss Eqns: 6.799e-01, Loss Aux: 6.044e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1608, It: 0, Loss Data: 2.786e-02, Loss Eqns: 6.089e-01, Loss Aux: 6.004e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1609, It: 0, Loss Data: 2.692e-02, Loss Eqns: 6.295e-01, Loss Aux: 5.985e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1610, It: 0, Loss Data: 3.201e-02, Loss Eqns: 5.853e-01, Loss Aux: 6.019e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1611, It: 0, Loss Data: 2.954e-02, Loss Eqns: 6.326e-01, Loss Aux: 6.116e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1612, It: 0, Loss Data: 2.596e-02, Loss Eqns: 6.154e-01, Loss Aux: 6.176e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1613, It: 0, Loss Data: 2.611e-02, Loss Eqns: 6.201e-01, Loss Aux: 6.163e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1614, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.157e-01, Loss Aux: 6.118e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1615, It: 0, Loss Data: 2.835e-02, Loss Eqns: 6.248e-01, Loss Aux: 6.154e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1616, It: 0, Loss Data: 3.150e-02, Loss Eqns: 6.144e-01, Loss Aux: 6.217e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1617, It: 0, Loss Data: 2.964e-02, Loss Eqns: 6.157e-01, Loss Aux: 6.266e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1618, It: 0, Loss Data: 2.987e-02, Loss Eqns: 5.773e-01, Loss Aux: 6.333e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1619, It: 0, Loss Data: 3.060e-02, Loss Eqns: 6.325e-01, Loss Aux: 6.328e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1620, It: 0, Loss Data: 2.814e-02, Loss Eqns: 6.135e-01, Loss Aux: 6.273e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1621, It: 0, Loss Data: 3.101e-02, Loss Eqns: 5.895e-01, Loss Aux: 6.156e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1622, It: 0, Loss Data: 2.892e-02, Loss Eqns: 6.128e-01, Loss Aux: 6.034e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1623, It: 0, Loss Data: 3.180e-02, Loss Eqns: 6.169e-01, Loss Aux: 5.939e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1624, It: 0, Loss Data: 3.035e-02, Loss Eqns: 6.226e-01, Loss Aux: 5.857e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1625, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.472e-01, Loss Aux: 5.791e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1626, It: 0, Loss Data: 2.761e-02, Loss Eqns: 6.319e-01, Loss Aux: 5.855e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1627, It: 0, Loss Data: 3.073e-02, Loss Eqns: 6.287e-01, Loss Aux: 6.104e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1628, It: 0, Loss Data: 3.030e-02, Loss Eqns: 6.013e-01, Loss Aux: 6.364e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1629, It: 0, Loss Data: 2.904e-02, Loss Eqns: 6.301e-01, Loss Aux: 6.534e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1630, It: 0, Loss Data: 3.082e-02, Loss Eqns: 6.103e-01, Loss Aux: 6.580e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1631, It: 0, Loss Data: 3.312e-02, Loss Eqns: 6.509e-01, Loss Aux: 6.560e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1632, It: 0, Loss Data: 2.919e-02, Loss Eqns: 5.995e-01, Loss Aux: 6.378e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1633, It: 0, Loss Data: 3.006e-02, Loss Eqns: 5.805e-01, Loss Aux: 6.157e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1634, It: 0, Loss Data: 2.973e-02, Loss Eqns: 6.041e-01, Loss Aux: 5.993e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1635, It: 0, Loss Data: 3.029e-02, Loss Eqns: 6.285e-01, Loss Aux: 5.908e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1636, It: 0, Loss Data: 2.988e-02, Loss Eqns: 6.226e-01, Loss Aux: 5.893e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1637, It: 0, Loss Data: 3.130e-02, Loss Eqns: 6.067e-01, Loss Aux: 5.937e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1638, It: 0, Loss Data: 2.938e-02, Loss Eqns: 6.301e-01, Loss Aux: 5.986e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1639, It: 0, Loss Data: 3.194e-02, Loss Eqns: 6.060e-01, Loss Aux: 6.119e-02, Time: 0.193, Learning Rate: 1.0e-04\n",
      "Epoch: 1640, It: 0, Loss Data: 3.118e-02, Loss Eqns: 5.956e-01, Loss Aux: 6.231e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1641, It: 0, Loss Data: 2.889e-02, Loss Eqns: 6.084e-01, Loss Aux: 6.361e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1642, It: 0, Loss Data: 3.078e-02, Loss Eqns: 6.381e-01, Loss Aux: 6.406e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1643, It: 0, Loss Data: 3.115e-02, Loss Eqns: 5.969e-01, Loss Aux: 6.396e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1644, It: 0, Loss Data: 2.951e-02, Loss Eqns: 6.338e-01, Loss Aux: 6.297e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1645, It: 0, Loss Data: 3.014e-02, Loss Eqns: 5.935e-01, Loss Aux: 6.205e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1646, It: 0, Loss Data: 3.048e-02, Loss Eqns: 6.418e-01, Loss Aux: 6.144e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1647, It: 0, Loss Data: 3.202e-02, Loss Eqns: 6.170e-01, Loss Aux: 6.164e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1648, It: 0, Loss Data: 2.851e-02, Loss Eqns: 6.272e-01, Loss Aux: 6.147e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1649, It: 0, Loss Data: 3.062e-02, Loss Eqns: 6.149e-01, Loss Aux: 6.195e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1650, It: 0, Loss Data: 3.354e-02, Loss Eqns: 6.294e-01, Loss Aux: 6.238e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1651, It: 0, Loss Data: 3.524e-02, Loss Eqns: 6.092e-01, Loss Aux: 6.214e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1652, It: 0, Loss Data: 3.320e-02, Loss Eqns: 6.231e-01, Loss Aux: 6.145e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1653, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.111e-01, Loss Aux: 6.079e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1654, It: 0, Loss Data: 2.828e-02, Loss Eqns: 6.258e-01, Loss Aux: 6.072e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1655, It: 0, Loss Data: 3.281e-02, Loss Eqns: 6.288e-01, Loss Aux: 6.164e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1656, It: 0, Loss Data: 3.109e-02, Loss Eqns: 6.236e-01, Loss Aux: 6.372e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1657, It: 0, Loss Data: 3.142e-02, Loss Eqns: 6.356e-01, Loss Aux: 6.656e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1658, It: 0, Loss Data: 3.279e-02, Loss Eqns: 5.918e-01, Loss Aux: 6.871e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1659, It: 0, Loss Data: 2.925e-02, Loss Eqns: 6.077e-01, Loss Aux: 6.886e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1660, It: 0, Loss Data: 2.938e-02, Loss Eqns: 6.090e-01, Loss Aux: 6.668e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1661, It: 0, Loss Data: 2.991e-02, Loss Eqns: 6.285e-01, Loss Aux: 6.287e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1662, It: 0, Loss Data: 2.840e-02, Loss Eqns: 6.195e-01, Loss Aux: 6.039e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1663, It: 0, Loss Data: 2.914e-02, Loss Eqns: 5.942e-01, Loss Aux: 5.927e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1664, It: 0, Loss Data: 3.053e-02, Loss Eqns: 5.709e-01, Loss Aux: 5.947e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1665, It: 0, Loss Data: 2.953e-02, Loss Eqns: 6.335e-01, Loss Aux: 6.048e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1666, It: 0, Loss Data: 3.105e-02, Loss Eqns: 5.946e-01, Loss Aux: 6.196e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1667, It: 0, Loss Data: 3.420e-02, Loss Eqns: 6.051e-01, Loss Aux: 6.401e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1668, It: 0, Loss Data: 3.081e-02, Loss Eqns: 5.849e-01, Loss Aux: 6.515e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1669, It: 0, Loss Data: 2.890e-02, Loss Eqns: 6.129e-01, Loss Aux: 6.438e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1670, It: 0, Loss Data: 2.954e-02, Loss Eqns: 6.246e-01, Loss Aux: 6.235e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1671, It: 0, Loss Data: 2.701e-02, Loss Eqns: 6.254e-01, Loss Aux: 5.977e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1672, It: 0, Loss Data: 2.904e-02, Loss Eqns: 6.604e-01, Loss Aux: 5.850e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1673, It: 0, Loss Data: 3.653e-02, Loss Eqns: 6.140e-01, Loss Aux: 5.830e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1674, It: 0, Loss Data: 2.733e-02, Loss Eqns: 6.189e-01, Loss Aux: 5.918e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1675, It: 0, Loss Data: 3.079e-02, Loss Eqns: 6.301e-01, Loss Aux: 6.103e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1676, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.009e-01, Loss Aux: 6.378e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1677, It: 0, Loss Data: 3.354e-02, Loss Eqns: 6.375e-01, Loss Aux: 6.559e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1678, It: 0, Loss Data: 3.330e-02, Loss Eqns: 6.087e-01, Loss Aux: 6.647e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1679, It: 0, Loss Data: 3.081e-02, Loss Eqns: 5.837e-01, Loss Aux: 6.597e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1680, It: 0, Loss Data: 2.620e-02, Loss Eqns: 5.692e-01, Loss Aux: 6.408e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1681, It: 0, Loss Data: 3.277e-02, Loss Eqns: 5.859e-01, Loss Aux: 6.187e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1682, It: 0, Loss Data: 3.333e-02, Loss Eqns: 5.983e-01, Loss Aux: 6.056e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1683, It: 0, Loss Data: 2.939e-02, Loss Eqns: 6.231e-01, Loss Aux: 6.037e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1684, It: 0, Loss Data: 2.862e-02, Loss Eqns: 6.081e-01, Loss Aux: 6.070e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1685, It: 0, Loss Data: 3.292e-02, Loss Eqns: 5.743e-01, Loss Aux: 6.190e-02, Time: 0.146, Learning Rate: 1.0e-04\n",
      "Epoch: 1686, It: 0, Loss Data: 2.883e-02, Loss Eqns: 6.299e-01, Loss Aux: 6.330e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1687, It: 0, Loss Data: 3.306e-02, Loss Eqns: 5.585e-01, Loss Aux: 6.481e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1688, It: 0, Loss Data: 3.190e-02, Loss Eqns: 6.507e-01, Loss Aux: 6.509e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1689, It: 0, Loss Data: 2.586e-02, Loss Eqns: 6.093e-01, Loss Aux: 6.330e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1690, It: 0, Loss Data: 2.956e-02, Loss Eqns: 5.599e-01, Loss Aux: 6.164e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1691, It: 0, Loss Data: 2.994e-02, Loss Eqns: 6.069e-01, Loss Aux: 6.092e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1692, It: 0, Loss Data: 2.896e-02, Loss Eqns: 6.059e-01, Loss Aux: 6.108e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1693, It: 0, Loss Data: 3.090e-02, Loss Eqns: 6.106e-01, Loss Aux: 6.155e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1694, It: 0, Loss Data: 3.114e-02, Loss Eqns: 6.107e-01, Loss Aux: 6.176e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1695, It: 0, Loss Data: 3.353e-02, Loss Eqns: 6.010e-01, Loss Aux: 6.262e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1696, It: 0, Loss Data: 2.615e-02, Loss Eqns: 6.078e-01, Loss Aux: 6.317e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1697, It: 0, Loss Data: 2.632e-02, Loss Eqns: 6.176e-01, Loss Aux: 6.330e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1698, It: 0, Loss Data: 3.118e-02, Loss Eqns: 6.753e-01, Loss Aux: 6.395e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1699, It: 0, Loss Data: 2.650e-02, Loss Eqns: 5.924e-01, Loss Aux: 6.282e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1700, It: 0, Loss Data: 2.755e-02, Loss Eqns: 6.086e-01, Loss Aux: 6.237e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1701, It: 0, Loss Data: 2.681e-02, Loss Eqns: 6.612e-01, Loss Aux: 6.181e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1702, It: 0, Loss Data: 2.981e-02, Loss Eqns: 6.193e-01, Loss Aux: 6.174e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1703, It: 0, Loss Data: 3.212e-02, Loss Eqns: 6.234e-01, Loss Aux: 6.266e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1704, It: 0, Loss Data: 2.598e-02, Loss Eqns: 5.990e-01, Loss Aux: 6.303e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1705, It: 0, Loss Data: 3.195e-02, Loss Eqns: 6.170e-01, Loss Aux: 6.255e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1706, It: 0, Loss Data: 3.177e-02, Loss Eqns: 6.387e-01, Loss Aux: 6.175e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1707, It: 0, Loss Data: 2.848e-02, Loss Eqns: 6.267e-01, Loss Aux: 6.152e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1708, It: 0, Loss Data: 3.380e-02, Loss Eqns: 6.519e-01, Loss Aux: 6.205e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1709, It: 0, Loss Data: 3.244e-02, Loss Eqns: 6.035e-01, Loss Aux: 6.306e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1710, It: 0, Loss Data: 3.122e-02, Loss Eqns: 5.996e-01, Loss Aux: 6.379e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1711, It: 0, Loss Data: 2.932e-02, Loss Eqns: 5.892e-01, Loss Aux: 6.288e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1712, It: 0, Loss Data: 3.006e-02, Loss Eqns: 5.771e-01, Loss Aux: 6.032e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1713, It: 0, Loss Data: 3.118e-02, Loss Eqns: 6.242e-01, Loss Aux: 5.852e-02, Time: 0.195, Learning Rate: 1.0e-04\n",
      "Epoch: 1714, It: 0, Loss Data: 3.053e-02, Loss Eqns: 6.153e-01, Loss Aux: 5.845e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1715, It: 0, Loss Data: 3.003e-02, Loss Eqns: 6.097e-01, Loss Aux: 5.991e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1716, It: 0, Loss Data: 3.240e-02, Loss Eqns: 5.966e-01, Loss Aux: 6.162e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1717, It: 0, Loss Data: 2.780e-02, Loss Eqns: 6.144e-01, Loss Aux: 6.325e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1718, It: 0, Loss Data: 3.130e-02, Loss Eqns: 5.874e-01, Loss Aux: 6.411e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1719, It: 0, Loss Data: 3.157e-02, Loss Eqns: 6.343e-01, Loss Aux: 6.437e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1720, It: 0, Loss Data: 2.985e-02, Loss Eqns: 5.802e-01, Loss Aux: 6.414e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1721, It: 0, Loss Data: 3.036e-02, Loss Eqns: 6.004e-01, Loss Aux: 6.389e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1722, It: 0, Loss Data: 2.963e-02, Loss Eqns: 6.429e-01, Loss Aux: 6.329e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1723, It: 0, Loss Data: 3.014e-02, Loss Eqns: 6.007e-01, Loss Aux: 6.280e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1724, It: 0, Loss Data: 3.215e-02, Loss Eqns: 5.749e-01, Loss Aux: 6.255e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1725, It: 0, Loss Data: 3.449e-02, Loss Eqns: 6.033e-01, Loss Aux: 6.226e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1726, It: 0, Loss Data: 3.118e-02, Loss Eqns: 6.059e-01, Loss Aux: 6.181e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1727, It: 0, Loss Data: 3.022e-02, Loss Eqns: 6.225e-01, Loss Aux: 6.119e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1728, It: 0, Loss Data: 2.768e-02, Loss Eqns: 5.579e-01, Loss Aux: 6.100e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1729, It: 0, Loss Data: 2.539e-02, Loss Eqns: 5.764e-01, Loss Aux: 6.089e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1730, It: 0, Loss Data: 3.559e-02, Loss Eqns: 6.331e-01, Loss Aux: 6.122e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1731, It: 0, Loss Data: 3.135e-02, Loss Eqns: 6.390e-01, Loss Aux: 6.093e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1732, It: 0, Loss Data: 2.975e-02, Loss Eqns: 6.085e-01, Loss Aux: 6.083e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1733, It: 0, Loss Data: 2.486e-02, Loss Eqns: 6.035e-01, Loss Aux: 6.086e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1734, It: 0, Loss Data: 2.818e-02, Loss Eqns: 5.966e-01, Loss Aux: 6.165e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1735, It: 0, Loss Data: 3.138e-02, Loss Eqns: 6.002e-01, Loss Aux: 6.264e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1736, It: 0, Loss Data: 2.948e-02, Loss Eqns: 6.166e-01, Loss Aux: 6.368e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1737, It: 0, Loss Data: 2.841e-02, Loss Eqns: 6.420e-01, Loss Aux: 6.392e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1738, It: 0, Loss Data: 3.046e-02, Loss Eqns: 6.183e-01, Loss Aux: 6.424e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1739, It: 0, Loss Data: 3.118e-02, Loss Eqns: 6.050e-01, Loss Aux: 6.455e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1740, It: 0, Loss Data: 2.676e-02, Loss Eqns: 5.979e-01, Loss Aux: 6.365e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1741, It: 0, Loss Data: 2.894e-02, Loss Eqns: 5.895e-01, Loss Aux: 6.230e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1742, It: 0, Loss Data: 2.734e-02, Loss Eqns: 5.867e-01, Loss Aux: 6.053e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1743, It: 0, Loss Data: 3.092e-02, Loss Eqns: 5.743e-01, Loss Aux: 5.957e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1744, It: 0, Loss Data: 2.848e-02, Loss Eqns: 5.904e-01, Loss Aux: 5.913e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1745, It: 0, Loss Data: 3.158e-02, Loss Eqns: 6.048e-01, Loss Aux: 5.962e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1746, It: 0, Loss Data: 2.753e-02, Loss Eqns: 5.733e-01, Loss Aux: 6.050e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1747, It: 0, Loss Data: 3.019e-02, Loss Eqns: 5.826e-01, Loss Aux: 6.106e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1748, It: 0, Loss Data: 3.221e-02, Loss Eqns: 5.780e-01, Loss Aux: 6.177e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1749, It: 0, Loss Data: 2.975e-02, Loss Eqns: 6.359e-01, Loss Aux: 6.310e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1750, It: 0, Loss Data: 2.429e-02, Loss Eqns: 5.807e-01, Loss Aux: 6.352e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1751, It: 0, Loss Data: 3.031e-02, Loss Eqns: 6.238e-01, Loss Aux: 6.372e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1752, It: 0, Loss Data: 3.071e-02, Loss Eqns: 6.190e-01, Loss Aux: 6.264e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1753, It: 0, Loss Data: 2.793e-02, Loss Eqns: 6.038e-01, Loss Aux: 6.143e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1754, It: 0, Loss Data: 2.996e-02, Loss Eqns: 6.072e-01, Loss Aux: 6.096e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1755, It: 0, Loss Data: 3.067e-02, Loss Eqns: 6.146e-01, Loss Aux: 6.149e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1756, It: 0, Loss Data: 2.810e-02, Loss Eqns: 5.851e-01, Loss Aux: 6.166e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1757, It: 0, Loss Data: 2.887e-02, Loss Eqns: 6.059e-01, Loss Aux: 6.206e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1758, It: 0, Loss Data: 2.872e-02, Loss Eqns: 6.286e-01, Loss Aux: 6.295e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1759, It: 0, Loss Data: 2.770e-02, Loss Eqns: 5.873e-01, Loss Aux: 6.412e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1760, It: 0, Loss Data: 3.571e-02, Loss Eqns: 6.185e-01, Loss Aux: 6.492e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1761, It: 0, Loss Data: 2.781e-02, Loss Eqns: 6.122e-01, Loss Aux: 6.404e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1762, It: 0, Loss Data: 3.353e-02, Loss Eqns: 5.795e-01, Loss Aux: 6.167e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1763, It: 0, Loss Data: 2.840e-02, Loss Eqns: 5.881e-01, Loss Aux: 6.005e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1764, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.403e-01, Loss Aux: 5.955e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1765, It: 0, Loss Data: 2.825e-02, Loss Eqns: 6.386e-01, Loss Aux: 6.005e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1766, It: 0, Loss Data: 2.836e-02, Loss Eqns: 6.005e-01, Loss Aux: 6.131e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1767, It: 0, Loss Data: 3.435e-02, Loss Eqns: 5.602e-01, Loss Aux: 6.374e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1768, It: 0, Loss Data: 3.320e-02, Loss Eqns: 6.156e-01, Loss Aux: 6.520e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1769, It: 0, Loss Data: 3.013e-02, Loss Eqns: 6.116e-01, Loss Aux: 6.535e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1770, It: 0, Loss Data: 3.128e-02, Loss Eqns: 5.843e-01, Loss Aux: 6.461e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1771, It: 0, Loss Data: 3.123e-02, Loss Eqns: 5.865e-01, Loss Aux: 6.240e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1772, It: 0, Loss Data: 2.634e-02, Loss Eqns: 5.910e-01, Loss Aux: 6.018e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1773, It: 0, Loss Data: 3.114e-02, Loss Eqns: 6.522e-01, Loss Aux: 5.955e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1774, It: 0, Loss Data: 3.070e-02, Loss Eqns: 5.831e-01, Loss Aux: 6.034e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1775, It: 0, Loss Data: 2.750e-02, Loss Eqns: 6.341e-01, Loss Aux: 6.243e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1776, It: 0, Loss Data: 2.873e-02, Loss Eqns: 6.000e-01, Loss Aux: 6.534e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1777, It: 0, Loss Data: 2.744e-02, Loss Eqns: 6.443e-01, Loss Aux: 6.676e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1778, It: 0, Loss Data: 3.593e-02, Loss Eqns: 5.993e-01, Loss Aux: 6.629e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1779, It: 0, Loss Data: 2.564e-02, Loss Eqns: 5.873e-01, Loss Aux: 6.463e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1780, It: 0, Loss Data: 3.284e-02, Loss Eqns: 6.431e-01, Loss Aux: 6.386e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1781, It: 0, Loss Data: 2.906e-02, Loss Eqns: 6.027e-01, Loss Aux: 6.350e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1782, It: 0, Loss Data: 2.970e-02, Loss Eqns: 5.734e-01, Loss Aux: 6.290e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1783, It: 0, Loss Data: 2.937e-02, Loss Eqns: 6.066e-01, Loss Aux: 6.315e-02, Time: 0.187, Learning Rate: 1.0e-04\n",
      "Epoch: 1784, It: 0, Loss Data: 3.620e-02, Loss Eqns: 5.880e-01, Loss Aux: 6.439e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1785, It: 0, Loss Data: 2.589e-02, Loss Eqns: 6.097e-01, Loss Aux: 6.460e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1786, It: 0, Loss Data: 3.039e-02, Loss Eqns: 6.151e-01, Loss Aux: 6.457e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1787, It: 0, Loss Data: 2.864e-02, Loss Eqns: 6.456e-01, Loss Aux: 6.416e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1788, It: 0, Loss Data: 3.093e-02, Loss Eqns: 5.710e-01, Loss Aux: 6.437e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1789, It: 0, Loss Data: 3.089e-02, Loss Eqns: 6.004e-01, Loss Aux: 6.453e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1790, It: 0, Loss Data: 3.051e-02, Loss Eqns: 6.152e-01, Loss Aux: 6.366e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1791, It: 0, Loss Data: 2.898e-02, Loss Eqns: 5.846e-01, Loss Aux: 6.257e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1792, It: 0, Loss Data: 2.776e-02, Loss Eqns: 6.120e-01, Loss Aux: 6.179e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1793, It: 0, Loss Data: 3.227e-02, Loss Eqns: 5.924e-01, Loss Aux: 6.143e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1794, It: 0, Loss Data: 3.199e-02, Loss Eqns: 6.268e-01, Loss Aux: 6.150e-02, Time: 0.189, Learning Rate: 1.0e-04\n",
      "Epoch: 1795, It: 0, Loss Data: 2.979e-02, Loss Eqns: 5.635e-01, Loss Aux: 6.193e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1796, It: 0, Loss Data: 3.224e-02, Loss Eqns: 6.080e-01, Loss Aux: 6.350e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1797, It: 0, Loss Data: 2.967e-02, Loss Eqns: 5.910e-01, Loss Aux: 6.475e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 1798, It: 0, Loss Data: 3.086e-02, Loss Eqns: 5.807e-01, Loss Aux: 6.513e-02, Time: 0.159, Learning Rate: 1.0e-04\n",
      "Epoch: 1799, It: 0, Loss Data: 3.233e-02, Loss Eqns: 5.886e-01, Loss Aux: 6.494e-02, Time: 0.153, Learning Rate: 1.0e-04\n",
      "Epoch: 1800, It: 0, Loss Data: 2.995e-02, Loss Eqns: 5.813e-01, Loss Aux: 6.384e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1801, It: 0, Loss Data: 3.289e-02, Loss Eqns: 5.820e-01, Loss Aux: 6.249e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1802, It: 0, Loss Data: 3.002e-02, Loss Eqns: 5.949e-01, Loss Aux: 6.163e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1803, It: 0, Loss Data: 2.692e-02, Loss Eqns: 5.818e-01, Loss Aux: 6.083e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1804, It: 0, Loss Data: 2.877e-02, Loss Eqns: 6.076e-01, Loss Aux: 6.029e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1805, It: 0, Loss Data: 2.810e-02, Loss Eqns: 6.180e-01, Loss Aux: 6.014e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1806, It: 0, Loss Data: 3.073e-02, Loss Eqns: 6.271e-01, Loss Aux: 6.016e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1807, It: 0, Loss Data: 3.058e-02, Loss Eqns: 5.893e-01, Loss Aux: 6.086e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1808, It: 0, Loss Data: 2.848e-02, Loss Eqns: 6.028e-01, Loss Aux: 6.242e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1809, It: 0, Loss Data: 2.894e-02, Loss Eqns: 5.869e-01, Loss Aux: 6.341e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1810, It: 0, Loss Data: 2.661e-02, Loss Eqns: 6.253e-01, Loss Aux: 6.404e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1811, It: 0, Loss Data: 3.028e-02, Loss Eqns: 5.743e-01, Loss Aux: 6.465e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1812, It: 0, Loss Data: 2.735e-02, Loss Eqns: 5.995e-01, Loss Aux: 6.390e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1813, It: 0, Loss Data: 2.970e-02, Loss Eqns: 5.897e-01, Loss Aux: 6.331e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1814, It: 0, Loss Data: 3.234e-02, Loss Eqns: 5.736e-01, Loss Aux: 6.259e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1815, It: 0, Loss Data: 2.959e-02, Loss Eqns: 5.774e-01, Loss Aux: 6.203e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1816, It: 0, Loss Data: 2.995e-02, Loss Eqns: 6.104e-01, Loss Aux: 6.168e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1817, It: 0, Loss Data: 3.258e-02, Loss Eqns: 6.039e-01, Loss Aux: 6.142e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1818, It: 0, Loss Data: 2.926e-02, Loss Eqns: 6.193e-01, Loss Aux: 6.134e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1819, It: 0, Loss Data: 2.962e-02, Loss Eqns: 5.982e-01, Loss Aux: 6.241e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1820, It: 0, Loss Data: 2.865e-02, Loss Eqns: 6.281e-01, Loss Aux: 6.378e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1821, It: 0, Loss Data: 3.024e-02, Loss Eqns: 6.024e-01, Loss Aux: 6.531e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1822, It: 0, Loss Data: 2.973e-02, Loss Eqns: 5.950e-01, Loss Aux: 6.618e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1823, It: 0, Loss Data: 3.099e-02, Loss Eqns: 5.805e-01, Loss Aux: 6.586e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1824, It: 0, Loss Data: 3.331e-02, Loss Eqns: 5.852e-01, Loss Aux: 6.567e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1825, It: 0, Loss Data: 3.281e-02, Loss Eqns: 5.849e-01, Loss Aux: 6.603e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1826, It: 0, Loss Data: 3.277e-02, Loss Eqns: 5.825e-01, Loss Aux: 6.588e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1827, It: 0, Loss Data: 3.002e-02, Loss Eqns: 5.520e-01, Loss Aux: 6.495e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1828, It: 0, Loss Data: 2.845e-02, Loss Eqns: 5.834e-01, Loss Aux: 6.445e-02, Time: 0.190, Learning Rate: 1.0e-04\n",
      "Epoch: 1829, It: 0, Loss Data: 2.905e-02, Loss Eqns: 5.811e-01, Loss Aux: 6.376e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1830, It: 0, Loss Data: 2.839e-02, Loss Eqns: 5.818e-01, Loss Aux: 6.286e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 1831, It: 0, Loss Data: 2.971e-02, Loss Eqns: 5.939e-01, Loss Aux: 6.205e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1832, It: 0, Loss Data: 2.990e-02, Loss Eqns: 6.147e-01, Loss Aux: 6.160e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1833, It: 0, Loss Data: 2.781e-02, Loss Eqns: 6.183e-01, Loss Aux: 6.189e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1834, It: 0, Loss Data: 2.957e-02, Loss Eqns: 5.891e-01, Loss Aux: 6.298e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1835, It: 0, Loss Data: 2.774e-02, Loss Eqns: 5.795e-01, Loss Aux: 6.548e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1836, It: 0, Loss Data: 3.125e-02, Loss Eqns: 6.150e-01, Loss Aux: 6.831e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1837, It: 0, Loss Data: 2.957e-02, Loss Eqns: 5.985e-01, Loss Aux: 7.037e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1838, It: 0, Loss Data: 3.292e-02, Loss Eqns: 6.181e-01, Loss Aux: 7.083e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1839, It: 0, Loss Data: 2.886e-02, Loss Eqns: 6.088e-01, Loss Aux: 6.972e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1840, It: 0, Loss Data: 3.540e-02, Loss Eqns: 5.840e-01, Loss Aux: 6.711e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1841, It: 0, Loss Data: 3.183e-02, Loss Eqns: 6.097e-01, Loss Aux: 6.513e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1842, It: 0, Loss Data: 2.657e-02, Loss Eqns: 6.154e-01, Loss Aux: 6.435e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1843, It: 0, Loss Data: 3.032e-02, Loss Eqns: 5.971e-01, Loss Aux: 6.447e-02, Time: 0.186, Learning Rate: 1.0e-04\n",
      "Epoch: 1844, It: 0, Loss Data: 2.777e-02, Loss Eqns: 6.091e-01, Loss Aux: 6.498e-02, Time: 0.147, Learning Rate: 1.0e-04\n",
      "Epoch: 1845, It: 0, Loss Data: 3.038e-02, Loss Eqns: 5.969e-01, Loss Aux: 6.623e-02, Time: 0.178, Learning Rate: 1.0e-04\n",
      "Epoch: 1846, It: 0, Loss Data: 3.327e-02, Loss Eqns: 5.771e-01, Loss Aux: 6.777e-02, Time: 0.183, Learning Rate: 1.0e-04\n",
      "Epoch: 1847, It: 0, Loss Data: 2.763e-02, Loss Eqns: 5.953e-01, Loss Aux: 6.833e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1848, It: 0, Loss Data: 2.835e-02, Loss Eqns: 6.276e-01, Loss Aux: 6.788e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1849, It: 0, Loss Data: 2.818e-02, Loss Eqns: 5.848e-01, Loss Aux: 6.682e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1850, It: 0, Loss Data: 3.082e-02, Loss Eqns: 5.987e-01, Loss Aux: 6.533e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1851, It: 0, Loss Data: 2.994e-02, Loss Eqns: 5.748e-01, Loss Aux: 6.421e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1852, It: 0, Loss Data: 3.013e-02, Loss Eqns: 5.901e-01, Loss Aux: 6.387e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1853, It: 0, Loss Data: 3.075e-02, Loss Eqns: 6.051e-01, Loss Aux: 6.536e-02, Time: 0.185, Learning Rate: 1.0e-04\n",
      "Epoch: 1854, It: 0, Loss Data: 2.985e-02, Loss Eqns: 5.867e-01, Loss Aux: 6.704e-02, Time: 0.179, Learning Rate: 1.0e-04\n",
      "Epoch: 1855, It: 0, Loss Data: 2.776e-02, Loss Eqns: 6.150e-01, Loss Aux: 6.798e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1856, It: 0, Loss Data: 3.216e-02, Loss Eqns: 5.678e-01, Loss Aux: 6.815e-02, Time: 0.182, Learning Rate: 1.0e-04\n",
      "Epoch: 1857, It: 0, Loss Data: 2.738e-02, Loss Eqns: 5.889e-01, Loss Aux: 6.710e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1858, It: 0, Loss Data: 2.677e-02, Loss Eqns: 6.403e-01, Loss Aux: 6.502e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1859, It: 0, Loss Data: 3.158e-02, Loss Eqns: 5.777e-01, Loss Aux: 6.268e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1860, It: 0, Loss Data: 3.427e-02, Loss Eqns: 5.779e-01, Loss Aux: 6.179e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1861, It: 0, Loss Data: 3.102e-02, Loss Eqns: 5.986e-01, Loss Aux: 6.158e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1862, It: 0, Loss Data: 2.834e-02, Loss Eqns: 6.139e-01, Loss Aux: 6.190e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1863, It: 0, Loss Data: 3.243e-02, Loss Eqns: 5.864e-01, Loss Aux: 6.314e-02, Time: 0.152, Learning Rate: 1.0e-04\n",
      "Epoch: 1864, It: 0, Loss Data: 2.727e-02, Loss Eqns: 5.406e-01, Loss Aux: 6.394e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1865, It: 0, Loss Data: 3.119e-02, Loss Eqns: 5.478e-01, Loss Aux: 6.418e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1866, It: 0, Loss Data: 2.849e-02, Loss Eqns: 5.789e-01, Loss Aux: 6.303e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1867, It: 0, Loss Data: 3.205e-02, Loss Eqns: 5.800e-01, Loss Aux: 6.120e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1868, It: 0, Loss Data: 3.047e-02, Loss Eqns: 6.034e-01, Loss Aux: 6.026e-02, Time: 0.164, Learning Rate: 1.0e-04\n",
      "Epoch: 1869, It: 0, Loss Data: 2.826e-02, Loss Eqns: 6.181e-01, Loss Aux: 6.011e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1870, It: 0, Loss Data: 2.990e-02, Loss Eqns: 5.910e-01, Loss Aux: 6.098e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1871, It: 0, Loss Data: 3.176e-02, Loss Eqns: 6.127e-01, Loss Aux: 6.229e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1872, It: 0, Loss Data: 2.817e-02, Loss Eqns: 5.867e-01, Loss Aux: 6.410e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1873, It: 0, Loss Data: 2.917e-02, Loss Eqns: 5.792e-01, Loss Aux: 6.518e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1874, It: 0, Loss Data: 2.738e-02, Loss Eqns: 6.001e-01, Loss Aux: 6.502e-02, Time: 0.162, Learning Rate: 1.0e-04\n",
      "Epoch: 1875, It: 0, Loss Data: 3.012e-02, Loss Eqns: 5.997e-01, Loss Aux: 6.412e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1876, It: 0, Loss Data: 2.794e-02, Loss Eqns: 6.158e-01, Loss Aux: 6.383e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1877, It: 0, Loss Data: 2.999e-02, Loss Eqns: 5.974e-01, Loss Aux: 6.369e-02, Time: 0.175, Learning Rate: 1.0e-04\n",
      "Epoch: 1878, It: 0, Loss Data: 2.828e-02, Loss Eqns: 5.672e-01, Loss Aux: 6.399e-02, Time: 0.180, Learning Rate: 1.0e-04\n",
      "Epoch: 1879, It: 0, Loss Data: 2.880e-02, Loss Eqns: 5.701e-01, Loss Aux: 6.424e-02, Time: 0.181, Learning Rate: 1.0e-04\n",
      "Epoch: 1880, It: 0, Loss Data: 2.971e-02, Loss Eqns: 5.876e-01, Loss Aux: 6.414e-02, Time: 0.174, Learning Rate: 1.0e-04\n",
      "Epoch: 1881, It: 0, Loss Data: 3.284e-02, Loss Eqns: 6.262e-01, Loss Aux: 6.359e-02, Time: 0.176, Learning Rate: 1.0e-04\n",
      "Epoch: 1882, It: 0, Loss Data: 2.746e-02, Loss Eqns: 5.819e-01, Loss Aux: 6.324e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1883, It: 0, Loss Data: 2.928e-02, Loss Eqns: 5.856e-01, Loss Aux: 6.349e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1884, It: 0, Loss Data: 2.959e-02, Loss Eqns: 6.139e-01, Loss Aux: 6.391e-02, Time: 0.163, Learning Rate: 1.0e-04\n",
      "Epoch: 1885, It: 0, Loss Data: 3.211e-02, Loss Eqns: 5.880e-01, Loss Aux: 6.450e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1886, It: 0, Loss Data: 3.045e-02, Loss Eqns: 6.190e-01, Loss Aux: 6.539e-02, Time: 0.150, Learning Rate: 1.0e-04\n",
      "Epoch: 1887, It: 0, Loss Data: 3.414e-02, Loss Eqns: 5.871e-01, Loss Aux: 6.481e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1888, It: 0, Loss Data: 2.862e-02, Loss Eqns: 6.155e-01, Loss Aux: 6.421e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1889, It: 0, Loss Data: 2.880e-02, Loss Eqns: 5.998e-01, Loss Aux: 6.391e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1890, It: 0, Loss Data: 3.006e-02, Loss Eqns: 6.083e-01, Loss Aux: 6.327e-02, Time: 0.156, Learning Rate: 1.0e-04\n",
      "Epoch: 1891, It: 0, Loss Data: 3.128e-02, Loss Eqns: 5.782e-01, Loss Aux: 6.279e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1892, It: 0, Loss Data: 2.757e-02, Loss Eqns: 5.942e-01, Loss Aux: 6.288e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1893, It: 0, Loss Data: 3.072e-02, Loss Eqns: 6.299e-01, Loss Aux: 6.355e-02, Time: 0.154, Learning Rate: 1.0e-04\n",
      "Epoch: 1894, It: 0, Loss Data: 2.782e-02, Loss Eqns: 5.889e-01, Loss Aux: 6.472e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1895, It: 0, Loss Data: 2.897e-02, Loss Eqns: 6.121e-01, Loss Aux: 6.594e-02, Time: 0.151, Learning Rate: 1.0e-04\n",
      "Epoch: 1896, It: 0, Loss Data: 3.019e-02, Loss Eqns: 5.768e-01, Loss Aux: 6.594e-02, Time: 0.155, Learning Rate: 1.0e-04\n",
      "Epoch: 1897, It: 0, Loss Data: 2.807e-02, Loss Eqns: 6.211e-01, Loss Aux: 6.431e-02, Time: 0.171, Learning Rate: 1.0e-04\n",
      "Epoch: 1898, It: 0, Loss Data: 2.540e-02, Loss Eqns: 5.898e-01, Loss Aux: 6.235e-02, Time: 0.161, Learning Rate: 1.0e-04\n",
      "Epoch: 1899, It: 0, Loss Data: 3.077e-02, Loss Eqns: 5.763e-01, Loss Aux: 6.147e-02, Time: 0.167, Learning Rate: 1.0e-04\n",
      "Epoch: 1900, It: 0, Loss Data: 2.828e-02, Loss Eqns: 5.760e-01, Loss Aux: 6.240e-02, Time: 0.169, Learning Rate: 1.0e-04\n",
      "Epoch: 1901, It: 0, Loss Data: 2.864e-02, Loss Eqns: 5.607e-01, Loss Aux: 6.360e-02, Time: 0.165, Learning Rate: 1.0e-04\n",
      "Epoch: 1902, It: 0, Loss Data: 3.083e-02, Loss Eqns: 5.866e-01, Loss Aux: 6.513e-02, Time: 0.160, Learning Rate: 1.0e-04\n",
      "Epoch: 1903, It: 0, Loss Data: 3.068e-02, Loss Eqns: 6.323e-01, Loss Aux: 6.541e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1904, It: 0, Loss Data: 2.653e-02, Loss Eqns: 5.999e-01, Loss Aux: 6.491e-02, Time: 0.188, Learning Rate: 1.0e-04\n",
      "Epoch: 1905, It: 0, Loss Data: 2.602e-02, Loss Eqns: 6.164e-01, Loss Aux: 6.386e-02, Time: 0.197, Learning Rate: 1.0e-04\n",
      "Epoch: 1906, It: 0, Loss Data: 2.795e-02, Loss Eqns: 5.866e-01, Loss Aux: 6.271e-02, Time: 0.172, Learning Rate: 1.0e-04\n",
      "Epoch: 1907, It: 0, Loss Data: 2.934e-02, Loss Eqns: 5.955e-01, Loss Aux: 6.210e-02, Time: 0.157, Learning Rate: 1.0e-04\n",
      "Epoch: 1908, It: 0, Loss Data: 2.827e-02, Loss Eqns: 5.952e-01, Loss Aux: 6.220e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1909, It: 0, Loss Data: 2.923e-02, Loss Eqns: 5.829e-01, Loss Aux: 6.303e-02, Time: 0.166, Learning Rate: 1.0e-04\n",
      "Epoch: 1910, It: 0, Loss Data: 3.026e-02, Loss Eqns: 6.165e-01, Loss Aux: 6.467e-02, Time: 0.177, Learning Rate: 1.0e-04\n",
      "Epoch: 1911, It: 0, Loss Data: 2.789e-02, Loss Eqns: 5.664e-01, Loss Aux: 6.540e-02, Time: 0.168, Learning Rate: 1.0e-04\n",
      "Epoch: 1912, It: 0, Loss Data: 3.128e-02, Loss Eqns: 5.841e-01, Loss Aux: 6.519e-02, Time: 0.158, Learning Rate: 1.0e-04\n",
      "Epoch: 1913, It: 0, Loss Data: 2.811e-02, Loss Eqns: 6.070e-01, Loss Aux: 6.471e-02, Time: 0.173, Learning Rate: 1.0e-04\n",
      "Epoch: 1914, It: 0, Loss Data: 2.915e-02, Loss Eqns: 5.996e-01, Loss Aux: 6.422e-02, Time: 0.149, Learning Rate: 1.0e-04\n",
      "Epoch: 1915, It: 0, Loss Data: 2.831e-02, Loss Eqns: 6.009e-01, Loss Aux: 6.428e-02, Time: 0.170, Learning Rate: 1.0e-04\n",
      "Epoch: 1916, It: 0, Loss Data: 2.761e-02, Loss Eqns: 5.930e-01, Loss Aux: 6.459e-02, Time: 0.184, Learning Rate: 1.0e-04\n",
      "Epoch: 1917, It: 0, Loss Data: 2.816e-02, Loss Eqns: 6.251e-01, Loss Aux: 6.481e-02, Time: 0.186, Learning Rate: 1.0e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "#from plotting import newfig, savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time\n",
    "\n",
    "# from utilities import neural_net, fwd_gradients,\\\n",
    "#                       tf_session, mean_squared_error, relative_error\n",
    "\n",
    "class HiddenPathways(object):\n",
    "    # Initialize the class\n",
    "    def __init__(self, t_data, S_data, t_eqns, layers):\n",
    "        \n",
    "        self.D = S_data.shape[1]\n",
    "        \n",
    "        self.t_min = t_data.min(0)\n",
    "        self.t_max = t_data.max(0)\n",
    "        \n",
    "        self.S_scale = tf.Variable(S_data.std(0), dtype=tf.float32, trainable=False)\n",
    "        \n",
    "        # data on all the species (only some are used as input)\n",
    "        self.t_data, self.S_data = t_data, S_data\n",
    "        self.t_eqns = t_eqns\n",
    "                \n",
    "        # layers\n",
    "        self.layers = layers\n",
    "        \n",
    "#        self.J0 = tf.Variable(2.5, dtype=tf.float32, trainable=False)\n",
    "#        self.k1 = tf.Variable(100.0, dtype=tf.float32, trainable=False)\n",
    "#        self.k2 = tf.Variable(6.0, dtype=tf.float32, trainable=False)\n",
    "#        self.k3 = tf.Variable(16.0, dtype=tf.float32, trainable=False)\n",
    "#        self.k4 = tf.Variable(100.0, dtype=tf.float32, trainable=False)\n",
    "#        self.k5 = tf.Variable(1.28, dtype=tf.float32, trainable=False)\n",
    "#        self.k6 = tf.Variable(12.0, dtype=tf.float32, trainable=False)\n",
    "#        self.k = tf.Variable(1.8, dtype=tf.float32, trainable=False)\n",
    "#        self.kappa = tf.Variable(13.0, dtype=tf.float32, trainable=False)\n",
    "#        self.q = tf.Variable(4.0, dtype=tf.float32, trainable=False)\n",
    "#        self.K1 = tf.Variable(0.52, dtype=tf.float32, trainable=False)\n",
    "#        self.psi = tf.Variable(0.1, dtype=tf.float32, trainable=False)\n",
    "#        self.N = tf.Variable(1.0, dtype=tf.float32, trainable=False)\n",
    "#        self.A = tf.Variable(4.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "        self.logJ0 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk1 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk2 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk3 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk4 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk5 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk6 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkappa = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logq = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logK1 = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "        self.logpsi = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logN = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logA = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        \n",
    "        self.var_list_eqns = [self.logJ0, self.logk1, self.logk2, self.logk3, self.logk4,\n",
    "                              self.logk5, self.logk6, self.logk, self.logkappa,\n",
    "                              self.logq, self.logK1, self.logpsi, self.logN, self.logA]\n",
    "  \n",
    "        self.J0 = tf.exp(self.logJ0)\n",
    "        self.k1 = tf.exp(self.logk1)\n",
    "        self.k2 = tf.exp(self.logk2)\n",
    "        self.k3 = tf.exp(self.logk3)\n",
    "        self.k4 = tf.exp(self.logk4)\n",
    "        self.k5 = tf.exp(self.logk5)\n",
    "        self.k6 = tf.exp(self.logk6)\n",
    "        self.k = tf.exp(self.logk)\n",
    "        self.kappa = tf.exp(self.logkappa)\n",
    "        self.q = tf.exp(self.logq)\n",
    "        self.K1 = tf.exp(self.logK1)\n",
    "        self.psi = tf.exp(self.logpsi)\n",
    "        self.N = tf.exp(self.logN)\n",
    "        self.A = tf.exp(self.logA)\n",
    "\n",
    "        # placeholders for data\n",
    "        self.t_data_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.S_data_tf = tf.placeholder(tf.float32, shape=[None, self.D])\n",
    "        self.t_eqns_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # physics uninformed neural networks\n",
    "        self.net_sysbio = neural_net(layers=self.layers)\n",
    "        \n",
    "        self.H_data = 2.0*(self.t_data_tf - self.t_min)/(self.t_max - self.t_min) - 1.0\n",
    "        self.S_data_pred = self.S_data[0,:] + self.S_scale*(self.H_data+1.0)*self.net_sysbio(self.H_data)\n",
    "\n",
    "        # physics informed neural networks\n",
    "        self.H_eqns = 2.0*(self.t_eqns_tf - self.t_min)/(self.t_max - self.t_min) - 1.0\n",
    "        self.S_eqns_pred = self.S_data[0,:] + self.S_scale*(self.H_eqns+1.0)*self.net_sysbio(self.H_eqns)\n",
    "\n",
    "        self.E_eqns_pred = self.SysODE(self.S_eqns_pred, self.t_eqns_tf)\n",
    "\n",
    "#        self.S_scale = 0.9*self.S_scale + 0.1*tf.math.reduce_std(self.S_eqns_pred, 0)\n",
    "#        scale_list = tf.unstack(self.S_scale)\n",
    "#        scale_list[4:6] = self.S_data.std(0)[4:6]\n",
    "#        self.S_scale = tf.stack(scale_list)\n",
    "        \n",
    "        # loss\n",
    "        self.loss_data = mean_squared_error(self.S_data_tf[:,4:6]/self.S_scale[4:6], self.S_data_pred[:,4:6]/self.S_scale[4:6])\n",
    "        self.loss_eqns = mean_squared_error(0.0, self.E_eqns_pred/self.S_scale)\n",
    "        self.loss_auxl = mean_squared_error(self.S_data_tf[-1,:]/self.S_scale[:], self.S_data_pred[-1,:]/self.S_scale[:])\n",
    "        self.loss = 0.95*self.loss_data + 0.05*self.loss_eqns + 0.05*self.loss_auxl\n",
    "        \n",
    "        # optimizers\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.optimizer_para = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "        self.train_op = self.optimizer.minimize(self.loss,\n",
    "                                                var_list=[self.net_sysbio.weights,\n",
    "                                                          self.net_sysbio.biases,\n",
    "                                                          self.net_sysbio.gammas])\n",
    "        self.trainpara_op = self.optimizer_para.minimize(self.loss,\n",
    "                                                         var_list=self.var_list_eqns)\n",
    "        self.sess = tf_session()\n",
    "\n",
    "    def SysODE(self, S, t):\n",
    "        F1 = self.J0 - (self.k1*S[:,0:1]*S[:,5:6])/(1+(S[:,5:6]/self.K1)**self.q)\n",
    "        F2 = 2*(self.k1*S[:,0:1]*S[:,5:6])/(1+(S[:,5:6]/self.K1)**self.q) - self.k2*S[:,1:2]*(self.N-S[:,4:5]) - self.k6*S[:,1:2]*S[:,4:5]\n",
    "        F3 = self.k2*S[:,1:2]*(self.N-S[:,4:5]) - self.k3*S[:,2:3]*(self.A-S[:,5:6])\n",
    "        F4 = self.k3*S[:,2:3]*(self.A-S[:,5:6]) - self.k4*S[:,3:4]*S[:,4:5] - self.kappa*(S[:,3:4]-S[:,6:7])\n",
    "        F5 = self.k2*S[:,1:2]*(self.N-S[:,4:5]) - self.k4*S[:,3:4]*S[:,4:5] - self.k6*S[:,1:2]*S[:,4:5]\n",
    "        F6 = -2*(self.k1*S[:,0:1]*S[:,5:6])/(1+(S[:,5:6]/self.K1)**self.q) + 2*self.k3*S[:,2:3]*(self.A-S[:,5:6]) - self.k5*S[:,5:6]\n",
    "        F7 = self.psi*self.kappa*(S[:,3:4]-S[:,6:7]) - self.k*S[:,6:7]\n",
    "        \n",
    "        F = tf.concat([F1, F2, F3, F4, F5, F6, F7], 1)\n",
    "\n",
    "        S_t = fwd_gradients(S, t)\n",
    "        \n",
    "        E = S_t - F\n",
    "        return E\n",
    "    \n",
    "    def train(self, num_epochs, batch_size, learning_rate):\n",
    "\n",
    "        N_data = self.t_data.shape[0]\n",
    "        N_eqns = self.t_eqns.shape[0]\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            for it in range(N_eqns//batch_size):\n",
    "                idx_data = np.concatenate([np.array([0]),\n",
    "                                           np.random.choice(np.arange(1, N_data-1), min(batch_size, N_data)-2),\n",
    "                                           np.array([N_data-1])])\n",
    "                idx_eqns = np.random.choice(N_eqns, batch_size)\n",
    "\n",
    "                t_data_batch, S_data_batch = self.t_data[idx_data,:], self.S_data[idx_data,:]\n",
    "                t_eqns_batch = self.t_eqns[idx_eqns,:]\n",
    "    \n",
    "                tf_dict = {self.t_data_tf: t_data_batch,\n",
    "                           self.S_data_tf: S_data_batch,\n",
    "                           self.t_eqns_tf: t_eqns_batch,\n",
    "                           self.learning_rate: learning_rate}\n",
    "                \n",
    "                self.sess.run([self.train_op, self.trainpara_op], tf_dict)\n",
    "                \n",
    "                # Print\n",
    "                if it % 10 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    [loss_data_value,\n",
    "                     loss_eqns_value,\n",
    "                     loss_auxl_value,\n",
    "                     learning_rate_value] = self.sess.run([self.loss_data,\n",
    "                                                           self.loss_eqns,\n",
    "                                                           self.loss_auxl,\n",
    "                                                           self.learning_rate], tf_dict)\n",
    "                    print('Epoch: %d, It: %d, Loss Data: %.3e, Loss Eqns: %.3e, Loss Aux: %.3e, Time: %.3f, Learning Rate: %.1e'\n",
    "                          %(epoch, it, loss_data_value, loss_eqns_value, loss_auxl_value, elapsed, learning_rate_value))\n",
    "                    start_time = time.time()\n",
    "\n",
    "    def predict(self, t_star):\n",
    "        \n",
    "        tf_dict = {self.t_eqns_tf: t_star}\n",
    "        \n",
    "        S_star, S_scale = self.sess.run([self.S_eqns_pred, self.S_scale], tf_dict)\n",
    "        return S_star, S_scale\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    layers = [1] + 7*[7*40] + [7]\n",
    "    \n",
    "    # function that returns dx/dt\n",
    "    def f(x, t): # x is 7 x 1\n",
    "        J0 = 2.5\n",
    "        k1 = 100.0\n",
    "        k2 = 6.0\n",
    "        k3 = 16.0\n",
    "        k4 = 100.0\n",
    "        k5 = 1.28\n",
    "        k6 = 12.0\n",
    "        k = 1.8\n",
    "        kappa = 13.0\n",
    "        q = 4.0\n",
    "        K1 = 0.52\n",
    "        psi = 0.1\n",
    "        N = 1.0\n",
    "        A = 4.0\n",
    "        \n",
    "        f1 = J0 - (k1*x[0]*x[5])/(1+(x[5]/K1)**q)\n",
    "        f2 = 2*(k1*x[0]*x[5])/(1+(x[5]/K1)**q) - k2*x[1]*(N-x[4]) - k6*x[1]*x[4]\n",
    "        f3 = k2*x[1]*(N-x[4]) - k3*x[2]*(A-x[5])\n",
    "        f4 = k3*x[2]*(A-x[5]) - k4*x[3]*x[4] - kappa*(x[3]-x[6])\n",
    "        f5 = k2*x[1]*(N-x[4]) - k4*x[3]*x[4] - k6*x[1]*x[4]\n",
    "        f6 = -2*(k1*x[0]*x[5])/(1+(x[5]/K1)**q) + 2*k3*x[2]*(A-x[5]) - k5*x[5]\n",
    "        f7 = psi*kappa*(x[3]-x[6]) - k*x[6]\n",
    "        \n",
    "        f = np.array([f1, f2, f3, f4, f5, f6, f7])\n",
    "        return f\n",
    "\n",
    "    def addNoise(S, noise):\n",
    "        std = noise*S.std(0)\n",
    "        S[1:,:] += np.random.normal(0.0, std, (S.shape[0]-1, S.shape[1]))\n",
    "        return S\n",
    "        \n",
    "    # time points\n",
    "    t_star = np.arange(0, 10, 0.005)\n",
    "    N = t_star.shape[0]\n",
    "    N_eqns = N\n",
    "    N_data = N // 4\n",
    "    \n",
    "    S1 = np.random.uniform(0.15, 1.60, 1)\n",
    "    S2 = np.random.uniform(0.19, 2.16, 1)\n",
    "    S3 = np.random.uniform(0.04, 0.20, 1)\n",
    "    S4 = np.random.uniform(0.10, 0.35, 1)\n",
    "    S5 = np.random.uniform(0.08, 0.30, 1)\n",
    "    S6 = np.random.uniform(0.14, 2.67, 1)\n",
    "    S7 = np.random.uniform(0.05, 0.10, 1)\n",
    "    \n",
    "    # initial condition\n",
    "#    x0 = np.array([S1, S2, S3, S4, S5, S6, S7]).flatten()\n",
    "    x0 = np.array([0.50144272, 1.95478666, 0.19788759, 0.14769148, 0.16059078,\n",
    "                   0.16127341, 0.06404702]).flatten()\n",
    "    \n",
    "    # solve ODE\n",
    "    S_star = odeint(f, x0, t_star)\n",
    "    \n",
    "    noise = 0.1\n",
    "    t_train = t_star[:,None]\n",
    "    S_train = addNoise(S_star, noise)\n",
    "\n",
    "    N0 = 0\n",
    "    N1 = N - 1 \n",
    "    idx_data = np.concatenate([np.array([N0]),\n",
    "                               np.random.choice(np.arange(1, N-1), size=N_data, replace=False),\n",
    "                               np.array([N-1]),\n",
    "                               np.array([N1])])\n",
    "    idx_eqns = np.concatenate([np.array([N0]),\n",
    "                               np.random.choice(np.arange(1, N-1), size=N_eqns-2, replace=False),\n",
    "                               np.array([N-1])])\n",
    "\n",
    "    model = HiddenPathways(t_train[idx_data],\n",
    "                           S_train[idx_data,:],\n",
    "                           t_train[idx_eqns],\n",
    "                           layers)\n",
    "\n",
    "    model.train(num_epochs=20000, batch_size=N_eqns, learning_rate=1e-3)\n",
    "    model.train(num_epochs=40000, batch_size=N_eqns, learning_rate=1e-4)\n",
    "    model.train(num_epochs=20000, batch_size=N_eqns, learning_rate=1e-5)\n",
    "    \n",
    "    S_pred, S_pred_std = model.predict(t_star[:,None])\n",
    "    \n",
    "    ####### Plotting ##################\n",
    "    \n",
    "    fig, ax = newfig(3.0, 0.3)\n",
    "    gs0 = gridspec.GridSpec(1, 2)\n",
    "    gs0.update(top=0.95, bottom=0.1, left=0.1, right=0.95, hspace=0.5, wspace=0.3)\n",
    "    ax = plt.subplot(gs0[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,4],'C1',linewidth=2,label='input data')\n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,4],marker='o',s=50,label='sampled input')\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_5\\ (mM)$', fontsize=18)\n",
    "    ax.legend(fontsize='large')\n",
    "    \n",
    "    ax = plt.subplot(gs0[0:1, 1:2])\n",
    "    ax.plot(t_star,S_star[:,5],'C1',linewidth=2)\n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,5],marker='o',s=50)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_6\\ (mM)$', fontsize=18)\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    fig, ax = newfig(3.0, 0.4)\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(top=0.95, bottom=0.15, left=0.1, right=0.95, hspace=0.3, wspace=0.3)\n",
    "    ax = plt.subplot(gs1[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,0],'C1',linewidth=2,label='exact')\n",
    "    ax.plot(t_star,S_pred[:,0],'g-.',linewidth=3,label='learned')\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_1\\ (mM)$', fontsize=18)\n",
    "    ax.legend(fontsize='large')\n",
    "    \n",
    "    ax = plt.subplot(gs1[0:1, 1:2])\n",
    "    ax.plot(t_star,S_star[:,1],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,1],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_2\\ (mM)$', fontsize=18)\n",
    "\n",
    "    ax = plt.subplot(gs1[0:1, 2:3])\n",
    "    ax.plot(t_star,S_star[:,2],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,2],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_3\\ (mM)$', fontsize=18)\n",
    "    \n",
    "    fig, ax = newfig(3.5, 0.4)\n",
    "    gs2 = gridspec.GridSpec(1, 3)\n",
    "    gs2.update(top=0.95, bottom=0.15, left=0.1, right=0.95, hspace=0.3, wspace=0.3)\n",
    "    ax = plt.subplot(gs2[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,3],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,3],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_4\\ (mM)$', fontsize=18)\n",
    "\n",
    "    ax = plt.subplot(gs2[0:1, 1:2])\n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,4],marker='o',c='C1',s=30)\n",
    "    ax.plot(t_star,S_pred[:,4],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_5\\ (mM)$', fontsize=18)\n",
    "    \n",
    "    ax = plt.subplot(gs2[0:1, 2:3])\n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,5],marker='o',c='C1',s=30)\n",
    "    ax.plot(t_star,S_pred[:,5],'g--',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_6\\ (mM)$', fontsize=18)\n",
    "\n",
    "    fig, ax = newfig(1, 1.5)\n",
    "    gs3 = gridspec.GridSpec(1, 1)\n",
    "    gs3.update(top=0.95, bottom=0.15, left=0.15, right=0.95, hspace=0.3, wspace=0.3)\n",
    "    ax = plt.subplot(gs3[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,6],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,6],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (min)$', fontsize=18)\n",
    "    ax.set_ylabel('$S_7\\ (mM)$', fontsize=18)\n",
    "\n",
    "    print('J0 = %.6f' % ( model.sess.run(model.J0) ) )\n",
    "    print('k1 = %.6f' % ( model.sess.run(model.k1) ) )\n",
    "    print('k2 = %.6f' % ( model.sess.run(model.k2) ) )\n",
    "    print('k3 = %.6f' % ( model.sess.run(model.k3) ) )\n",
    "    print('k4 = %.6f' % ( model.sess.run(model.k4) ) )\n",
    "    print('k5 = %.6f' % ( model.sess.run(model.k5) ) )\n",
    "    print('k6 = %.6f' % ( model.sess.run(model.k6) ) )\n",
    "    print('k = %.6f' % ( model.sess.run(model.k) ) )\n",
    "    print('kappa = %.6f' % ( model.sess.run(model.kappa) ) )\n",
    "    print('q = %.6f' % ( model.sess.run(model.q) ) )\n",
    "    print('K1 = %.6f' % ( model.sess.run(model.K1) ) )\n",
    "    print('psi = %.6f' % ( model.sess.run(model.psi) ) )\n",
    "    print('N = %.6f' % ( model.sess.run(model.N) ) )\n",
    "    print('A = %.6f' % ( model.sess.run(model.A) ) )\n",
    "    \n",
    "    savefig('./figures/Glycolytic', crop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyOL_DJ3lfnO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SBINNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
