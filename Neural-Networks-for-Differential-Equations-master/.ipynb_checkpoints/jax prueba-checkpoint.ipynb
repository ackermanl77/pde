{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 35.91 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "6.73 ms ± 7.91 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "10.4 ms ± 4.76 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as np\n",
    "from jax import jit\n",
    "\n",
    "def slow_f(x):\n",
    "  # Element-wise ops see a large benefit from fusion\n",
    "  return x * x + x * 2.0\n",
    "\n",
    "x = np.ones((5000, 5000))\n",
    "fast_f = jit(slow_f)\n",
    "%timeit -n10 -r3 fast_f(x)  # ~ 4.5 ms / loop on Titan X\n",
    "%timeit -n10 -r3 slow_f(x)  # ~ 14.5 ms / loop (also on GPU via JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.77\n",
      "Trained loss: 0.17\n"
     ]
    }
   ],
   "source": [
    "from jax import grad, jit\n",
    "import jax.numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (np.tanh(x / 2.) + 1)\n",
    "\n",
    "# Outputs probability of a label being true according to logistic model.\n",
    "def logistic_predictions(weights, inputs):\n",
    "    return sigmoid(np.dot(inputs, weights))\n",
    "\n",
    "# Training loss is the negative log-likelihood of the training labels.\n",
    "def loss(weights, inputs, targets):\n",
    "    preds = logistic_predictions(weights, inputs)\n",
    "    label_logprobs = np.log(preds) * targets + np.log(1 - preds) * (1 - targets)\n",
    "    return -np.sum(label_logprobs)\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = np.array([[0.52, 1.12,  0.77],\n",
    "                   [0.88, -1.08, 0.15],\n",
    "                   [0.52, 0.06, -1.30],\n",
    "                   [0.74, -2.49, 1.39]])\n",
    "targets = np.array([True, True, False, True])\n",
    "\n",
    "# Define a compiled function that returns gradients of the training loss\n",
    "training_gradient_fun = jit(grad(loss))\n",
    "\n",
    "# Optimize weights using gradient descent.\n",
    "weights = np.array([0.0, 0.0, 0.0])\n",
    "print(\"Initial loss: {:0.2f}\".format(loss(weights, inputs, targets)))\n",
    "for i in range(100):\n",
    "    weights -= 0.1 * training_gradient_fun(weights, inputs, targets)\n",
    "\n",
    "print(\"Trained loss: {:0.2f}\".format(loss(weights, inputs, targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap\n",
    "\n",
    "def predict(params, inputs):\n",
    "    for W, b in params:\n",
    "        outputs = np.dot(inputs, W) + b\n",
    "        inputs = np.tanh(outputs)\n",
    "    return outputs\n",
    "\n",
    "def logprob_fun(params, inputs, targets):\n",
    "    preds = predict(params, inputs)\n",
    "    return np.sum((preds - targets)**2)\n",
    "\n",
    "grad_fun = jit(grad(logprob_fun))  # compiled gradient evaluation function\n",
    "perex_grads = jit(vmap(grad_fun, in_axes=(None, 0, 0)))  # fast per-example grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4199743\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "import jax.numpy as np\n",
    "\n",
    "def tanh(x):  # Define a function\n",
    "    y = np.exp(-2.0 * x)\n",
    "    return (1.0 - y) / (1.0 + y)\n",
    "\n",
    "grad_tanh = grad(tanh)  # Obtain its gradient function\n",
    "print(grad_tanh(1.0))   # Evaluate it at x = 1.0\n",
    "# prints 0.4199743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216266\n"
     ]
    }
   ],
   "source": [
    "print(grad(grad(grad(tanh)))(1.0))\n",
    "# prints 0.62162673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, jacfwd, jacrev\n",
    "\n",
    "def hessian(fun):\n",
    "    return jit(jacfwd(jacrev(fun)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "def abs_val(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x\n",
    "\n",
    "abs_val_grad = grad(abs_val)\n",
    "print(abs_val_grad(1.0))   # prints 1.0\n",
    "print(abs_val_grad(-1.0))  # prints -1.0 (abs_val is re-evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 ms ± 836 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "6.75 ms ± 239 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as np\n",
    "from jax import jit\n",
    "\n",
    "def slow_f(x):\n",
    "  # Element-wise ops see a large benefit from fusion\n",
    "  return x * x + x * 2.0\n",
    "\n",
    "x = np.ones((5000, 5000))\n",
    "fast_f = jit(slow_f)\n",
    "%timeit -n10 -r3 fast_f(x)  # ~ 4.5 ms / loop on Titan X\n",
    "%timeit -n10 -r3 slow_f(x)  # ~ 14.5 ms / loop (also on GPU via JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
