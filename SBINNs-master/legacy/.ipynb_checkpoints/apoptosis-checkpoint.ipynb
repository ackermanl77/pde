{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting import newfig, savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "from utilities import neural_net, fwd_gradients,\\\n",
    "                      tf_session, mean_squared_error, relative_error\n",
    "\n",
    "class HiddenPathways:\n",
    "    # Initialize the class\n",
    "    def __init__(self, t_data, S_data, t_eqns, layers):\n",
    "        \n",
    "        self.D = S_data.shape[1]\n",
    "        \n",
    "        self.t_min = t_data.min(0)\n",
    "        self.t_max = t_data.max(0)\n",
    "        \n",
    "        self.S_scale = S_data.std(0) # tf.Variable(tf.ones(self.D, tf.float32), trainable=False)\n",
    "        \n",
    "        # data on all the species (only some are used as input)\n",
    "        self.t_data, self.S_data = t_data, S_data\n",
    "        self.t_eqns = t_eqns\n",
    "                \n",
    "        # layers\n",
    "        self.layers = layers\n",
    "\n",
    "#        self.k1 = tf.Variable(2.67e-9, dtype=tf.float32, trainable=False)\n",
    "#        self.kd1 = tf.Variable(1e-2, dtype=tf.float32, trainable=False)\n",
    "#        self.kd2 = tf.Variable(8e-3, dtype=tf.float32, trainable=False)\n",
    "#        self.k3 = tf.Variable(6.8e-8, dtype=tf.float32, trainable=False)\n",
    "#        self.kd3 = tf.Variable(5e-2, dtype=tf.float32, trainable=False)\n",
    "#        self.kd4 = tf.Variable(1e-3, dtype=tf.float32, trainable=False)\n",
    "#        self.k5 = tf.Variable(7e-5, dtype=tf.float32, trainable=False)\n",
    "#        self.kd5 = tf.Variable(1.67e-5, dtype=tf.float32, trainable=False)\n",
    "#        self.kd6 = tf.Variable(1.67e-4, dtype=tf.float32, trainable=False)\n",
    "\n",
    "        self.logk1 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd1 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd2 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk3 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd3 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd4 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logk5 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd5 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        self.logkd6 = tf.Variable(0.0, dtype=tf.float32, trainable=True)\n",
    "        \n",
    "        self.var_list_eqns = [self.logk1, self.logkd1, self.logkd2, self.logk3, self.logkd3,\n",
    "                              self.logkd4, self.logk5, self.logkd5, self.logkd6]\n",
    "  \n",
    "        self.k1 = tf.exp(self.logk1)\n",
    "        self.kd1 = tf.exp(self.logkd1)\n",
    "        self.kd2 = tf.exp(self.logkd2)\n",
    "        self.k3 = tf.exp(self.logk3)\n",
    "        self.kd3 = tf.exp(self.logkd3)\n",
    "        self.kd4 = tf.exp(self.logkd4)\n",
    "        self.k5 = tf.exp(self.logk5)\n",
    "        self.kd5 = tf.exp(self.logkd5)\n",
    "        self.kd6 = tf.exp(self.logkd6)\n",
    "        \n",
    "        # placeholders for data\n",
    "        self.t_data_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.S_data_tf = tf.placeholder(tf.float32, shape=[None, self.D])\n",
    "        self.t_eqns_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # physics uninformed neural networks\n",
    "        self.net_sysbio = neural_net(layers=self.layers)\n",
    "        \n",
    "        self.H_data = 2.0*(self.t_data_tf - self.t_min)/(self.t_max - self.t_min) - 1.0\n",
    "        self.S_data_pred = self.S_data[0,:] + self.S_scale*(self.H_data+1.0)*self.net_sysbio(self.H_data)\n",
    "\n",
    "        # physics informed neural networks\n",
    "        self.H_eqns = 2.0*(self.t_eqns_tf - self.t_min)/(self.t_max - self.t_min) - 1.0\n",
    "        self.S_eqns_pred = self.S_data[0,:] + self.S_scale*(self.H_eqns+1.0)*self.net_sysbio(self.H_eqns)\n",
    "\n",
    "        self.E_eqns_pred = self.SysODE(self.S_eqns_pred, self.t_eqns_tf)\n",
    "\n",
    "#        self.S_scale = 0.9*self.S_scale + 0.1*tf.math.reduce_std(self.S_eqns_pred, 0)\n",
    "#        self.S_scale = tf.map_fn(lambda x: x, self.S_data_std[3:4])\n",
    "        \n",
    "        #loss\n",
    "        self.loss_data = mean_squared_error(self.S_data_tf[:,3:5]/self.S_scale[3:5], self.S_data_pred[:,3:5]/self.S_scale[3:5])\n",
    "        self.loss_eqns = mean_squared_error(self.E_eqns_pred/self.S_scale, 0.0)\n",
    "        self.loss_auxl = mean_squared_error(self.S_data_tf[-1,:]/self.S_scale, self.S_data_pred[-1,:]/self.S_scale)\n",
    "        self.loss = 0.95*self.loss_data + 0.05*self.loss_eqns + 0.05*self.loss_auxl\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        self.optimizer_para = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "\n",
    "        self.train_op = self.optimizer.minimize(self.loss,\n",
    "                                                var_list=[self.net_sysbio.weights,\n",
    "                                                          self.net_sysbio.biases,\n",
    "                                                          self.net_sysbio.gammas])\n",
    "        self.trainpara_op = self.optimizer_para.minimize(self.loss,\n",
    "                                                         var_list = self.var_list_eqns)\n",
    "        self.sess = tf_session()\n",
    "        \n",
    "    def SysODE(self, S, t):\n",
    "        F1 = -self.k1*S[:,3:4]*S[:,0:1] + self.kd1*S[:,4:5]\n",
    "        F2 = self.kd2*S[:,4:5] - self.k3*S[:,1:2]*S[:,2:3] + self.kd3*S[:,5:6] + self.kd4*S[:,5:6]\n",
    "        F3 = -self.k3*S[:,1:2]*S[:,2:3] + self.kd3*S[:,5:6]\n",
    "        F4 = self.kd4*S[:,5:6] - self.k1*S[:,3:4]*S[:,0:1] + self.kd1*S[:,4:5] - \\\n",
    "             self.k5*S[:,6:7]*S[:,3:4] + self.kd5*S[:,7:8] + self.kd2*S[:,4:5]\n",
    "        F5 = -self.kd2*S[:,4:5] + self.k1*S[:,3:4]*S[:,0:1] - self.kd1*S[:,4:5]\n",
    "        F6 = -self.kd4*S[:,5:6] + self.k3*S[:,1:2]*S[:,2:3] - self.kd3*S[:,5:6]\n",
    "        F7 = -self.k5*S[:,6:7]*S[:,3:4] + self.kd5*S[:,7:8] + self.kd6*S[:,7:8]\n",
    "        F8 = self.k5*S[:,6:7]*S[:,3:4] - self.kd5*S[:,7:8] - self.kd6*S[:,7:8]\n",
    "\n",
    "        F = tf.concat([F1, F2, F3, F4, F5, F6, F7, F8], 1)\n",
    "\n",
    "        S_t = fwd_gradients(S, t)\n",
    "        \n",
    "        E = S_t - F\n",
    "        return E\n",
    "    \n",
    "    def train(self, num_epochs, batch_size, learning_rate):\n",
    "\n",
    "        N_data = self.t_data.shape[0]\n",
    "        N_eqns = self.t_eqns.shape[0]\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            for it in range(N_eqns//batch_size):\n",
    "                idx_data = np.concatenate([np.array([0]),\n",
    "                                          np.random.choice(np.arange(1, N_data-1), min(batch_size, N_data)-2),\n",
    "                                          np.array([N_data-1])])\n",
    "                idx_eqns = np.random.choice(N_eqns, batch_size)\n",
    "\n",
    "                t_data_batch, S_data_batch = self.t_data[idx_data,:], self.S_data[idx_data,:]\n",
    "                t_eqns_batch = self.t_eqns[idx_eqns,:]\n",
    "    \n",
    "                tf_dict = {self.t_data_tf: t_data_batch,\n",
    "                           self.S_data_tf: S_data_batch,\n",
    "                           self.t_eqns_tf: t_eqns_batch,\n",
    "                           self.learning_rate: learning_rate}\n",
    "                \n",
    "                self.sess.run([self.train_op, self.trainpara_op], tf_dict)\n",
    "                \n",
    "                # Print\n",
    "                if it % 10 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    [loss_data_value,\n",
    "                     loss_eqns_value,\n",
    "                     loss_auxl_value,\n",
    "                     learning_rate_value] = self.sess.run([self.loss_data,\n",
    "                                                           self.loss_eqns,\n",
    "                                                           self.loss_auxl,\n",
    "                                                           self.learning_rate], tf_dict)\n",
    "                    print('Epoch: %d, It: %d, Loss Data: %.3e, Loss Eqns: %.3e, Loss Aux: %.3e, Time: %.3f, Learning Rate: %.1e'\n",
    "                          %(epoch, it, loss_data_value, loss_eqns_value, loss_auxl_value, elapsed, learning_rate_value))\n",
    "                    start_time = time.time()\n",
    "\n",
    "    def predict(self, t_star):\n",
    "        \n",
    "        tf_dict = {self.t_data_tf: t_star}\n",
    "        \n",
    "        S_star = self.sess.run(self.S_data_pred, tf_dict)\n",
    "        return S_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3b4be0645c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m                            layers)\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_eqns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_eqns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_eqns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-381b88212a94>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_eqns\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 idx_data = np.concatenate([np.array([0]),\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'time'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    start_time = time.time()\n",
    "    layers = [1] + 5*[8*30] + [8]\n",
    "    \n",
    "    t_scale = 3600\n",
    "    c_scale = 1e5\n",
    "    # function that returns dx/dt\n",
    "    def f(x,t): # x is 8 x 1\n",
    "        k1 = 2.67e-9*c_scale*t_scale\n",
    "        kd1 = 1e-2*t_scale\n",
    "        kd2 = 8e-3*t_scale\n",
    "        k3 = 6.8e-8*c_scale*t_scale\n",
    "        kd3 = 5e-2*t_scale\n",
    "        kd4 = 1e-3*t_scale\n",
    "        k5 = 7e-5*c_scale*t_scale\n",
    "        kd5 = 1.67e-5*t_scale\n",
    "        kd6 = 1.67e-4*t_scale\n",
    "      \n",
    "        f1 = -k1*x[3]*x[0] + kd1*x[4]\n",
    "        f2 = kd2*x[4] - k3*x[1]*x[2] + kd3*x[5] + kd4*x[5]\n",
    "        f3 = -k3*x[1]*x[2] + kd3*x[5]\n",
    "        f4 = kd4*x[5] - k1*x[3]*x[0] + kd1*x[4] - k5*x[6]*x[3] + kd5*x[7] + kd2*x[4]\n",
    "        f5 = -kd2*x[4] + k1*x[3]*x[0] - kd1*x[4]\n",
    "        f6 = -kd4*x[5] + k3*x[1]*x[2] - kd3*x[5]\n",
    "        f7 = -k5*x[6]*x[3] + kd5*x[7] + kd6*x[7]\n",
    "        f8 = k5*x[6]*x[3] - kd5*x[7] - kd6*x[7]\n",
    "        \n",
    "        f = np.array([f1,f2,f3,f4,f5,f6,f7,f8])\n",
    "        return f\n",
    "        \n",
    "    def addNoise(S, noise):\n",
    "        std = noise*S.std(0)\n",
    "        S[1:,:] += np.random.normal(0.0, std, (S.shape[0]-1, S.shape[1]))\n",
    "        return S\n",
    "    \n",
    "    # time points\n",
    "    t_star = np.concatenate((np.arange(0,60,0.1), np.arange(60,60,0.5)))\n",
    "    N = t_star.shape[0]\n",
    "    N_eqns = N\n",
    "    N_data = N // 5\n",
    "    \n",
    "    S1 = 1.34e5/c_scale\n",
    "    S2 = 1e5/c_scale\n",
    "    S3 = 2.67e5/c_scale\n",
    "    S4 = 0.0\n",
    "    S5 = 0.0\n",
    "    S6 = 0.0\n",
    "    S7 = 2.9e3/c_scale\n",
    "    S8 = 0.0\n",
    "    \n",
    "    # initial condition\n",
    "    x0 = np.array([S1,S2,S3,S4,S5,S6,S7,S8]).flatten()\n",
    "    \n",
    "    # solve ODE\n",
    "    S_star = odeint(f, x0, t_star)\n",
    "\n",
    "    noise = 0.0\n",
    "    t_train = t_star[:,None]\n",
    "    S_train = addNoise(S_star, noise)\n",
    "\n",
    "    N0 = 0\n",
    "    N1 = N // 2\n",
    "    idx_data = np.concatenate([np.array([N0]),\n",
    "                               np.random.choice(np.arange(1, N-1), size=N_data, replace=False),\n",
    "                               np.array([N-1]),\n",
    "                               np.array([N1])])\n",
    "    idx_eqns = np.concatenate([np.array([N0]),\n",
    "                               np.random.choice(np.arange(1, N-1), size=N_eqns-2, replace=False),\n",
    "                               np.array([N-1])])\n",
    "\n",
    "    model = HiddenPathways(t_train[idx_data],\n",
    "                           S_train[idx_data,:],\n",
    "                           t_train[idx_eqns],\n",
    "                           layers)\n",
    "\n",
    "    model.train(num_epochs=15000, batch_size=N_eqns, learning_rate=1e-3)\n",
    "    model.train(num_epochs=15000, batch_size=N_eqns, learning_rate=1e-4)\n",
    "    model.train(num_epochs=10000, batch_size=N_eqns, learning_rate=1e-5)\n",
    "\n",
    "    S_pred = model.predict(t_star[:,None])\n",
    "    \n",
    "    ####### Plotting ##################\n",
    "\n",
    "    fig, ax = newfig(2.0, 0.7)\n",
    "    gs0 = gridspec.GridSpec(1, 1)\n",
    "    gs0.update(top=0.95, bottom=0.15, left=0.1, right=0.95, hspace=0.5, wspace=0.3)\n",
    "\n",
    "    ax = plt.subplot(gs0[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,3],'C1',linewidth=2,label='input data')\n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,3],marker='o',s=50,label='sampled input')\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_4 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "    ax.legend(fontsize='large')\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    fig, ax = newfig(3.5, 0.4)\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(top=0.85, bottom=0.15, left=0.1, right=0.95, hspace=0.3, wspace=0.3)    \n",
    "    ax = plt.subplot(gs1[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,0],'C1',linewidth=2,label='exact')\n",
    "    ax.plot(t_star,S_pred[:,0],'g-.',linewidth=3,label='learned')\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_1 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "    ax.legend(fontsize='large')\n",
    "    \n",
    "    ax = plt.subplot(gs1[0:1, 1:2])\n",
    "    ax.plot(t_star,S_star[:,1],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,1],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_2 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "\n",
    "    ax = plt.subplot(gs1[0:1, 2:3])\n",
    "    ax.plot(t_star,S_star[:,2],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,2],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_3 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "\n",
    "    fig, ax = newfig(3.5, 0.4)\n",
    "    gs2 = gridspec.GridSpec(1, 3)\n",
    "    gs2.update(top=0.85, bottom=0.15, left=0.1, right=0.95, hspace=0.3, wspace=0.3)    \n",
    "    ax = plt.subplot(gs2[0:1, 0:1])    \n",
    "    ax.scatter(t_star[idx_data],S_star[idx_data,3],marker='o',c='C1',s=30)\n",
    "    ax.plot(t_star,S_pred[:,3],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_4 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "    \n",
    "    ax = plt.subplot(gs2[0:1, 1:2])\n",
    "    ax.plot(t_star,S_star[:,4],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,4],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_5 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "    \n",
    "    ax = plt.subplot(gs2[0:1, 2:3])\n",
    "    ax.plot(t_star,S_star[:,5],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,5],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_6 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "\n",
    "    fig, ax = newfig(1.8, 0.75)\n",
    "    gs3 = gridspec.GridSpec(1, 2)\n",
    "    gs3.update(top=0.85, bottom=0.15, left=0.1, right=0.95, hspace=0.3, wspace=0.3)\n",
    "    ax = plt.subplot(gs3[0:1, 0:1])\n",
    "    ax.plot(t_star,S_star[:,6],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,6],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_7 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "    \n",
    "    ax = plt.subplot(gs3[0:1, 1:2])\n",
    "    ax.plot(t_star,S_star[:,7],'C1',linewidth=2)\n",
    "    ax.plot(t_star,S_pred[:,7],'g-.',linewidth=3)\n",
    "    ax.set_xlabel('$t\\ (hours)$', fontsize=18)\n",
    "    ax.set_ylabel('$x_8 \\ \\mathrm{x} \\ 10^5 \\ (molecules/cell)$', fontsize=18)\n",
    "\n",
    "    print('k1 = %.4e' % ( model.sess.run(model.k1)/t_scale/c_scale ) )\n",
    "    print('kd1 = %.4e' % ( model.sess.run(model.kd1)/t_scale ) )\n",
    "    print('kd2 = %.4e' % ( model.sess.run(model.kd2)/t_scale ) )\n",
    "    print('k3 = %.4e' % ( model.sess.run(model.k3)/t_scale/c_scale ) )\n",
    "    print('kd3 = %.4e' % ( model.sess.run(model.kd3)/t_scale ) )\n",
    "    print('kd4 = %.4e' % ( model.sess.run(model.kd4)/t_scale ) )\n",
    "    print('k5 = %.4e' % ( model.sess.run(model.k5)/t_scale/c_scale ) )\n",
    "    print('kd5 = %.4e' % ( model.sess.run(model.kd5)/t_scale ) )\n",
    "    print('kd6 = %.4e' % ( model.sess.run(model.kd6)/t_scale ) )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Tiempo de ejecucion: %i minutos.\" % (elapsed_time/60))\n",
    "    # savefig('./figures/Glycolytic', crop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
